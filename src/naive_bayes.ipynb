{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef bag_of_words_multi_stats(tweets, scores):\\n    dataFrame = pd.DataFrame({\\'tweet\\': tweets, \\'score\\': scores})\\n\\n    vectorizer = CountVectorizer()\\n    X = vectorizer.fit_transform(dataFrame.tweet).toarray()\\n    y = dataFrame.score\\n\\n    # print(vectorizer.get_feature_names())\\n    # print(X.shape, y.shape)\\n\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)\\n\\n    # print(X_train.shape, y_train.shape)\\n    # print(X_test.shape, y_test.shape)\\n\\n    classifier = MultinomialNB()\\n    classifier.fit(X_train, y_train)\\n\\n    y_pred = classifier.predict(X_test)\\n    # print(y_pred)\\n\\n    print(confusion_matrix(y_test, y_pred))\\n    print(\\'Accuracy: \\', accuracy_score(y_test, y_pred))\\n    print(\\'Precision: \\', precision_score(y_test, y_pred, average=\\'weighted\\'))\\n    print(\\'Recall: \\', recall_score(y_test, y_pred, average=\\'weighted\\'))\\n    print(\\'F1: \\', f1_score(y_test, y_pred, average=\\'weighted\\'))\\n\\n\\ndef bag_of_words_multi_input(tweets, scores):\\n    df = pd.DataFrame({\\'tweet\\': tweets,\\n                       \\'score\\': scores})\\n\\n    vectorizer = CountVectorizer(max_features=1000)\\n    X = vectorizer.fit_transform(df.tweet).toarray()\\n    y = df.score\\n\\n    #print(vectorizer.get_feature_names())\\n    #print(X.shape, y.shape)\\n\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\\n\\n    #print(X_train.shape, y_train.shape)\\n    #print(X_test.shape, y_test.shape)\\n\\n    classifier = MultinomialNB()\\n    classifier.fit(X_train, y_train)\\n\\n    y_pred = classifier.predict(X_test)\\n    #print(y_pred)\\n\\n    ps = PorterStemmer()\\n    tweet = input(\"Tweet: \")\\n    tweet = re.sub(\\'[^a-zA-Z]\\', \\' \\', tweet).split()\\n    tweet = \\' \\'.join([ps.stem(w) for w in tweet])\\n    X = vectorizer.transform([tweet]).toarray()\\n\\n    result = classifier.predict(X)\\n\\n    print(\"From 0 to 1, 0 being \\'non-ironic\\' and 1 \\'ironic\\', you tweet scored \", result)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "sns.set() # use seaborn plotting style\n",
    "\n",
    "def proccess(trainData, trainScores, testData, testScores, task, trainDataProcessTime):\n",
    "    start = time.time()\n",
    "    model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "    model.fit(trainData, trainScores)\n",
    "    predictions = model.predict(testData)\n",
    "    end = time.time()\n",
    "    \n",
    "    if(task == \"A\"):\n",
    "        labels=[\"0\", \"1\"]\n",
    "        print(\"------------ TASK A -------------\")\n",
    "        print(\"---------- NAIVE BAYES ----------\")\n",
    "        print(\"Ironic = 0 | Non-ironic = 1\")\n",
    "    else:\n",
    "        labels=[\"0\", \"1\", \"2\", \"3\"]\n",
    "        print(\"------------ TASK B -------------\")\n",
    "        print(\"---------- NAIVE BAYES ----------\")\n",
    "        print(\"\\n\")\n",
    "        print(\"Ironic with polarity contrast = 0 | Ironic without polarity contrast = 1 | Situationaly ironic = 2 | Non-ironic = 3\")\n",
    "    \n",
    "    mat = confusion_matrix(testScores, predictions)\n",
    "    sns.heatmap(mat.T, square = True, annot=True, fmt = \"d\", xticklabels=labels,yticklabels=labels)\n",
    "    plt.xlabel(\"Actual irony\")\n",
    "    plt.ylabel(\"Predicted irony\")\n",
    "    plt.show()\n",
    "    print(\"The accuracy is {value:.5f}%\".format(value = accuracy_score(testScores, predictions)))\n",
    "    print(\"The precision is {value:.5f}%\".format(value = precision_score(testScores, predictions, average='weighted')))\n",
    "    print(\"The recall is {value:.5f}%\".format(value = recall_score(testScores, predictions, average='weighted')))\n",
    "    print(\"The f1 is {value:.5f}%\".format(value = f1_score(testScores, predictions, average='weighted')))\n",
    "    testDataProcessTime = end - start\n",
    "    print(\"\\n\")\n",
    "    print(\"Time taken to train model: {value:.5f} seconds\".format(value = trainDataProcessTime))\n",
    "    print(\"Time taken to test model: {value:.5f} seconds\".format(value = testDataProcessTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
