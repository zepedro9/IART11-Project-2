{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\ZÃ©\n",
      "[nltk_data]     Pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import time\n",
    "import emoji\n",
    "import tweet_cleaning as tc\n",
    "import naive_bayes as nb\n",
    "import decisionTree as dt\n",
    "import neuralNetwork as nn\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def listToString(s): \n",
    "    str1 = \"\" \n",
    "    for ele in s: \n",
    "        str1 += (\" \" + ele)\n",
    "    return str1 \n",
    "\n",
    "def readData(filename):\n",
    "    tweets = []\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            tweets.append([line.split(\"\t\")[0], line.split(\"\t\")[1], line.split(\"\t\")[2]])\n",
    "    return tweets\n",
    "\n",
    "def getInfoFromTweets(data):\n",
    "    ids = []\n",
    "    scores = []\n",
    "    tweets = []\n",
    "    for line in data:\n",
    "        ids.append(line[0])\n",
    "        scores.append(line[1])\n",
    "        tweets.append(line[2])\n",
    "    return ids, scores, tweets\n",
    "\n",
    "def stripEmojisFromTweets(tweets):\n",
    "    emojis = []\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        emojis.append(getEmojisFromTweet(tweet))\n",
    "        new_tweets.append(re.sub(\"(:)\\w*(:)\", \"\", tweet))\n",
    "    return emojis, new_tweets\n",
    "\n",
    "def getEmojisFromTweet(tweet):\n",
    "    emoji = []\n",
    "    for i in tweet.split():\n",
    "        if i.startswith(\":\"):\n",
    "            emoji.extend(list(filter(None, i.split(\":\"))))\n",
    "    emoji = list(set(emoji))\n",
    "    emoji = [i for i in emoji if i[0].isalpha()]\n",
    "    return emoji\n",
    "\n",
    "def stripHashtagsFromTweets(tweets):\n",
    "    hashtags = []\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        hashtagsOfTweet = re.findall(\"#\\w+\", tweet)\n",
    "        hashtags.append(hashtagsOfTweet)\n",
    "        new_tweets.append(\" \".join(filter(lambda x: x[0] != '#', tweet.split())))\n",
    "    return hashtags, new_tweets\n",
    "\n",
    "def cleanTweets(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        new_tweets.append(tc.clean_tweet(tweet))\n",
    "    return new_tweets\n",
    "\n",
    "def chooseTask():\n",
    "    option = input(\"Specify which task to evaluate (possible tasks are \\\"A\\\" or \\\"B\\\"), or \\\"EXIT\\\" to terminate: \")\n",
    "    if option.upper() == \"A\":\n",
    "        testFileName = \"../Test Data/test_taskA.txt\"\n",
    "        trainFileName = \"../Train Data/train_taskA.txt\"\n",
    "        chooseAlgorithm(testFileName, trainFileName, \"A\")\n",
    "    elif option.upper() == \"B\":\n",
    "        testFileName = \"../Test Data/test_taskB.txt\"\n",
    "        trainFileName = \"../Train Data/train_taskB.txt\"\n",
    "        chooseAlgorithm(testFileName, trainFileName, \"B\")\n",
    "    elif option.upper() == \"EXIT\":\n",
    "        print('Terminating..')\n",
    "        sys.exit()\n",
    "    else:\n",
    "        print('Wrong input, try again!')\n",
    "        chooseTask()\n",
    "        \n",
    "def chooseAlgorithm(testFileName, trainFileName, task):\n",
    "    option = input(\"Specify which algorithm to use (possible algorithms are \\\"nb\\\" (Naive Bayes), \\\"dt\\\" (Decision Trees) or \\\"nn\\\" (Neural Networks)), or \\\"EXIT\\\" to terminate: \")\n",
    "    print(\"\\nLoading...\\n\")\n",
    "    trainData, trainScores, testData, testScores = getData(testFileName, trainFileName)\n",
    "    if option.upper() == \"NB\":\n",
    "        nb.proccess(trainData, trainScores, testData, testScores, task)\n",
    "    elif option.upper() == \"DT\":\n",
    "        dt.proccess(trainData, trainScores, testData, testScores, task)\n",
    "    elif option.upper() == \"NN\":\n",
    "        nn.proccess(trainData, trainScores, testData, testScores, task)\n",
    "    elif option.upper() == \"EXIT\":\n",
    "        print('Terminating..')\n",
    "        sys.exit()\n",
    "    else:\n",
    "        print('Wrong input, try again!')\n",
    "        chooseAlgorithm(testFileName, trainFileName, task)\n",
    "\n",
    "def getData(testFileName, trainFileName):\n",
    "    trainRawData = readData(trainFileName)\n",
    "\n",
    "    trainIds, trainScores, trainTweets = getInfoFromTweets(trainRawData)\n",
    "\n",
    "    trainEmojis, trainTweets = stripEmojisFromTweets(trainTweets)\n",
    "\n",
    "    trainHashtags, trainTweets  = stripHashtagsFromTweets(trainTweets)\n",
    "\n",
    "    trainTweets = cleanTweets(trainTweets)\n",
    "\n",
    "    trainData = []\n",
    "\n",
    "    testRawData = readData(testFileName)\n",
    "\n",
    "    testIds, testScores, testTweets = getInfoFromTweets(testRawData)\n",
    "\n",
    "    for tweet in testTweets:\n",
    "        emoji.demojize(tweet, delimiters=(\":\", \":\"))\n",
    "\n",
    "    testEmojis, testTweets = stripEmojisFromTweets(testTweets)\n",
    "\n",
    "    testHashtags, testTweets  = stripHashtagsFromTweets(testTweets)\n",
    "\n",
    "    testTweets = cleanTweets(testTweets)\n",
    "\n",
    "    testData = []\n",
    "\n",
    "    count = 0\n",
    "    for tweet in trainTweets:\n",
    "        trainData.append(trainTweets[count] + listToString(trainEmojis[count]) + listToString(trainHashtags[count]))\n",
    "        count += 1\n",
    "\n",
    "    count = 0\n",
    "    for tweet in testTweets:\n",
    "        testData.append(testTweets[count] + listToString(testEmojis[count]) + listToString(testHashtags[count]))\n",
    "        count += 1\n",
    "        \n",
    "    return trainData, trainScores, testData, testScores\n",
    "\n",
    "def runAll():\n",
    "    trainData, trainScores, testData, testScores = getData(\"../Test Data/test_taskA.txt\", \"../Train Data/train_taskA.txt\")\n",
    "    nb.proccess(trainData, trainScores, testData, testScores, \"A\")\n",
    "    dt.proccess(trainData, trainScores, testData, testScores, \"A\")\n",
    "    nn.proccess(trainData, trainScores, testData, testScores, \"A\")\n",
    "    trainData, trainScores, testData, testScores = getData(\"../Test Data/test_taskB.txt\", \"../Train Data/train_taskB.txt\")\n",
    "    nb.proccess(trainData, trainScores, testData, testScores, \"B\")\n",
    "    dt.proccess(trainData, trainScores, testData, testScores, \"B\")\n",
    "    nn.proccess(trainData, trainScores, testData, testScores, \"B\")\n",
    "\n",
    "chooseTask() #USE THIS FUNCTION FOR REGULAR USER-FRIENDLY USE\n",
    "\n",
    "#runAll() #USE THIS FUNCTION FOR FULL-USAGE OF THE PROGRAM WITH ALL SELECTION POSSIBILITIES OF EVALUATION COMBINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
