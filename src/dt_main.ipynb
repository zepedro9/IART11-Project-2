{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- TASK A -------\n",
      "\n",
      "Number of tweets:  3834\n",
      "\n",
      "\n",
      "Tweet  1 :\n",
      "\n",
      "\tTweet's text':  sweet unit nation video just time christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#imagine', '#NoReligion'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sweet', 'unit', 'nation', 'video', 'just', 'time', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sweet unit nation video just time christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2 :\n",
      "\n",
      "\tTweet's text':  we rumor talk erv hardli noth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'rumor', 'talk', 'erv', 'hardli', 'noth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we rumor talk erv hardli noth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3 :\n",
      "\n",
      "\tTweet's text':  hey nice see minnesota nd winter weather \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'nice', 'see', 'minnesota', 'nd', 'winter', 'weather'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey nice see minnesota nd winter weather'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  4 :\n",
      "\n",
      "\tTweet's text':  episod left i die \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['episod', 'left', 'i', 'die'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['episod left i die'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  5 :\n",
      "\n",
      "\tTweet's text':  i breath chosen notabl quot year annual list releas yale univers librarian \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'breath', 'chosen', 'notabl', 'quot', 'year', 'annual', 'list', 'releas', 'yale', 'univers', 'librarian'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i breath chosen notabl quot year annual list releas yale univers librarian'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  6 :\n",
      "\n",
      "\tTweet's text':  you never old footi pajama \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'never', 'old', 'footi', 'pajama'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you never old footi pajama'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  7 :\n",
      "\n",
      "\tTweet's text':  noth make happier get highway see break light light like christma tree \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['noth', 'make', 'happier', 'get', 'highway', 'see', 'break', 'light', 'light', 'like', 'christma', 'tree'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noth make happier get highway see break light light like christma tree'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  8 :\n",
      "\n",
      "\tTweet's text':  open first beer gonna long night day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['open', 'first', 'beer', 'gon', 'na', 'long', 'night', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['open first beer gonna long night day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  9 :\n",
      "\n",
      "\tTweet's text':  think would support guy knock daughter rice deserv support \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['think', 'would', 'support', 'guy', 'knock', 'daughter', 'rice', 'deserv', 'support'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['think would support guy knock daughter rice deserv support'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  10 :\n",
      "\n",
      "\tTweet's text':  you allow open christma day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'allow', 'open', 'christma', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you allow open christma day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  11 :\n",
      "\n",
      "\tTweet's text':  oh thank god entir offic email system know just get xma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'thank', 'god', 'entir', 'offic', 'email', 'system', 'know', 'just', 'get', 'xma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh thank god entir offic email system know just get xma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  12 :\n",
      "\n",
      "\tTweet's text':  but instead i scroll facebook instagram twitter hour end accomplish noth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'instead', 'i', 'scroll', 'facebook', 'instagram', 'twitter', 'hour', 'end', 'accomplish', 'noth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but instead i scroll facebook instagram twitter hour end accomplish noth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  13 :\n",
      "\n",
      "\tTweet's text':  bloodi i upstair get chang \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pouting_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bloodi', 'i', 'upstair', 'get', 'chang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bloodi i upstair get chang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  14 :\n",
      "\n",
      "\tTweet's text':  cold warmth suffus one cheek pink colour tone do understand underli differ textur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cold', 'warmth', 'suffus', 'one', 'cheek', 'pink', 'colour', 'tone', 'do', 'understand', 'underli', 'differ', 'textur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cold warmth suffus one cheek pink colour tone do understand underli differ textur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  15 :\n",
      "\n",
      "\tTweet's text':  just great mobil bill arriv text \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'great', 'mobil', 'bill', 'arriv', 'text'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just great mobil bill arriv text'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  16 :\n",
      "\n",
      "\tTweet's text':  crush great realiz never interest p \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['p'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['crush', 'great', 'realiz', 'never', 'interest', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['crush great realiz never interest p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  17 :\n",
      "\n",
      "\tTweet's text':  buffalo sport media smarter us where els get qualiti insight offer harrington busgaglia \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['buffalo', 'sport', 'media', 'smarter', 'us', 'where', 'els', 'get', 'qualiti', 'insight', 'offer', 'harrington', 'busgaglia'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['buffalo sport media smarter us where els get qualiti insight offer harrington busgaglia'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  18 :\n",
      "\n",
      "\tTweet's text':  i guess cat also lost pound went vet i feed time day eat food workingout \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Eating', '#food', '#WorkingOut'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'cat', 'also', 'lost', 'pound', 'went', 'vet', 'i', 'feed', 'time', 'day', 'eat', 'food', 'workingout'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guess cat also lost pound went vet i feed time day eat food workingout'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  19 :\n",
      "\n",
      "\tTweet's text':  trade sp defens ss brilliant trade \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['trade', 'sp', 'defens', 'ss', 'brilliant', 'trade'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['trade sp defens ss brilliant trade'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  20 :\n",
      "\n",
      "\tTweet's text':  but tri find us batteri die guess found us ye bastard wand \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'tri', 'find', 'us', 'batteri', 'die', 'guess', 'found', 'us', 'ye', 'bastard', 'wand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but tri find us batteri die guess found us ye bastard wand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  21 :\n",
      "\n",
      "\tTweet's text':  pleas \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pleas'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pleas'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  22 :\n",
      "\n",
      "\tTweet's text':  i never care beyonc bc i could never get sens her interview lack depth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'never', 'care', 'beyonc', 'bc', 'i', 'could', 'never', 'get', 'sens', 'her', 'interview', 'lack', 'depth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i never care beyonc bc i could never get sens her interview lack depth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  23 :\n",
      "\n",
      "\tTweet's text':  time hit book \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'hit', 'book'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time hit book'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  24 :\n",
      "\n",
      "\tTweet's text':  thx flw flwthemus we r \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ElektrikBLOOM', '#ElektrikFANTASY', '#iwant2DRIFT', '#Elev8TheUnderground'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thx', 'flw', 'flwthemus', 'we', 'r'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thx flw flwthemus we r'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  25 :\n",
      "\n",
      "\tTweet's text':  love cold winter morn best feel everrrrrrr \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['grimacing_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'cold', 'winter', 'morn', 'best', 'feel', 'everrrrrrr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love cold winter morn best feel everrrrrrr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  26 :\n",
      "\n",
      "\tTweet's text':  amazingli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BHP', '#BHPBilliton', '#South32'] \n",
      "\n",
      "\tTweet tokenized by words:  ['amazingli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['amazingli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  27 :\n",
      "\n",
      "\tTweet's text':  wish could told \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['heavy_black_heart'] \n",
      "\n",
      "\tTweet's hashtags':  ['#nicolescherzinger', '#OneLove', '#myfav', '#MyQueen'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wish', 'could', 'told'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wish could told'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  28 :\n",
      "\n",
      "\tTweet's text':  the rain made extra extra lazi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'rain', 'made', 'extra', 'extra', 'lazi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the rain made extra extra lazi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  29 :\n",
      "\n",
      "\tTweet's text':  i great summari year i got june th weekend birthday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#rivertrip', '#groupchat'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'great', 'summari', 'year', 'i', 'got', 'june', 'th', 'weekend', 'birthday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i great summari year i got june th weekend birthday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  30 :\n",
      "\n",
      "\tTweet's text':  see might show background check deni catch right self protect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['see', 'might', 'show', 'background', 'check', 'deni', 'catch', 'right', 'self', 'protect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['see might show background check deni catch right self protect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  31 :\n",
      "\n",
      "\tTweet's text':  smh never knew someth could learn someth new guess \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['smh', 'never', 'knew', 'someth', 'could', 'learn', 'someth', 'new', 'guess'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['smh never knew someth could learn someth new guess'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  32 :\n",
      "\n",
      "\tTweet's text':  a wonder day start work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'wonder', 'day', 'start', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a wonder day start work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  33 :\n",
      "\n",
      "\tTweet's text':  feel like whole life wait wait wait \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'like', 'whole', 'life', 'wait', 'wait', 'wait'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel like whole life wait wait wait'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  34 :\n",
      "\n",
      "\tTweet's text':  lol will let kid know get morn thank tip \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'will', 'let', 'kid', 'know', 'get', 'morn', 'thank', 'tip'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol will let kid know get morn thank tip'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  35 :\n",
      "\n",
      "\tTweet's text':  guy sure screw royal i happi lester brain trust suck \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nicejob', '#LesterToChicago'] \n",
      "\n",
      "\tTweet tokenized by words:  ['guy', 'sure', 'screw', 'royal', 'i', 'happi', 'lester', 'brain', 'trust', 'suck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['guy sure screw royal i happi lester brain trust suck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  36 :\n",
      "\n",
      "\tTweet's text':  terrorist pm sydney the gunman took hostag s \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Aussie', '#gunman', '#was', '#on', '#watch', '#list', '#says'] \n",
      "\n",
      "\tTweet tokenized by words:  ['terrorist', 'pm', 'sydney', 'the', 'gunman', 'took', 'hostag', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['terrorist pm sydney the gunman took hostag s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  37 :\n",
      "\n",
      "\tTweet's text':  twig sprig sec limit new social video platform \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#techtalk', '#editorspick', '#sillyvine', '#Tr'] \n",
      "\n",
      "\tTweet tokenized by words:  ['twig', 'sprig', 'sec', 'limit', 'new', 'social', 'video', 'platform'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['twig sprig sec limit new social video platform'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  38 :\n",
      "\n",
      "\tTweet's text':  achiev serious to \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['achiev', 'serious', 'to'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['achiev serious to'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  39 :\n",
      "\n",
      "\tTweet's text':  yay anoth work day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['neutral_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'anoth', 'work', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay anoth work day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  40 :\n",
      "\n",
      "\tTweet's text':  physic therapi i want friday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#iwanttosleep'] \n",
      "\n",
      "\tTweet tokenized by words:  ['physic', 'therapi', 'i', 'want', 'friday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['physic therapi i want friday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  41 :\n",
      "\n",
      "\tTweet's text':  omg tell town \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_screaming_in_fear'] \n",
      "\n",
      "\tTweet's hashtags':  ['#trueFriend'] \n",
      "\n",
      "\tTweet tokenized by words:  ['omg', 'tell', 'town'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['omg tell town'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  42 :\n",
      "\n",
      "\tTweet's text':  i thought what we had wa real how could you be fine coz i m not fine at all oh wait fix cap lock \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#LaughNow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'thought', 'what', 'we', 'had', 'wa', 'real', 'how', 'could', 'you', 'be', 'fine', 'coz', 'i', 'm', 'not', 'fine', 'at', 'all', 'oh', 'wait', 'fix', 'cap', 'lock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i thought what we had wa real how could you be fine coz i m not fine at all oh wait fix cap lock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  43 :\n",
      "\n",
      "\tTweet's text':  hahahaha mt kati hopkin call russel brand \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hypocrisy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hahahaha', 'mt', 'kati', 'hopkin', 'call', 'russel', 'brand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hahahaha mt kati hopkin call russel brand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  44 :\n",
      "\n",
      "\tTweet's text':  that moment much stuff open \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#productivity', '#tumblr'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'moment', 'much', 'stuff', 'open'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that moment much stuff open'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  45 :\n",
      "\n",
      "\tTweet's text':  lol i enjoy sleepi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['white_smiling_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Talks', '#Crazyness', '#SheNeverLeft'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'i', 'enjoy', 'sleepi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol i enjoy sleepi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  46 :\n",
      "\n",
      "\tTweet's text':  luv \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['luv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['luv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  47 :\n",
      "\n",
      "\tTweet's text':  when naturopath sell aromat herb way apothecari sell noxiou poison \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Naturopath', '#Apothecary', '#Herb', '#Poison'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'naturopath', 'sell', 'aromat', 'herb', 'way', 'apothecari', 'sell', 'noxiou', 'poison'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when naturopath sell aromat herb way apothecari sell noxiou poison'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  48 :\n",
      "\n",
      "\tTweet's text':  dixiessixti goal season goal jon sammel vs \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ARSENAL', '#manutd'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dixiessixti', 'goal', 'season', 'goal', 'jon', 'sammel', 'vs'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dixiessixti goal season goal jon sammel vs'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  49 :\n",
      "\n",
      "\tTweet's text':  realli els fish besid fish \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'els', 'fish', 'besid', 'fish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli els fish besid fish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  50 :\n",
      "\n",
      "\tTweet's text':  i think safe bet fit crime \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'safe', 'bet', 'fit', 'crime'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think safe bet fit crime'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  51 :\n",
      "\n",
      "\tTweet's text':  it imposs late i start dress right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#studing', '#university', '#lazy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'imposs', 'late', 'i', 'start', 'dress', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it imposs late i start dress right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  52 :\n",
      "\n",
      "\tTweet's text':  when alreadi run late car start \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FantasticFriday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'alreadi', 'run', 'late', 'car', 'start'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when alreadi run late car start'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  53 :\n",
      "\n",
      "\tTweet's text':  decid becom boss free time time left whatsoev \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['decid', 'becom', 'boss', 'free', 'time', 'time', 'left', 'whatsoev'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['decid becom boss free time time left whatsoev'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  54 :\n",
      "\n",
      "\tTweet's text':  loyalti vs self protect loyalti vs self protect loyalti vs self protect loyalti vs self protect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['loyalti', 'vs', 'self', 'protect', 'loyalti', 'vs', 'self', 'protect', 'loyalti', 'vs', 'self', 'protect', 'loyalti', 'vs', 'self', 'protect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['loyalti vs self protect loyalti vs self protect loyalti vs self protect loyalti vs self protect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  55 :\n",
      "\n",
      "\tTweet's text':  american kid start play i super miss \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#summer2k14', '#kennychesney'] \n",
      "\n",
      "\tTweet tokenized by words:  ['american', 'kid', 'start', 'play', 'i', 'super', 'miss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['american kid start play i super miss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  56 :\n",
      "\n",
      "\tTweet's text':  know monsanto among sustain co world sure paramet measur net posit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Monsanto', '#net'] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'monsanto', 'among', 'sustain', 'co', 'world', 'sure', 'paramet', 'measur', 'net', 'posit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know monsanto among sustain co world sure paramet measur net posit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  57 :\n",
      "\n",
      "\tTweet's text':  none big disrupt innov live come brainstorm bruce nussbaum \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['none', 'big', 'disrupt', 'innov', 'live', 'come', 'brainstorm', 'bruce', 'nussbaum'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['none big disrupt innov live come brainstorm bruce nussbaum'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  58 :\n",
      "\n",
      "\tTweet's text':  way peopl get understand disabl stare us funni wen idpwd disabl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#IDPwD', '#disability'] \n",
      "\n",
      "\tTweet tokenized by words:  ['way', 'peopl', 'get', 'understand', 'disabl', 'stare', 'us', 'funni', 'wen', 'idpwd', 'disabl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['way peopl get understand disabl stare us funni wen idpwd disabl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  59 :\n",
      "\n",
      "\tTweet's text':  shit i better shut stupid girli mouth im concern men might think \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shit', 'i', 'better', 'shut', 'stupid', 'girli', 'mouth', 'im', 'concern', 'men', 'might', 'think'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shit i better shut stupid girli mouth im concern men might think'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  60 :\n",
      "\n",
      "\tTweet's text':  whi tongu feel necessari tri touch high speed tool dentist put mouth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'tongu', 'feel', 'necessari', 'tri', 'touch', 'high', 'speed', 'tool', 'dentist', 'put', 'mouth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi tongu feel necessari tri touch high speed tool dentist put mouth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  61 :\n",
      "\n",
      "\tTweet's text':  tell govt paid job hyde buy oversea onlin pay gst mmm \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Quintessential', '#Aussie', '#SadButTrue'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tell', 'govt', 'paid', 'job', 'hyde', 'buy', 'oversea', 'onlin', 'pay', 'gst', 'mmm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tell govt paid job hyde buy oversea onlin pay gst mmm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  62 :\n",
      "\n",
      "\tTweet's text':  dirk got lot move i tri steal kevin durant one leg fadeway \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dirk', 'got', 'lot', 'move', 'i', 'tri', 'steal', 'kevin', 'durant', 'one', 'leg', 'fadeway'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dirk got lot move i tri steal kevin durant one leg fadeway'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  63 :\n",
      "\n",
      "\tTweet's text':  about yr i get littl nutti reach orang marmalad \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#livingontheedge'] \n",
      "\n",
      "\tTweet tokenized by words:  ['about', 'yr', 'i', 'get', 'littl', 'nutti', 'reach', 'orang', 'marmalad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['about yr i get littl nutti reach orang marmalad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  64 :\n",
      "\n",
      "\tTweet's text':  roger smile accur captur reaction i receiv extra high phone bill \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['roger', 'smile', 'accur', 'captur', 'reaction', 'i', 'receiv', 'extra', 'high', 'phone', 'bill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['roger smile accur captur reaction i receiv extra high phone bill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  65 :\n",
      "\n",
      "\tTweet's text':  whatev happen guano ape did ever make big japan \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whatev', 'happen', 'guano', 'ape', 'did', 'ever', 'make', 'big', 'japan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whatev happen guano ape did ever make big japan'] \n",
      "\n",
      "---------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet  66 :\n",
      "\n",
      "\tTweet's text':  bmw sexi az hell slow dinero quarter mile slow design feel \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bmw', 'sexi', 'az', 'hell', 'slow', 'dinero', 'quarter', 'mile', 'slow', 'design', 'feel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bmw sexi az hell slow dinero quarter mile slow design feel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  67 :\n",
      "\n",
      "\tTweet's text':  let humil guard pride vaniti allow delic thing \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'humil', 'guard', 'pride', 'vaniti', 'allow', 'delic', 'thing'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let humil guard pride vaniti allow delic thing'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  68 :\n",
      "\n",
      "\tTweet's text':  whenev i get sad thing go i think awesom futur look \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#secondsemester', '#drumcorps', '#college'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whenev', 'i', 'get', 'sad', 'thing', 'go', 'i', 'think', 'awesom', 'futur', 'look'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whenev i get sad thing go i think awesom futur look'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  69 :\n",
      "\n",
      "\tTweet's text':  i ask god protect enemi shortli i start lose friend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['hundred_points_symbol', 'flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#naah'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'ask', 'god', 'protect', 'enemi', 'shortli', 'i', 'start', 'lose', 'friend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i ask god protect enemi shortli i start lose friend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  70 :\n",
      "\n",
      "\tTweet's text':  just deliv hmmm custom i hope \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cronuts'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'deliv', 'hmmm', 'custom', 'i', 'hope'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just deliv hmmm custom i hope'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  71 :\n",
      "\n",
      "\tTweet's text':  such you still \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#praisehim'] \n",
      "\n",
      "\tTweet tokenized by words:  ['such', 'you', 'still'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['such you still'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  72 :\n",
      "\n",
      "\tTweet's text':  hey heyi i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#vscocam', '#vsocam', '#hero', '#spiderman'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'heyi', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey heyi i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  73 :\n",
      "\n",
      "\tTweet's text':  maggielindemann awk moment i tweet first \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fakefan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['maggielindemann', 'awk', 'moment', 'i', 'tweet', 'first'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['maggielindemann awk moment i tweet first'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  74 :\n",
      "\n",
      "\tTweet's text':  waa mockingjay part tahon depan meh nov wtvr night museum \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mustwatchb4decemberendssobssobs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['waa', 'mockingjay', 'part', 'tahon', 'depan', 'meh', 'nov', 'wtvr', 'night', 'museum'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['waa mockingjay part tahon depan meh nov wtvr night museum'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  75 :\n",
      "\n",
      "\tTweet's text':  nice see ambul servic import our mp \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'see', 'ambul', 'servic', 'import', 'our', 'mp'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice see ambul servic import our mp'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  76 :\n",
      "\n",
      "\tTweet's text':  i love final week \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#justkidding', '#stressed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'final', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love final week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  77 :\n",
      "\n",
      "\tTweet's text':  fuck copycat although name mint act share probabl caus alcohol fill celebr \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fuck', 'copycat', 'although', 'name', 'mint', 'act', 'share', 'probabl', 'caus', 'alcohol', 'fill', 'celebr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fuck copycat although name mint act share probabl caus alcohol fill celebr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  78 :\n",
      "\n",
      "\tTweet's text':  liter cri i woke i know day store readi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TheStartOfTechWeek', '#JustShootMeKnow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['liter', 'cri', 'i', 'woke', 'i', 'know', 'day', 'store', 'readi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['liter cri i woke i know day store readi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  79 :\n",
      "\n",
      "\tTweet's text':  becaus i disagre w trade three pick one glare hole numer posit ass backward \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['becaus', 'i', 'disagre', 'w', 'trade', 'three', 'pick', 'one', 'glare', 'hole', 'numer', 'posit', 'ass', 'backward'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['becaus i disagre w trade three pick one glare hole numer posit ass backward'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  80 :\n",
      "\n",
      "\tTweet's text':  nypost cameron gray oh make better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nypost', 'cameron', 'gray', 'oh', 'make', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nypost cameron gray oh make better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  81 :\n",
      "\n",
      "\tTweet's text':  whi i start watch tudor earlier \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#iloveit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'i', 'start', 'watch', 'tudor', 'earlier'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi i start watch tudor earlier'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  82 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CHRISTMAS', '#GIFT'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  83 :\n",
      "\n",
      "\tTweet's text':  knw react everytim sum say wheelchair inspir im live dude \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['knw', 'react', 'everytim', 'sum', 'say', 'wheelchair', 'inspir', 'im', 'live', 'dude'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['knw react everytim sum say wheelchair inspir im live dude'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  84 :\n",
      "\n",
      "\tTweet's text':  get aht a tahn the made pgh gift guid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'aht', 'a', 'tahn', 'the', 'made', 'pgh', 'gift', 'guid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get aht a tahn the made pgh gift guid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  85 :\n",
      "\n",
      "\tTweet's text':  on lunch break sleepi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['on', 'lunch', 'break', 'sleepi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['on lunch break sleepi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  86 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Work', '#Trains', '#TheGrind', '#London', '#Business', '#MyHappyFace'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  87 :\n",
      "\n",
      "\tTweet's text':  dude said i better think hard take cheddar lmao \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dude', 'said', 'i', 'better', 'think', 'hard', 'take', 'cheddar', 'lmao'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dude said i better think hard take cheddar lmao'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  88 :\n",
      "\n",
      "\tTweet's text':  my \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Christmas', '#HowTheGrinchStoleChristmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  89 :\n",
      "\n",
      "\tTweet's text':  overcast creso \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#todayimloving', '#beachwalk', '#crescenthead'] \n",
      "\n",
      "\tTweet tokenized by words:  ['overcast', 'creso'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['overcast creso'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  90 :\n",
      "\n",
      "\tTweet's text':  end fast enough stupid dead batteri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['end', 'fast', 'enough', 'stupid', 'dead', 'batteri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['end fast enough stupid dead batteri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  91 :\n",
      "\n",
      "\tTweet's text':  not even i alreadi see go wonder day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#needmorecoffee'] \n",
      "\n",
      "\tTweet tokenized by words:  ['not', 'even', 'i', 'alreadi', 'see', 'go', 'wonder', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['not even i alreadi see go wonder day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  92 :\n",
      "\n",
      "\tTweet's text':  i idea oper ever describ race and polic wear color blind glass \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'idea', 'oper', 'ever', 'describ', 'race', 'and', 'polic', 'wear', 'color', 'blind', 'glass'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i idea oper ever describ race and polic wear color blind glass'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  93 :\n",
      "\n",
      "\tTweet's text':  russel good christian fella \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['russel', 'good', 'christian', 'fella'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['russel good christian fella'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  94 :\n",
      "\n",
      "\tTweet's text':  appar youth group think are kid default express nomal face \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#areyoukiddingme'] \n",
      "\n",
      "\tTweet tokenized by words:  ['appar', 'youth', 'group', 'think', 'are', 'kid', 'default', 'express', 'nomal', 'face'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['appar youth group think are kid default express nomal face'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  95 :\n",
      "\n",
      "\tTweet's text':  hey jay i tune u said cocain talk escobar th \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PSA'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'jay', 'i', 'tune', 'u', 'said', 'cocain', 'talk', 'escobar', 'th'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey jay i tune u said cocain talk escobar th'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  96 :\n",
      "\n",
      "\tTweet's text':  interview turkey say \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Thanksgiving'] \n",
      "\n",
      "\tTweet tokenized by words:  ['interview', 'turkey', 'say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['interview turkey say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  97 :\n",
      "\n",
      "\tTweet's text':  plan earli night last night oh yaa cours happen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#gotinterupted'] \n",
      "\n",
      "\tTweet tokenized by words:  ['plan', 'earli', 'night', 'last', 'night', 'oh', 'yaa', 'cours', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['plan earli night last night oh yaa cours happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  98 :\n",
      "\n",
      "\tTweet's text':  last retweet though \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['last', 'retweet', 'though'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['last retweet though'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  99 :\n",
      "\n",
      "\tTweet's text':  v s d match \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['v', 's', 'd', 'match'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['v s d match'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  100 :\n",
      "\n",
      "\tTweet's text':  lovee bein short sweatpant go way feet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['pile_of_poo'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lovee', 'bein', 'short', 'sweatpant', 'go', 'way', 'feet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lovee bein short sweatpant go way feet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  101 :\n",
      "\n",
      "\tTweet's text':  i love wake saturday morn go bed midnight \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wake', 'saturday', 'morn', 'go', 'bed', 'midnight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wake saturday morn go bed midnight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  102 :\n",
      "\n",
      "\tTweet's text':  a day rule i got follow wht day lollllll \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'day', 'rule', 'i', 'got', 'follow', 'wht', 'day', 'lollllll'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a day rule i got follow wht day lollllll'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  103 :\n",
      "\n",
      "\tTweet's text':  jusuf nurkic rt he clearli lot talent kind amaz denver got gari harri mcdermott \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bulls'] \n",
      "\n",
      "\tTweet tokenized by words:  ['jusuf', 'nurkic', 'rt', 'he', 'clearli', 'lot', 'talent', 'kind', 'amaz', 'denver', 'got', 'gari', 'harri', 'mcdermott'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jusuf nurkic rt he clearli lot talent kind amaz denver got gari harri mcdermott'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  104 :\n",
      "\n",
      "\tTweet's text':  i even progress thesi ta prepar event thursday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['weary_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'even', 'progress', 'thesi', 'ta', 'prepar', 'event', 'thursday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i even progress thesi ta prepar event thursday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  105 :\n",
      "\n",
      "\tTweet's text':  gym i gonna reeeaaalll nice date tomorrow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#imgoingtostruggle', '#VSFS2014'] \n",
      "\n",
      "\tTweet tokenized by words:  ['gym', 'i', 'gon', 'na', 'reeeaaalll', 'nice', 'date', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gym i gonna reeeaaalll nice date tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  106 :\n",
      "\n",
      "\tTweet's text':  soni pull movi bc scare countri even keep light night even motel better \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Zing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['soni', 'pull', 'movi', 'bc', 'scare', 'countri', 'even', 'keep', 'light', 'night', 'even', 'motel', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['soni pull movi bc scare countri even keep light night even motel better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  107 :\n",
      "\n",
      "\tTweet's text':  had nice hour nap pick chines take set watch i ad water chestnut dinner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GuardiansOfTheGalaxy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['had', 'nice', 'hour', 'nap', 'pick', 'chines', 'take', 'set', 'watch', 'i', 'ad', 'water', 'chestnut', 'dinner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['had nice hour nap pick chines take set watch i ad water chestnut dinner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  108 :\n",
      "\n",
      "\tTweet's text':  the bear probabl worst franchis footbal moment \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'bear', 'probabl', 'worst', 'franchis', 'footbal', 'moment'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the bear probabl worst franchis footbal moment'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  109 :\n",
      "\n",
      "\tTweet's text':  i piss chicago like peopl airport ruin mani peopl chanc ever meet boy way go \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['expressionless_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'piss', 'chicago', 'like', 'peopl', 'airport', 'ruin', 'mani', 'peopl', 'chanc', 'ever', 'meet', 'boy', 'way', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i piss chicago like peopl airport ruin mani peopl chanc ever meet boy way go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  110 :\n",
      "\n",
      "\tTweet's text':  hell frozen liter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Texas2015'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hell', 'frozen', 'liter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hell frozen liter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  111 :\n",
      "\n",
      "\tTweet's text':  can write name paper take pictur i i busi answer question \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'write', 'name', 'paper', 'take', 'pictur', 'i', 'i', 'busi', 'answer', 'question'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can write name paper take pictur i i busi answer question'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  112 :\n",
      "\n",
      "\tTweet's text':  it marshmallow world winter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['multiple_musical_notes'] \n",
      "\n",
      "\tTweet's hashtags':  ['#getthisoutofmyhead'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'marshmallow', 'world', 'winter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it marshmallow world winter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  113 :\n",
      "\n",
      "\tTweet's text':  take bike raini cold dark street dentist yaaaay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Somuchfun'] \n",
      "\n",
      "\tTweet tokenized by words:  ['take', 'bike', 'raini', 'cold', 'dark', 'street', 'dentist', 'yaaaay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['take bike raini cold dark street dentist yaaaay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  114 :\n",
      "\n",
      "\tTweet's text':  read barack obama barack plaza oh \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Obama', '#moneygall'] \n",
      "\n",
      "\tTweet tokenized by words:  ['read', 'barack', 'obama', 'barack', 'plaza', 'oh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['read barack obama barack plaza oh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  115 :\n",
      "\n",
      "\tTweet's text':  face tire man hahahahah \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['face', 'tire', 'man', 'hahahahah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['face tire man hahahahah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  116 :\n",
      "\n",
      "\tTweet's text':  we want turkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'want', 'turkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we want turkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  117 :\n",
      "\n",
      "\tTweet's text':  happi small servic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'small', 'servic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi small servic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  118 :\n",
      "\n",
      "\tTweet's text':  choos word care hurt someon feel right way go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['choos', 'word', 'care', 'hurt', 'someon', 'feel', 'right', 'way', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['choos word care hurt someon feel right way go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  119 :\n",
      "\n",
      "\tTweet's text':  what joke thank detail respons commun custom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'joke', 'thank', 'detail', 'respons', 'commun', 'custom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what joke thank detail respons commun custom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  120 :\n",
      "\n",
      "\tTweet's text':  a thank much it post nd decemb alreadi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth', 'smiling_face_with_halo'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'thank', 'much', 'it', 'post', 'nd', 'decemb', 'alreadi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a thank much it post nd decemb alreadi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  121 :\n",
      "\n",
      "\tTweet's text':  feel artsi tonight b e apart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#artsy', '#homealone', '#vienna', '#studentlife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'artsi', 'tonight', 'b', 'e', 'apart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel artsi tonight b e apart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  122 :\n",
      "\n",
      "\tTweet's text':  show mom pictur say grung goe haha i love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#momgoals'] \n",
      "\n",
      "\tTweet tokenized by words:  ['show', 'mom', 'pictur', 'say', 'grung', 'goe', 'haha', 'i', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['show mom pictur say grung goe haha i love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  123 :\n",
      "\n",
      "\tTweet's text':  explain inter went calciopoli j \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['explain', 'inter', 'went', 'calciopoli', 'j'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['explain inter went calciopoli j'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  124 :\n",
      "\n",
      "\tTweet's text':  i pray god come back america save us \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'pray', 'god', 'come', 'back', 'america', 'save', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i pray god come back america save us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  125 :\n",
      "\n",
      "\tTweet's text':  the appoint reverend libbi lane \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Libby', '#Lane', '#appointment', '#Women', '#bishops', '#debate', '#over'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'appoint', 'reverend', 'libbi', 'lane'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the appoint reverend libbi lane'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  126 :\n",
      "\n",
      "\tTweet's text':  sad someon drink treat like shit talk \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sad', 'someon', 'drink', 'treat', 'like', 'shit', 'talk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sad someon drink treat like shit talk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  127 :\n",
      "\n",
      "\tTweet's text':  we provid structur ensur success invest real estat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'provid', 'structur', 'ensur', 'success', 'invest', 'real', 'estat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we provid structur ensur success invest real estat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  128 :\n",
      "\n",
      "\tTweet's text':  ask liber tell obama got us iraq afghan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ask', 'liber', 'tell', 'obama', 'got', 'us', 'iraq', 'afghan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ask liber tell obama got us iraq afghan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  129 :\n",
      "\n",
      "\tTweet's text':  whi i sick look tweet oh yeah \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lame'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'i', 'sick', 'look', 'tweet', 'oh', 'yeah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi i sick look tweet oh yeah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  130 :\n",
      "\n",
      "\tTweet's text':  work doubl hour sleep go let get \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'doubl', 'hour', 'sleep', 'go', 'let', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work doubl hour sleep go let get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  131 :\n",
      "\n",
      "\tTweet's text':  for love time year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['for', 'love', 'time', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['for love time year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  132 :\n",
      "\n",
      "\tTweet's text':  in news havent good night sleep week i feel great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'news', 'havent', 'good', 'night', 'sleep', 'week', 'i', 'feel', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in news havent good night sleep week i feel great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  133 :\n",
      "\n",
      "\tTweet's text':  the pure \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#reality'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'pure'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the pure'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  134 :\n",
      "\n",
      "\tTweet's text':  chang everi day enjoy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#DIY', '#MobileCover'] \n",
      "\n",
      "\tTweet tokenized by words:  ['chang', 'everi', 'day', 'enjoy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['chang everi day enjoy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  135 :\n",
      "\n",
      "\tTweet's text':  happi nd anniversari sgv happi ot client woohoo i loooooov job super more year go \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'nd', 'anniversari', 'sgv', 'happi', 'ot', 'client', 'woohoo', 'i', 'loooooov', 'job', 'super', 'more', 'year', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi nd anniversari sgv happi ot client woohoo i loooooov job super more year go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  136 :\n",
      "\n",
      "\tTweet's text':  caus thing life seem music medicin doctor superdaylineup \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Balance', '#SuperDayLineUp'] \n",
      "\n",
      "\tTweet tokenized by words:  ['caus', 'thing', 'life', 'seem', 'music', 'medicin', 'doctor', 'superdaylineup'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['caus thing life seem music medicin doctor superdaylineup'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  137 :\n",
      "\n",
      "\tTweet's text':  i guess mean msm dig someth smear barkley ferguson \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ferguson'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'mean', 'msm', 'dig', 'someth', 'smear', 'barkley', 'ferguson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guess mean msm dig someth smear barkley ferguson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  138 :\n",
      "\n",
      "\tTweet's text':  jimi agbaj fine test j \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jimi', 'agbaj', 'fine', 'test', 'j'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jimi agbaj fine test j'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  139 :\n",
      "\n",
      "\tTweet's text':  good thing enough surviv need \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whitewine', '#christmastrees', '#chardsohard', '#fashion'] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'thing', 'enough', 'surviv', 'need'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good thing enough surviv need'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  140 :\n",
      "\n",
      "\tTweet's text':  delay happi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['delay', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['delay happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  141 :\n",
      "\n",
      "\tTweet's text':  the fun part drive winter one clean snow yet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'fun', 'part', 'drive', 'winter', 'one', 'clean', 'snow', 'yet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the fun part drive winter one clean snow yet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  142 :\n",
      "\n",
      "\tTweet's text':  i miss day close friend live citi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'miss', 'day', 'close', 'friend', 'live', 'citi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i miss day close friend live citi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  143 :\n",
      "\n",
      "\tTweet's text':  claim russian athlet take perform enhanc drug surpris \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['claim', 'russian', 'athlet', 'take', 'perform', 'enhanc', 'drug', 'surpris'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['claim russian athlet take perform enhanc drug surpris'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  144 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  145 :\n",
      "\n",
      "\tTweet's text':  shoutout mom hella support \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shoutout', 'mom', 'hella', 'support'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shoutout mom hella support'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  146 :\n",
      "\n",
      "\tTweet's text':  may also see flag isi govt ch nisar admit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['may', 'also', 'see', 'flag', 'isi', 'govt', 'ch', 'nisar', 'admit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['may also see flag isi govt ch nisar admit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  147 :\n",
      "\n",
      "\tTweet's text':  funni \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['funni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['funni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  148 :\n",
      "\n",
      "\tTweet's text':  do want period relat post like i post person thing instagram \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['do', 'want', 'period', 'relat', 'post', 'like', 'i', 'post', 'person', 'thing', 'instagram'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['do want period relat post like i post person thing instagram'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  149 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AnalScreen', '#Exotic'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  150 :\n",
      "\n",
      "\tTweet's text':  time ufc press confer tomorrow name numer fighter get cut \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'ufc', 'press', 'confer', 'tomorrow', 'name', 'numer', 'fighter', 'get', 'cut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time ufc press confer tomorrow name numer fighter get cut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  151 :\n",
      "\n",
      "\tTweet's text':  high sea fish boat allegedli blow sea \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Terror', '#Pakistan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['high', 'sea', 'fish', 'boat', 'allegedli', 'blow', 'sea'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['high sea fish boat allegedli blow sea'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  152 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#what', '#matters', '#to', '#me', '#is', '#gym', '#holidays', '#work', '#the', '#hell', '#out'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  153 :\n",
      "\n",
      "\tTweet's text':  i like listen dad truck driver tell go strip joint old ladi get mad \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'like', 'listen', 'dad', 'truck', 'driver', 'tell', 'go', 'strip', 'joint', 'old', 'ladi', 'get', 'mad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i like listen dad truck driver tell go strip joint old ladi get mad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  154 :\n",
      "\n",
      "\tTweet's text':  hate go back old format pleas \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hate', 'go', 'back', 'old', 'format', 'pleas'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hate go back old format pleas'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  155 :\n",
      "\n",
      "\tTweet's text':  week joke i jessica niec \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['week', 'joke', 'i', 'jessica', 'niec'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['week joke i jessica niec'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  156 :\n",
      "\n",
      "\tTweet's text':  you serious bought giant tv play box \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'serious', 'bought', 'giant', 'tv', 'play', 'box'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you serious bought giant tv play box'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  157 :\n",
      "\n",
      "\tTweet's text':  haha fuck say someon truegentlemen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TrueGentlemen'] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'fuck', 'say', 'someon', 'truegentlemen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha fuck say someon truegentlemen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  158 :\n",
      "\n",
      "\tTweet's text':  if want hall eventu ask trade hope consist messag chang much might well start \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'want', 'hall', 'eventu', 'ask', 'trade', 'hope', 'consist', 'messag', 'chang', 'much', 'might', 'well', 'start'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if want hall eventu ask trade hope consist messag chang much might well start'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  159 :\n",
      "\n",
      "\tTweet's text':  wow that though sorri grandpa use mac day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WelcomeToTheWorld', '#NeverArgueWithFools'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'that', 'though', 'sorri', 'grandpa', 'use', 'mac', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow that though sorri grandpa use mac day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  160 :\n",
      "\n",
      "\tTweet's text':  i like first one never care enough watch sequel that said i watch \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#reboot', '#ChrisPratt'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'like', 'first', 'one', 'never', 'care', 'enough', 'watch', 'sequel', 'that', 'said', 'i', 'watch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i like first one never care enough watch sequel that said i watch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  161 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#working'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  162 :\n",
      "\n",
      "\tTweet's text':  the badger crusad continu gloucestershir badger patrol trigger illeg trap fear \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'badger', 'crusad', 'continu', 'gloucestershir', 'badger', 'patrol', 'trigger', 'illeg', 'trap', 'fear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the badger crusad continu gloucestershir badger patrol trigger illeg trap fear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  163 :\n",
      "\n",
      "\tTweet's text':  i also support instantli murder year old fake plastic gun public \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'also', 'support', 'instantli', 'murder', 'year', 'old', 'fake', 'plastic', 'gun', 'public'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i also support instantli murder year old fake plastic gun public'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  164 :\n",
      "\n",
      "\tTweet's text':  aunti call said she way i better get dress \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'astonished_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aunti', 'call', 'said', 'she', 'way', 'i', 'better', 'get', 'dress'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aunti call said she way i better get dress'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  165 :\n",
      "\n",
      "\tTweet's text':  ahhh bedtim i miss \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#examproblems'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ahhh', 'bedtim', 'i', 'miss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ahhh bedtim i miss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  166 :\n",
      "\n",
      "\tTweet's text':  nerd bit fun georgia chill \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#piccollage', '#nerd', '#chistmas', '#sillybilly'] \n",
      "\n",
      "\tTweet tokenized by words:  ['nerd', 'bit', 'fun', 'georgia', 'chill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nerd bit fun georgia chill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  167 :\n",
      "\n",
      "\tTweet's text':  i think hotel \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'hotel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think hotel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  168 :\n",
      "\n",
      "\tTweet's text':  one day i want travel bestfriend earth globe asia australiaairplan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['heavy_black_heart', 'airplane', 'earth_globe_asia-australia'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'day', 'i', 'want', 'travel', 'bestfriend', 'earth', 'globe', 'asia', 'australiaairplan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one day i want travel bestfriend earth globe asia australiaairplan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  169 :\n",
      "\n",
      "\tTweet's text':  again fan come second thank \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['again', 'fan', 'come', 'second', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['again fan come second thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  170 :\n",
      "\n",
      "\tTweet's text':  when return kind call friend label unkind \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'return', 'kind', 'call', 'friend', 'label', 'unkind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when return kind call friend label unkind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  171 :\n",
      "\n",
      "\tTweet's text':  sometim dont understand anyth stubborn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#stubborn'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sometim', 'dont', 'understand', 'anyth', 'stubborn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sometim dont understand anyth stubborn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  172 :\n",
      "\n",
      "\tTweet's text':  that cutest thing ever smile face heart shape eyesfac throw kiss \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes', 'face_throwing_a_kiss'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'cutest', 'thing', 'ever', 'smile', 'face', 'heart', 'shape', 'eyesfac', 'throw', 'kiss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that cutest thing ever smile face heart shape eyesfac throw kiss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  173 :\n",
      "\n",
      "\tTweet's text':  oh i love ass big fit jean anymor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bigbootybitches'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'i', 'love', 'ass', 'big', 'fit', 'jean', 'anymor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh i love ass big fit jean anymor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  174 :\n",
      "\n",
      "\tTweet's text':  lucki fortun mean thing \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lucki', 'fortun', 'mean', 'thing'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lucki fortun mean thing'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  175 :\n",
      "\n",
      "\tTweet's text':  i enjoy steal husband hat everi awhil smile face heart shape eyesfac throw kissflush face \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes', 'face_throwing_a_kiss', 'flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#heyyall', '#GoodMorning'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'enjoy', 'steal', 'husband', 'hat', 'everi', 'awhil', 'smile', 'face', 'heart', 'shape', 'eyesfac', 'throw', 'kissflush', 'face'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i enjoy steal husband hat everi awhil smile face heart shape eyesfac throw kissflush face'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  176 :\n",
      "\n",
      "\tTweet's text':  hi tweet context histori make clear bait \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hi', 'tweet', 'context', 'histori', 'make', 'clear', 'bait'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hi tweet context histori make clear bait'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  177 :\n",
      "\n",
      "\tTweet's text':  insan thing twice expect differ result \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['insan', 'thing', 'twice', 'expect', 'differ', 'result'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['insan thing twice expect differ result'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  178 :\n",
      "\n",
      "\tTweet's text':  hour sleep yay love life \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hour', 'sleep', 'yay', 'love', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hour sleep yay love life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  179 :\n",
      "\n",
      "\tTweet's text':  wow look hotshot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#isthatajoke'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'look', 'hotshot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow look hotshot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  180 :\n",
      "\n",
      "\tTweet's text':  can wait play beta xd \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BFHardline', '#Epic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'play', 'beta', 'xd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait play beta xd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  181 :\n",
      "\n",
      "\tTweet's text':  contempl respond tweet say remain pride sure well go \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['contempl', 'respond', 'tweet', 'say', 'remain', 'pride', 'sure', 'well', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['contempl respond tweet say remain pride sure well go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  182 :\n",
      "\n",
      "\tTweet's text':  have four hour sound great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['have', 'four', 'hour', 'sound', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['have four hour sound great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  183 :\n",
      "\n",
      "\tTweet's text':  oh district line major signal failur delay fantast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'district', 'line', 'major', 'signal', 'failur', 'delay', 'fantast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh district line major signal failur delay fantast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  184 :\n",
      "\n",
      "\tTweet's text':  sure end well \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sure', 'end', 'well'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sure end well'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  185 :\n",
      "\n",
      "\tTweet's text':  countri music photo edit type morn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['black_sun_with_rays', 'multiple_musical_notes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['countri', 'music', 'photo', 'edit', 'type', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['countri music photo edit type morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  186 :\n",
      "\n",
      "\tTweet's text':  lol micromax promis servic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'micromax', 'promis', 'servic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol micromax promis servic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  187 :\n",
      "\n",
      "\tTweet's text':  it hard choos pleasur pain \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Girl', '#December', '#Love', '#Dream', '#Strong'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'hard', 'choos', 'pleasur', 'pain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it hard choos pleasur pain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  188 :\n",
      "\n",
      "\tTweet's text':  adrian rais way made nfl mayb thought would motiv kid get \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['adrian', 'rais', 'way', 'made', 'nfl', 'mayb', 'thought', 'would', 'motiv', 'kid', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['adrian rais way made nfl mayb thought would motiv kid get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  189 :\n",
      "\n",
      "\tTweet's text':  she heard him cri hi littl finger toe count mari exclaim he perfect oh mari cray cray \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['she', 'heard', 'him', 'cri', 'hi', 'littl', 'finger', 'toe', 'count', 'mari', 'exclaim', 'he', 'perfect', 'oh', 'mari', 'cray', 'cray'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['she heard him cri hi littl finger toe count mari exclaim he perfect oh mari cray cray'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  190 :\n",
      "\n",
      "\tTweet's text':  my secret name lizard squad i like ruin peopl fun time follow rt billion fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#psn', '#giveitup'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'secret', 'name', 'lizard', 'squad', 'i', 'like', 'ruin', 'peopl', 'fun', 'time', 'follow', 'rt', 'billion', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my secret name lizard squad i like ruin peopl fun time follow rt billion fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  191 :\n",
      "\n",
      "\tTweet's text':  sexist articl daili fail men wast money cycl accompani recommend handbag cost \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sexist', 'articl', 'daili', 'fail', 'men', 'wast', 'money', 'cycl', 'accompani', 'recommend', 'handbag', 'cost'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sexist articl daili fail men wast money cycl accompani recommend handbag cost'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  192 :\n",
      "\n",
      "\tTweet's text':  tweet flip phone now definit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tweet', 'flip', 'phone', 'now', 'definit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tweet flip phone now definit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  193 :\n",
      "\n",
      "\tTweet's text':  yea coupl school play black black domin game \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yea', 'coupl', 'school', 'play', 'black', 'black', 'domin', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yea coupl school play black black domin game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  194 :\n",
      "\n",
      "\tTweet's text':  don forget join night tonight start pm \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Steak', '#nyc', '#food', '#foodie'] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'forget', 'join', 'night', 'tonight', 'start', 'pm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don forget join night tonight start pm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  195 :\n",
      "\n",
      "\tTweet's text':  i think i ever seen love actual way i tri last year i rememb \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'i', 'ever', 'seen', 'love', 'actual', 'way', 'i', 'tri', 'last', 'year', 'i', 'rememb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think i ever seen love actual way i tri last year i rememb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  196 :\n",
      "\n",
      "\tTweet's text':  my nephew stop lot hi long hair look like drug dealer never smoke anyth pill aspirin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'nephew', 'stop', 'lot', 'hi', 'long', 'hair', 'look', 'like', 'drug', 'dealer', 'never', 'smoke', 'anyth', 'pill', 'aspirin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my nephew stop lot hi long hair look like drug dealer never smoke anyth pill aspirin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  197 :\n",
      "\n",
      "\tTweet's text':  ask permiss \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#QZ8501', '#takeoff', '#towercontrol', '#Surubaya'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ask', 'permiss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ask permiss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  198 :\n",
      "\n",
      "\tTweet's text':  answer more artist winsunburnpass \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WinSunburnPasses'] \n",
      "\n",
      "\tTweet tokenized by words:  ['answer', 'more', 'artist', 'winsunburnpass'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['answer more artist winsunburnpass'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  199 :\n",
      "\n",
      "\tTweet's text':  play provinc like oh mississippi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['play', 'provinc', 'like', 'oh', 'mississippi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['play provinc like oh mississippi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  200 :\n",
      "\n",
      "\tTweet's text':  church sign day how would feel celebr birthday without speak evil monkey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['speak-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  ['#StoleEm', '#TheReasonForTheSeason'] \n",
      "\n",
      "\tTweet tokenized by words:  ['church', 'sign', 'day', 'how', 'would', 'feel', 'celebr', 'birthday', 'without', 'speak', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['church sign day how would feel celebr birthday without speak evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  201 :\n",
      "\n",
      "\tTweet's text':  rich herrera it ha the word man in it just sexist say mail man instead mail carrier \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MichiganMan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rich', 'herrera', 'it', 'ha', 'the', 'word', 'man', 'in', 'it', 'just', 'sexist', 'say', 'mail', 'man', 'instead', 'mail', 'carrier'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rich herrera it ha the word man in it just sexist say mail man instead mail carrier'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  202 :\n",
      "\n",
      "\tTweet's text':  did know if read right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['did', 'know', 'if', 'read', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['did know if read right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  203 :\n",
      "\n",
      "\tTweet's text':  yeah wont talk bodi cop kill bk ambulanc immedi elit finest \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'wont', 'talk', 'bodi', 'cop', 'kill', 'bk', 'ambulanc', 'immedi', 'elit', 'finest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah wont talk bodi cop kill bk ambulanc immedi elit finest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  204 :\n",
      "\n",
      "\tTweet's text':  love weather \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'weather'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love weather'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  205 :\n",
      "\n",
      "\tTweet's text':  psssst you spelt thing wrong \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['psssst', 'you', 'spelt', 'thing', 'wrong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['psssst you spelt thing wrong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  206 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#follow', '#Jesus', '#Christ', '#FBC', '#FBCJAX'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  207 :\n",
      "\n",
      "\tTweet's text':  tough day sun costa teguis lanzarot \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#kitsch', '#funny'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tough', 'day', 'sun', 'costa', 'teguis', 'lanzarot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tough day sun costa teguis lanzarot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  208 :\n",
      "\n",
      "\tTweet's text':  exclud bf map i realli want sein cross back i would pay \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['loudly_crying_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['exclud', 'bf', 'map', 'i', 'realli', 'want', 'sein', 'cross', 'back', 'i', 'would', 'pay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['exclud bf map i realli want sein cross back i would pay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  209 :\n",
      "\n",
      "\tTweet's text':  i love hour shift \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['weary_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'hour', 'shift'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love hour shift'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  210 :\n",
      "\n",
      "\tTweet's text':  the whole thing hang women right a cat fight imagin pull left \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Misogyny', '#pmlive'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'whole', 'thing', 'hang', 'women', 'right', 'a', 'cat', 'fight', 'imagin', 'pull', 'left'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the whole thing hang women right a cat fight imagin pull left'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  211 :\n",
      "\n",
      "\tTweet's text':  yea yea logic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yea', 'yea', 'logic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yea yea logic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  212 :\n",
      "\n",
      "\tTweet's text':  over cb noon fox \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BALvsMIA', '#SEAvsPHI', '#Saints', '#NFL'] \n",
      "\n",
      "\tTweet tokenized by words:  ['over', 'cb', 'noon', 'fox'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['over cb noon fox'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  213 :\n",
      "\n",
      "\tTweet's text':  so aaron sorkin goe talk like media talk soni hack use media bitch media \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'aaron', 'sorkin', 'goe', 'talk', 'like', 'media', 'talk', 'soni', 'hack', 'use', 'media', 'bitch', 'media'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so aaron sorkin goe talk like media talk soni hack use media bitch media'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  214 :\n",
      "\n",
      "\tTweet's text':  argument insan rbrnetwork \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['argument', 'insan', 'rbrnetwork'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['argument insan rbrnetwork'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  215 :\n",
      "\n",
      "\tTweet's text':  rememb way ppl listen burn store ferguson \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FergusonRiotTips', '#Ferguson', '#VitoandVito', '#WAARMedia', '#tcot', '#ycot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rememb', 'way', 'ppl', 'listen', 'burn', 'store', 'ferguson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rememb way ppl listen burn store ferguson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  216 :\n",
      "\n",
      "\tTweet's text':  my finger smell like lavashak \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'finger', 'smell', 'like', 'lavashak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my finger smell like lavashak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  217 :\n",
      "\n",
      "\tTweet's text':  juncker receiv birthday surpris one million signatur oppos ttip ceta \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcies', '#eu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['juncker', 'receiv', 'birthday', 'surpris', 'one', 'million', 'signatur', 'oppos', 'ttip', 'ceta'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['juncker receiv birthday surpris one million signatur oppos ttip ceta'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  218 :\n",
      "\n",
      "\tTweet's text':  forev forev rip \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Forever', '#Young', '#Out', '#our', '#hearts', '#RIP', '#PhillipJoelHughes'] \n",
      "\n",
      "\tTweet tokenized by words:  ['forev', 'forev', 'rip'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['forev forev rip'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  219 :\n",
      "\n",
      "\tTweet's text':  last day napl emma girl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['black_sun_with_rays', 'palm_tree'] \n",
      "\n",
      "\tTweet's hashtags':  ['#soeasytotakeapicwithatoddler', '#19wksandcounting'] \n",
      "\n",
      "\tTweet tokenized by words:  ['last', 'day', 'napl', 'emma', 'girl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['last day napl emma girl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  220 :\n",
      "\n",
      "\tTweet's text':  say \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bigclub'] \n",
      "\n",
      "\tTweet tokenized by words:  ['say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  221 :\n",
      "\n",
      "\tTweet's text':  anytim cash accept everi and use toward whatev want need \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['anytim', 'cash', 'accept', 'everi', 'and', 'use', 'toward', 'whatev', 'want', 'need'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anytim cash accept everi and use toward whatev want need'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  222 :\n",
      "\n",
      "\tTweet's text':  nah better act like north korean govt polic peopl privat thought \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nah', 'better', 'act', 'like', 'north', 'korean', 'govt', 'polic', 'peopl', 'privat', 'thought'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nah better act like north korean govt polic peopl privat thought'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  223 :\n",
      "\n",
      "\tTweet's text':  year old got i think maci \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['year', 'old', 'got', 'i', 'think', 'maci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['year old got i think maci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  224 :\n",
      "\n",
      "\tTweet's text':  blow nose hard ear pop greatest way start wednesday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['blow', 'nose', 'hard', 'ear', 'pop', 'greatest', 'way', 'start', 'wednesday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['blow nose hard ear pop greatest way start wednesday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  225 :\n",
      "\n",
      "\tTweet's text':  today court proceed allow prison access book england wale sure confirm time limit judici review \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'court', 'proceed', 'allow', 'prison', 'access', 'book', 'england', 'wale', 'sure', 'confirm', 'time', 'limit', 'judici', 'review'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today court proceed allow prison access book england wale sure confirm time limit judici review'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  226 :\n",
      "\n",
      "\tTweet's text':  yay i love awak morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face', 'pistol'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'i', 'love', 'awak', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay i love awak morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  227 :\n",
      "\n",
      "\tTweet's text':  off slow start morn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['weary_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['off', 'slow', 'start', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['off slow start morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  228 :\n",
      "\n",
      "\tTweet's text':  get power wind outdat unsightli siphon directli sun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'power', 'wind', 'outdat', 'unsightli', 'siphon', 'directli', 'sun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get power wind outdat unsightli siphon directli sun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  229 :\n",
      "\n",
      "\tTweet's text':  realli look forward wake earli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'look', 'forward', 'wake', 'earli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli look forward wake earli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  230 :\n",
      "\n",
      "\tTweet's text':  oh i love listen fox new background open present \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'i', 'love', 'listen', 'fox', 'new', 'background', 'open', 'present'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh i love listen fox new background open present'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  231 :\n",
      "\n",
      "\tTweet's text':  those bad anonym occupi peopl support white supremaci \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['those', 'bad', 'anonym', 'occupi', 'peopl', 'support', 'white', 'supremaci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['those bad anonym occupi peopl support white supremaci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  232 :\n",
      "\n",
      "\tTweet's text':  well complet well reason thought argument you chang mind \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ferguson'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'complet', 'well', 'reason', 'thought', 'argument', 'you', 'chang', 'mind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well complet well reason thought argument you chang mind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  233 :\n",
      "\n",
      "\tTweet's text':  yeah i still laugh it even funni i still laugh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'i', 'still', 'laugh', 'it', 'even', 'funni', 'i', 'still', 'laugh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah i still laugh it even funni i still laugh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  234 :\n",
      "\n",
      "\tTweet's text':  gotta joke tootin horn somewher \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'joke', 'tootin', 'horn', 'somewher'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta joke tootin horn somewher'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  235 :\n",
      "\n",
      "\tTweet's text':  gotta go third forth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WinterThought'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'go', 'third', 'forth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta go third forth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  236 :\n",
      "\n",
      "\tTweet's text':  cc my last tweet wayn world great movi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cc', 'my', 'last', 'tweet', 'wayn', 'world', 'great', 'movi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cc my last tweet wayn world great movi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  237 :\n",
      "\n",
      "\tTweet's text':  zero place karma train find raiola i hope full head steam \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['zero', 'place', 'karma', 'train', 'find', 'raiola', 'i', 'hope', 'full', 'head', 'steam'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['zero place karma train find raiola i hope full head steam'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  238 :\n",
      "\n",
      "\tTweet's text':  earn cash post tweet get start cashforcontain \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CashForContainers', '#homebasedbusiness', '#LOL'] \n",
      "\n",
      "\tTweet tokenized by words:  ['earn', 'cash', 'post', 'tweet', 'get', 'start', 'cashforcontain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['earn cash post tweet get start cashforcontain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  239 :\n",
      "\n",
      "\tTweet's text':  oracl window thi fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oracl', 'window', 'thi', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oracl window thi fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  240 :\n",
      "\n",
      "\tTweet's text':  last day class except final whoop \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#trill'] \n",
      "\n",
      "\tTweet tokenized by words:  ['last', 'day', 'class', 'except', 'final', 'whoop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['last day class except final whoop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  241 :\n",
      "\n",
      "\tTweet's text':  you blame everyth els \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'blame', 'everyth', 'els'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you blame everyth els'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  242 :\n",
      "\n",
      "\tTweet's text':  with drop oil price thank good work hard tri tie economi oil ga sector \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PMHarper', '#cdnpoli'] \n",
      "\n",
      "\tTweet tokenized by words:  ['with', 'drop', 'oil', 'price', 'thank', 'good', 'work', 'hard', 'tri', 'tie', 'economi', 'oil', 'ga', 'sector'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['with drop oil price thank good work hard tri tie economi oil ga sector'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  243 :\n",
      "\n",
      "\tTweet's text':  sing along song korean part english i sing korean accent whi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sing', 'along', 'song', 'korean', 'part', 'english', 'i', 'sing', 'korean', 'accent', 'whi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sing along song korean part english i sing korean accent whi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  244 :\n",
      "\n",
      "\tTweet's text':  save work folk offic cntrl alt delet week \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['save', 'work', 'folk', 'offic', 'cntrl', 'alt', 'delet', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['save work folk offic cntrl alt delet week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  245 :\n",
      "\n",
      "\tTweet's text':  i glad andi tweet day text back \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#loved'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'glad', 'andi', 'tweet', 'day', 'text', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i glad andi tweet day text back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  246 :\n",
      "\n",
      "\tTweet's text':  when masseus offer sooth massag way review offer sting critic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Masseuse', '#Reviewer', '#Massage', '#Criticism'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'masseus', 'offer', 'sooth', 'massag', 'way', 'review', 'offer', 'sting', 'critic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when masseus offer sooth massag way review offer sting critic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  247 :\n",
      "\n",
      "\tTweet's text':  show apc free fair parti run intellectu call democraci dictatorship \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#it', '#run', '#and'] \n",
      "\n",
      "\tTweet tokenized by words:  ['show', 'apc', 'free', 'fair', 'parti', 'run', 'intellectu', 'call', 'democraci', 'dictatorship'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['show apc free fair parti run intellectu call democraci dictatorship'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  248 :\n",
      "\n",
      "\tTweet's text':  how dare accus boomer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'dare', 'accus', 'boomer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how dare accus boomer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  249 :\n",
      "\n",
      "\tTweet's text':  hungri hungov \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#a', '#good', '#day'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hungri', 'hungov'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hungri hungov'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  250 :\n",
      "\n",
      "\tTweet's text':  oi na i function right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sleepdeprived'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oi', 'na', 'i', 'function', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oi na i function right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  251 :\n",
      "\n",
      "\tTweet's text':  i liter know \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'liter', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i liter know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  252 :\n",
      "\n",
      "\tTweet's text':  what pti apart whine \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Youthiacrasy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'pti', 'apart', 'whine'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what pti apart whine'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  253 :\n",
      "\n",
      "\tTweet's text':  true \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['true'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['true'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  254 :\n",
      "\n",
      "\tTweet's text':  tell someon spell correctli complet fuck tweet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tell', 'someon', 'spell', 'correctli', 'complet', 'fuck', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tell someon spell correctli complet fuck tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  255 :\n",
      "\n",
      "\tTweet's text':  my solo costum far charcoal grey b \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'solo', 'costum', 'far', 'charcoal', 'grey', 'b'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my solo costum far charcoal grey b'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  256 :\n",
      "\n",
      "\tTweet's text':  pay ghost soldier iraq cut pay us \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Military', '#keepyourpromise'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pay', 'ghost', 'soldier', 'iraq', 'cut', 'pay', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pay ghost soldier iraq cut pay us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  257 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  258 :\n",
      "\n",
      "\tTweet's text':  one love smile face open mouth tightli close eyesfath christmasparti poppermultipl music note \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['multiple_musical_notes', 'party_popper', 'smiling_face_with_open_mouth_and_tightly-closed_eyes', 'father_christmas'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'love', 'smile', 'face', 'open', 'mouth', 'tightli', 'close', 'eyesfath', 'christmasparti', 'poppermultipl', 'music', 'note'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one love smile face open mouth tightli close eyesfath christmasparti poppermultipl music note'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  259 :\n",
      "\n",
      "\tTweet's text':  in need rose wine \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'need', 'rose', 'wine'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in need rose wine'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  260 :\n",
      "\n",
      "\tTweet's text':  yesterday top tag today thing twitter nation seem concern \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PeshawarAttack', '#PTIKeptPakFirst'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yesterday', 'top', 'tag', 'today', 'thing', 'twitter', 'nation', 'seem', 'concern'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yesterday top tag today thing twitter nation seem concern'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  261 :\n",
      "\n",
      "\tTweet's text':  my whole life oh ok \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'whole', 'life', 'oh', 'ok'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my whole life oh ok'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  262 :\n",
      "\n",
      "\tTweet's text':  leg snap alik twig i complet front flip i scream like hungri newborn babi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['leg', 'snap', 'alik', 'twig', 'i', 'complet', 'front', 'flip', 'i', 'scream', 'like', 'hungri', 'newborn', 'babi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['leg snap alik twig i complet front flip i scream like hungri newborn babi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  263 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#succes', '#it', '#is', '#about', '#what', '#we', '#see', '#if', '#we', '#keep', '#hope', '#and', '#never', '#give', '#up', '#success', '#is'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  264 :\n",
      "\n",
      "\tTweet's text':  i alreadi tell today go wonder day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'alreadi', 'tell', 'today', 'go', 'wonder', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i alreadi tell today go wonder day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  265 :\n",
      "\n",
      "\tTweet's text':  junior got rim shot rim job joke \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['junior', 'got', 'rim', 'shot', 'rim', 'job', 'joke'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['junior got rim shot rim job joke'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  266 :\n",
      "\n",
      "\tTweet's text':  found reason weekend closer make life miser i atheist \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hypocrite', '#atheistproblems', '#serverproblems'] \n",
      "\n",
      "\tTweet tokenized by words:  ['found', 'reason', 'weekend', 'closer', 'make', 'life', 'miser', 'i', 'atheist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['found reason weekend closer make life miser i atheist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  267 :\n",
      "\n",
      "\tTweet's text':  stay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#casual', '#monday', '#funday', '#ootd', '#fashion', '#style', '#allyouneedisstyle', '#todayimwearing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['stay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  268 :\n",
      "\n",
      "\tTweet's text':  problemat god bless it shame done pakistan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['problemat', 'god', 'bless', 'it', 'shame', 'done', 'pakistan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['problemat god bless it shame done pakistan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  269 :\n",
      "\n",
      "\tTweet's text':  trend i awar j k rowl releas new book \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TortureReport'] \n",
      "\n",
      "\tTweet tokenized by words:  ['trend', 'i', 'awar', 'j', 'k', 'rowl', 'releas', 'new', 'book'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['trend i awar j k rowl releas new book'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  270 :\n",
      "\n",
      "\tTweet's text':  too s \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['too', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['too s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  271 :\n",
      "\n",
      "\tTweet's text':  wtf thank say bye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wtf', 'thank', 'say', 'bye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wtf thank say bye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  272 :\n",
      "\n",
      "\tTweet's text':  ahh gotta love decemb electr bill \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ahh', 'got', 'ta', 'love', 'decemb', 'electr', 'bill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ahh gotta love decemb electr bill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  273 :\n",
      "\n",
      "\tTweet's text':  dead whi stupidest meme still perpetu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dead', 'whi', 'stupidest', 'meme', 'still', 'perpetu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dead whi stupidest meme still perpetu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  274 :\n",
      "\n",
      "\tTweet's text':  when someon retrica wali pictur complain mani filter someon use pictur look pretti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'someon', 'retrica', 'wali', 'pictur', 'complain', 'mani', 'filter', 'someon', 'use', 'pictur', 'look', 'pretti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when someon retrica wali pictur complain mani filter someon use pictur look pretti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  275 :\n",
      "\n",
      "\tTweet's text':  great i got lung infect thi fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notfun', '#miserable'] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'i', 'got', 'lung', 'infect', 'thi', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great i got lung infect thi fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  276 :\n",
      "\n",
      "\tTweet's text':  jeez love morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['splashing_sweat_symbol', 'dash_symbol', 'droplet', 'thumbs_down_sign'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ireland', '#December'] \n",
      "\n",
      "\tTweet tokenized by words:  ['jeez', 'love', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jeez love morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  277 :\n",
      "\n",
      "\tTweet's text':  i need spot birthday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'need', 'spot', 'birthday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i need spot birthday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  278 :\n",
      "\n",
      "\tTweet's text':  i think i know \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'i', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think i know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  279 :\n",
      "\n",
      "\tTweet's text':  i love peopl leav smelli shoe car it make car smell great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'peopl', 'leav', 'smelli', 'shoe', 'car', 'it', 'make', 'car', 'smell', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love peopl leav smelli shoe car it make car smell great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  280 :\n",
      "\n",
      "\tTweet's text':  rush hi leg still attach right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dr'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rush', 'hi', 'leg', 'still', 'attach', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rush hi leg still attach right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  281 :\n",
      "\n",
      "\tTweet's text':  mph wind make great hair fan photo shoot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mph', 'wind', 'make', 'great', 'hair', 'fan', 'photo', 'shoot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mph wind make great hair fan photo shoot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  282 :\n",
      "\n",
      "\tTweet's text':  gotta love work day christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#smellya'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'love', 'work', 'day', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta love work day christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  283 :\n",
      "\n",
      "\tTweet's text':  is i valid lack reaction \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whenyouseeit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'i', 'valid', 'lack', 'reaction'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is i valid lack reaction'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  284 :\n",
      "\n",
      "\tTweet's text':  chipbrent i love concept harass spam porn critic proof hate group \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#gamergate'] \n",
      "\n",
      "\tTweet tokenized by words:  ['chipbrent', 'i', 'love', 'concept', 'harass', 'spam', 'porn', 'critic', 'proof', 'hate', 'group'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['chipbrent i love concept harass spam porn critic proof hate group'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  285 :\n",
      "\n",
      "\tTweet's text':  the thing i love come work earli have everyon ask i earli get everi time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#annoying'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'thing', 'i', 'love', 'come', 'work', 'earli', 'have', 'everyon', 'ask', 'i', 'earli', 'get', 'everi', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the thing i love come work earli have everyon ask i earli get everi time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  286 :\n",
      "\n",
      "\tTweet's text':  thank noth all famili fli kl attend wed \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#everyonecanfly', '#AdelaideRouteCancelled'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'noth', 'all', 'famili', 'fli', 'kl', 'attend', 'wed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank noth all famili fli kl attend wed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  287 :\n",
      "\n",
      "\tTweet's text':  know put reck countri pdp clan deserv anoth day even month \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#he', '#they', '#PDP'] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'put', 'reck', 'countri', 'pdp', 'clan', 'deserv', 'anoth', 'day', 'even', 'month'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know put reck countri pdp clan deserv anoth day even month'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  288 :\n",
      "\n",
      "\tTweet's text':  could someon make hot chocol right ahaha \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['could', 'someon', 'make', 'hot', 'chocol', 'right', 'ahaha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['could someon make hot chocol right ahaha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  289 :\n",
      "\n",
      "\tTweet's text':  restaur is wi fi beach is wi fi famili parti is wi fi hell is wi fi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wifi'] \n",
      "\n",
      "\tTweet tokenized by words:  ['restaur', 'is', 'wi', 'fi', 'beach', 'is', 'wi', 'fi', 'famili', 'parti', 'is', 'wi', 'fi', 'hell', 'is', 'wi', 'fi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['restaur is wi fi beach is wi fi famili parti is wi fi hell is wi fi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  290 :\n",
      "\n",
      "\tTweet's text':  love type work spider come keyboard hang see evil monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['see-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'type', 'work', 'spider', 'come', 'keyboard', 'hang', 'see', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love type work spider come keyboard hang see evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  291 :\n",
      "\n",
      "\tTweet's text':  don either \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#text', '#drive'] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'either'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don either'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  292 :\n",
      "\n",
      "\tTweet's text':  realli unbeliev u mean thug crimin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'unbeliev', 'u', 'mean', 'thug', 'crimin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli unbeliev u mean thug crimin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  293 :\n",
      "\n",
      "\tTweet's text':  alway gonna uphil battl sometim i gonna lose \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['alway', 'gon', 'na', 'uphil', 'battl', 'sometim', 'i', 'gon', 'na', 'lose'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alway gonna uphil battl sometim i gonna lose'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  294 :\n",
      "\n",
      "\tTweet's text':  today i feel like anyth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'i', 'feel', 'like', 'anyth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today i feel like anyth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  295 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Murders', '#IcantBreathe'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  296 :\n",
      "\n",
      "\tTweet's text':  def came closet and dunk \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#rudygay'] \n",
      "\n",
      "\tTweet tokenized by words:  ['def', 'came', 'closet', 'and', 'dunk'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by sentences:  ['def came closet and dunk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  297 :\n",
      "\n",
      "\tTweet's text':  peopl school talk sex drug so awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'school', 'talk', 'sex', 'drug', 'so', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl school talk sex drug so awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  298 :\n",
      "\n",
      "\tTweet's text':  perfect time get realli sick \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['tired_face', 'face_with_medical_mask'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['perfect', 'time', 'get', 'realli', 'sick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['perfect time get realli sick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  299 :\n",
      "\n",
      "\tTweet's text':  funni \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['funni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['funni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  300 :\n",
      "\n",
      "\tTweet's text':  the thing \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hardest', '#knowing', '#having', '#faith', '#keep', '#going'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'thing'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the thing'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  301 :\n",
      "\n",
      "\tTweet's text':  bush fulli inform cia method realli s \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bush', 'fulli', 'inform', 'cia', 'method', 'realli', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bush fulli inform cia method realli s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  302 :\n",
      "\n",
      "\tTweet's text':  your jedi mind trick work servic guy glad i drop car oil chang instead av \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['your', 'jedi', 'mind', 'trick', 'work', 'servic', 'guy', 'glad', 'i', 'drop', 'car', 'oil', 'chang', 'instead', 'av'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['your jedi mind trick work servic guy glad i drop car oil chang instead av'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  303 :\n",
      "\n",
      "\tTweet's text':  i often worri wealth enough influenc societi pleas see address \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'often', 'worri', 'wealth', 'enough', 'influenc', 'societi', 'pleas', 'see', 'address'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i often worri wealth enough influenc societi pleas see address'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  304 :\n",
      "\n",
      "\tTweet's text':  women say man asltd long say sumtin young parent hotel wit grn ass man smh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['women', 'say', 'man', 'asltd', 'long', 'say', 'sumtin', 'young', 'parent', 'hotel', 'wit', 'grn', 'ass', 'man', 'smh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['women say man asltd long say sumtin young parent hotel wit grn ass man smh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  305 :\n",
      "\n",
      "\tTweet's text':  some new vinyl turntabl tonight here joe \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#JoeStrummer', '#Sandinista'] \n",
      "\n",
      "\tTweet tokenized by words:  ['some', 'new', 'vinyl', 'turntabl', 'tonight', 'here', 'joe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['some new vinyl turntabl tonight here joe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  306 :\n",
      "\n",
      "\tTweet's text':  call bottl job i take teeth yeah i game mate train tonight i rememb hat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['call', 'bottl', 'job', 'i', 'take', 'teeth', 'yeah', 'i', 'game', 'mate', 'train', 'tonight', 'i', 'rememb', 'hat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['call bottl job i take teeth yeah i game mate train tonight i rememb hat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  307 :\n",
      "\n",
      "\tTweet's text':  to held back start sanfranciscovc it never late start \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#2014', '#2015'] \n",
      "\n",
      "\tTweet tokenized by words:  ['to', 'held', 'back', 'start', 'sanfranciscovc', 'it', 'never', 'late', 'start'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['to held back start sanfranciscovc it never late start'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  308 :\n",
      "\n",
      "\tTweet's text':  funni \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['funni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['funni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  309 :\n",
      "\n",
      "\tTweet's text':  song day love like winter a fire insid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['song', 'day', 'love', 'like', 'winter', 'a', 'fire', 'insid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['song day love like winter a fire insid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  310 :\n",
      "\n",
      "\tTweet's text':  thank occ concern enough safeti drive school cancel \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'occ', 'concern', 'enough', 'safeti', 'drive', 'school', 'cancel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank occ concern enough safeti drive school cancel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  311 :\n",
      "\n",
      "\tTweet's text':  oh sprint i love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'sprint', 'i', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh sprint i love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  312 :\n",
      "\n",
      "\tTweet's text':  finnish jax \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WreathAcrossAmerica', '#Jax', '#honor', '#FallenHeros'] \n",
      "\n",
      "\tTweet tokenized by words:  ['finnish', 'jax'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['finnish jax'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  313 :\n",
      "\n",
      "\tTweet's text':  head nana place go fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['head', 'nana', 'place', 'go', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['head nana place go fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  314 :\n",
      "\n",
      "\tTweet's text':  big thank teacher four test i take tomorrow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#woohoo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['big', 'thank', 'teacher', 'four', 'test', 'i', 'take', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['big thank teacher four test i take tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  315 :\n",
      "\n",
      "\tTweet's text':  last semest i drop class i write pg paper thi semest i write \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['last', 'semest', 'i', 'drop', 'class', 'i', 'write', 'pg', 'paper', 'thi', 'semest', 'i', 'write'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['last semest i drop class i write pg paper thi semest i write'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  316 :\n",
      "\n",
      "\tTweet's text':  workhors practic glu hand \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['workhors', 'practic', 'glu', 'hand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['workhors practic glu hand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  317 :\n",
      "\n",
      "\tTweet's text':  prevent blood clot more like stop blood circul \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SurgicalStockings', '#attractive'] \n",
      "\n",
      "\tTweet tokenized by words:  ['prevent', 'blood', 'clot', 'more', 'like', 'stop', 'blood', 'circul'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['prevent blood clot more like stop blood circul'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  318 :\n",
      "\n",
      "\tTweet's text':  bet sunderland end \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#limbs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bet', 'sunderland', 'end'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bet sunderland end'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  319 :\n",
      "\n",
      "\tTweet's text':  thank mother natur you give us snow day twitter fill peopl complain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'mother', 'natur', 'you', 'give', 'us', 'snow', 'day', 'twitter', 'fill', 'peopl', 'complain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank mother natur you give us snow day twitter fill peopl complain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  320 :\n",
      "\n",
      "\tTweet's text':  you know go great day garmin reset spill cinnamon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#slowclap'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'know', 'go', 'great', 'day', 'garmin', 'reset', 'spill', 'cinnamon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you know go great day garmin reset spill cinnamon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  321 :\n",
      "\n",
      "\tTweet's text':  written gold gel pen wait i hate relationship consist twitter messag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fulfilling'] \n",
      "\n",
      "\tTweet tokenized by words:  ['written', 'gold', 'gel', 'pen', 'wait', 'i', 'hate', 'relationship', 'consist', 'twitter', 'messag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['written gold gel pen wait i hate relationship consist twitter messag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  322 :\n",
      "\n",
      "\tTweet's text':  you need experi say least \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'need', 'experi', 'say', 'least'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you need experi say least'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  323 :\n",
      "\n",
      "\tTweet's text':  johni ur crack facebook chat mate smile face open mouth tightli close eyessmil face open mouth tightli close eyessmil face open mouth tightli close eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth_and_tightly-closed_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['johni', 'ur', 'crack', 'facebook', 'chat', 'mate', 'smile', 'face', 'open', 'mouth', 'tightli', 'close', 'eyessmil', 'face', 'open', 'mouth', 'tightli', 'close', 'eyessmil', 'face', 'open', 'mouth', 'tightli', 'close', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['johni ur crack facebook chat mate smile face open mouth tightli close eyessmil face open mouth tightli close eyessmil face open mouth tightli close eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  324 :\n",
      "\n",
      "\tTweet's text':  weeeeee you i love xbox live playstat network due hacker christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['weeeeee', 'you', 'i', 'love', 'xbox', 'live', 'playstat', 'network', 'due', 'hacker', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['weeeeee you i love xbox live playstat network due hacker christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  325 :\n",
      "\n",
      "\tTweet's text':  bidu offici announc uber stake bidu market cap billion uber top next vc round right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bidu', 'offici', 'announc', 'uber', 'stake', 'bidu', 'market', 'cap', 'billion', 'uber', 'top', 'next', 'vc', 'round', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bidu offici announc uber stake bidu market cap billion uber top next vc round right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  326 :\n",
      "\n",
      "\tTweet's text':  check \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ugly', '#christmas', '#sweater', '#ebayipad'] \n",
      "\n",
      "\tTweet tokenized by words:  ['check'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['check'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  327 :\n",
      "\n",
      "\tTweet's text':  i love abl sleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sotired'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'abl', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love abl sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  328 :\n",
      "\n",
      "\tTweet's text':  garnetngold so psn xbox live day mani peopl get new video game north korean hack \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['tired_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['garnetngold', 'so', 'psn', 'xbox', 'live', 'day', 'mani', 'peopl', 'get', 'new', 'video', 'game', 'north', 'korean', 'hack'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['garnetngold so psn xbox live day mani peopl get new video game north korean hack'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  329 :\n",
      "\n",
      "\tTweet's text':  tri cut past tweet sa mine got go green consult timelin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tri', 'cut', 'past', 'tweet', 'sa', 'mine', 'got', 'go', 'green', 'consult', 'timelin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tri cut past tweet sa mine got go green consult timelin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  330 :\n",
      "\n",
      "\tTweet's text':  i serious loveeee much care \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'serious', 'loveeee', 'much', 'care'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i serious loveeee much care'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  331 :\n",
      "\n",
      "\tTweet's text':  you know awesom when gear slider dolli monitor etc get deliv end film \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#somadatBandHandadorama'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'know', 'awesom', 'when', 'gear', 'slider', 'dolli', 'monitor', 'etc', 'get', 'deliv', 'end', 'film'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you know awesom when gear slider dolli monitor etc get deliv end film'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  332 :\n",
      "\n",
      "\tTweet's text':  dayumm chti brown maaayuun \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dayumm', 'chti', 'brown', 'maaayuun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dayumm chti brown maaayuun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  333 :\n",
      "\n",
      "\tTweet's text':  now tomorrow product work would hamper \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GetMeToEVC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['now', 'tomorrow', 'product', 'work', 'would', 'hamper'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['now tomorrow product work would hamper'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  334 :\n",
      "\n",
      "\tTweet's text':  stay faith stay singl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stay', 'faith', 'stay', 'singl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stay faith stay singl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  335 :\n",
      "\n",
      "\tTweet's text':  absolut love wake snow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['absolut', 'love', 'wake', 'snow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['absolut love wake snow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  336 :\n",
      "\n",
      "\tTweet's text':  i believ n suck \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'believ', 'n', 'suck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i believ n suck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  337 :\n",
      "\n",
      "\tTweet's text':  ye repli these public dollar use what lack transpar around union pearson express \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TOpoli'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'repli', 'these', 'public', 'dollar', 'use', 'what', 'lack', 'transpar', 'around', 'union', 'pearson', 'express'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye repli these public dollar use what lack transpar around union pearson express'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  338 :\n",
      "\n",
      "\tTweet's text':  jet pick draft ironi blow mind \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NFLDraft'] \n",
      "\n",
      "\tTweet tokenized by words:  ['jet', 'pick', 'draft', 'ironi', 'blow', 'mind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jet pick draft ironi blow mind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  339 :\n",
      "\n",
      "\tTweet's text':  like i need remind bp cup competit date \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['like', 'i', 'need', 'remind', 'bp', 'cup', 'competit', 'date'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['like i need remind bp cup competit date'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  340 :\n",
      "\n",
      "\tTweet's text':  awesom and well deserv \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['awesom', 'and', 'well', 'deserv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['awesom and well deserv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  341 :\n",
      "\n",
      "\tTweet's text':  ye vote satan hillaryclinton \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'vote', 'satan', 'hillaryclinton'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye vote satan hillaryclinton'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  342 :\n",
      "\n",
      "\tTweet's text':  moron one ever said ball squar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#STRAWMAN'] \n",
      "\n",
      "\tTweet tokenized by words:  ['moron', 'one', 'ever', 'said', 'ball', 'squar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['moron one ever said ball squar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  343 :\n",
      "\n",
      "\tTweet's text':  your friend bring fuck male femal fool \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['your', 'friend', 'bring', 'fuck', 'male', 'femal', 'fool'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['your friend bring fuck male femal fool'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  344 :\n",
      "\n",
      "\tTweet's text':  that quit interest number coz i manag read sure make \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#2015'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'quit', 'interest', 'number', 'coz', 'i', 'manag', 'read', 'sure', 'make'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that quit interest number coz i manag read sure make'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  345 :\n",
      "\n",
      "\tTweet's text':  know abt goal never cross line \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#holierthanthou', '#henryisalegend'] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'abt', 'goal', 'never', 'cross', 'line'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know abt goal never cross line'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  346 :\n",
      "\n",
      "\tTweet's text':  isnt obviou case case differ thing you cannot co relat thng sentenc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sadhvi', '#Rape'] \n",
      "\n",
      "\tTweet tokenized by words:  ['isnt', 'obviou', 'case', 'case', 'differ', 'thing', 'you', 'can', 'not', 'co', 'relat', 'thng', 'sentenc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['isnt obviou case case differ thing you cannot co relat thng sentenc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  347 :\n",
      "\n",
      "\tTweet's text':  aw thank mother natur merri christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aw', 'thank', 'mother', 'natur', 'merri', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aw thank mother natur merri christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  348 :\n",
      "\n",
      "\tTweet's text':  what event \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['victory_hand'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'event'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what event'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  349 :\n",
      "\n",
      "\tTweet's text':  day joyou day speak home \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#decemberchallenge', '#picture', '#costateguise', '#beach', '#peace', '#2nd'] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'joyou', 'day', 'speak', 'home'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day joyou day speak home'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  350 :\n",
      "\n",
      "\tTweet's text':  no wr dime dozen complet replac which packer overspend retain \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'wr', 'dime', 'dozen', 'complet', 'replac', 'which', 'packer', 'overspend', 'retain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no wr dime dozen complet replac which packer overspend retain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  351 :\n",
      "\n",
      "\tTweet's text':  japan want japan prime minist s \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Abe', '#gets', '#the', '#mandate', '#he', '#wanted', '#â', '#but', '#recovery'] \n",
      "\n",
      "\tTweet tokenized by words:  ['japan', 'want', 'japan', 'prime', 'minist', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['japan want japan prime minist s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  352 :\n",
      "\n",
      "\tTweet's text':  i got tampon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'got', 'tampon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i got tampon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  353 :\n",
      "\n",
      "\tTweet's text':  for can hear us talk nb power record number outag \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#transmitterproblems'] \n",
      "\n",
      "\tTweet tokenized by words:  ['for', 'can', 'hear', 'us', 'talk', 'nb', 'power', 'record', 'number', 'outag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['for can hear us talk nb power record number outag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  354 :\n",
      "\n",
      "\tTweet's text':  would nice right true call burn money \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GlobalWarming', '#AlGore', '#Christmas', '#ＦＯＬＬＯＷ'] \n",
      "\n",
      "\tTweet tokenized by words:  ['would', 'nice', 'right', 'true', 'call', 'burn', 'money'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['would nice right true call burn money'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  355 :\n",
      "\n",
      "\tTweet's text':  you truli son \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'truli', 'son'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you truli son'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  356 :\n",
      "\n",
      "\tTweet's text':  i love question test morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'question', 'test', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love question test morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  357 :\n",
      "\n",
      "\tTweet's text':  at \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sketch', '#today', '#spudshed', '#fresh', '#fruit', '#for', '#drawing', '#Perth'] \n",
      "\n",
      "\tTweet tokenized by words:  ['at'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['at'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  358 :\n",
      "\n",
      "\tTweet's text':  won nation hockey expert sussex drive join \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['won', 'nation', 'hockey', 'expert', 'sussex', 'drive', 'join'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['won nation hockey expert sussex drive join'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  359 :\n",
      "\n",
      "\tTweet's text':  thi look like right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'look', 'like', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi look like right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  360 :\n",
      "\n",
      "\tTweet's text':  ha shown speak famili yet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ZemirBegic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ha', 'shown', 'speak', 'famili', 'yet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ha shown speak famili yet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  361 :\n",
      "\n",
      "\tTweet's text':  let squat deadlift hurt realli realli good trainer \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fitnessmotivation'] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'squat', 'deadlift', 'hurt', 'realli', 'realli', 'good', 'trainer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let squat deadlift hurt realli realli good trainer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  362 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BBC', '#News', '#Thailand', '#crown', '#prince', '#wife', '#resigns', '#from', '#royalty'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  363 :\n",
      "\n",
      "\tTweet's text':  first photo infin vision gt concept emerg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['first', 'photo', 'infin', 'vision', 'gt', 'concept', 'emerg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['first photo infin vision gt concept emerg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  364 :\n",
      "\n",
      "\tTweet's text':  racism pool liber democrat democrat must foment racism divis maintain control divid conquer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['racism', 'pool', 'liber', 'democrat', 'democrat', 'must', 'foment', 'racism', 'divis', 'maintain', 'control', 'divid', 'conquer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['racism pool liber democrat democrat must foment racism divis maintain control divid conquer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  365 :\n",
      "\n",
      "\tTweet's text':  so topless feminist look someon love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'topless', 'feminist', 'look', 'someon', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so topless feminist look someon love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  366 :\n",
      "\n",
      "\tTweet's text':  feel bad american peopl invad countri kill children save \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'bad', 'american', 'peopl', 'invad', 'countri', 'kill', 'children', 'save'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel bad american peopl invad countri kill children save'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  367 :\n",
      "\n",
      "\tTweet's text':  i good \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  368 :\n",
      "\n",
      "\tTweet's text':  wow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  369 :\n",
      "\n",
      "\tTweet's text':  just floss ate right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#inconvenient'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'floss', 'ate', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just floss ate right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  370 :\n",
      "\n",
      "\tTweet's text':  no reason given some wait expect call found chosen media announc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'reason', 'given', 'some', 'wait', 'expect', 'call', 'found', 'chosen', 'media', 'announc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no reason given some wait expect call found chosen media announc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  371 :\n",
      "\n",
      "\tTweet's text':  ill see i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['winking_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ill', 'see', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ill see i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  372 :\n",
      "\n",
      "\tTweet's text':  sysdig cloud the fascin world linux system call remind solari dtrace day earli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sysdig', 'cloud', 'the', 'fascin', 'world', 'linux', 'system', 'call', 'remind', 'solari', 'dtrace', 'day', 'earli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sysdig cloud the fascin world linux system call remind solari dtrace day earli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  373 :\n",
      "\n",
      "\tTweet's text':  i realli need get nail eyebrow done tomorrow slack \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['information_desk_person', 'grinning_face_with_smiling_eyes', 'face_with_no_good_gesture', 'nail_polish'] \n",
      "\n",
      "\tTweet's hashtags':  ['#cool'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'realli', 'need', 'get', 'nail', 'eyebrow', 'done', 'tomorrow', 'slack'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i realli need get nail eyebrow done tomorrow slack'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  374 :\n",
      "\n",
      "\tTweet's text':  one obviou see oh clever idea glad approv \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'obviou', 'see', 'oh', 'clever', 'idea', 'glad', 'approv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one obviou see oh clever idea glad approv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  375 :\n",
      "\n",
      "\tTweet's text':  replurk acatholicpray lord jesu christ son god merci sinner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Catholic', '#prayer'] \n",
      "\n",
      "\tTweet tokenized by words:  ['replurk', 'acatholicpray', 'lord', 'jesu', 'christ', 'son', 'god', 'merci', 'sinner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['replurk acatholicpray lord jesu christ son god merci sinner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  376 :\n",
      "\n",
      "\tTweet's text':  i bet warmer nova scotia today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#frio', '#cold', '#freezing', '#costadelsol', '#IloveCanada'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'bet', 'warmer', 'nova', 'scotia', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i bet warmer nova scotia today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  377 :\n",
      "\n",
      "\tTweet's text':  bbc new new forest road safeti campaign donkey kill car \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bbc', 'new', 'new', 'forest', 'road', 'safeti', 'campaign', 'donkey', 'kill', 'car'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bbc new new forest road safeti campaign donkey kill car'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  378 :\n",
      "\n",
      "\tTweet's text':  suppos i best move ars anyth put wrap present \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['wrapped_present', 'confused_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#gym', '#christmas', '#chore'] \n",
      "\n",
      "\tTweet tokenized by words:  ['suppos', 'i', 'best', 'move', 'ars', 'anyth', 'put', 'wrap', 'present'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['suppos i best move ars anyth put wrap present'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  379 :\n",
      "\n",
      "\tTweet's text':  thank awesom support page much appreci \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#instagram', '#women', '#motivation', '#rolemode'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'awesom', 'support', 'page', 'much', 'appreci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank awesom support page much appreci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  380 :\n",
      "\n",
      "\tTweet's text':  i adapt snoopi comic academ paper submiss p review stuff nightmar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['P'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'adapt', 'snoopi', 'comic', 'academ', 'paper', 'submiss', 'p', 'review', 'stuff', 'nightmar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i adapt snoopi comic academ paper submiss p review stuff nightmar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  381 :\n",
      "\n",
      "\tTweet's text':  kind love i got voicemail seat neighbor wonder i yet constantli sell ticket i never ask \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['kind', 'love', 'i', 'got', 'voicemail', 'seat', 'neighbor', 'wonder', 'i', 'yet', 'constantli', 'sell', 'ticket', 'i', 'never', 'ask'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kind love i got voicemail seat neighbor wonder i yet constantli sell ticket i never ask'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  382 :\n",
      "\n",
      "\tTweet's text':  happi new year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'new', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi new year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  383 :\n",
      "\n",
      "\tTweet's text':  georgia nativ play morn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['georgia', 'nativ', 'play', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['georgia nativ play morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  384 :\n",
      "\n",
      "\tTweet's text':  sanjay dutt ask parol meet wife wherea husband want parol wive bodi exist grant \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sanjay', 'dutt', 'ask', 'parol', 'meet', 'wife', 'wherea', 'husband', 'want', 'parol', 'wive', 'bodi', 'exist', 'grant'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sanjay dutt ask parol meet wife wherea husband want parol wive bodi exist grant'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  385 :\n",
      "\n",
      "\tTweet's text':  who eat everyth tabl noch buena \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['happy_person_raising_one_hand'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['who', 'eat', 'everyth', 'tabl', 'noch', 'buena'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['who eat everyth tabl noch buena'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  386 :\n",
      "\n",
      "\tTweet's text':  let get anoth big win vol bball keep go volnat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#VolNation', '#BeatNCState'] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'get', 'anoth', 'big', 'win', 'vol', 'bball', 'keep', 'go', 'volnat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let get anoth big win vol bball keep go volnat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  387 :\n",
      "\n",
      "\tTweet's text':  you spit rose still rose \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#contempt', '#mockery'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'spit', 'rose', 'still', 'rose'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you spit rose still rose'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  388 :\n",
      "\n",
      "\tTweet's text':  want upgrad io keep mani pictur yeah great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['want', 'upgrad', 'io', 'keep', 'mani', 'pictur', 'yeah', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['want upgrad io keep mani pictur yeah great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  389 :\n",
      "\n",
      "\tTweet's text':  alert pleas chang thi relentlezz who i be tune in \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NowPlaying'] \n",
      "\n",
      "\tTweet tokenized by words:  ['alert', 'pleas', 'chang', 'thi', 'relentlezz', 'who', 'i', 'be', 'tune', 'in'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alert pleas chang thi relentlezz who i be tune in'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  390 :\n",
      "\n",
      "\tTweet's text':  half world starv half struggl lose weight \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SickWorld'] \n",
      "\n",
      "\tTweet tokenized by words:  ['half', 'world', 'starv', 'half', 'struggl', 'lose', 'weight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['half world starv half struggl lose weight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  391 :\n",
      "\n",
      "\tTweet's text':  i like don regret anyth made \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'like', 'don', 'regret', 'anyth', 'made'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i like don regret anyth made'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  392 :\n",
      "\n",
      "\tTweet's text':  dat u kno winter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dat', 'u', 'kno', 'winter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dat u kno winter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  393 :\n",
      "\n",
      "\tTweet's text':  i like creepi guy ask random question swic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'like', 'creepi', 'guy', 'ask', 'random', 'question', 'swic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i like creepi guy ask random question swic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  394 :\n",
      "\n",
      "\tTweet's text':  someon stop obama usa relat human right love nation like saudi arabia not terrorist cuba \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Cuba'] \n",
      "\n",
      "\tTweet tokenized by words:  ['someon', 'stop', 'obama', 'usa', 'relat', 'human', 'right', 'love', 'nation', 'like', 'saudi', 'arabia', 'not', 'terrorist', 'cuba'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['someon stop obama usa relat human right love nation like saudi arabia not terrorist cuba'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  395 :\n",
      "\n",
      "\tTweet's text':  watch father daughter fuck \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Old', '#father', '#and'] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'father', 'daughter', 'fuck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch father daughter fuck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  396 :\n",
      "\n",
      "\tTweet's text':  no vote somebodi latvia way import vote best player \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'vote', 'somebodi', 'latvia', 'way', 'import', 'vote', 'best', 'player'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no vote somebodi latvia way import vote best player'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  397 :\n",
      "\n",
      "\tTweet's text':  marvin lewi clearli think highli johnni footbal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#norespect'] \n",
      "\n",
      "\tTweet tokenized by words:  ['marvin', 'lewi', 'clearli', 'think', 'highli', 'johnni', 'footbal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['marvin lewi clearli think highli johnni footbal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  398 :\n",
      "\n",
      "\tTweet's text':  final week drain bodi much ruin life place l \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'week', 'drain', 'bodi', 'much', 'ruin', 'life', 'place', 'l'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final week drain bodi much ruin life place l'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  399 :\n",
      "\n",
      "\tTweet's text':  about write math final realli excit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#somethingrandom'] \n",
      "\n",
      "\tTweet tokenized by words:  ['about', 'write', 'math', 'final', 'realli', 'excit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['about write math final realli excit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  400 :\n",
      "\n",
      "\tTweet's text':  pull school first time life good mood find doesnt start anoth hour \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BLESSED'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pull', 'school', 'first', 'time', 'life', 'good', 'mood', 'find', 'doesnt', 'start', 'anoth', 'hour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pull school first time life good mood find doesnt start anoth hour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  401 :\n",
      "\n",
      "\tTweet's text':  drag feet smack lip scowl empti street scream phone \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['drag', 'feet', 'smack', 'lip', 'scowl', 'empti', 'street', 'scream', 'phone'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['drag feet smack lip scowl empti street scream phone'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  402 :\n",
      "\n",
      "\tTweet's text':  i say misti johnni mathi one favourit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'say', 'misti', 'johnni', 'mathi', 'one', 'favourit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i say misti johnni mathi one favourit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  403 :\n",
      "\n",
      "\tTweet's text':  scari bollywood film i watch bhootnaath \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['scari', 'bollywood', 'film', 'i', 'watch', 'bhootnaath'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['scari bollywood film i watch bhootnaath'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  404 :\n",
      "\n",
      "\tTweet's text':  read middl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Middle', '#East', '#updates', '#Assad', '#US', '#airstrikes', '#serious', '#or', '#efficient'] \n",
      "\n",
      "\tTweet tokenized by words:  ['read', 'middl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['read middl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  405 :\n",
      "\n",
      "\tTweet's text':  love work hard tri fix peopl fuck up \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'work', 'hard', 'tri', 'fix', 'peopl', 'fuck', 'up'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love work hard tri fix peopl fuck up'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  406 :\n",
      "\n",
      "\tTweet's text':  went neck deep swamp today fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#chilly'] \n",
      "\n",
      "\tTweet tokenized by words:  ['went', 'neck', 'deep', 'swamp', 'today', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['went neck deep swamp today fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  407 :\n",
      "\n",
      "\tTweet's text':  and wrap show kiddi end berkshir \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BoseL1Model2'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'wrap', 'show', 'kiddi', 'end', 'berkshir'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and wrap show kiddi end berkshir'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  408 :\n",
      "\n",
      "\tTweet's text':  gonna need k state play littl better love see team action beckthi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gon', 'na', 'need', 'k', 'state', 'play', 'littl', 'better', 'love', 'see', 'team', 'action', 'beckthi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gonna need k state play littl better love see team action beckthi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  409 :\n",
      "\n",
      "\tTweet's text':  lot drink strap \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AnalQueenAlysa', '#Four', '#8230', '#8217', '#8230'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lot', 'drink', 'strap'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lot drink strap'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  410 :\n",
      "\n",
      "\tTweet's text':  noth like wait airport \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#youcanthearit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['noth', 'like', 'wait', 'airport'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noth like wait airport'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  411 :\n",
      "\n",
      "\tTweet's text':  i love custom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#annoying', '#stoptalking'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'custom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love custom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  412 :\n",
      "\n",
      "\tTweet's text':  better bust aluminum hat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#chemtrailsdontexist', '#growup'] \n",
      "\n",
      "\tTweet tokenized by words:  ['better', 'bust', 'aluminum', 'hat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['better bust aluminum hat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  413 :\n",
      "\n",
      "\tTweet's text':  one night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pensive_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  414 :\n",
      "\n",
      "\tTweet's text':  univers alway help \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['univers', 'alway', 'help'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['univers alway help'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  415 :\n",
      "\n",
      "\tTweet's text':  that one time i feel head \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'one', 'time', 'i', 'feel', 'head'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that one time i feel head'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  416 :\n",
      "\n",
      "\tTweet's text':  we must toler embrac peac islam faith muslim peac brother \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'must', 'toler', 'embrac', 'peac', 'islam', 'faith', 'muslim', 'peac', 'brother'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we must toler embrac peac islam faith muslim peac brother'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  417 :\n",
      "\n",
      "\tTweet's text':  today i lectur crm invest sharehold valu so excit sleepi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smirking_face', 'sleeping_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'i', 'lectur', 'crm', 'invest', 'sharehold', 'valu', 'so', 'excit', 'sleepi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today i lectur crm invest sharehold valu so excit sleepi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  418 :\n",
      "\n",
      "\tTweet's text':  wait hour drive back home \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#betarocks15'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wait', 'hour', 'drive', 'back', 'home'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wait hour drive back home'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  419 :\n",
      "\n",
      "\tTweet's text':  left lunch home swansea canteen outdo gener well price portion food \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['left', 'lunch', 'home', 'swansea', 'canteen', 'outdo', 'gener', 'well', 'price', 'portion', 'food'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['left lunch home swansea canteen outdo gener well price portion food'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  420 :\n",
      "\n",
      "\tTweet's text':  oh sound like great plan \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'sound', 'like', 'great', 'plan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh sound like great plan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  421 :\n",
      "\n",
      "\tTweet's text':  doubl standard alway fun thing \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['doubl', 'standard', 'alway', 'fun', 'thing'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['doubl standard alway fun thing'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  422 :\n",
      "\n",
      "\tTweet's text':  it \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#has', '#seen', '#MonsterMMORPG', '#bean'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  423 :\n",
      "\n",
      "\tTweet's text':  mayb differ propos the girl wear differ shoe guy wear differ coat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mayb', 'differ', 'propos', 'the', 'girl', 'wear', 'differ', 'shoe', 'guy', 'wear', 'differ', 'coat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mayb differ propos the girl wear differ shoe guy wear differ coat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  424 :\n",
      "\n",
      "\tTweet's text':  so far today i burn tongu coffe saw dead guy freeway chip windshield truck \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#gonnahaveagoodday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'far', 'today', 'i', 'burn', 'tongu', 'coffe', 'saw', 'dead', 'guy', 'freeway', 'chip', 'windshield', 'truck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so far today i burn tongu coffe saw dead guy freeway chip windshield truck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  425 :\n",
      "\n",
      "\tTweet's text':  ceeeeebz work allow dat ting fam \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ceeeeebz', 'work', 'allow', 'dat', 'ting', 'fam'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ceeeeebz work allow dat ting fam'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  426 :\n",
      "\n",
      "\tTweet's text':  had sleep got school happi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['had', 'sleep', 'got', 'school', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['had sleep got school happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  427 :\n",
      "\n",
      "\tTweet's text':  love love love left side face swollen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['loudly_crying_face', 'pouting_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'love', 'love', 'left', 'side', 'face', 'swollen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love love love left side face swollen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  428 :\n",
      "\n",
      "\tTweet's text':  nice see admit error slightli differ earlier stat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'see', 'admit', 'error', 'slightli', 'differ', 'earlier', 'stat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice see admit error slightli differ earlier stat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  429 :\n",
      "\n",
      "\tTweet's text':  thing made go harm us given us lesson teach someon weaker \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thing', 'made', 'go', 'harm', 'us', 'given', 'us', 'lesson', 'teach', 'someon', 'weaker'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thing made go harm us given us lesson teach someon weaker'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  430 :\n",
      "\n",
      "\tTweet's text':  good old day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'old', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good old day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  431 :\n",
      "\n",
      "\tTweet's text':  mirror mirror wall i find happi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mirror', 'mirror', 'wall', 'i', 'find', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mirror mirror wall i find happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  432 :\n",
      "\n",
      "\tTweet's text':  that alway great way boost self esteem \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'alway', 'great', 'way', 'boost', 'self', 'esteem'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that alway great way boost self esteem'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  433 :\n",
      "\n",
      "\tTweet's text':  i pretti sure i snowman problem \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'pretti', 'sure', 'i', 'snowman', 'problem'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i pretti sure i snowman problem'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  434 :\n",
      "\n",
      "\tTweet's text':  watch grandpar parent pay bill realli excit futur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'grandpar', 'parent', 'pay', 'bill', 'realli', 'excit', 'futur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch grandpar parent pay bill realli excit futur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  435 :\n",
      "\n",
      "\tTweet's text':  yeah nice hair babe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'nice', 'hair', 'babe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah nice hair babe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  436 :\n",
      "\n",
      "\tTweet's text':  didn carolina beat tampa bay pick sheet tb win \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['didn', 'carolina', 'beat', 'tampa', 'bay', 'pick', 'sheet', 'tb', 'win'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['didn carolina beat tampa bay pick sheet tb win'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  437 :\n",
      "\n",
      "\tTweet's text':  i guess stop insult \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'stop', 'insult'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guess stop insult'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  438 :\n",
      "\n",
      "\tTweet's text':  trip feet three time hall \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#soclumsy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['trip', 'feet', 'three', 'time', 'hall'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['trip feet three time hall'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  439 :\n",
      "\n",
      "\tTweet's text':  i feel like crap today so instead redbul i drink someth healthi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NewYearNewMe', '#TotallyStillGoingToDrinkTheRedbull'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'feel', 'like', 'crap', 'today', 'so', 'instead', 'redbul', 'i', 'drink', 'someth', 'healthi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i feel like crap today so instead redbul i drink someth healthi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  440 :\n",
      "\n",
      "\tTweet's text':  about fuck media exam \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#actuallyihopeso'] \n",
      "\n",
      "\tTweet tokenized by words:  ['about', 'fuck', 'media', 'exam'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['about fuck media exam'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  441 :\n",
      "\n",
      "\tTweet's text':  particip th forum profit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#almajmoua', '#CSR', '#lebanon', '#togetherwegrow', '#microfinance', '#supporting'] \n",
      "\n",
      "\tTweet tokenized by words:  ['particip', 'th', 'forum', 'profit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['particip th forum profit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  442 :\n",
      "\n",
      "\tTweet's text':  whoever run yeovil town fc twitter account fire start line look like mxit fantasi leagu team \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whoever', 'run', 'yeovil', 'town', 'fc', 'twitter', 'account', 'fire', 'start', 'line', 'look', 'like', 'mxit', 'fantasi', 'leagu', 'team'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whoever run yeovil town fc twitter account fire start line look like mxit fantasi leagu team'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  443 :\n",
      "\n",
      "\tTweet's text':  a teen name bud weisser arrest cop break st loui parti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'teen', 'name', 'bud', 'weisser', 'arrest', 'cop', 'break', 'st', 'loui', 'parti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a teen name bud weisser arrest cop break st loui parti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  444 :\n",
      "\n",
      "\tTweet's text':  at length forget fundament commun sanghi hindu fanat rss backyard \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['at', 'length', 'forget', 'fundament', 'commun', 'sanghi', 'hindu', 'fanat', 'rss', 'backyard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['at length forget fundament commun sanghi hindu fanat rss backyard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  445 :\n",
      "\n",
      "\tTweet's text':  kmrheadlin electr gener kashmir illumin whole india pm illumin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Kashmir'] \n",
      "\n",
      "\tTweet tokenized by words:  ['kmrheadlin', 'electr', 'gener', 'kashmir', 'illumin', 'whole', 'india', 'pm', 'illumin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kmrheadlin electr gener kashmir illumin whole india pm illumin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  446 :\n",
      "\n",
      "\tTweet's text':  a british world champion one demand popular sport earth yeah cours i sarcast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'british', 'world', 'champion', 'one', 'demand', 'popular', 'sport', 'earth', 'yeah', 'cours', 'i', 'sarcast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a british world champion one demand popular sport earth yeah cours i sarcast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  447 :\n",
      "\n",
      "\tTweet's text':  got spine caus i feel pain back \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thinkpositive'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'spine', 'caus', 'i', 'feel', 'pain', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['got spine caus i feel pain back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  448 :\n",
      "\n",
      "\tTweet's text':  pour rain sing wonder time year walk offic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mondaymorning'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pour', 'rain', 'sing', 'wonder', 'time', 'year', 'walk', 'offic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pour rain sing wonder time year walk offic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  449 :\n",
      "\n",
      "\tTweet's text':  best asian style went group pretti boy all wear black suit tie bow how stylish \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#2014MAMA'] \n",
      "\n",
      "\tTweet tokenized by words:  ['best', 'asian', 'style', 'went', 'group', 'pretti', 'boy', 'all', 'wear', 'black', 'suit', 'tie', 'bow', 'how', 'stylish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['best asian style went group pretti boy all wear black suit tie bow how stylish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  450 :\n",
      "\n",
      "\tTweet's text':  whi paper sharp someon put ban paper \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#liberalmentality'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'paper', 'sharp', 'someon', 'put', 'ban', 'paper'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi paper sharp someon put ban paper'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  451 :\n",
      "\n",
      "\tTweet's text':  jonah hill funni kevin hart smith jim carrey sacha baron cohen \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jonah', 'hill', 'funni', 'kevin', 'hart', 'smith', 'jim', 'carrey', 'sacha', 'baron', 'cohen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jonah hill funni kevin hart smith jim carrey sacha baron cohen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  452 :\n",
      "\n",
      "\tTweet's text':  thursday arizona court appeal order \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Arizona', '#Court', '#Of', '#Appeals', '#Decides', '#To', '#Retry', '#Milke'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thursday', 'arizona', 'court', 'appeal', 'order'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thursday arizona court appeal order'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  453 :\n",
      "\n",
      "\tTweet's text':  i doubt week could get better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'doubt', 'week', 'could', 'get', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i doubt week could get better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  454 :\n",
      "\n",
      "\tTweet's text':  damn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#communication', '#truth'] \n",
      "\n",
      "\tTweet tokenized by words:  ['damn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['damn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  455 :\n",
      "\n",
      "\tTweet's text':  i get bed lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'get', 'bed', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i get bed lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  456 :\n",
      "\n",
      "\tTweet's text':  some realli love critic zoella let rest pleas i wonder would \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['some', 'realli', 'love', 'critic', 'zoella', 'let', 'rest', 'pleas', 'i', 'wonder', 'would'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['some realli love critic zoella let rest pleas i wonder would'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  457 :\n",
      "\n",
      "\tTweet's text':  i bring work the hoop one hit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'bring', 'work', 'the', 'hoop', 'one', 'hit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i bring work the hoop one hit'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------\n",
      "\n",
      "Tweet  458 :\n",
      "\n",
      "\tTweet's text':  transfer fund given \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['transfer', 'fund', 'given'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['transfer fund given'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  459 :\n",
      "\n",
      "\tTweet's text':  galliani alreadi jump chang room like discov seedorf told along thing pippo say \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['galliani', 'alreadi', 'jump', 'chang', 'room', 'like', 'discov', 'seedorf', 'told', 'along', 'thing', 'pippo', 'say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['galliani alreadi jump chang room like discov seedorf told along thing pippo say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  460 :\n",
      "\n",
      "\tTweet's text':  hey alex thank support my fb page bless success \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'alex', 'thank', 'support', 'my', 'fb', 'page', 'bless', 'success'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey alex thank support my fb page bless success'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  461 :\n",
      "\n",
      "\tTweet's text':  peopl speak law protest fight justic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ModelTownNotForgotten', '#PAT', '#PTI', '#GoNawazGo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'speak', 'law', 'protest', 'fight', 'justic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl speak law protest fight justic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  462 :\n",
      "\n",
      "\tTweet's text':  ohh climb rope just like everi commando super talent \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TakeMeOut'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ohh', 'climb', 'rope', 'just', 'like', 'everi', 'commando', 'super', 'talent'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ohh climb rope just like everi commando super talent'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  463 :\n",
      "\n",
      "\tTweet's text':  probabl go fail tomorrow yayi one direct \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GlobalArtistHMA', '#MTVStars'] \n",
      "\n",
      "\tTweet tokenized by words:  ['probabl', 'go', 'fail', 'tomorrow', 'yayi', 'one', 'direct'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['probabl go fail tomorrow yayi one direct'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  464 :\n",
      "\n",
      "\tTweet's text':  feed flesh blood make alley way smell terribl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#90ssarcasm', '#thesun', '#thingsthatarewrong'] \n",
      "\n",
      "\tTweet tokenized by words:  ['feed', 'flesh', 'blood', 'make', 'alley', 'way', 'smell', 'terribl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feed flesh blood make alley way smell terribl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  465 :\n",
      "\n",
      "\tTweet's text':  is sleep medic like ambien better rt thi alcohol sleep \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'sleep', 'medic', 'like', 'ambien', 'better', 'rt', 'thi', 'alcohol', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is sleep medic like ambien better rt thi alcohol sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  466 :\n",
      "\n",
      "\tTweet's text':  einstein would amus strider jump around time \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['einstein', 'would', 'amus', 'strider', 'jump', 'around', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['einstein would amus strider jump around time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  467 :\n",
      "\n",
      "\tTweet's text':  love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  468 :\n",
      "\n",
      "\tTweet's text':  last day pk riga hotel \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Riga', '#self', '#finnishgirl', '#businesswoman'] \n",
      "\n",
      "\tTweet tokenized by words:  ['last', 'day', 'pk', 'riga', 'hotel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['last day pk riga hotel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  469 :\n",
      "\n",
      "\tTweet's text':  well morn go nice \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'morn', 'go', 'nice'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well morn go nice'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  470 :\n",
      "\n",
      "\tTweet's text':  sad i christma jumper thank super fast deliveri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sad', 'i', 'christma', 'jumper', 'thank', 'super', 'fast', 'deliveri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sad i christma jumper thank super fast deliveri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  471 :\n",
      "\n",
      "\tTweet's text':  i love wake everyday run mile favorit part armi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wake', 'everyday', 'run', 'mile', 'favorit', 'part', 'armi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wake everyday run mile favorit part armi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  472 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Germany', '#ECB', '#Weidmann', '#says', '#German', '#2015', '#growth', '#may', '#be', '#better', '#than', '#expected'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  473 :\n",
      "\n",
      "\tTweet's text':  a deal negoti gtaa that deal hidden built price tix whi secreci \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#UPX', '#TOpoli'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'deal', 'negoti', 'gtaa', 'that', 'deal', 'hidden', 'built', 'price', 'tix', 'whi', 'secreci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a deal negoti gtaa that deal hidden built price tix whi secreci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  474 :\n",
      "\n",
      "\tTweet's text':  yup must good ivi leagu educ alot good \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yup', 'must', 'good', 'ivi', 'leagu', 'educ', 'alot', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yup must good ivi leagu educ alot good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  475 :\n",
      "\n",
      "\tTweet's text':  we live small world day stori end australian news \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#LAFire'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'live', 'small', 'world', 'day', 'stori', 'end', 'australian', 'news'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we live small world day stori end australian news'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  476 :\n",
      "\n",
      "\tTweet's text':  one pleas cri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'pleas', 'cri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one pleas cri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  477 :\n",
      "\n",
      "\tTweet's text':  love life \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  478 :\n",
      "\n",
      "\tTweet's text':  half deserv yet ever want \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['half', 'deserv', 'yet', 'ever', 'want'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['half deserv yet ever want'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  479 :\n",
      "\n",
      "\tTweet's text':  a protest peac forc stop earn livelihood \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'protest', 'peac', 'forc', 'stop', 'earn', 'livelihood'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a protest peac forc stop earn livelihood'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  480 :\n",
      "\n",
      "\tTweet's text':  most use algorithm i learn class far find substr use fast fourier transform \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['most', 'use', 'algorithm', 'i', 'learn', 'class', 'far', 'find', 'substr', 'use', 'fast', 'fourier', 'transform'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['most use algorithm i learn class far find substr use fast fourier transform'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  481 :\n",
      "\n",
      "\tTweet's text':  shakespear great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['pistol', 'face_with_no_good_gesture'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shakespear', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shakespear great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  482 :\n",
      "\n",
      "\tTweet's text':  where dannymakkisyria the gunman also said monitor social media activ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ShamiWitness', '#sydneysiege'] \n",
      "\n",
      "\tTweet tokenized by words:  ['where', 'dannymakkisyria', 'the', 'gunman', 'also', 'said', 'monitor', 'social', 'media', 'activ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['where dannymakkisyria the gunman also said monitor social media activ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  483 :\n",
      "\n",
      "\tTweet's text':  anoth case away lad put song tell north london \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TyneWeirSunday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'case', 'away', 'lad', 'put', 'song', 'tell', 'north', 'london'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth case away lad put song tell north london'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  484 :\n",
      "\n",
      "\tTweet's text':  decri hate crime bosnian man back old game incit hate torward muslim \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['decri', 'hate', 'crime', 'bosnian', 'man', 'back', 'old', 'game', 'incit', 'hate', 'torward', 'muslim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['decri hate crime bosnian man back old game incit hate torward muslim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  485 :\n",
      "\n",
      "\tTweet's text':  mmsevent sat dec tabl book r includ bottl uh oh i smell much love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OneloveFestival'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mmsevent', 'sat', 'dec', 'tabl', 'book', 'r', 'includ', 'bottl', 'uh', 'oh', 'i', 'smell', 'much', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mmsevent sat dec tabl book r includ bottl uh oh i smell much love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  486 :\n",
      "\n",
      "\tTweet's text':  get fat honeymoon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'fat', 'honeymoon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get fat honeymoon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  487 :\n",
      "\n",
      "\tTweet's text':  say obama indoctrin rigid ideolog \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hannity'] \n",
      "\n",
      "\tTweet tokenized by words:  ['say', 'obama', 'indoctrin', 'rigid', 'ideolog'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['say obama indoctrin rigid ideolog'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  488 :\n",
      "\n",
      "\tTweet's text':  lol timehop guy though \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'timehop', 'guy', 'though'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol timehop guy though'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  489 :\n",
      "\n",
      "\tTweet's text':  yeah i set overwork rooki pitcher total okay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'i', 'set', 'overwork', 'rooki', 'pitcher', 'total', 'okay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah i set overwork rooki pitcher total okay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  490 :\n",
      "\n",
      "\tTweet's text':  putin prais constitut court defend arbitrari action part govern \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['putin', 'prais', 'constitut', 'court', 'defend', 'arbitrari', 'action', 'part', 'govern'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['putin prais constitut court defend arbitrari action part govern'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  491 :\n",
      "\n",
      "\tTweet's text':  i couldnt help i bad \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'couldnt', 'help', 'i', 'bad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i couldnt help i bad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  492 :\n",
      "\n",
      "\tTweet's text':  i love watch liverpool truli inspir \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'watch', 'liverpool', 'truli', 'inspir'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love watch liverpool truli inspir'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  493 :\n",
      "\n",
      "\tTweet's text':  i ad video playlist giveaway \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'ad', 'video', 'playlist', 'giveaway'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i ad video playlist giveaway'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  494 :\n",
      "\n",
      "\tTweet's text':  off search christma gift dad bc procrastin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['wrapped_present'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['off', 'search', 'christma', 'gift', 'dad', 'bc', 'procrastin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['off search christma gift dad bc procrastin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  495 :\n",
      "\n",
      "\tTweet's text':  i realli excit brendan fraser birthday tomorrow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BrendanFraserBirthdayBash'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'realli', 'excit', 'brendan', 'fraser', 'birthday', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i realli excit brendan fraser birthday tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  496 :\n",
      "\n",
      "\tTweet's text':  that infam pepper shaker replac \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'infam', 'pepper', 'shaker', 'replac'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that infam pepper shaker replac'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  497 :\n",
      "\n",
      "\tTweet's text':  save manag make money join make \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Discounts', '#Vacations'] \n",
      "\n",
      "\tTweet tokenized by words:  ['save', 'manag', 'make', 'money', 'join', 'make'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['save manag make money join make'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  498 :\n",
      "\n",
      "\tTweet's text':  lol show name show gotta quit caus snake hurt arm \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EatenAlive', '#goodtv', '#garbage'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'show', 'name', 'show', 'got', 'ta', 'quit', 'caus', 'snake', 'hurt', 'arm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol show name show gotta quit caus snake hurt arm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  499 :\n",
      "\n",
      "\tTweet's text':  cia report highlight stark differ b present former administr approach nat l secur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cia', 'report', 'highlight', 'stark', 'differ', 'b', 'present', 'former', 'administr', 'approach', 'nat', 'l', 'secur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cia report highlight stark differ b present former administr approach nat l secur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  500 :\n",
      "\n",
      "\tTweet's text':  you guy serious need tri game \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BananaBonanza'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'guy', 'serious', 'need', 'tri', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you guy serious need tri game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  501 :\n",
      "\n",
      "\tTweet's text':  thank notic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'notic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank notic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  502 :\n",
      "\n",
      "\tTweet's text':  well weekend now d have nice monday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['D|Have'] \n",
      "\n",
      "\tTweet's hashtags':  ['#TwitterTime'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'weekend', 'now', 'd', 'have', 'nice', 'monday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well weekend now d have nice monday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  503 :\n",
      "\n",
      "\tTweet's text':  so glad work \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'glad', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so glad work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  504 :\n",
      "\n",
      "\tTweet's text':  whenev i write anyth word immigr i happi back forth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whenev', 'i', 'write', 'anyth', 'word', 'immigr', 'i', 'happi', 'back', 'forth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whenev i write anyth word immigr i happi back forth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  505 :\n",
      "\n",
      "\tTweet's text':  i gunna sit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'gunna', 'sit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i gunna sit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  506 :\n",
      "\n",
      "\tTweet's text':  they probabl contract work free \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'probabl', 'contract', 'work', 'free'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they probabl contract work free'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  507 :\n",
      "\n",
      "\tTweet's text':  yay anoth outag less hour keep good work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'anoth', 'outag', 'less', 'hour', 'keep', 'good', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay anoth outag less hour keep good work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  508 :\n",
      "\n",
      "\tTweet's text':  a happi birthday toast honor tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'happi', 'birthday', 'toast', 'honor', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a happi birthday toast honor tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  509 :\n",
      "\n",
      "\tTweet's text':  i liter plan everi night entir vacat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'liter', 'plan', 'everi', 'night', 'entir', 'vacat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i liter plan everi night entir vacat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  510 :\n",
      "\n",
      "\tTweet's text':  kevin durant pt shoot nigga ineffici sinc came \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['kevin', 'durant', 'pt', 'shoot', 'nigga', 'ineffici', 'sinc', 'came'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kevin durant pt shoot nigga ineffici sinc came'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  511 :\n",
      "\n",
      "\tTweet's text':  i alway look super cute guy come fix stuff condo \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'alway', 'look', 'super', 'cute', 'guy', 'come', 'fix', 'stuff', 'condo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i alway look super cute guy come fix stuff condo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  512 :\n",
      "\n",
      "\tTweet's text':  wow neat nice mini tour belfast well i think ask one xma larri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'neat', 'nice', 'mini', 'tour', 'belfast', 'well', 'i', 'think', 'ask', 'one', 'xma', 'larri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow neat nice mini tour belfast well i think ask one xma larri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  513 :\n",
      "\n",
      "\tTweet's text':  skdar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#New', '#color', '#new', '#beginning', '#new', '#goals', '#dont', '#giveup', '#never', '#life', '#should', '#be', '#easy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['skdar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['skdar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  514 :\n",
      "\n",
      "\tTweet's text':  gotta hand realli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['clapping_hands_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'hand', 'realli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta hand realli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  515 :\n",
      "\n",
      "\tTweet's text':  thank god kany give unknown help \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'god', 'kany', 'give', 'unknown', 'help'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank god kany give unknown help'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  516 :\n",
      "\n",
      "\tTweet's text':  good thing i scare clown kindergarten teacher dress one today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['expressionless_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'thing', 'i', 'scare', 'clown', 'kindergarten', 'teacher', 'dress', 'one', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good thing i scare clown kindergarten teacher dress one today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  517 :\n",
      "\n",
      "\tTweet's text':  luv hair frozen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['luv', 'hair', 'frozen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['luv hair frozen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  518 :\n",
      "\n",
      "\tTweet's text':  uncertainti principl whatev studi also chang \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Heisenberg', '#JurassicParkTheLostWorld', '#JurassicWorld', '#BreakingBad'] \n",
      "\n",
      "\tTweet tokenized by words:  ['uncertainti', 'principl', 'whatev', 'studi', 'also', 'chang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['uncertainti principl whatev studi also chang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  519 :\n",
      "\n",
      "\tTweet's text':  glad i \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['glad', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['glad i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  520 :\n",
      "\n",
      "\tTweet's text':  a cool look cool mind need parti night quiksilvergoessuperson \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#QuiksilverGoesSupersonic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'cool', 'look', 'cool', 'mind', 'need', 'parti', 'night', 'quiksilvergoessuperson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a cool look cool mind need parti night quiksilvergoessuperson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  521 :\n",
      "\n",
      "\tTweet's text':  hope tulisa get job back next year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#xfactor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hope', 'tulisa', 'get', 'job', 'back', 'next', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hope tulisa get job back next year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  522 :\n",
      "\n",
      "\tTweet's text':  soccer game fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['soccer', 'game', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['soccer game fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  523 :\n",
      "\n",
      "\tTweet's text':  i know fredo you broke heart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'fredo', 'you', 'broke', 'heart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know fredo you broke heart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  524 :\n",
      "\n",
      "\tTweet's text':  just realiz i watch week episod degrassi i eventu get around \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'realiz', 'i', 'watch', 'week', 'episod', 'degrassi', 'i', 'eventu', 'get', 'around'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just realiz i watch week episod degrassi i eventu get around'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  525 :\n",
      "\n",
      "\tTweet's text':  shop mall take year off your skin seacret miner dead sea \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shop', 'mall', 'take', 'year', 'off', 'your', 'skin', 'seacret', 'miner', 'dead', 'sea'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shop mall take year off your skin seacret miner dead sea'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  526 :\n",
      "\n",
      "\tTweet's text':  ok get ta fix \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ok', 'get', 'ta', 'fix'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ok get ta fix'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  527 :\n",
      "\n",
      "\tTweet's text':  fit purpos labour sort \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#coalition', '#Labour'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fit', 'purpos', 'labour', 'sort'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fit purpos labour sort'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  528 :\n",
      "\n",
      "\tTweet's text':  whi i wide awak right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'i', 'wide', 'awak', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi i wide awak right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  529 :\n",
      "\n",
      "\tTweet's text':  kohli show gut scoobi doo \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CaptainCourageous'] \n",
      "\n",
      "\tTweet tokenized by words:  ['kohli', 'show', 'gut', 'scoobi', 'doo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kohli show gut scoobi doo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  530 :\n",
      "\n",
      "\tTweet's text':  your opinion affect i go keep live life \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['your', 'opinion', 'affect', 'i', 'go', 'keep', 'live', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['your opinion affect i go keep live life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  531 :\n",
      "\n",
      "\tTweet's text':  that one long walk \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['ok_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoMe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'one', 'long', 'walk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that one long walk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  532 :\n",
      "\n",
      "\tTweet's text':  work christma eve christma day can wait \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'christma', 'eve', 'christma', 'day', 'can', 'wait'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work christma eve christma day can wait'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  533 :\n",
      "\n",
      "\tTweet's text':  wecameashaile hour car ride and i cant sleep in car yayaayayayayay fun bff \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wecameashaile', 'hour', 'car', 'ride', 'and', 'i', 'cant', 'sleep', 'in', 'car', 'yayaayayayayay', 'fun', 'bff'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wecameashaile hour car ride and i cant sleep in car yayaayayayayay fun bff'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  534 :\n",
      "\n",
      "\tTweet's text':  oh i tip gamerg hand now know end game \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'i', 'tip', 'gamerg', 'hand', 'now', 'know', 'end', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh i tip gamerg hand now know end game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  535 :\n",
      "\n",
      "\tTweet's text':  thegoldcoin class done research \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#latergram', '#gradschool', '#basic', '#blessed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thegoldcoin', 'class', 'done', 'research'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thegoldcoin class done research'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  536 :\n",
      "\n",
      "\tTweet's text':  i chang gazilion time configur not check updat it nice everi five minut ask updat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#java'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'chang', 'gazilion', 'time', 'configur', 'not', 'check', 'updat', 'it', 'nice', 'everi', 'five', 'minut', 'ask', 'updat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i chang gazilion time configur not check updat it nice everi five minut ask updat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  537 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TeenAnalCasting', '#Alice'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  538 :\n",
      "\n",
      "\tTweet's text':  halfway thorough workday woooo \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['halfway', 'thorough', 'workday', 'woooo'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by sentences:  ['halfway thorough workday woooo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  539 :\n",
      "\n",
      "\tTweet's text':  don think second i drown memori worth whiskey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'think', 'second', 'i', 'drown', 'memori', 'worth', 'whiskey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don think second i drown memori worth whiskey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  540 :\n",
      "\n",
      "\tTweet's text':  youv got love effici two day servic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#7DayService', '#prioritymail', '#hahahaha'] \n",
      "\n",
      "\tTweet tokenized by words:  ['youv', 'got', 'love', 'effici', 'two', 'day', 'servic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['youv got love effici two day servic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  541 :\n",
      "\n",
      "\tTweet's text':  no secur cartel charg huge sum money illeg cross us \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'secur', 'cartel', 'charg', 'huge', 'sum', 'money', 'illeg', 'cross', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no secur cartel charg huge sum money illeg cross us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  542 :\n",
      "\n",
      "\tTweet's text':  one favourit thing go fanshaw walk z build \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'favourit', 'thing', 'go', 'fanshaw', 'walk', 'z', 'build'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one favourit thing go fanshaw walk z build'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  543 :\n",
      "\n",
      "\tTweet's text':  argument butler moral \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['argument', 'butler', 'moral'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['argument butler moral'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  544 :\n",
      "\n",
      "\tTweet's text':  those wave epic he \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['those', 'wave', 'epic', 'he'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['those wave epic he'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  545 :\n",
      "\n",
      "\tTweet's text':  bad cnn conceiv stori \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#truth', '#news', '#hypocrite', '#expose', '#fake', '#exposed2014', '#boycott', '#sponsors'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bad', 'cnn', 'conceiv', 'stori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bad cnn conceiv stori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  546 :\n",
      "\n",
      "\tTweet's text':  would tell ya \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['would', 'tell', 'ya'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['would tell ya'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  547 :\n",
      "\n",
      "\tTweet's text':  drop new singl singl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['drop', 'new', 'singl', 'singl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['drop new singl singl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  548 :\n",
      "\n",
      "\tTweet's text':  can even explain excit i tomorrow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['hundred_points_symbol', 'basketball_and_hoop'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'even', 'explain', 'excit', 'i', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can even explain excit i tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  549 :\n",
      "\n",
      "\tTweet's text':  of spice girl pick \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['of', 'spice', 'girl', 'pick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['of spice girl pick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  550 :\n",
      "\n",
      "\tTweet's text':  have gotten tree yet xma tree nail wrap avail \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nailwraps', '#nailart'] \n",
      "\n",
      "\tTweet tokenized by words:  ['have', 'gotten', 'tree', 'yet', 'xma', 'tree', 'nail', 'wrap', 'avail'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['have gotten tree yet xma tree nail wrap avail'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  551 :\n",
      "\n",
      "\tTweet's text':  welsh devolut how \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['welsh', 'devolut', 'how'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['welsh devolut how'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  552 :\n",
      "\n",
      "\tTweet's text':  can alway impart especi special day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#countonmother', '#wordsofkindness'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'alway', 'impart', 'especi', 'special', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can alway impart especi special day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  553 :\n",
      "\n",
      "\tTweet's text':  i glad h m employ enough staff today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nohelp', '#terrible'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'glad', 'h', 'm', 'employ', 'enough', 'staff', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i glad h m employ enough staff today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  554 :\n",
      "\n",
      "\tTweet's text':  aaaaaaaaand back er hooray sleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aaaaaaaaand', 'back', 'er', 'hooray', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aaaaaaaaand back er hooray sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  555 :\n",
      "\n",
      "\tTweet's text':  whi ye of cours i use lot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'ye', 'of', 'cours', 'i', 'use', 'lot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi ye of cours i use lot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  556 :\n",
      "\n",
      "\tTweet's text':  my dad let drywal christma just i alway want \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'dad', 'let', 'drywal', 'christma', 'just', 'i', 'alway', 'want'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my dad let drywal christma just i alway want'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  557 :\n",
      "\n",
      "\tTweet's text':  feel well \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'well'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel well'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  558 :\n",
      "\n",
      "\tTweet's text':  thi christma number \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#accounting', '#absolutetosh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'christma', 'number'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi christma number'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  559 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Italy', '#Cabinet', '#approves', '#first', '#planks', '#Renzi', '#labour', '#reform'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  560 :\n",
      "\n",
      "\tTweet's text':  same day th anniversari brave critic abandon conformist \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FreeSpeechMovement', '#Press'] \n",
      "\n",
      "\tTweet tokenized by words:  ['same', 'day', 'th', 'anniversari', 'brave', 'critic', 'abandon', 'conformist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['same day th anniversari brave critic abandon conformist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  561 :\n",
      "\n",
      "\tTweet's text':  i realli need shoot someth soon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'realli', 'need', 'shoot', 'someth', 'soon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i realli need shoot someth soon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  562 :\n",
      "\n",
      "\tTweet's text':  also i would tone joke though difficult properli convey tweet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['also', 'i', 'would', 'tone', 'joke', 'though', 'difficult', 'properli', 'convey', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['also i would tone joke though difficult properli convey tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  563 :\n",
      "\n",
      "\tTweet's text':  do like qualiti go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dancemusic', '#UK', '#NightClub'] \n",
      "\n",
      "\tTweet tokenized by words:  ['do', 'like', 'qualiti', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['do like qualiti go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  564 :\n",
      "\n",
      "\tTweet's text':  know damn thing basebal \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'damn', 'thing', 'basebal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know damn thing basebal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  565 :\n",
      "\n",
      "\tTweet's text':  ye much logic support crimin attack polic offic protect life properti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HandsUpDontShoot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'much', 'logic', 'support', 'crimin', 'attack', 'polic', 'offic', 'protect', 'life', 'properti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye much logic support crimin attack polic offic protect life properti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  566 :\n",
      "\n",
      "\tTweet's text':  are go origin plan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['are', 'go', 'origin', 'plan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['are go origin plan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  567 :\n",
      "\n",
      "\tTweet's text':  larg compani pay tax get away pay get lock fine \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['larg', 'compani', 'pay', 'tax', 'get', 'away', 'pay', 'get', 'lock', 'fine'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['larg compani pay tax get away pay get lock fine'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  568 :\n",
      "\n",
      "\tTweet's text':  upper deck definit seem like philli south \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['upper', 'deck', 'definit', 'seem', 'like', 'philli', 'south'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['upper deck definit seem like philli south'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  569 :\n",
      "\n",
      "\tTweet's text':  get midterm back great start day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#badday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'midterm', 'back', 'great', 'start', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get midterm back great start day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  570 :\n",
      "\n",
      "\tTweet's text':  moz woot woot whiteboard friday favorit friday activ \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['moz', 'woot', 'woot', 'whiteboard', 'friday', 'favorit', 'friday', 'activ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['moz woot woot whiteboard friday favorit friday activ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  571 :\n",
      "\n",
      "\tTweet's text':  life requir one strong differ time i wear red brief pant u need lil lust see em \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TooMuch'] \n",
      "\n",
      "\tTweet tokenized by words:  ['life', 'requir', 'one', 'strong', 'differ', 'time', 'i', 'wear', 'red', 'brief', 'pant', 'u', 'need', 'lil', 'lust', 'see', 'em'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['life requir one strong differ time i wear red brief pant u need lil lust see em'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  572 :\n",
      "\n",
      "\tTweet's text':  i sign \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'sign'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i sign'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  573 :\n",
      "\n",
      "\tTweet's text':  well play matt well play \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'play', 'matt', 'well', 'play'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well play matt well play'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  574 :\n",
      "\n",
      "\tTweet's text':  where rodger brigad \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['where', 'rodger', 'brigad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['where rodger brigad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  575 :\n",
      "\n",
      "\tTweet's text':  holi fuck lyric fit good movi interstellar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#chills', '#freakyfriday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['holi', 'fuck', 'lyric', 'fit', 'good', 'movi', 'interstellar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['holi fuck lyric fit good movi interstellar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  576 :\n",
      "\n",
      "\tTweet's text':  porygon found \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#are', '#wild', '#working'] \n",
      "\n",
      "\tTweet tokenized by words:  ['porygon', 'found'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['porygon found'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  577 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#2n1Edition'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  578 :\n",
      "\n",
      "\tTweet's text':  lol i reckon wa jest i hope \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'i', 'reckon', 'wa', 'jest', 'i', 'hope'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol i reckon wa jest i hope'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  579 :\n",
      "\n",
      "\tTweet's text':  today day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pensive_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  580 :\n",
      "\n",
      "\tTweet's text':  becaus need excus pop open my dream mcdonald grand cru \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ChampagneExcuses'] \n",
      "\n",
      "\tTweet tokenized by words:  ['becaus', 'need', 'excus', 'pop', 'open', 'my', 'dream', 'mcdonald', 'grand', 'cru'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['becaus need excus pop open my dream mcdonald grand cru'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  581 :\n",
      "\n",
      "\tTweet's text':  expert doubt north korea hack soni cb dalla fort worth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hacker', '#hacked'] \n",
      "\n",
      "\tTweet tokenized by words:  ['expert', 'doubt', 'north', 'korea', 'hack', 'soni', 'cb', 'dalla', 'fort', 'worth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['expert doubt north korea hack soni cb dalla fort worth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  582 :\n",
      "\n",
      "\tTweet's text':  the raider i guess see thing play tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'raider', 'i', 'guess', 'see', 'thing', 'play', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the raider i guess see thing play tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  583 :\n",
      "\n",
      "\tTweet's text':  oh hello flu thank fool think gone i miss much \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#flu', '#yaay'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'hello', 'flu', 'thank', 'fool', 'think', 'gone', 'i', 'miss', 'much'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh hello flu thank fool think gone i miss much'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  584 :\n",
      "\n",
      "\tTweet's text':  the word trust come mouth rich \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Trust', '#Holder', '#Obama', '#hypocrisy', '#IRS', '#racebaiters'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'word', 'trust', 'come', 'mouth', 'rich'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the word trust come mouth rich'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  585 :\n",
      "\n",
      "\tTweet's text':  when show valid railcard she charg full price anyway great servic tamworth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'show', 'valid', 'railcard', 'she', 'charg', 'full', 'price', 'anyway', 'great', 'servic', 'tamworth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when show valid railcard she charg full price anyway great servic tamworth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  586 :\n",
      "\n",
      "\tTweet's text':  suddenli w wada \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['suddenli', 'w', 'wada'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['suddenli w wada'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  587 :\n",
      "\n",
      "\tTweet's text':  sail \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#me', '#selfie', '#ootd', '#cool', '#cute', '#girl', '#tumblr', '#black', '#style', '#rock', '#punk', '#vsco'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sail'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sail'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  588 :\n",
      "\n",
      "\tTweet's text':  a romant candlelit dinner two would cost less switch light eskom pic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'romant', 'candlelit', 'dinner', 'two', 'would', 'cost', 'less', 'switch', 'light', 'eskom', 'pic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a romant candlelit dinner two would cost less switch light eskom pic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  589 :\n",
      "\n",
      "\tTweet's text':  accordng lawyr evid support side could hav supportd mani differnt scenario warrant indict \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['accordng', 'lawyr', 'evid', 'support', 'side', 'could', 'hav', 'supportd', 'mani', 'differnt', 'scenario', 'warrant', 'indict'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['accordng lawyr evid support side could hav supportd mani differnt scenario warrant indict'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  590 :\n",
      "\n",
      "\tTweet's text':  the fan need heard tho rt wenger will never quitt sorri lad for few year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'fan', 'need', 'heard', 'tho', 'rt', 'wenger', 'will', 'never', 'quitt', 'sorri', 'lad', 'for', 'few', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the fan need heard tho rt wenger will never quitt sorri lad for few year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  591 :\n",
      "\n",
      "\tTweet's text':  my prayer answer we out \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'prayer', 'answer', 'we', 'out'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my prayer answer we out'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  592 :\n",
      "\n",
      "\tTweet's text':  fulli charg portabl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Anker', '#Fail'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fulli', 'charg', 'portabl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fulli charg portabl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  593 :\n",
      "\n",
      "\tTweet's text':  as need water pastur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['as', 'need', 'water', 'pastur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['as need water pastur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  594 :\n",
      "\n",
      "\tTweet's text':  it crackhead uncl hbcu famili kkoolpointz everi hbcu alabama look alabama state sideway lmao \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'crackhead', 'uncl', 'hbcu', 'famili', 'kkoolpointz', 'everi', 'hbcu', 'alabama', 'look', 'alabama', 'state', 'sideway', 'lmao'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it crackhead uncl hbcu famili kkoolpointz everi hbcu alabama look alabama state sideway lmao'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  595 :\n",
      "\n",
      "\tTweet's text':  no respons alway seem attract respons the \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#aintnobodygottimeforthat'] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'respons', 'alway', 'seem', 'attract', 'respons', 'the'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no respons alway seem attract respons the'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  596 :\n",
      "\n",
      "\tTweet's text':  girl rock thang \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PrincipalSwag'] \n",
      "\n",
      "\tTweet tokenized by words:  ['girl', 'rock', 'thang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['girl rock thang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  597 :\n",
      "\n",
      "\tTweet's text':  and christma shop done \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'christma', 'shop', 'done'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and christma shop done'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  598 :\n",
      "\n",
      "\tTweet's text':  lol cthulhu funni autocorrect help \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'cthulhu', 'funni', 'autocorrect', 'help'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol cthulhu funni autocorrect help'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  599 :\n",
      "\n",
      "\tTweet's text':  my son thought love take snack class alway think other right selfish \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#raising'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'son', 'thought', 'love', 'take', 'snack', 'class', 'alway', 'think', 'other', 'right', 'selfish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my son thought love take snack class alway think other right selfish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  600 :\n",
      "\n",
      "\tTweet's text':  a year old whatev age idgaf act like immatur littl public yup classi one \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SoNotClassy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'year', 'old', 'whatev', 'age', 'idgaf', 'act', 'like', 'immatur', 'littl', 'public', 'yup', 'classi', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a year old whatev age idgaf act like immatur littl public yup classi one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  601 :\n",
      "\n",
      "\tTweet's text':  updat punt ostrich via \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['updat', 'punt', 'ostrich', 'via'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['updat punt ostrich via'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  602 :\n",
      "\n",
      "\tTweet's text':  hide plain sight by \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MichaelBeerens', '#graffiti', '#streetart'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hide', 'plain', 'sight', 'by'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hide plain sight by'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  603 :\n",
      "\n",
      "\tTweet's text':  get cynic karna \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'cynic', 'karna'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get cynic karna'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  604 :\n",
      "\n",
      "\tTweet's text':  today awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  605 :\n",
      "\n",
      "\tTweet's text':  nm i silli see websit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nm', 'i', 'silli', 'see', 'websit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nm i silli see websit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  606 :\n",
      "\n",
      "\tTweet's text':  heh fat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ShotsFired'] \n",
      "\n",
      "\tTweet tokenized by words:  ['heh', 'fat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['heh fat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  607 :\n",
      "\n",
      "\tTweet's text':  braaanchi love randomli wake everyday multipl time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['braaanchi', 'love', 'randomli', 'wake', 'everyday', 'multipl', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['braaanchi love randomli wake everyday multipl time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  608 :\n",
      "\n",
      "\tTweet's text':  christma shop hr sleep go fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['christma', 'shop', 'hr', 'sleep', 'go', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['christma shop hr sleep go fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  609 :\n",
      "\n",
      "\tTweet's text':  stay tune drunk video mom \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stay', 'tune', 'drunk', 'video', 'mom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stay tune drunk video mom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  610 :\n",
      "\n",
      "\tTweet's text':  the call end hold sign referenc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#American', '#protesters', '#RacialProfiling', '#BlackPeople', '#ICantBreathe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'call', 'end', 'hold', 'sign', 'referenc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the call end hold sign referenc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  611 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sup', '#twitter', '#sorry', '#i', '#talking', '#alot', '#so', '#i', '#thort', '#i', '#sould', '#just', '#say', '#hi'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  612 :\n",
      "\n",
      "\tTweet's text':  you realli know treat girl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'realli', 'know', 'treat', 'girl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you realli know treat girl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  613 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SchoolSystem', '#Textbook', '#Evolution', '#Tco'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  614 :\n",
      "\n",
      "\tTweet's text':  thi chap seem bit sex go extrovert must overli masculin voic demeanor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'chap', 'seem', 'bit', 'sex', 'go', 'extrovert', 'must', 'overli', 'masculin', 'voic', 'demeanor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi chap seem bit sex go extrovert must overli masculin voic demeanor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  615 :\n",
      "\n",
      "\tTweet's text':  they bombard countri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#immigration'] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'bombard', 'countri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they bombard countri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  616 :\n",
      "\n",
      "\tTweet's text':  soooo deep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#narrowminds', '#stopwatchingthenews', '#andstoppreachingoffyoutube'] \n",
      "\n",
      "\tTweet tokenized by words:  ['soooo', 'deep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['soooo deep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  617 :\n",
      "\n",
      "\tTweet's text':  i realli big support like sheriff clark said theatric \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lawenforcement', '#Ferguson'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'realli', 'big', 'support', 'like', 'sheriff', 'clark', 'said', 'theatric'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i realli big support like sheriff clark said theatric'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  618 :\n",
      "\n",
      "\tTweet's text':  feel like play ref game that clean wall block ref took away ugh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'like', 'play', 'ref', 'game', 'that', 'clean', 'wall', 'block', 'ref', 'took', 'away', 'ugh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel like play ref game that clean wall block ref took away ugh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  619 :\n",
      "\n",
      "\tTweet's text':  ed sheeran smash tune victoria secret catwalk ginger legend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by words:  ['ed', 'sheeran', 'smash', 'tune', 'victoria', 'secret', 'catwalk', 'ginger', 'legend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ed sheeran smash tune victoria secret catwalk ginger legend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  620 :\n",
      "\n",
      "\tTweet's text':  well pain makin feel sick anymor sobe better big fella \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['wrapped_present', 'father_christmas'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'pain', 'makin', 'feel', 'sick', 'anymor', 'sobe', 'better', 'big', 'fella'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well pain makin feel sick anymor sobe better big fella'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  621 :\n",
      "\n",
      "\tTweet's text':  thing racist one race human \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thing', 'racist', 'one', 'race', 'human'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thing racist one race human'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  622 :\n",
      "\n",
      "\tTweet's text':  day left enter planner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#giveaway', '#bbloggers', '#lbloggers'] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'left', 'enter', 'planner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day left enter planner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  623 :\n",
      "\n",
      "\tTweet's text':  walk mall front group guy hear even momma got jesu lol everyon love polli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['walk', 'mall', 'front', 'group', 'guy', 'hear', 'even', 'momma', 'got', 'jesu', 'lol', 'everyon', 'love', 'polli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['walk mall front group guy hear even momma got jesu lol everyon love polli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  624 :\n",
      "\n",
      "\tTweet's text':  i okay snow sleet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#howaboutno'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'okay', 'snow', 'sleet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i okay snow sleet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  625 :\n",
      "\n",
      "\tTweet's text':  pleas instagram xma present i die see \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nobodycares'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pleas', 'instagram', 'xma', 'present', 'i', 'die', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pleas instagram xma present i die see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  626 :\n",
      "\n",
      "\tTweet's text':  patrick kielti host radio comedi a \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['patrick', 'kielti', 'host', 'radio', 'comedi', 'a'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['patrick kielti host radio comedi a'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  627 :\n",
      "\n",
      "\tTweet's text':  face stuck tongu wink eye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_stuck-out_tongue_and_winking_eye'] \n",
      "\n",
      "\tTweet's hashtags':  ['#instacraze', '#addiction'] \n",
      "\n",
      "\tTweet tokenized by words:  ['face', 'stuck', 'tongu', 'wink', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['face stuck tongu wink eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  628 :\n",
      "\n",
      "\tTweet's text':  ecb ponder best act whether reuter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ECB', '#pondering', '#how', '#best', '#to', '#act', '#whether'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ecb', 'ponder', 'best', 'act', 'whether', 'reuter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ecb ponder best act whether reuter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  629 :\n",
      "\n",
      "\tTweet's text':  world greatest war mind invinc one go within mind \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lifequotes', '#copycatsays'] \n",
      "\n",
      "\tTweet tokenized by words:  ['world', 'greatest', 'war', 'mind', 'invinc', 'one', 'go', 'within', 'mind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['world greatest war mind invinc one go within mind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  630 :\n",
      "\n",
      "\tTweet's text':  i love see guy go text school zone \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#soproud', '#gpabdrivers'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'see', 'guy', 'go', 'text', 'school', 'zone'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love see guy go text school zone'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  631 :\n",
      "\n",
      "\tTweet's text':  lolol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whoISshe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lolol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lolol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  632 :\n",
      "\n",
      "\tTweet's text':  i waitlov love can tell much gonna last beth rip twd forev \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#this', '#is', '#love', '#and', '#you', '#cAn', '#tell', '#me', '#how', '#much', '#this', '#is', '#gonna', '#last', '#beth', '#rip', '#twd', '#forever', '#bae'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'waitlov', 'love', 'can', 'tell', 'much', 'gon', 'na', 'last', 'beth', 'rip', 'twd', 'forev'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i waitlov love can tell much gonna last beth rip twd forev'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  633 :\n",
      "\n",
      "\tTweet's text':  main issu walk dead forget breath watch so bloodi good \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WalkingDead'] \n",
      "\n",
      "\tTweet tokenized by words:  ['main', 'issu', 'walk', 'dead', 'forget', 'breath', 'watch', 'so', 'bloodi', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['main issu walk dead forget breath watch so bloodi good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  634 :\n",
      "\n",
      "\tTweet's text':  i bit sweati time i get \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'bit', 'sweati', 'time', 'i', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i bit sweati time i get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  635 :\n",
      "\n",
      "\tTweet's text':  until becom love athlet new citi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['until', 'becom', 'love', 'athlet', 'new', 'citi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['until becom love athlet new citi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  636 :\n",
      "\n",
      "\tTweet's text':  it earli awak \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['confounded_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'earli', 'awak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it earli awak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  637 :\n",
      "\n",
      "\tTweet's text':  wassup edumkarethadj boss kupotea nayo acha hizo bro \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcool'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wassup', 'edumkarethadj', 'boss', 'kupotea', 'nayo', 'acha', 'hizo', 'bro'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wassup edumkarethadj boss kupotea nayo acha hizo bro'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  638 :\n",
      "\n",
      "\tTweet's text':  thatneilguy isn great ppl done public mea culpa sinc happen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thatneilguy', 'isn', 'great', 'ppl', 'done', 'public', 'mea', 'culpa', 'sinc', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thatneilguy isn great ppl done public mea culpa sinc happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  639 :\n",
      "\n",
      "\tTweet's text':  my teacher gave i feel sorri look i must look realli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'teacher', 'gave', 'i', 'feel', 'sorri', 'look', 'i', 'must', 'look', 'realli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my teacher gave i feel sorri look i must look realli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  640 :\n",
      "\n",
      "\tTweet's text':  gift god improv skill \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#KarmicThought', '#WiseWord'] \n",
      "\n",
      "\tTweet tokenized by words:  ['gift', 'god', 'improv', 'skill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gift god improv skill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  641 :\n",
      "\n",
      "\tTweet's text':  oh matur girl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'matur', 'girl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh matur girl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  642 :\n",
      "\n",
      "\tTweet's text':  use white maroon xma tree \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['use', 'white', 'maroon', 'xma', 'tree'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['use white maroon xma tree'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  643 :\n",
      "\n",
      "\tTweet's text':  sure s \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sure', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sure s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  644 :\n",
      "\n",
      "\tTweet's text':  love work exhaust time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'work', 'exhaust', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love work exhaust time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  645 :\n",
      "\n",
      "\tTweet's text':  i hate random peopl get hot tub \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#favthings'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hate', 'random', 'peopl', 'get', 'hot', 'tub'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hate random peopl get hot tub'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  646 :\n",
      "\n",
      "\tTweet's text':  problem the express tribun \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['problem', 'the', 'express', 'tribun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['problem the express tribun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  647 :\n",
      "\n",
      "\tTweet's text':  si ms educ heheh clear ignor smile face heart shape eyesfac tear joy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes', 'face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['si', 'ms', 'educ', 'heheh', 'clear', 'ignor', 'smile', 'face', 'heart', 'shape', 'eyesfac', 'tear', 'joy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['si ms educ heheh clear ignor smile face heart shape eyesfac tear joy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  648 :\n",
      "\n",
      "\tTweet's text':  worship b c research call everi els ignor guy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SteveHarvey', '#Obama', '#Fuck', '#Idiot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['worship', 'b', 'c', 'research', 'call', 'everi', 'els', 'ignor', 'guy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['worship b c research call everi els ignor guy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  649 :\n",
      "\n",
      "\tTweet's text':  can wait see ig pic peopl brag got \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#noonegivesafuck'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'see', 'ig', 'pic', 'peopl', 'brag', 'got'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait see ig pic peopl brag got'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  650 :\n",
      "\n",
      "\tTweet's text':  benedryl run allerg reaction drug liter save million live everi year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#yippee', '#happiness'] \n",
      "\n",
      "\tTweet tokenized by words:  ['benedryl', 'run', 'allerg', 'reaction', 'drug', 'liter', 'save', 'million', 'live', 'everi', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['benedryl run allerg reaction drug liter save million live everi year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  651 :\n",
      "\n",
      "\tTweet's text':  quizfreak \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#proud', '#Brummie'] \n",
      "\n",
      "\tTweet tokenized by words:  ['quizfreak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['quizfreak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  652 :\n",
      "\n",
      "\tTweet's text':  just submit final paper semest it make break whether i pass class no big deal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['expressionless_face', 'thumbs_down_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'submit', 'final', 'paper', 'semest', 'it', 'make', 'break', 'whether', 'i', 'pass', 'class', 'no', 'big', 'deal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just submit final paper semest it make break whether i pass class no big deal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  653 :\n",
      "\n",
      "\tTweet's text':  pediatr grand round statin therapi dyslipidemia obes breakfast offer grand platter donut \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pediatr', 'grand', 'round', 'statin', 'therapi', 'dyslipidemia', 'obes', 'breakfast', 'offer', 'grand', 'platter', 'donut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pediatr grand round statin therapi dyslipidemia obes breakfast offer grand platter donut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  654 :\n",
      "\n",
      "\tTweet's text':  me stomach upset my stomach i am more than upset \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['me', 'stomach', 'upset', 'my', 'stomach', 'i', 'am', 'more', 'than', 'upset'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['me stomach upset my stomach i am more than upset'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  655 :\n",
      "\n",
      "\tTweet's text':  bad kid az hockey work desert \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bad', 'kid', 'az', 'hockey', 'work', 'desert'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bad kid az hockey work desert'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  656 :\n",
      "\n",
      "\tTweet's text':  ohio state put no match \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OnWisconsin'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ohio', 'state', 'put', 'no', 'match'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ohio state put no match'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  657 :\n",
      "\n",
      "\tTweet's text':  love see peopl read facebook privat messag repli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'see', 'peopl', 'read', 'facebook', 'privat', 'messag', 'repli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love see peopl read facebook privat messag repli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  658 :\n",
      "\n",
      "\tTweet's text':  i need new boot birthday and new boot i mean like pair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth_and_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  ['#ineednewboots', '#boots'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'need', 'new', 'boot', 'birthday', 'and', 'new', 'boot', 'i', 'mean', 'like', 'pair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i need new boot birthday and new boot i mean like pair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  659 :\n",
      "\n",
      "\tTweet's text':  the ever care get see sieg end first great journal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'ever', 'care', 'get', 'see', 'sieg', 'end', 'first', 'great', 'journal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the ever care get see sieg end first great journal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  660 :\n",
      "\n",
      "\tTweet's text':  whi tarmac speed hump the cut go instead bit bit brickwork disintegr scienc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'tarmac', 'speed', 'hump', 'the', 'cut', 'go', 'instead', 'bit', 'bit', 'brickwork', 'disintegr', 'scienc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi tarmac speed hump the cut go instead bit bit brickwork disintegr scienc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  661 :\n",
      "\n",
      "\tTweet's text':  go go power ranger \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#f2xmasparty'] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'go', 'power', 'ranger'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go go power ranger'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  662 :\n",
      "\n",
      "\tTweet's text':  what good way start new year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'good', 'way', 'start', 'new', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what good way start new year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  663 :\n",
      "\n",
      "\tTweet's text':  sit hall fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sit', 'hall', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sit hall fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  664 :\n",
      "\n",
      "\tTweet's text':  rodger need go man think i would ever say bought shit player \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#good', '#enough'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rodger', 'need', 'go', 'man', 'think', 'i', 'would', 'ever', 'say', 'bought', 'shit', 'player'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rodger need go man think i would ever say bought shit player'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  665 :\n",
      "\n",
      "\tTweet's text':  rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bit', '#Chair', '#Comfy', '#Mind', '#Nope', '#ikea', '#decor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  666 :\n",
      "\n",
      "\tTweet's text':  i think gorgeou thing world \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['sparkles'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Stars'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'gorgeou', 'thing', 'world'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think gorgeou thing world'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  667 :\n",
      "\n",
      "\tTweet's text':  me cam newton engag end year wait lmao byyer foolisha good night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['me', 'cam', 'newton', 'engag', 'end', 'year', 'wait', 'lmao', 'byyer', 'foolisha', 'good', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['me cam newton engag end year wait lmao byyer foolisha good night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  668 :\n",
      "\n",
      "\tTweet's text':  ladi red ootd \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['sparkles', 'heavy_black_heart', 'princess', 'dancer', 'kiss_mark'] \n",
      "\n",
      "\tTweet's hashtags':  ['#ootd', '#im', '#the', '#mom', '#the', '#godmother', '#lol', '#athenakairalyn', '#baptism', '#love'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ladi', 'red', 'ootd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ladi red ootd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  669 :\n",
      "\n",
      "\tTweet's text':  i know right not like lapd anyth better thi distract noth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'right', 'not', 'like', 'lapd', 'anyth', 'better', 'thi', 'distract', 'noth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know right not like lapd anyth better thi distract noth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  670 :\n",
      "\n",
      "\tTweet's text':  rapper go act \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Law'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rapper', 'go', 'act'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rapper go act'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  671 :\n",
      "\n",
      "\tTweet's text':  i alway love famili last one open present \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'alway', 'love', 'famili', 'last', 'one', 'open', 'present'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i alway love famili last one open present'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  672 :\n",
      "\n",
      "\tTweet's text':  of cours i nervou i hyperventil fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['of', 'cours', 'i', 'nervou', 'i', 'hyperventil', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['of cours i nervou i hyperventil fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  673 :\n",
      "\n",
      "\tTweet's text':  we take bad \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'take', 'bad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we take bad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  674 :\n",
      "\n",
      "\tTweet's text':  haha go iceland x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'go', 'iceland', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha go iceland x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  675 :\n",
      "\n",
      "\tTweet's text':  i love knee click \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face', 'smiling_face_with_open_mouth_and_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'knee', 'click'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love knee click'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  676 :\n",
      "\n",
      "\tTweet's text':  uniti stand white peopl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['uniti', 'stand', 'white', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['uniti stand white peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  677 :\n",
      "\n",
      "\tTweet's text':  who franc imped free market capit socialist n \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#shocker', '#Uber'] \n",
      "\n",
      "\tTweet tokenized by words:  ['who', 'franc', 'imped', 'free', 'market', 'capit', 'socialist', 'n'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['who franc imped free market capit socialist n'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  678 :\n",
      "\n",
      "\tTweet's text':  ugh make stop \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#finalsweekgotmelike', '#finals', '#finalsweek', '#EWU'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ugh', 'make', 'stop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ugh make stop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  679 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  680 :\n",
      "\n",
      "\tTweet's text':  fuck yeah viewer \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fuck', 'yeah', 'viewer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fuck yeah viewer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  681 :\n",
      "\n",
      "\tTweet's text':  a lot ingredi more \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'lot', 'ingredi', 'more'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a lot ingredi more'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  682 :\n",
      "\n",
      "\tTweet's text':  so glad awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'glad', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so glad awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  683 :\n",
      "\n",
      "\tTweet's text':  wanna cri that cri omg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wan', 'na', 'cri', 'that', 'cri', 'omg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wanna cri that cri omg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  684 :\n",
      "\n",
      "\tTweet's text':  oh aye i give \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'aye', 'i', 'give'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh aye i give'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  685 :\n",
      "\n",
      "\tTweet's text':  alway nice year old man know call pretti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['alway', 'nice', 'year', 'old', 'man', 'know', 'call', 'pretti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alway nice year old man know call pretti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  686 :\n",
      "\n",
      "\tTweet's text':  i expect sort appl quip guy joke i news tbh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'expect', 'sort', 'appl', 'quip', 'guy', 'joke', 'i', 'news', 'tbh'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet tokenized by sentences:  ['i expect sort appl quip guy joke i news tbh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  687 :\n",
      "\n",
      "\tTweet's text':  mostli lr store depend get i say i tend split \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mostli', 'lr', 'store', 'depend', 'get', 'i', 'say', 'i', 'tend', 'split'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mostli lr store depend get i say i tend split'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  688 :\n",
      "\n",
      "\tTweet's text':  extend trade tell peopl extend trade best idea ever \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['extend', 'trade', 'tell', 'peopl', 'extend', 'trade', 'best', 'idea', 'ever'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['extend trade tell peopl extend trade best idea ever'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  689 :\n",
      "\n",
      "\tTweet's text':  nypd blog feel safe protect \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ICantBreathe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['nypd', 'blog', 'feel', 'safe', 'protect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nypd blog feel safe protect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  690 :\n",
      "\n",
      "\tTweet's text':  my professor moustach uneven mohstash would asham right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'professor', 'moustach', 'uneven', 'mohstash', 'would', 'asham', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my professor moustach uneven mohstash would asham right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  691 :\n",
      "\n",
      "\tTweet's text':  no repli day i mean week happi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Happiness'] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'repli', 'day', 'i', 'mean', 'week', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no repli day i mean week happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  692 :\n",
      "\n",
      "\tTweet's text':  up night took hour nap i readi work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['up', 'night', 'took', 'hour', 'nap', 'i', 'readi', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['up night took hour nap i readi work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  693 :\n",
      "\n",
      "\tTweet's text':  can come shovel driveway you owe help becom man today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#givingback'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'come', 'shovel', 'driveway', 'you', 'owe', 'help', 'becom', 'man', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can come shovel driveway you owe help becom man today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  694 :\n",
      "\n",
      "\tTweet's text':  my life daili basi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notreally', '#lcsbeauty', '#followme', '#lblogger'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'life', 'daili', 'basi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my life daili basi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  695 :\n",
      "\n",
      "\tTweet's text':  wow seem turnt \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'seem', 'turnt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow seem turnt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  696 :\n",
      "\n",
      "\tTweet's text':  sleep wake next ac game leak \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ACVictory'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sleep', 'wake', 'next', 'ac', 'game', 'leak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sleep wake next ac game leak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  697 :\n",
      "\n",
      "\tTweet's text':  heaven help fool wrong \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['heaven', 'help', 'fool', 'wrong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['heaven help fool wrong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  698 :\n",
      "\n",
      "\tTweet's text':  i hate plane ride i wanna go mani differ countri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hate', 'plane', 'ride', 'i', 'wan', 'na', 'go', 'mani', 'differ', 'countri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hate plane ride i wanna go mani differ countri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  699 :\n",
      "\n",
      "\tTweet's text':  oh lord rt rt befor becom actor tom cruis want cathol priest \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'lord', 'rt', 'rt', 'befor', 'becom', 'actor', 'tom', 'cruis', 'want', 'cathol', 'priest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh lord rt rt befor becom actor tom cruis want cathol priest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  700 :\n",
      "\n",
      "\tTweet's text':  not fun day one reengag i get wisdom teeth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#soexcited'] \n",
      "\n",
      "\tTweet tokenized by words:  ['not', 'fun', 'day', 'one', 'reengag', 'i', 'get', 'wisdom', 'teeth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['not fun day one reengag i get wisdom teeth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  701 :\n",
      "\n",
      "\tTweet's text':  ummm i pleas christma dang look great tonight whi i go thing tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ummm', 'i', 'pleas', 'christma', 'dang', 'look', 'great', 'tonight', 'whi', 'i', 'go', 'thing', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ummm i pleas christma dang look great tonight whi i go thing tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  702 :\n",
      "\n",
      "\tTweet's text':  yet anoth raini goshen concert night \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#surprised'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yet', 'anoth', 'raini', 'goshen', 'concert', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yet anoth raini goshen concert night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  703 :\n",
      "\n",
      "\tTweet's text':  write hundr tweet kejriw everi day go declar irrelev come indian polit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['write', 'hundr', 'tweet', 'kejriw', 'everi', 'day', 'go', 'declar', 'irrelev', 'come', 'indian', 'polit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['write hundr tweet kejriw everi day go declar irrelev come indian polit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  704 :\n",
      "\n",
      "\tTweet's text':  sink teeth sp fail vt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sink', 'teeth', 'sp', 'fail', 'vt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sink teeth sp fail vt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  705 :\n",
      "\n",
      "\tTweet's text':  while politician busi scuffl job yet malign peac h salut pakarmi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PakArmy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['while', 'politician', 'busi', 'scuffl', 'job', 'yet', 'malign', 'peac', 'h', 'salut', 'pakarmi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['while politician busi scuffl job yet malign peac h salut pakarmi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  706 :\n",
      "\n",
      "\tTweet's text':  yay it work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HateWhenThingsDontWorkRight'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'it', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay it work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  707 :\n",
      "\n",
      "\tTweet's text':  idk i love cold western civ class western civ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['idk', 'i', 'love', 'cold', 'western', 'civ', 'class', 'western', 'civ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['idk i love cold western civ class western civ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  708 :\n",
      "\n",
      "\tTweet's text':  are excit new check articl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Blackberry', '#Classic', '#smartphone'] \n",
      "\n",
      "\tTweet tokenized by words:  ['are', 'excit', 'new', 'check', 'articl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['are excit new check articl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  709 :\n",
      "\n",
      "\tTweet's text':  go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  710 :\n",
      "\n",
      "\tTweet's text':  stage \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#flzjingleball', '#Tampa', '#iheartradio'] \n",
      "\n",
      "\tTweet tokenized by words:  ['stage'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stage'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  711 :\n",
      "\n",
      "\tTweet's text':  alright dream last night i could life fall asleep \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['alright', 'dream', 'last', 'night', 'i', 'could', 'life', 'fall', 'asleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alright dream last night i could life fall asleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  712 :\n",
      "\n",
      "\tTweet's text':  isnt best your realli tire final get bed your wide awak i love it \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['isnt', 'best', 'your', 'realli', 'tire', 'final', 'get', 'bed', 'your', 'wide', 'awak', 'i', 'love', 'it'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['isnt best your realli tire final get bed your wide awak i love it'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  713 :\n",
      "\n",
      "\tTweet's text':  travel tourism morn my favourit lesson whoooo \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['travel', 'tourism', 'morn', 'my', 'favourit', 'lesson', 'whoooo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['travel tourism morn my favourit lesson whoooo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  714 :\n",
      "\n",
      "\tTweet's text':  but girl friend upcom movi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#DrAmbarish'] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'girl', 'friend', 'upcom', 'movi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but girl friend upcom movi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  715 :\n",
      "\n",
      "\tTweet's text':  can bring back youkili rememb year old youk charg mound year old porcello drop \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#RedSox'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'bring', 'back', 'youkili', 'rememb', 'year', 'old', 'youk', 'charg', 'mound', 'year', 'old', 'porcello', 'drop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can bring back youkili rememb year old youk charg mound year old porcello drop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  716 :\n",
      "\n",
      "\tTweet's text':  him amaz i love team they scrap alway find way inde \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dcRising'] \n",
      "\n",
      "\tTweet tokenized by words:  ['him', 'amaz', 'i', 'love', 'team', 'they', 'scrap', 'alway', 'find', 'way', 'inde'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['him amaz i love team they scrap alway find way inde'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  717 :\n",
      "\n",
      "\tTweet's text':  would wear size hahaha \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#proudly', '#NZ'] \n",
      "\n",
      "\tTweet tokenized by words:  ['would', 'wear', 'size', 'hahaha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['would wear size hahaha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  718 :\n",
      "\n",
      "\tTweet's text':  san diego amaz i never come home \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['san', 'diego', 'amaz', 'i', 'never', 'come', 'home'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['san diego amaz i never come home'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  719 :\n",
      "\n",
      "\tTweet's text':  my favorit part disloc shoulder abl feel roll around socket \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'favorit', 'part', 'disloc', 'shoulder', 'abl', 'feel', 'roll', 'around', 'socket'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my favorit part disloc shoulder abl feel roll around socket'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  720 :\n",
      "\n",
      "\tTweet's text':  success morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ChristmasShopping'] \n",
      "\n",
      "\tTweet tokenized by words:  ['success', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['success morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  721 :\n",
      "\n",
      "\tTweet's text':  knock knock \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sketchy', '#dignity', '#smile', '#funtimes', '#brotherskeeper', '#whosonfirst', '#holiday', '#shenanigans'] \n",
      "\n",
      "\tTweet tokenized by words:  ['knock', 'knock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['knock knock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  722 :\n",
      "\n",
      "\tTweet's text':  gah desper tri bust cold \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gah', 'desper', 'tri', 'bust', 'cold'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gah desper tri bust cold'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  723 :\n",
      "\n",
      "\tTweet's text':  yay more worthless window updat comput still never sleep hibern \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fixit', '#fail', '#Microsoft'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'more', 'worthless', 'window', 'updat', 'comput', 'still', 'never', 'sleep', 'hibern'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay more worthless window updat comput still never sleep hibern'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  724 :\n",
      "\n",
      "\tTweet's text':  applic alreadi fill wait turn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['applic', 'alreadi', 'fill', 'wait', 'turn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['applic alreadi fill wait turn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  725 :\n",
      "\n",
      "\tTweet's text':  sourc say patrick schwarzenegg is miley cyru \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MIley', '#Cyrus', '#Is', '#The', '#Bad', '#Influence'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sourc', 'say', 'patrick', 'schwarzenegg', 'is', 'miley', 'cyru'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sourc say patrick schwarzenegg is miley cyru'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  726 :\n",
      "\n",
      "\tTweet's text':  just watch last ever one tree hill i emot wreck even clock \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'watch', 'last', 'ever', 'one', 'tree', 'hill', 'i', 'emot', 'wreck', 'even', 'clock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just watch last ever one tree hill i emot wreck even clock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  727 :\n",
      "\n",
      "\tTweet's text':  make perfect sens get mad someth happen year ago \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['make', 'perfect', 'sens', 'get', 'mad', 'someth', 'happen', 'year', 'ago'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['make perfect sens get mad someth happen year ago'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  728 :\n",
      "\n",
      "\tTweet's text':  are young understand \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['are', 'young', 'understand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['are young understand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  729 :\n",
      "\n",
      "\tTweet's text':  love carnousti beach \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#soggybreeks'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'carnousti', 'beach'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love carnousti beach'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  730 :\n",
      "\n",
      "\tTweet's text':  if year wld fill w raini day wont cool cool way start e year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'year', 'wld', 'fill', 'w', 'raini', 'day', 'wont', 'cool', 'cool', 'way', 'start', 'e', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if year wld fill w raini day wont cool cool way start e year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  731 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Landlord', '#Rent', '#HoneyBees', '#BeeHive', '#Bee', '#Honey', '#ItalianBees'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  732 :\n",
      "\n",
      "\tTweet's text':  i bought peopl gift year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'bought', 'peopl', 'gift', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i bought peopl gift year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  733 :\n",
      "\n",
      "\tTweet's text':  well done make possibl get emerg messag member staff \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'done', 'make', 'possibl', 'get', 'emerg', 'messag', 'member', 'staff'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well done make possibl get emerg messag member staff'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  734 :\n",
      "\n",
      "\tTweet's text':  now i rememb i buy book onlin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#servicewithasmile'] \n",
      "\n",
      "\tTweet tokenized by words:  ['now', 'i', 'rememb', 'i', 'buy', 'book', 'onlin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['now i rememb i buy book onlin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  735 :\n",
      "\n",
      "\tTweet's text':  i see respons time dm good phone line hold music legendari servic guy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'see', 'respons', 'time', 'dm', 'good', 'phone', 'line', 'hold', 'music', 'legendari', 'servic', 'guy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i see respons time dm good phone line hold music legendari servic guy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  736 :\n",
      "\n",
      "\tTweet's text':  thank clear everyth koenig \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#serialbrady'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'clear', 'everyth', 'koenig'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank clear everyth koenig'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  737 :\n",
      "\n",
      "\tTweet's text':  that moment next philosoph lack skill \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BabyBoomer', '#communication', '#GenerationY', '#NewWayToCommunicate'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'moment', 'next', 'philosoph', 'lack', 'skill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that moment next philosoph lack skill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  738 :\n",
      "\n",
      "\tTweet's text':  busi staff stand peopl queue \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#joke'] \n",
      "\n",
      "\tTweet tokenized by words:  ['busi', 'staff', 'stand', 'peopl', 'queue'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['busi staff stand peopl queue'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  739 :\n",
      "\n",
      "\tTweet's text':  i sure miss downtown dalla traffic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Dallas', '#traffic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'sure', 'miss', 'downtown', 'dalla', 'traffic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i sure miss downtown dalla traffic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  740 :\n",
      "\n",
      "\tTweet's text':  spend harper done w public sector job injur economi multipli effect job \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cdnpoli'] \n",
      "\n",
      "\tTweet tokenized by words:  ['spend', 'harper', 'done', 'w', 'public', 'sector', 'job', 'injur', 'economi', 'multipli', 'effect', 'job'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['spend harper done w public sector job injur economi multipli effect job'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  741 :\n",
      "\n",
      "\tTweet's text':  remind younger \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['remind', 'younger'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['remind younger'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  742 :\n",
      "\n",
      "\tTweet's text':  fear loath la ukra \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Politics', '#Russia', '#Ukraine'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fear', 'loath', 'la', 'ukra'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fear loath la ukra'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  743 :\n",
      "\n",
      "\tTweet's text':  somebodi wake earli tomorrow ive face weird ach back sinc earli decemb u think relat madaka \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['somebodi', 'wake', 'earli', 'tomorrow', 'ive', 'face', 'weird', 'ach', 'back', 'sinc', 'earli', 'decemb', 'u', 'think', 'relat', 'madaka'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['somebodi wake earli tomorrow ive face weird ach back sinc earli decemb u think relat madaka'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  744 :\n",
      "\n",
      "\tTweet's text':  funni lolololol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['funni', 'lolololol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['funni lolololol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  745 :\n",
      "\n",
      "\tTweet's text':  so see reign lame superman punch spear gee wait \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#RAW'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'see', 'reign', 'lame', 'superman', 'punch', 'spear', 'gee', 'wait'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so see reign lame superman punch spear gee wait'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  746 :\n",
      "\n",
      "\tTweet's text':  of dy on your birthday fail it e \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#np', '#NowPlaying', '#NowListening', '#Music', '#Senses', '#album', '#Let'] \n",
      "\n",
      "\tTweet tokenized by words:  ['of', 'dy', 'on', 'your', 'birthday', 'fail', 'it', 'e'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['of dy on your birthday fail it e'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  747 :\n",
      "\n",
      "\tTweet's text':  i love cold winter day caus i never know car decid start \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['expressionless_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'cold', 'winter', 'day', 'caus', 'i', 'never', 'know', 'car', 'decid', 'start'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love cold winter day caus i never know car decid start'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  748 :\n",
      "\n",
      "\tTweet's text':  time listen ppl complain bout lot life bec cudnt make anyth yay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'listen', 'ppl', 'complain', 'bout', 'lot', 'life', 'bec', 'cudnt', 'make', 'anyth', 'yay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time listen ppl complain bout lot life bec cudnt make anyth yay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  749 :\n",
      "\n",
      "\tTweet's text':  i pick great night want sleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'pick', 'great', 'night', 'want', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i pick great night want sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  750 :\n",
      "\n",
      "\tTweet's text':  it hot humid wear ugg wow nice style \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'hot', 'humid', 'wear', 'ugg', 'wow', 'nice', 'style'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it hot humid wear ugg wow nice style'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  751 :\n",
      "\n",
      "\tTweet's text':  omg ye final on a friday are my favorit smile face heart shape eyesheavi black heart \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes', 'heavy_black_heart', 'information_desk_person'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['omg', 'ye', 'final', 'on', 'a', 'friday', 'are', 'my', 'favorit', 'smile', 'face', 'heart', 'shape', 'eyesheavi', 'black', 'heart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['omg ye final on a friday are my favorit smile face heart shape eyesheavi black heart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  752 :\n",
      "\n",
      "\tTweet's text':  it realli difficult bark back pm ing daughter when bae tweet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'realli', 'difficult', 'bark', 'back', 'pm', 'ing', 'daughter', 'when', 'bae', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it realli difficult bark back pm ing daughter when bae tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  753 :\n",
      "\n",
      "\tTweet's text':  kick raiola leagu \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Scumbag', '#RepeatOffender', '#OneGameIsNotEnough'] \n",
      "\n",
      "\tTweet tokenized by words:  ['kick', 'raiola', 'leagu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kick raiola leagu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  754 :\n",
      "\n",
      "\tTweet's text':  today awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  755 :\n",
      "\n",
      "\tTweet's text':  oh joy ti season christma came earli lead \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#DoBetter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'joy', 'ti', 'season', 'christma', 'came', 'earli', 'lead'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh joy ti season christma came earli lead'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  756 :\n",
      "\n",
      "\tTweet's text':  it freez hazi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'freez', 'hazi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it freez hazi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  757 :\n",
      "\n",
      "\tTweet's text':  can wait see talk never \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'see', 'talk', 'never'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait see talk never'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  758 :\n",
      "\n",
      "\tTweet's text':  i find peopl differ idea way life interest \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'find', 'peopl', 'differ', 'idea', 'way', 'life', 'interest'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by sentences:  ['i find peopl differ idea way life interest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  759 :\n",
      "\n",
      "\tTweet's text':  just order new pair underwear victoria secret smile face heart shape eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  ['#yay'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'order', 'new', 'pair', 'underwear', 'victoria', 'secret', 'smile', 'face', 'heart', 'shape', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just order new pair underwear victoria secret smile face heart shape eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  760 :\n",
      "\n",
      "\tTweet's text':  tottenham there end \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Big', '#match', '#verdict', '#Chelsea', '#loss', '#was', '#another', '#dark', '#night', '#at', '#the'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tottenham', 'there', 'end'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tottenham there end'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  761 :\n",
      "\n",
      "\tTweet's text':  what order kona grill for fast food sushi place delish \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'order', 'kona', 'grill', 'for', 'fast', 'food', 'sushi', 'place', 'delish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what order kona grill for fast food sushi place delish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  762 :\n",
      "\n",
      "\tTweet's text':  here it cold i scrape window i sad \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['here', 'it', 'cold', 'i', 'scrape', 'window', 'i', 'sad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['here it cold i scrape window i sad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  763 :\n",
      "\n",
      "\tTweet's text':  lol throw middl finger pictur anymor oh bad \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'throw', 'middl', 'finger', 'pictur', 'anymor', 'oh', 'bad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol throw middl finger pictur anymor oh bad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  764 :\n",
      "\n",
      "\tTweet's text':  day someth read our cosi hous \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#decemberchallenge', '#lovehistory', '#lovenonfiction'] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'someth', 'read', 'our', 'cosi', 'hous'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day someth read our cosi hous'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  765 :\n",
      "\n",
      "\tTweet's text':  climat chang redux californian experi drought vote bond cover climat chang rain year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['climat', 'chang', 'redux', 'californian', 'experi', 'drought', 'vote', 'bond', 'cover', 'climat', 'chang', 'rain', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['climat chang redux californian experi drought vote bond cover climat chang rain year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  766 :\n",
      "\n",
      "\tTweet's text':  mom told i fine \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mom', 'told', 'i', 'fine'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mom told i fine'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  767 :\n",
      "\n",
      "\tTweet's text':  look realli awak like i made effort today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'realli', 'awak', 'like', 'i', 'made', 'effort', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look realli awak like i made effort today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  768 :\n",
      "\n",
      "\tTweet's text':  my dove wrapper told mischiev anyth happen extenu extern attribut blame \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#psych'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'dove', 'wrapper', 'told', 'mischiev', 'anyth', 'happen', 'extenu', 'extern', 'attribut', 'blame'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my dove wrapper told mischiev anyth happen extenu extern attribut blame'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  769 :\n",
      "\n",
      "\tTweet's text':  kiss cheek enough im love bot \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['kiss', 'cheek', 'enough', 'im', 'love', 'bot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kiss cheek enough im love bot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  770 :\n",
      "\n",
      "\tTweet's text':  so band wear cloth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Karma'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'band', 'wear', 'cloth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so band wear cloth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  771 :\n",
      "\n",
      "\tTweet's text':  yeah \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  772 :\n",
      "\n",
      "\tTweet's text':  hula hoop hot chocol law revis break work fill glamour fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hula', 'hoop', 'hot', 'chocol', 'law', 'revis', 'break', 'work', 'fill', 'glamour', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hula hoop hot chocol law revis break work fill glamour fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  773 :\n",
      "\n",
      "\tTweet's text':  they still tri decid terror omg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sydneysiege'] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'still', 'tri', 'decid', 'terror', 'omg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they still tri decid terror omg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  774 :\n",
      "\n",
      "\tTweet's text':  the fandom show matur side alway kind topic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'fandom', 'show', 'matur', 'side', 'alway', 'kind', 'topic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the fandom show matur side alway kind topic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  775 :\n",
      "\n",
      "\tTweet's text':  i love put flobeam mech back togeth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'put', 'flobeam', 'mech', 'back', 'togeth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love put flobeam mech back togeth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  776 :\n",
      "\n",
      "\tTweet's text':  like tyndal system i think robert hubb play give us anoth scorer consist pt shooter o need \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['like', 'tyndal', 'system', 'i', 'think', 'robert', 'hubb', 'play', 'give', 'us', 'anoth', 'scorer', 'consist', 'pt', 'shooter', 'o', 'need'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['like tyndal system i think robert hubb play give us anoth scorer consist pt shooter o need'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  777 :\n",
      "\n",
      "\tTweet's text':  you fun \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  778 :\n",
      "\n",
      "\tTweet's text':  whi i love penguin madagascar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#humor', '#reliefcomedy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'i', 'love', 'penguin', 'madagascar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi i love penguin madagascar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  779 :\n",
      "\n",
      "\tTweet's text':  realli want watch \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#excessivecomsumption'] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'want', 'watch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli want watch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  780 :\n",
      "\n",
      "\tTweet's text':  that remember new year kiss \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'heavy_black_heart', 'kiss_mark'] \n",
      "\n",
      "\tTweet's hashtags':  ['#lovemyrelationship'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'remember', 'new', 'year', 'kiss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that remember new year kiss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  781 :\n",
      "\n",
      "\tTweet's text':  w crawl great start thursday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CLEtraffic', '#cleveland', '#traffic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['w', 'crawl', 'great', 'start', 'thursday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['w crawl great start thursday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  782 :\n",
      "\n",
      "\tTweet's text':  just realiz name comic san creator mean asshol french \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nooffense'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'realiz', 'name', 'comic', 'san', 'creator', 'mean', 'asshol', 'french'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just realiz name comic san creator mean asshol french'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  783 :\n",
      "\n",
      "\tTweet's text':  is khallilah henriqu nnn she mostli sound blond morn confirm ignor race relat articul minor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ignorant', '#Articulate'] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'khallilah', 'henriqu', 'nnn', 'she', 'mostli', 'sound', 'blond', 'morn', 'confirm', 'ignor', 'race', 'relat', 'articul', 'minor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is khallilah henriqu nnn she mostli sound blond morn confirm ignor race relat articul minor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  784 :\n",
      "\n",
      "\tTweet's text':  it super ignor put desper plea \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'super', 'ignor', 'put', 'desper', 'plea'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it super ignor put desper plea'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  785 :\n",
      "\n",
      "\tTweet's text':  bhopal victim get justic aft yr find place prime man travel busi cl prime time news \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bhopal', 'victim', 'get', 'justic', 'aft', 'yr', 'find', 'place', 'prime', 'man', 'travel', 'busi', 'cl', 'prime', 'time', 'news'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bhopal victim get justic aft yr find place prime man travel busi cl prime time news'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  786 :\n",
      "\n",
      "\tTweet's text':  thi link relev coupl day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'link', 'relev', 'coupl', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi link relev coupl day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  787 :\n",
      "\n",
      "\tTweet's text':  think burgerk work sjw fri salti sjw win award \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['think', 'burgerk', 'work', 'sjw', 'fri', 'salti', 'sjw', 'win', 'award'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['think burgerk work sjw fri salti sjw win award'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  788 :\n",
      "\n",
      "\tTweet's text':  i white hoe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'white', 'hoe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i white hoe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  789 :\n",
      "\n",
      "\tTweet's text':  caribbean girl anthem caribbean girl stainless mob store onlin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#IYON', '#Dancehall'] \n",
      "\n",
      "\tTweet tokenized by words:  ['caribbean', 'girl', 'anthem', 'caribbean', 'girl', 'stainless', 'mob', 'store', 'onlin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['caribbean girl anthem caribbean girl stainless mob store onlin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  790 :\n",
      "\n",
      "\tTweet's text':  it seem erdogan send best regard eu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'seem', 'erdogan', 'send', 'best', 'regard', 'eu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it seem erdogan send best regard eu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  791 :\n",
      "\n",
      "\tTweet's text':  yay famili leav go seneca leav fend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'famili', 'leav', 'go', 'seneca', 'leav', 'fend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay famili leav go seneca leav fend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  792 :\n",
      "\n",
      "\tTweet's text':  aww poor thing i feel bad sunni florida i know handl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aww', 'poor', 'thing', 'i', 'feel', 'bad', 'sunni', 'florida', 'i', 'know', 'handl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aww poor thing i feel bad sunni florida i know handl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  793 :\n",
      "\n",
      "\tTweet's text':  ca h tweetin bout newsvid start \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BlackLivesMatter', '#ICantBreathe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ca', 'h', 'tweetin', 'bout', 'newsvid', 'start'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ca h tweetin bout newsvid start'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  794 :\n",
      "\n",
      "\tTweet's text':  a smile smile smile smile smile is a million peopl stare at your piss pant manic laughter smile \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'smile', 'smile', 'smile', 'smile', 'smile', 'is', 'a', 'million', 'peopl', 'stare', 'at', 'your', 'piss', 'pant', 'manic', 'laughter', 'smile'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a smile smile smile smile smile is a million peopl stare at your piss pant manic laughter smile'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  795 :\n",
      "\n",
      "\tTweet's text':  casper friendli ghost level \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thingsmichelleobamathinksareracist'] \n",
      "\n",
      "\tTweet tokenized by words:  ['casper', 'friendli', 'ghost', 'level'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['casper friendli ghost level'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  796 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  797 :\n",
      "\n",
      "\tTweet's text':  put muhammad ali i find twitter id quit blasphem offend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['put', 'muhammad', 'ali', 'i', 'find', 'twitter', 'id', 'quit', 'blasphem', 'offend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['put muhammad ali i find twitter id quit blasphem offend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  798 :\n",
      "\n",
      "\tTweet's text':  yeah english stop say jane word \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'english', 'stop', 'say', 'jane', 'word'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah english stop say jane word'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  799 :\n",
      "\n",
      "\tTweet's text':  law park residenti street opposit side road face wrong direct \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#curiosity'] \n",
      "\n",
      "\tTweet tokenized by words:  ['law', 'park', 'residenti', 'street', 'opposit', 'side', 'road', 'face', 'wrong', 'direct'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['law park residenti street opposit side road face wrong direct'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  800 :\n",
      "\n",
      "\tTweet's text':  good job same sex marriag harm free speech new ontario judg wrote \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'job', 'same', 'sex', 'marriag', 'harm', 'free', 'speech', 'new', 'ontario', 'judg', 'wrote'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good job same sex marriag harm free speech new ontario judg wrote'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  801 :\n",
      "\n",
      "\tTweet's text':  don forget true mean christma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'forget', 'true', 'mean', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don forget true mean christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  802 :\n",
      "\n",
      "\tTweet's text':  um realli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nothanks', '#UVA'] \n",
      "\n",
      "\tTweet tokenized by words:  ['um', 'realli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['um realli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  803 :\n",
      "\n",
      "\tTweet's text':  miss u alway respect u \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#phillhughes', '#63', '#out'] \n",
      "\n",
      "\tTweet tokenized by words:  ['miss', 'u', 'alway', 'respect', 'u'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['miss u alway respect u'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  804 :\n",
      "\n",
      "\tTweet's text':  i miss see face rex hand everyday vlogma rexemoji see evil monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'miss', 'see', 'face', 'rex', 'hand', 'everyday', 'vlogma', 'rexemoji', 'see', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i miss see face rex hand everyday vlogma rexemoji see evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  805 :\n",
      "\n",
      "\tTweet's text':  gawd i love lectur pm lectur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gawd', 'i', 'love', 'lectur', 'pm', 'lectur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gawd i love lectur pm lectur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  806 :\n",
      "\n",
      "\tTweet's text':  wear ranger shirt flip crowd hometown boston so much \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wear', 'ranger', 'shirt', 'flip', 'crowd', 'hometown', 'boston', 'so', 'much'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wear ranger shirt flip crowd hometown boston so much'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  807 :\n",
      "\n",
      "\tTweet's text':  sinc train fare get expens jesu might aswel drink \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sinc', 'train', 'fare', 'get', 'expens', 'jesu', 'might', 'aswel', 'drink'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sinc train fare get expens jesu might aswel drink'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  808 :\n",
      "\n",
      "\tTweet's text':  the citi sleep mass transit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#naptime', '#isntitironic', '#donchathink', '#imnotsure'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'citi', 'sleep', 'mass', 'transit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the citi sleep mass transit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  809 :\n",
      "\n",
      "\tTweet's text':  i hate babysit i sick i wanna sleep i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pensive_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hate', 'babysit', 'i', 'sick', 'i', 'wan', 'na', 'sleep', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hate babysit i sick i wanna sleep i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  810 :\n",
      "\n",
      "\tTweet's text':  i zero resect demarcu cousin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'zero', 'resect', 'demarcu', 'cousin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i zero resect demarcu cousin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  811 :\n",
      "\n",
      "\tTweet's text':  uhhh sleep someon like n i text u phone dri ass fuck fr \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#am', '#a', '#boring', '#person'] \n",
      "\n",
      "\tTweet tokenized by words:  ['uhhh', 'sleep', 'someon', 'like', 'n', 'i', 'text', 'u', 'phone', 'dri', 'ass', 'fuck', 'fr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['uhhh sleep someon like n i text u phone dri ass fuck fr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  812 :\n",
      "\n",
      "\tTweet's text':  jordan fan face stuck tongu hater \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_stuck-out_tongue'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jordan', 'fan', 'face', 'stuck', 'tongu', 'hater'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jordan fan face stuck tongu hater'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  813 :\n",
      "\n",
      "\tTweet's text':  r women consid inferior men societi even wen famili day men need women decis make d \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['D'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['r', 'women', 'consid', 'inferior', 'men', 'societi', 'even', 'wen', 'famili', 'day', 'men', 'need', 'women', 'decis', 'make', 'd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['r women consid inferior men societi even wen famili day men need women decis make d'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  814 :\n",
      "\n",
      "\tTweet's text':  that fine compani \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'fine', 'compani'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that fine compani'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  815 :\n",
      "\n",
      "\tTweet's text':  well becki london nan big girl dan start new job tomorrow haha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#feelingabandoned'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'becki', 'london', 'nan', 'big', 'girl', 'dan', 'start', 'new', 'job', 'tomorrow', 'haha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well becki london nan big girl dan start new job tomorrow haha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  816 :\n",
      "\n",
      "\tTweet's text':  it okay know play loud music quiet hour perfectli fine \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#somepplhavetostudy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'okay', 'know', 'play', 'loud', 'music', 'quiet', 'hour', 'perfectli', 'fine'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it okay know play loud music quiet hour perfectli fine'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  817 :\n",
      "\n",
      "\tTweet's text':  american mum \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['american', 'mum'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['american mum'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  818 :\n",
      "\n",
      "\tTweet's text':  it begin look lot intraven selfi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#selfie', '#xmasdo', '#xmasparty'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'begin', 'look', 'lot', 'intraven', 'selfi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it begin look lot intraven selfi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  819 :\n",
      "\n",
      "\tTweet's text':  i love famili \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'famili'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love famili'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  820 :\n",
      "\n",
      "\tTweet's text':  probabl scar clean ladi half death know i home \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['probabl', 'scar', 'clean', 'ladi', 'half', 'death', 'know', 'i', 'home'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['probabl scar clean ladi half death know i home'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  821 :\n",
      "\n",
      "\tTweet's text':  it even i alreadi call cop twice damn i love job \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'even', 'i', 'alreadi', 'call', 'cop', 'twice', 'damn', 'i', 'love', 'job'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it even i alreadi call cop twice damn i love job'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  822 :\n",
      "\n",
      "\tTweet's text':  oh crap mac shutdown corrupt iphoto hour rebuild ahead might well eat drink \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FestiveFattyBumBum'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'crap', 'mac', 'shutdown', 'corrupt', 'iphoto', 'hour', 'rebuild', 'ahead', 'might', 'well', 'eat', 'drink'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh crap mac shutdown corrupt iphoto hour rebuild ahead might well eat drink'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  823 :\n",
      "\n",
      "\tTweet's text':  it great hear bloodcurdl scream \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'great', 'hear', 'bloodcurdl', 'scream'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it great hear bloodcurdl scream'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  824 :\n",
      "\n",
      "\tTweet's text':  have success avoid everyth season i seen s one timelin thank indi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['have', 'success', 'avoid', 'everyth', 'season', 'i', 'seen', 's', 'one', 'timelin', 'thank', 'indi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['have success avoid everyth season i seen s one timelin thank indi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  825 :\n",
      "\n",
      "\tTweet's text':  and amazingli small opportun sustain life go feed anim kill \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'amazingli', 'small', 'opportun', 'sustain', 'life', 'go', 'feed', 'anim', 'kill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and amazingli small opportun sustain life go feed anim kill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  826 :\n",
      "\n",
      "\tTweet's text':  can get british weather rememb check car wheel small anim like hide car \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['cat_face', 'dog_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'get', 'british', 'weather', 'rememb', 'check', 'car', 'wheel', 'small', 'anim', 'like', 'hide', 'car'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can get british weather rememb check car wheel small anim like hide car'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  827 :\n",
      "\n",
      "\tTweet's text':  it reward work place teacher student reduc noth number test score \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'reward', 'work', 'place', 'teacher', 'student', 'reduc', 'noth', 'number', 'test', 'score'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it reward work place teacher student reduc noth number test score'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  828 :\n",
      "\n",
      "\tTweet's text':  our physic exam quit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Prelim'] \n",
      "\n",
      "\tTweet tokenized by words:  ['our', 'physic', 'exam', 'quit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['our physic exam quit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  829 :\n",
      "\n",
      "\tTweet's text':  photoset leupagu itsxandi thefingerfuckingfemalefuri sevenpoint get paid enough put \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['photoset', 'leupagu', 'itsxandi', 'thefingerfuckingfemalefuri', 'sevenpoint', 'get', 'paid', 'enough', 'put'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photoset leupagu itsxandi thefingerfuckingfemalefuri sevenpoint get paid enough put'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  830 :\n",
      "\n",
      "\tTweet's text':  offic singl www monstermmorpg com cesta follow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Jenny', '#entity', '#dancing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['offic', 'singl', 'www', 'monstermmorpg', 'com', 'cesta', 'follow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['offic singl www monstermmorpg com cesta follow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  831 :\n",
      "\n",
      "\tTweet's text':  will go metric inch mar mile km way \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NASA', '#OrionLaunch', '#NASA_Orion'] \n",
      "\n",
      "\tTweet tokenized by words:  ['will', 'go', 'metric', 'inch', 'mar', 'mile', 'km', 'way'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['will go metric inch mar mile km way'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  832 :\n",
      "\n",
      "\tTweet's text':  i visit great nephew ill fair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'visit', 'great', 'nephew', 'ill', 'fair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i visit great nephew ill fair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  833 :\n",
      "\n",
      "\tTweet's text':  anw long noth go u rn still forgiv u cant promis forget \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['anw', 'long', 'noth', 'go', 'u', 'rn', 'still', 'forgiv', 'u', 'cant', 'promis', 'forget'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anw long noth go u rn still forgiv u cant promis forget'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  834 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Fears', '#for', '#female', '#Saudi', '#activist', '#detention', '#driving', '#car', '#extended'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  835 :\n",
      "\n",
      "\tTweet's text':  oh posit balmi c \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'posit', 'balmi', 'c'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh posit balmi c'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  836 :\n",
      "\n",
      "\tTweet's text':  i may \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#may', '#watching', '#Rockos', '#Modern', '#Life', '#ForeverA90sKid', '#ImNotTheWallabyIusedToBe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'may'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i may'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  837 :\n",
      "\n",
      "\tTweet's text':  decid realli fun thing left hour sit exam write x min word essay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['decid', 'realli', 'fun', 'thing', 'left', 'hour', 'sit', 'exam', 'write', 'x', 'min', 'word', 'essay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['decid realli fun thing left hour sit exam write x min word essay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  838 :\n",
      "\n",
      "\tTweet's text':  i accept way \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'accept', 'way'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i accept way'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  839 :\n",
      "\n",
      "\tTweet's text':  i love wil ignor embrac hate still think hold moral high ground \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wil', 'ignor', 'embrac', 'hate', 'still', 'think', 'hold', 'moral', 'high', 'ground'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wil ignor embrac hate still think hold moral high ground'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  840 :\n",
      "\n",
      "\tTweet's text':  kiss cheek next time enough \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['kiss', 'cheek', 'next', 'time', 'enough'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kiss cheek next time enough'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  841 :\n",
      "\n",
      "\tTweet's text':  no clue talk well first \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'clue', 'talk', 'well', 'first'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no clue talk well first'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  842 :\n",
      "\n",
      "\tTweet's text':  bad game last night way go packer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bad', 'game', 'last', 'night', 'way', 'go', 'packer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bad game last night way go packer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  843 :\n",
      "\n",
      "\tTweet's text':  great christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  844 :\n",
      "\n",
      "\tTweet's text':  florida author say polic offic shot kill \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Florida', '#TarponSprings', '#TampaBay'] \n",
      "\n",
      "\tTweet tokenized by words:  ['florida', 'author', 'say', 'polic', 'offic', 'shot', 'kill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['florida author say polic offic shot kill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  845 :\n",
      "\n",
      "\tTweet's text':  i wrong i thought i find way lead \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wrong', 'i', 'thought', 'i', 'find', 'way', 'lead'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wrong i thought i find way lead'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  846 :\n",
      "\n",
      "\tTweet's text':  player penal play defens awar david ortiz bare averag base war \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['player', 'penal', 'play', 'defens', 'awar', 'david', 'ortiz', 'bare', 'averag', 'base', 'war'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['player penal play defens awar david ortiz bare averag base war'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  847 :\n",
      "\n",
      "\tTweet's text':  unit next semest plu work ye excit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['unit', 'next', 'semest', 'plu', 'work', 'ye', 'excit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['unit next semest plu work ye excit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  848 :\n",
      "\n",
      "\tTweet's text':  need start go bed goodnight everyon say goodmorn haha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#morning'] \n",
      "\n",
      "\tTweet tokenized by words:  ['need', 'start', 'go', 'bed', 'goodnight', 'everyon', 'say', 'goodmorn', 'haha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['need start go bed goodnight everyon say goodmorn haha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  849 :\n",
      "\n",
      "\tTweet's text':  tri nahe akhtar nayyara noor gold stash \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tri', 'nahe', 'akhtar', 'nayyara', 'noor', 'gold', 'stash'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tri nahe akhtar nayyara noor gold stash'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  850 :\n",
      "\n",
      "\tTweet's text':  i idea brad would \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'idea', 'brad', 'would'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i idea brad would'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  851 :\n",
      "\n",
      "\tTweet's text':  bbc new skywalk passport cancel frivol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#trademarks'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bbc', 'new', 'skywalk', 'passport', 'cancel', 'frivol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bbc new skywalk passport cancel frivol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  852 :\n",
      "\n",
      "\tTweet's text':  jami took account don worri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jami', 'took', 'account', 'don', 'worri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jami took account don worri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  853 :\n",
      "\n",
      "\tTweet's text':  final worri free year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'worri', 'free', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final worri free year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  854 :\n",
      "\n",
      "\tTweet's text':  tomorrow afternoon sked area wecp p p wpgx p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NFL', '#PanamaCity', '#KCvsPIT', '#INDvsDAL', '#ATLvsNO'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tomorrow', 'afternoon', 'sked', 'area', 'wecp', 'p', 'p', 'wpgx', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tomorrow afternoon sked area wecp p p wpgx p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  855 :\n",
      "\n",
      "\tTweet's text':  duh is owner fire goodel my guess get rais \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoodellMustGo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['duh', 'is', 'owner', 'fire', 'goodel', 'my', 'guess', 'get', 'rais'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['duh is owner fire goodel my guess get rais'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  856 :\n",
      "\n",
      "\tTweet's text':  i surpris mani ppl block \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['weary_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#ITalkTooMuchShit', '#YOURSTILLCLOCKINGMETHO', '#ThatsWhyYourGirlStillFollows'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'surpris', 'mani', 'ppl', 'block'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i surpris mani ppl block'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  857 :\n",
      "\n",
      "\tTweet's text':  cup tea say fame dad top leader \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#politics', '#sonakshi', '#lingaa', '#sonakshi', '#shatru', '#bjp'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cup', 'tea', 'say', 'fame', 'dad', 'top', 'leader'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cup tea say fame dad top leader'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  858 :\n",
      "\n",
      "\tTweet's text':  much herb new trend pothead contribut societi mayb darn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['much', 'herb', 'new', 'trend', 'pothead', 'contribut', 'societi', 'mayb', 'darn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['much herb new trend pothead contribut societi mayb darn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  859 :\n",
      "\n",
      "\tTweet's text':  exo come soon better pray better member sigh but either way obssess fan would still obsses \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['exo', 'come', 'soon', 'better', 'pray', 'better', 'member', 'sigh', 'but', 'either', 'way', 'obssess', 'fan', 'would', 'still', 'obsses'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['exo come soon better pray better member sigh but either way obssess fan would still obsses'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  860 :\n",
      "\n",
      "\tTweet's text':  big fan flock support tcu ou beat texa loss wvu manhandl lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['big', 'fan', 'flock', 'support', 'tcu', 'ou', 'beat', 'texa', 'loss', 'wvu', 'manhandl', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['big fan flock support tcu ou beat texa loss wvu manhandl lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  861 :\n",
      "\n",
      "\tTweet's text':  i veri limit number press seat avail meet me there screen austin januari hit press type \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'veri', 'limit', 'number', 'press', 'seat', 'avail', 'meet', 'me', 'there', 'screen', 'austin', 'januari', 'hit', 'press', 'type'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i veri limit number press seat avail meet me there screen austin januari hit press type'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  862 :\n",
      "\n",
      "\tTweet's text':  toppscard i find letter binder i find \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['toppscard', 'i', 'find', 'letter', 'binder', 'i', 'find'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['toppscard i find letter binder i find'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  863 :\n",
      "\n",
      "\tTweet's text':  mani anim peta kill everi year hypocrisi want point cid inward \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hypocrisy', '#idiots'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mani', 'anim', 'peta', 'kill', 'everi', 'year', 'hypocrisi', 'want', 'point', 'cid', 'inward'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mani anim peta kill everi year hypocrisi want point cid inward'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  864 :\n",
      "\n",
      "\tTweet's text':  i love wake feel like insid chop tini piec set fire \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['loudly_crying_face', 'fire', 'hocho'] \n",
      "\n",
      "\tTweet's hashtags':  ['#killmenow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wake', 'feel', 'like', 'insid', 'chop', 'tini', 'piec', 'set', 'fire'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wake feel like insid chop tini piec set fire'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  865 :\n",
      "\n",
      "\tTweet's text':  sure wow nintendo achiev soni alreadi year ago \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sure', 'wow', 'nintendo', 'achiev', 'soni', 'alreadi', 'year', 'ago'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sure wow nintendo achiev soni alreadi year ago'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  866 :\n",
      "\n",
      "\tTweet's text':  show us even though \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#America', '#continues', '#BlackPeople'] \n",
      "\n",
      "\tTweet tokenized by words:  ['show', 'us', 'even', 'though'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['show us even though'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  867 :\n",
      "\n",
      "\tTweet's text':  hmmm i wonder astec one fewer employe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lol'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hmmm', 'i', 'wonder', 'astec', 'one', 'fewer', 'employe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hmmm i wonder astec one fewer employe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  868 :\n",
      "\n",
      "\tTweet's text':  i sure inconsol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'sure', 'inconsol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i sure inconsol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  869 :\n",
      "\n",
      "\tTweet's text':  listen rain bed \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['splashing_sweat_symbol', 'droplet', 'umbrella_with_rain_drops'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Peacefull'] \n",
      "\n",
      "\tTweet tokenized by words:  ['listen', 'rain', 'bed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['listen rain bed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  870 :\n",
      "\n",
      "\tTweet's text':  yay get pink eye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whyme'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'get', 'pink', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay get pink eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  871 :\n",
      "\n",
      "\tTweet's text':  wow great banter \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'great', 'banter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow great banter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  872 :\n",
      "\n",
      "\tTweet's text':  dna richard iii thrown surpris evid infidel famili tree well i shock \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dna', 'richard', 'iii', 'thrown', 'surpris', 'evid', 'infidel', 'famili', 'tree', 'well', 'i', 'shock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dna richard iii thrown surpris evid infidel famili tree well i shock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  873 :\n",
      "\n",
      "\tTweet's text':  isn great sleep hour feel like million buck \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#gettingold'] \n",
      "\n",
      "\tTweet tokenized by words:  ['isn', 'great', 'sleep', 'hour', 'feel', 'like', 'million', 'buck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['isn great sleep hour feel like million buck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  874 :\n",
      "\n",
      "\tTweet's text':  i honestli clue i hope sinc surveil cam i seen show bare anyth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'honestli', 'clue', 'i', 'hope', 'sinc', 'surveil', 'cam', 'i', 'seen', 'show', 'bare', 'anyth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i honestli clue i hope sinc surveil cam i seen show bare anyth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  875 :\n",
      "\n",
      "\tTweet's text':  peopl get the best \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'get', 'the', 'best'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl get the best'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  876 :\n",
      "\n",
      "\tTweet's text':  i like video semi sweet vs origin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'like', 'video', 'semi', 'sweet', 'vs', 'origin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i like video semi sweet vs origin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  877 :\n",
      "\n",
      "\tTweet's text':  can wait appoint tomorrow oh time pleas speed today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dental'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'appoint', 'tomorrow', 'oh', 'time', 'pleas', 'speed', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait appoint tomorrow oh time pleas speed today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  878 :\n",
      "\n",
      "\tTweet's text':  i look bridg without cri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'look', 'bridg', 'without', 'cri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i look bridg without cri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  879 :\n",
      "\n",
      "\tTweet's text':  love i never fall asleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#insomnia'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'i', 'never', 'fall', 'asleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love i never fall asleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  880 :\n",
      "\n",
      "\tTweet's text':  wast \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  881 :\n",
      "\n",
      "\tTweet's text':  can trade mccain biden help republican mccain in time mccain would democrat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'trade', 'mccain', 'biden', 'help', 'republican', 'mccain', 'in', 'time', 'mccain', 'would', 'democrat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can trade mccain biden help republican mccain in time mccain would democrat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  882 :\n",
      "\n",
      "\tTweet's text':  happi monday hate monday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'monday', 'hate', 'monday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi monday hate monday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  883 :\n",
      "\n",
      "\tTweet's text':  is hold rule anymor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'hold', 'rule', 'anymor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is hold rule anymor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  884 :\n",
      "\n",
      "\tTweet's text':  doubt and wonder xma make ppl crazi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['doubt', 'and', 'wonder', 'xma', 'make', 'ppl', 'crazi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['doubt and wonder xma make ppl crazi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  885 :\n",
      "\n",
      "\tTweet's text':  it get yo lazi butt outta bed thank prove point \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'get', 'yo', 'lazi', 'butt', 'outta', 'bed', 'thank', 'prove', 'point'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it get yo lazi butt outta bed thank prove point'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  886 :\n",
      "\n",
      "\tTweet's text':  much lie deceit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['much', 'lie', 'deceit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['much lie deceit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  887 :\n",
      "\n",
      "\tTweet's text':  i like video ps my career mode ep tripl threat wwe k \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#12'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'like', 'video', 'ps', 'my', 'career', 'mode', 'ep', 'tripl', 'threat', 'wwe', 'k'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i like video ps my career mode ep tripl threat wwe k'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  888 :\n",
      "\n",
      "\tTweet's text':  hey denialcsgo decid want replac i new player nobodi safe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NAShuffle', '#CSGO'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'denialcsgo', 'decid', 'want', 'replac', 'i', 'new', 'player', 'nobodi', 'safe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey denialcsgo decid want replac i new player nobodi safe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  889 :\n",
      "\n",
      "\tTweet's text':  thi time chang crazi everyon like woohoo let live life i like i slept yet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'time', 'chang', 'crazi', 'everyon', 'like', 'woohoo', 'let', 'live', 'life', 'i', 'like', 'i', 'slept', 'yet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi time chang crazi everyon like woohoo let live life i like i slept yet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  890 :\n",
      "\n",
      "\tTweet's text':  whi playoff legend romo \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'playoff', 'legend', 'romo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi playoff legend romo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  891 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Palestinian', '#Authority', '#Abbas', '#trades', '#stalemate', '#confrontation', '#ICC', '#move'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  892 :\n",
      "\n",
      "\tTweet's text':  thnx sort thank tri help thaku repli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  ['#kids', '#happy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thnx', 'sort', 'thank', 'tri', 'help', 'thaku', 'repli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thnx sort thank tri help thaku repli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  893 :\n",
      "\n",
      "\tTweet's text':  how know realli love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tmi', '#imsorry', '#chickfila'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'know', 'realli', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how know realli love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  894 :\n",
      "\n",
      "\tTweet's text':  damit fatima bhutto instagram account pic some random \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['damit', 'fatima', 'bhutto', 'instagram', 'account', 'pic', 'some', 'random'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['damit fatima bhutto instagram account pic some random'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  895 :\n",
      "\n",
      "\tTweet's text':  i love today go \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'today', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love today go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  896 :\n",
      "\n",
      "\tTweet's text':  tribut brave eleph simpli defend famili \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tribut', 'brave', 'eleph', 'simpli', 'defend', 'famili'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tribut brave eleph simpli defend famili'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  897 :\n",
      "\n",
      "\tTweet's text':  i gave head bed orz \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'gave', 'head', 'bed', 'orz'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i gave head bed orz'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  898 :\n",
      "\n",
      "\tTweet's text':  so nice final sun even \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'nice', 'final', 'sun', 'even'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so nice final sun even'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  899 :\n",
      "\n",
      "\tTweet's text':  still wait son happi enjo christma gift cant understand u prevent \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['still', 'wait', 'son', 'happi', 'enjo', 'christma', 'gift', 'cant', 'understand', 'u', 'prevent'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['still wait son happi enjo christma gift cant understand u prevent'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  900 :\n",
      "\n",
      "\tTweet's text':  count pushkin end fvckin night smh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['count', 'pushkin', 'end', 'fvckin', 'night', 'smh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['count pushkin end fvckin night smh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  901 :\n",
      "\n",
      "\tTweet's text':  home final what way start christma break \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign', 'ok_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['home', 'final', 'what', 'way', 'start', 'christma', 'break'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['home final what way start christma break'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  902 :\n",
      "\n",
      "\tTweet's text':  you argument obvious impact fact famili tsi appear \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'argument', 'obvious', 'impact', 'fact', 'famili', 'tsi', 'appear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you argument obvious impact fact famili tsi appear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  903 :\n",
      "\n",
      "\tTweet's text':  i got tonsil good luck \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lovinglife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'got', 'tonsil', 'good', 'luck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i got tonsil good luck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  904 :\n",
      "\n",
      "\tTweet's text':  the counter baylor would talk benefit big champ \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'counter', 'baylor', 'would', 'talk', 'benefit', 'big', 'champ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the counter baylor would talk benefit big champ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  905 :\n",
      "\n",
      "\tTweet's text':  oh get see the queen garden address nation just i alway want \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#itv'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'get', 'see', 'the', 'queen', 'garden', 'address', 'nation', 'just', 'i', 'alway', 'want'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh get see the queen garden address nation just i alway want'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  906 :\n",
      "\n",
      "\tTweet's text':  oh i love faint randomli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'i', 'love', 'faint', 'randomli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh i love faint randomli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  907 :\n",
      "\n",
      "\tTweet's text':  my jambo buddi see scottish ident emerg hmfc the john wilson type travel govan \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'jambo', 'buddi', 'see', 'scottish', 'ident', 'emerg', 'hmfc', 'the', 'john', 'wilson', 'type', 'travel', 'govan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my jambo buddi see scottish ident emerg hmfc the john wilson type travel govan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  908 :\n",
      "\n",
      "\tTweet's text':  it joy wake sick abl use one arm i everyth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'joy', 'wake', 'sick', 'abl', 'use', 'one', 'arm', 'i', 'everyth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it joy wake sick abl use one arm i everyth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  909 :\n",
      "\n",
      "\tTweet's text':  photo loud say quitter never \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Say', '#proud', '#Nope', '#never', '#be', '#always', '#winning'] \n",
      "\n",
      "\tTweet tokenized by words:  ['photo', 'loud', 'say', 'quitter', 'never'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photo loud say quitter never'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  910 :\n",
      "\n",
      "\tTweet's text':  far import problem know money \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Love', '#money', '#life', '#humanity'] \n",
      "\n",
      "\tTweet tokenized by words:  ['far', 'import', 'problem', 'know', 'money'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['far import problem know money'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  911 :\n",
      "\n",
      "\tTweet's text':  contrari i wide awak caffein inject conscious \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes', 'flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['contrari', 'i', 'wide', 'awak', 'caffein', 'inject', 'conscious'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['contrari i wide awak caffein inject conscious'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  912 :\n",
      "\n",
      "\tTweet's text':  mani best idea come finger fat keyboard \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nimble', '#agile'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mani', 'best', 'idea', 'come', 'finger', 'fat', 'keyboard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mani best idea come finger fat keyboard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  913 :\n",
      "\n",
      "\tTweet's text':  time babi i take medicin get better \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'babi', 'i', 'take', 'medicin', 'get', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time babi i take medicin get better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  914 :\n",
      "\n",
      "\tTweet's text':  yet anoth million doctor visit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yet', 'anoth', 'million', 'doctor', 'visit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yet anoth million doctor visit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  915 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TeenAnalCasting', '#2003'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  916 :\n",
      "\n",
      "\tTweet's text':  been problem actual rt tough road trip cant win em coach strong \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['been', 'problem', 'actual', 'rt', 'tough', 'road', 'trip', 'cant', 'win', 'em', 'coach', 'strong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['been problem actual rt tough road trip cant win em coach strong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  917 :\n",
      "\n",
      "\tTweet's text':  roll royc envis wonder peopl mansori \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#rollsroyce', '#purple', '#customcar'] \n",
      "\n",
      "\tTweet tokenized by words:  ['roll', 'royc', 'envis', 'wonder', 'peopl', 'mansori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['roll royc envis wonder peopl mansori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  918 :\n",
      "\n",
      "\tTweet's text':  it s definit not friday the reason is it tuesday yesterday monday friday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 's', 'definit', 'not', 'friday', 'the', 'reason', 'is', 'it', 'tuesday', 'yesterday', 'monday', 'friday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it s definit not friday the reason is it tuesday yesterday monday friday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  919 :\n",
      "\n",
      "\tTweet's text':  never seen \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['never', 'seen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['never seen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  920 :\n",
      "\n",
      "\tTweet's text':  last day school much fun much peopl came shocker \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['last', 'day', 'school', 'much', 'fun', 'much', 'peopl', 'came', 'shocker'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['last day school much fun much peopl came shocker'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  921 :\n",
      "\n",
      "\tTweet's text':  besid overpr holiday candl i seen one deal worthwhil today brutal \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CyberMonday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['besid', 'overpr', 'holiday', 'candl', 'i', 'seen', 'one', 'deal', 'worthwhil', 'today', 'brutal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['besid overpr holiday candl i seen one deal worthwhil today brutal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  922 :\n",
      "\n",
      "\tTweet's text':  thi weather love walk work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#worst', '#weatherbomb'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'weather', 'love', 'walk', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi weather love walk work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  923 :\n",
      "\n",
      "\tTweet's text':  the campaign hour ps it still better bf campaign tho i finish p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['p'] \n",
      "\n",
      "\tTweet's hashtags':  ['#AdvancedWarfare'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'campaign', 'hour', 'ps', 'it', 'still', 'better', 'bf', 'campaign', 'tho', 'i', 'finish', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the campaign hour ps it still better bf campaign tho i finish p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  924 :\n",
      "\n",
      "\tTweet's text':  noth like wake financi formula yay corpor financ comprehens final \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#finalsweek'] \n",
      "\n",
      "\tTweet tokenized by words:  ['noth', 'like', 'wake', 'financi', 'formula', 'yay', 'corpor', 'financ', 'comprehens', 'final'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noth like wake financi formula yay corpor financ comprehens final'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  925 :\n",
      "\n",
      "\tTweet's text':  i pick great week start new show netflix \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HellOnWheels'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'pick', 'great', 'week', 'start', 'new', 'show', 'netflix'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i pick great week start new show netflix'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  926 :\n",
      "\n",
      "\tTweet's text':  bday lili paint \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['purple_heart'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bday', 'lili', 'paint'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bday lili paint'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  927 :\n",
      "\n",
      "\tTweet's text':  tomorrowstand yup that exactli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tomorrowstand', 'yup', 'that', 'exactli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tomorrowstand yup that exactli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  928 :\n",
      "\n",
      "\tTweet's text':  bad pictur seem indic you still horribl person \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bad', 'pictur', 'seem', 'indic', 'you', 'still', 'horribl', 'person'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bad pictur seem indic you still horribl person'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  929 :\n",
      "\n",
      "\tTweet's text':  like \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  930 :\n",
      "\n",
      "\tTweet's text':  can believ even consid renam academ build p \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'believ', 'even', 'consid', 'renam', 'academ', 'build', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can believ even consid renam academ build p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  931 :\n",
      "\n",
      "\tTweet's text':  that nice \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'nice'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that nice'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  932 :\n",
      "\n",
      "\tTweet's text':  check out youtub channel \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['check', 'out', 'youtub', 'channel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['check out youtub channel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  933 :\n",
      "\n",
      "\tTweet's text':  it great week dictat congrat north korea cuba \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'great', 'week', 'dictat', 'congrat', 'north', 'korea', 'cuba'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it great week dictat congrat north korea cuba'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  934 :\n",
      "\n",
      "\tTweet's text':  my boy anoth cold spent night cough sneez \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sexy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'boy', 'anoth', 'cold', 'spent', 'night', 'cough', 'sneez'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my boy anoth cold spent night cough sneez'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  935 :\n",
      "\n",
      "\tTweet's text':  heard back yet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['heard', 'back', 'yet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['heard back yet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  936 :\n",
      "\n",
      "\tTweet's text':  went check caus way late sleep bam never whi find import tell \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['went', 'check', 'caus', 'way', 'late', 'sleep', 'bam', 'never', 'whi', 'find', 'import', 'tell'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['went check caus way late sleep bam never whi find import tell'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  937 :\n",
      "\n",
      "\tTweet's text':  the whole world never get level \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'whole', 'world', 'never', 'get', 'level'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the whole world never get level'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  938 :\n",
      "\n",
      "\tTweet's text':  great job keep peopl safe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'job', 'keep', 'peopl', 'safe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great job keep peopl safe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  939 :\n",
      "\n",
      "\tTweet's text':  dont think would matter metric english doesnt understand math \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dont', 'think', 'would', 'matter', 'metric', 'english', 'doesnt', 'understand', 'math'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dont think would matter metric english doesnt understand math'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  940 :\n",
      "\n",
      "\tTweet's text':  wing i wing of cours boy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wing', 'i', 'wing', 'of', 'cours', 'boy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wing i wing of cours boy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  941 :\n",
      "\n",
      "\tTweet's text':  the uofl student ticket polici well thought plan good job sga \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ihateyou'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'uofl', 'student', 'ticket', 'polici', 'well', 'thought', 'plan', 'good', 'job', 'sga'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the uofl student ticket polici well thought plan good job sga'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  942 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['fisted_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  ['#fistbump', '#positive', '#focus', '#starve', '#distractions', '#werk', '#motivation', '#createpath', '#uplift', '#success'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  943 :\n",
      "\n",
      "\tTweet's text':  rant pregnant judg buy bottl wine pose weekli belli pic front wine rack \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fail'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rant', 'pregnant', 'judg', 'buy', 'bottl', 'wine', 'pose', 'weekli', 'belli', 'pic', 'front', 'wine', 'rack'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rant pregnant judg buy bottl wine pose weekli belli pic front wine rack'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  944 :\n",
      "\n",
      "\tTweet's text':  get around \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'around'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get around'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  945 :\n",
      "\n",
      "\tTweet's text':  oh right know john parker pisshead \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'right', 'know', 'john', 'parker', 'pisshead'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh right know john parker pisshead'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  946 :\n",
      "\n",
      "\tTweet's text':  herp \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FEMALECONDOMS', '#herpes', '#curable', '#can', '#be', '#managed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['herp'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['herp'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  947 :\n",
      "\n",
      "\tTweet's text':  what event weekend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'event', 'weekend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what event weekend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  948 :\n",
      "\n",
      "\tTweet's text':  awesom destin site high popul k super easi get lot great site will well \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['awesom', 'destin', 'site', 'high', 'popul', 'k', 'super', 'easi', 'get', 'lot', 'great', 'site', 'will', 'well'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['awesom destin site high popul k super easi get lot great site will well'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  949 :\n",
      "\n",
      "\tTweet's text':  kyle let but yeah grown ass men fast car who give af lol and bring room hooah see ya bit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['kyle', 'let', 'but', 'yeah', 'grown', 'ass', 'men', 'fast', 'car', 'who', 'give', 'af', 'lol', 'and', 'bring', 'room', 'hooah', 'see', 'ya', 'bit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kyle let but yeah grown ass men fast car who give af lol and bring room hooah see ya bit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  950 :\n",
      "\n",
      "\tTweet's text':  wrong i watch film follow twitter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wrong', 'i', 'watch', 'film', 'follow', 'twitter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wrong i watch film follow twitter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  951 :\n",
      "\n",
      "\tTweet's text':  i rememb last time i saw newish gti ever seen golf r what chang \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'rememb', 'last', 'time', 'i', 'saw', 'newish', 'gti', 'ever', 'seen', 'golf', 'r', 'what', 'chang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i rememb last time i saw newish gti ever seen golf r what chang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  952 :\n",
      "\n",
      "\tTweet's text':  i realli realli want appl pie boilo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'realli', 'realli', 'want', 'appl', 'pie', 'boilo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i realli realli want appl pie boilo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  953 :\n",
      "\n",
      "\tTweet's text':  thi sound high safe short term use it dramat increas antimicrobi peptid blood \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'sound', 'high', 'safe', 'short', 'term', 'use', 'it', 'dramat', 'increas', 'antimicrobi', 'peptid', 'blood'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi sound high safe short term use it dramat increas antimicrobi peptid blood'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  954 :\n",
      "\n",
      "\tTweet's text':  ostentati showi display design impress that word i immedi think i see woman feed child \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Idiot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ostentati', 'showi', 'display', 'design', 'impress', 'that', 'word', 'i', 'immedi', 'think', 'i', 'see', 'woman', 'feed', 'child'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ostentati showi display design impress that word i immedi think i see woman feed child'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  955 :\n",
      "\n",
      "\tTweet's text':  for queen countri yet go destroy english citi attack english polic lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['for', 'queen', 'countri', 'yet', 'go', 'destroy', 'english', 'citi', 'attack', 'english', 'polic', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['for queen countri yet go destroy english citi attack english polic lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  956 :\n",
      "\n",
      "\tTweet's text':  congrat still sasmvt good run ulitin nalang ulit ang peat next year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['congrat', 'still', 'sasmvt', 'good', 'run', 'ulitin', 'nalang', 'ulit', 'ang', 'peat', 'next', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['congrat still sasmvt good run ulitin nalang ulit ang peat next year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  957 :\n",
      "\n",
      "\tTweet's text':  she malawi i stuck joburg fair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['she', 'malawi', 'i', 'stuck', 'joburg', 'fair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['she malawi i stuck joburg fair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  958 :\n",
      "\n",
      "\tTweet's text':  if someon could come give massag would gr \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'someon', 'could', 'come', 'give', 'massag', 'would', 'gr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if someon could come give massag would gr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  959 :\n",
      "\n",
      "\tTweet's text':  i play back ground p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['p'] \n",
      "\n",
      "\tTweet's hashtags':  ['#OTH', '#naughty', '#FUN'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'play', 'back', 'ground', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i play back ground p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  960 :\n",
      "\n",
      "\tTweet's text':  favorit thing tuesday write psycholog paper \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#killme'] \n",
      "\n",
      "\tTweet tokenized by words:  ['favorit', 'thing', 'tuesday', 'write', 'psycholog', 'paper'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['favorit thing tuesday write psycholog paper'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  961 :\n",
      "\n",
      "\tTweet's text':  yay earli morn protestor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#heavyamountsofsarcasm'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'earli', 'morn', 'protestor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay earli morn protestor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  962 :\n",
      "\n",
      "\tTweet's text':  nbcsportsroc arizona coyot forg deal bmw but reloc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nbcsportsroc', 'arizona', 'coyot', 'forg', 'deal', 'bmw', 'but', 'reloc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nbcsportsroc arizona coyot forg deal bmw but reloc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  963 :\n",
      "\n",
      "\tTweet's text':  hello give guess xbox core servic fix \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hello', 'give', 'guess', 'xbox', 'core', 'servic', 'fix'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hello give guess xbox core servic fix'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  964 :\n",
      "\n",
      "\tTweet's text':  joel olstein man hardli ever mention jesu sermon go talk mean christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['joel', 'olstein', 'man', 'hardli', 'ever', 'mention', 'jesu', 'sermon', 'go', 'talk', 'mean', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['joel olstein man hardli ever mention jesu sermon go talk mean christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  965 :\n",
      "\n",
      "\tTweet's text':  today see evil monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['see-no-evil_monkey', 'smiling_face_with_open_mouth_and_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  ['#ready', '#business', '#tiredashell', '#coffeecoffeecoffee', '#morecoffee'] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'see', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today see evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  966 :\n",
      "\n",
      "\tTweet's text':  i dont understand tlist i dont read inamorata i read inamorato lmao prob lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sorry'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'dont', 'understand', 'tlist', 'i', 'dont', 'read', 'inamorata', 'i', 'read', 'inamorato', 'lmao', 'prob', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i dont understand tlist i dont read inamorata i read inamorato lmao prob lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  967 :\n",
      "\n",
      "\tTweet's text':  she two marijuana look happen don \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet's hashtags':  ['#LegalizeIt', '#Merica'] \n",
      "\n",
      "\tTweet tokenized by words:  ['she', 'two', 'marijuana', 'look', 'happen', 'don'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['she two marijuana look happen don'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  968 :\n",
      "\n",
      "\tTweet's text':  slay igloo australia home countri lol rt nicki slay new zealand \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['slay', 'igloo', 'australia', 'home', 'countri', 'lol', 'rt', 'nicki', 'slay', 'new', 'zealand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['slay igloo australia home countri lol rt nicki slay new zealand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  969 :\n",
      "\n",
      "\tTweet's text':  see use version control \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notjustWordPress'] \n",
      "\n",
      "\tTweet tokenized by words:  ['see', 'use', 'version', 'control'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['see use version control'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  970 :\n",
      "\n",
      "\tTweet's text':  less hour sleep fantast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['less', 'hour', 'sleep', 'fantast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['less hour sleep fantast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  971 :\n",
      "\n",
      "\tTweet's text':  wesay yar date good i guess first meet want b seen girl smth hindsight i found mashkook \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['winking_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wesay', 'yar', 'date', 'good', 'i', 'guess', 'first', 'meet', 'want', 'b', 'seen', 'girl', 'smth', 'hindsight', 'i', 'found', 'mashkook'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wesay yar date good i guess first meet want b seen girl smth hindsight i found mashkook'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  972 :\n",
      "\n",
      "\tTweet's text':  sorri miss tag end tweet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sorri', 'miss', 'tag', 'end', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sorri miss tag end tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  973 :\n",
      "\n",
      "\tTweet's text':  i love adult act like children \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#eyeroll'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'adult', 'act', 'like', 'children'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love adult act like children'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  974 :\n",
      "\n",
      "\tTweet's text':  i feel faint chase whippet lili libbi gabbi milli cat play chase garden \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AintItFun', '#notfun'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'feel', 'faint', 'chase', 'whippet', 'lili', 'libbi', 'gabbi', 'milli', 'cat', 'play', 'chase', 'garden'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i feel faint chase whippet lili libbi gabbi milli cat play chase garden'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  975 :\n",
      "\n",
      "\tTweet's text':  earthpix ador littl white tiger \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['earthpix', 'ador', 'littl', 'white', 'tiger'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['earthpix ador littl white tiger'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  976 :\n",
      "\n",
      "\tTweet's text':  i ask god protect enemi long time ago short i start lose friend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#naah'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'ask', 'god', 'protect', 'enemi', 'long', 'time', 'ago', 'short', 'i', 'start', 'lose', 'friend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i ask god protect enemi long time ago short i start lose friend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  977 :\n",
      "\n",
      "\tTweet's text':  aren human one play sport \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aren', 'human', 'one', 'play', 'sport'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aren human one play sport'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  978 :\n",
      "\n",
      "\tTweet's text':  guy final \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['hundred_points_symbol'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['guy', 'final'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['guy final'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  979 :\n",
      "\n",
      "\tTweet's text':  k give us famou bf fan need entertain appar \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['k', 'give', 'us', 'famou', 'bf', 'fan', 'need', 'entertain', 'appar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['k give us famou bf fan need entertain appar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  980 :\n",
      "\n",
      "\tTweet's text':  that \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HellBeFiredinElevenMonths'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  981 :\n",
      "\n",
      "\tTweet's text':  didnt time wake bake mornin winnin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pouting_face', 'face_with_no_good_gesture'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['didnt', 'time', 'wake', 'bake', 'mornin', 'winnin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['didnt time wake bake mornin winnin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  982 :\n",
      "\n",
      "\tTweet's text':  awak earli day bung \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['awak', 'earli', 'day', 'bung'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['awak earli day bung'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  983 :\n",
      "\n",
      "\tTweet's text':  it begin look lot like christma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#timetodecorate', '#tistheseason'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'begin', 'look', 'lot', 'like', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it begin look lot like christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  984 :\n",
      "\n",
      "\tTweet's text':  soni studio boss to employe don worri we be fine feel better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['soni', 'studio', 'boss', 'to', 'employe', 'don', 'worri', 'we', 'be', 'fine', 'feel', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['soni studio boss to employe don worri we be fine feel better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  985 :\n",
      "\n",
      "\tTweet's text':  i bet fairway green rival work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'bet', 'fairway', 'green', 'rival', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i bet fairway green rival work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  986 :\n",
      "\n",
      "\tTweet's text':  haha quit right mate they coonti worker got aff easi al tell ye oot workin like hamilton acci \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'man_with_turban'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'quit', 'right', 'mate', 'they', 'coonti', 'worker', 'got', 'aff', 'easi', 'al', 'tell', 'ye', 'oot', 'workin', 'like', 'hamilton', 'acci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha quit right mate they coonti worker got aff easi al tell ye oot workin like hamilton acci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  987 :\n",
      "\n",
      "\tTweet's text':  life like bird pretti cute crap head \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Gharwapsi', '#72HoursOfCrazy', '#PowerOfFive', '#lol', '#AntiConversionLaw'] \n",
      "\n",
      "\tTweet tokenized by words:  ['life', 'like', 'bird', 'pretti', 'cute', 'crap', 'head'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['life like bird pretti cute crap head'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  988 :\n",
      "\n",
      "\tTweet's text':  shallow af stop discrimin eye eye beauti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shallow', 'af', 'stop', 'discrimin', 'eye', 'eye', 'beauti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shallow af stop discrimin eye eye beauti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  989 :\n",
      "\n",
      "\tTweet's text':  mk shadow shift much fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mk', 'shadow', 'shift', 'much', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mk shadow shift much fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  990 :\n",
      "\n",
      "\tTweet's text':  pierc what wrong \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pierc', 'what', 'wrong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pierc what wrong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  991 :\n",
      "\n",
      "\tTweet's text':  when stop accept crumb name love equal appreci silenc solitud festiv love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'stop', 'accept', 'crumb', 'name', 'love', 'equal', 'appreci', 'silenc', 'solitud', 'festiv', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when stop accept crumb name love equal appreci silenc solitud festiv love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  992 :\n",
      "\n",
      "\tTweet's text':  god bless whoever came idea make colour \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['god', 'bless', 'whoever', 'came', 'idea', 'make', 'colour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['god bless whoever came idea make colour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  993 :\n",
      "\n",
      "\tTweet's text':  new music crack music \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HipHop', '#JerseyCity', '#NJ', '#NY', '#BirthOfAWinner'] \n",
      "\n",
      "\tTweet tokenized by words:  ['new', 'music', 'crack', 'music'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['new music crack music'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  994 :\n",
      "\n",
      "\tTweet's text':  saturday selfi miss guy jessica xxx mark kiss \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['kiss', 'face_throwing_a_kiss'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['saturday', 'selfi', 'miss', 'guy', 'jessica', 'xxx', 'mark', 'kiss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['saturday selfi miss guy jessica xxx mark kiss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  995 :\n",
      "\n",
      "\tTweet's text':  if love game got dessert might enjoy even arbi talk smack fsu \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Turnovers', '#OREvsFSU'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'love', 'game', 'got', 'dessert', 'might', 'enjoy', 'even', 'arbi', 'talk', 'smack', 'fsu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if love game got dessert might enjoy even arbi talk smack fsu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  996 :\n",
      "\n",
      "\tTweet's text':  exactli year ago today via \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['exactli', 'year', 'ago', 'today', 'via'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['exactli year ago today via'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  997 :\n",
      "\n",
      "\tTweet's text':  it greaaaat night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes', 'white_smiling_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'greaaaat', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it greaaaat night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  998 :\n",
      "\n",
      "\tTweet's text':  i wonder audio \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wonder', 'audio'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wonder audio'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  999 :\n",
      "\n",
      "\tTweet's text':  queen of the stone age rock in rio \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#queensofthestoneage', '#rockinrio'] \n",
      "\n",
      "\tTweet tokenized by words:  ['queen', 'of', 'the', 'stone', 'age', 'rock', 'in', 'rio'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['queen of the stone age rock in rio'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1000 :\n",
      "\n",
      "\tTweet's text':  want get hit bu get \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bestroomieaward'] \n",
      "\n",
      "\tTweet tokenized by words:  ['want', 'get', 'hit', 'bu', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['want get hit bu get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1001 :\n",
      "\n",
      "\tTweet's text':  hold it bub \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cartoon', '#comics', '#funny', '#jesus'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hold', 'it', 'bub'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hold it bub'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1002 :\n",
      "\n",
      "\tTweet's text':  unless chang \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['unless', 'chang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['unless chang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1003 :\n",
      "\n",
      "\tTweet's text':  pleas follow i technic question thank \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pleas', 'follow', 'i', 'technic', 'question', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pleas follow i technic question thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1004 :\n",
      "\n",
      "\tTweet's text':  morelik app \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#necklace', '#sweet', '#you', '#running', '#inlove', '#iphoneonly', '#igers', '#russia', '#sm'] \n",
      "\n",
      "\tTweet tokenized by words:  ['morelik', 'app'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['morelik app'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1005 :\n",
      "\n",
      "\tTweet's text':  im mate yea good pretti much shud b gd nxt week bit sore kneel still twing sumtim ok \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['im', 'mate', 'yea', 'good', 'pretti', 'much', 'shud', 'b', 'gd', 'nxt', 'week', 'bit', 'sore', 'kneel', 'still', 'twing', 'sumtim', 'ok'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['im mate yea good pretti much shud b gd nxt week bit sore kneel still twing sumtim ok'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1006 :\n",
      "\n",
      "\tTweet's text':  when archer fight suppl bow way hoplit fight stiff spear \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Archer', '#Hoplite', '#Bow', '#Spear'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'archer', 'fight', 'suppl', 'bow', 'way', 'hoplit', 'fight', 'stiff', 'spear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when archer fight suppl bow way hoplit fight stiff spear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1007 :\n",
      "\n",
      "\tTweet's text':  lol rt wouldn surpris soldado bang hatrick win chelsea tonight the legend back \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'rt', 'wouldn', 'surpris', 'soldado', 'bang', 'hatrick', 'win', 'chelsea', 'tonight', 'the', 'legend', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol rt wouldn surpris soldado bang hatrick win chelsea tonight the legend back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1008 :\n",
      "\n",
      "\tTweet's text':  tonight famili bond present dark quit hous play marco polo side nerf gun \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lovemyfam'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tonight', 'famili', 'bond', 'present', 'dark', 'quit', 'hous', 'play', 'marco', 'polo', 'side', 'nerf', 'gun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tonight famili bond present dark quit hous play marco polo side nerf gun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1009 :\n",
      "\n",
      "\tTweet's text':  all can do beauti is your win is import take part have fun is what matter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#U', '#BEST'] \n",
      "\n",
      "\tTweet tokenized by words:  ['all', 'can', 'do', 'beauti', 'is', 'your', 'win', 'is', 'import', 'take', 'part', 'have', 'fun', 'is', 'what', 'matter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['all can do beauti is your win is import take part have fun is what matter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1010 :\n",
      "\n",
      "\tTweet's text':  so i heard colleg dropout offer graduat best colleg jawdrop packag \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'i', 'heard', 'colleg', 'dropout', 'offer', 'graduat', 'best', 'colleg', 'jawdrop', 'packag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so i heard colleg dropout offer graduat best colleg jawdrop packag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1011 :\n",
      "\n",
      "\tTweet's text':  when bugger countri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'bugger', 'countri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when bugger countri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1012 :\n",
      "\n",
      "\tTweet's text':  amazebal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#superman'] \n",
      "\n",
      "\tTweet tokenized by words:  ['amazebal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['amazebal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1013 :\n",
      "\n",
      "\tTweet's text':  i infer besmirch coffe right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'infer', 'besmirch', 'coffe', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i infer besmirch coffe right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1014 :\n",
      "\n",
      "\tTweet's text':  i need new job i read book i miss read be english teacher realli get way read \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'need', 'new', 'job', 'i', 'read', 'book', 'i', 'miss', 'read', 'be', 'english', 'teacher', 'realli', 'get', 'way', 'read'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i need new job i read book i miss read be english teacher realli get way read'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1015 :\n",
      "\n",
      "\tTweet's text':  yep say \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yep', 'say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yep say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1016 :\n",
      "\n",
      "\tTweet's text':  gimmick \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Israel', '#raps', '#Palestinian', '#U', '#draft', '#gimmick'] \n",
      "\n",
      "\tTweet tokenized by words:  ['gimmick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gimmick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1017 :\n",
      "\n",
      "\tTweet's text':  see ppl walk w crutch make realli excit next week life \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['see', 'ppl', 'walk', 'w', 'crutch', 'make', 'realli', 'excit', 'next', 'week', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['see ppl walk w crutch make realli excit next week life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1018 :\n",
      "\n",
      "\tTweet's text':  day train \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Novel', '#comfortzone', '#christmastree', '#nextlevel', '#buzzkillington', '#familyguy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'train'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day train'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1019 :\n",
      "\n",
      "\tTweet's text':  run less hour \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#longnight', '#longday', '#sleepy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['run', 'less', 'hour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['run less hour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1020 :\n",
      "\n",
      "\tTweet's text':  love fulham look like playoff team \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NotReally'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'fulham', 'look', 'like', 'playoff', 'team'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love fulham look like playoff team'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1021 :\n",
      "\n",
      "\tTweet's text':  count scar soul \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['count', 'scar', 'soul'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['count scar soul'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1022 :\n",
      "\n",
      "\tTweet's text':  big shocker call \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['big', 'shocker', 'call'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['big shocker call'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1023 :\n",
      "\n",
      "\tTweet's text':  doe word counter product ever mean anyth peopl sit around dream idea doubl wage \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['doe', 'word', 'counter', 'product', 'ever', 'mean', 'anyth', 'peopl', 'sit', 'around', 'dream', 'idea', 'doubl', 'wage'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['doe word counter product ever mean anyth peopl sit around dream idea doubl wage'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1024 :\n",
      "\n",
      "\tTweet's text':  check thing i realli love recent holiday season \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['check', 'thing', 'i', 'realli', 'love', 'recent', 'holiday', 'season'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['check thing i realli love recent holiday season'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1025 :\n",
      "\n",
      "\tTweet's text':  hour food drink go strong \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['person_with_folded_hands', 'loudly_crying_face', 'hot_beverage'] \n",
      "\n",
      "\tTweet's hashtags':  ['#givemeabrew'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hour', 'food', 'drink', 'go', 'strong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hour food drink go strong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1026 :\n",
      "\n",
      "\tTweet's text':  anoth great day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TTC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'great', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth great day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1027 :\n",
      "\n",
      "\tTweet's text':  damn that would made excel thing recount autobiographi p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['damn', 'that', 'would', 'made', 'excel', 'thing', 'recount', 'autobiographi', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['damn that would made excel thing recount autobiographi p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1028 :\n",
      "\n",
      "\tTweet's text':  couldn agre rt noth make feel special receiv autom dm \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['couldn', 'agre', 'rt', 'noth', 'make', 'feel', 'special', 'receiv', 'autom', 'dm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['couldn agre rt noth make feel special receiv autom dm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1029 :\n",
      "\n",
      "\tTweet's text':  photoset babaybubblez aquabreez disgustinghotel men but let forget in real stori \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['photoset', 'babaybubblez', 'aquabreez', 'disgustinghotel', 'men', 'but', 'let', 'forget', 'in', 'real', 'stori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photoset babaybubblez aquabreez disgustinghotel men but let forget in real stori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1030 :\n",
      "\n",
      "\tTweet's text':  thank love peopl come work sick come eat sick i appreci \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'love', 'peopl', 'come', 'work', 'sick', 'come', 'eat', 'sick', 'i', 'appreci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank love peopl come work sick come eat sick i appreci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1031 :\n",
      "\n",
      "\tTweet's text':  e reader would definit help save life someon broke hous good call \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['e', 'reader', 'would', 'definit', 'help', 'save', 'life', 'someon', 'broke', 'hous', 'good', 'call'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['e reader would definit help save life someon broke hous good call'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1032 :\n",
      "\n",
      "\tTweet's text':  too late thrown window last night cu play \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PS4'] \n",
      "\n",
      "\tTweet tokenized by words:  ['too', 'late', 'thrown', 'window', 'last', 'night', 'cu', 'play'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['too late thrown window last night cu play'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1033 :\n",
      "\n",
      "\tTweet's text':  they thought i gone these vega nigga gone respect know i shit i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'thought', 'i', 'gone', 'these', 'vega', 'nigga', 'gone', 'respect', 'know', 'i', 'shit', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they thought i gone these vega nigga gone respect know i shit i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1034 :\n",
      "\n",
      "\tTweet's text':  lost licens long mwahaha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lost', 'licens', 'long', 'mwahaha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lost licens long mwahaha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1035 :\n",
      "\n",
      "\tTweet's text':  stuck traffic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['high_voltage_sign', 'umbrella_with_rain_drops'] \n",
      "\n",
      "\tTweet's hashtags':  ['#mondays', '#athensbyrain', '#traffic', '#ontheroad', '#ontime', '#sisters', '#COOLURSTYLE'] \n",
      "\n",
      "\tTweet tokenized by words:  ['stuck', 'traffic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stuck traffic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1036 :\n",
      "\n",
      "\tTweet's text':  diagnos w bipolar disord yet i assum he need beat hard feel emot submiss \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['diagnos', 'w', 'bipolar', 'disord', 'yet', 'i', 'assum', 'he', 'need', 'beat', 'hard', 'feel', 'emot', 'submiss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['diagnos w bipolar disord yet i assum he need beat hard feel emot submiss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1037 :\n",
      "\n",
      "\tTweet's text':  i hope know much realli love philli to greatest shortstop philli histori thank \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hope', 'know', 'much', 'realli', 'love', 'philli', 'to', 'greatest', 'shortstop', 'philli', 'histori', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hope know much realli love philli to greatest shortstop philli histori thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1038 :\n",
      "\n",
      "\tTweet's text':  watch news like oh total restor faith human \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'news', 'like', 'oh', 'total', 'restor', 'faith', 'human'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch news like oh total restor faith human'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1039 :\n",
      "\n",
      "\tTweet's text':  whi the hous committe inform thu far uniteblu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#UniteBlue'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'the', 'hous', 'committe', 'inform', 'thu', 'far', 'uniteblu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi the hous committe inform thu far uniteblu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1040 :\n",
      "\n",
      "\tTweet's text':  my favorit dream one wake cover tear \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'favorit', 'dream', 'one', 'wake', 'cover', 'tear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my favorit dream one wake cover tear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1041 :\n",
      "\n",
      "\tTweet's text':  had insomnia cooki i sleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['had', 'insomnia', 'cooki', 'i', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['had insomnia cooki i sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1042 :\n",
      "\n",
      "\tTweet's text':  like loss son \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['like', 'loss', 'son'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['like loss son'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1043 :\n",
      "\n",
      "\tTweet's text':  you know gonna good day roommat come say took aderol anxieti attack \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'know', 'gon', 'na', 'good', 'day', 'roommat', 'come', 'say', 'took', 'aderol', 'anxieti', 'attack'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you know gonna good day roommat come say took aderol anxieti attack'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1044 :\n",
      "\n",
      "\tTweet's text':  i go finnish homework get caught everyth break \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'go', 'finnish', 'homework', 'get', 'caught', 'everyth', 'break'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i go finnish homework get caught everyth break'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1045 :\n",
      "\n",
      "\tTweet's text':  violenc lebron jame said thursday violenc answer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#LeBron', '#James', '#Violence', '#is', '#the', '#answer'] \n",
      "\n",
      "\tTweet tokenized by words:  ['violenc', 'lebron', 'jame', 'said', 'thursday', 'violenc', 'answer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['violenc lebron jame said thursday violenc answer'] \n",
      "\n",
      "---------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet  1046 :\n",
      "\n",
      "\tTweet's text':  puli avail will guarante stay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['puli', 'avail', 'will', 'guarante', 'stay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['puli avail will guarante stay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1047 :\n",
      "\n",
      "\tTweet's text':  i alway \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sorry', '#sorry', '#cant', '#help', '#it', '#im', '#an', '#asshole', '#like', '#that'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'alway'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i alway'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1048 :\n",
      "\n",
      "\tTweet's text':  cat cute i wish i allerg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['loudly_crying_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cat', 'cute', 'i', 'wish', 'i', 'allerg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cat cute i wish i allerg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1049 :\n",
      "\n",
      "\tTweet's text':  kabhi i messier usual messi wesay i need chai i rest last day may reason \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['persevering_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['kabhi', 'i', 'messier', 'usual', 'messi', 'wesay', 'i', 'need', 'chai', 'i', 'rest', 'last', 'day', 'may', 'reason'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kabhi i messier usual messi wesay i need chai i rest last day may reason'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1050 :\n",
      "\n",
      "\tTweet's text':  claybo dawson i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_sunglasses'] \n",
      "\n",
      "\tTweet's hashtags':  ['#squadgoals'] \n",
      "\n",
      "\tTweet tokenized by words:  ['claybo', 'dawson', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['claybo dawson i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1051 :\n",
      "\n",
      "\tTweet's text':  email need i mani mani time right xx \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['email', 'need', 'i', 'mani', 'mani', 'time', 'right', 'xx'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['email need i mani mani time right xx'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1052 :\n",
      "\n",
      "\tTweet's text':  my entir bodi send sympathi i diagnos rheumatoid arthriti yr ago yay flare up \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'entir', 'bodi', 'send', 'sympathi', 'i', 'diagnos', 'rheumatoid', 'arthriti', 'yr', 'ago', 'yay', 'flare', 'up'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my entir bodi send sympathi i diagnos rheumatoid arthriti yr ago yay flare up'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1053 :\n",
      "\n",
      "\tTweet's text':  love scoop feed bunk feed calv \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'scoop', 'feed', 'bunk', 'feed', 'calv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love scoop feed bunk feed calv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1054 :\n",
      "\n",
      "\tTweet's text':  d do do tri tri repeat get right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Yoda', '#JarrodDavis'] \n",
      "\n",
      "\tTweet tokenized by words:  ['d', 'do', 'do', 'tri', 'tri', 'repeat', 'get', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['d do do tri tri repeat get right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1055 :\n",
      "\n",
      "\tTweet's text':  bruhh i saw licens plate letter fdb \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bruhh', 'i', 'saw', 'licens', 'plate', 'letter', 'fdb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bruhh i saw licens plate letter fdb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1056 :\n",
      "\n",
      "\tTweet's text':  just case anyon wonder veni vidi vici spanish vine vi venc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#studybreaks', '#UMDFinalsWeek'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'case', 'anyon', 'wonder', 'veni', 'vidi', 'vici', 'spanish', 'vine', 'vi', 'venc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just case anyon wonder veni vidi vici spanish vine vi venc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1057 :\n",
      "\n",
      "\tTweet's text':  honk whilst drive past romant make want trace number plate forev \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['honk', 'whilst', 'drive', 'past', 'romant', 'make', 'want', 'trace', 'number', 'plate', 'forev'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['honk whilst drive past romant make want trace number plate forev'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1058 :\n",
      "\n",
      "\tTweet's text':  no it actual friday today proudli present sunday s \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'it', 'actual', 'friday', 'today', 'proudli', 'present', 'sunday', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no it actual friday today proudli present sunday s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1059 :\n",
      "\n",
      "\tTweet's text':  few thing amazingli wonder get earli monday morn start work week \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['sleeping_symbol', 'confused_face', 'sleeping_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#needmoresleep'] \n",
      "\n",
      "\tTweet tokenized by words:  ['few', 'thing', 'amazingli', 'wonder', 'get', 'earli', 'monday', 'morn', 'start', 'work', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['few thing amazingli wonder get earli monday morn start work week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1060 :\n",
      "\n",
      "\tTweet's text':  and peopl start drink mean fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'peopl', 'start', 'drink', 'mean', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and peopl start drink mean fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1061 :\n",
      "\n",
      "\tTweet's text':  bad tom bradi throw pressur nd quarter sunday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Patriots', '#report', '#card', '#Grades', '#half'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bad', 'tom', 'bradi', 'throw', 'pressur', 'nd', 'quarter', 'sunday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bad tom bradi throw pressur nd quarter sunday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1062 :\n",
      "\n",
      "\tTweet's text':  new year eve gener overr parti year it suppos huge shindig usual i disappoint \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['new', 'year', 'eve', 'gener', 'overr', 'parti', 'year', 'it', 'suppos', 'huge', 'shindig', 'usual', 'i', 'disappoint'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['new year eve gener overr parti year it suppos huge shindig usual i disappoint'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1063 :\n",
      "\n",
      "\tTweet's text':  i love unappreci \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'unappreci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love unappreci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1064 :\n",
      "\n",
      "\tTweet's text':  look \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Poulan', '#Chainsaw', '#New', '#shopping', '#chain', '#saws', '#start', '#starting', '#will', '#wont'] \n",
      "\n",
      "\tTweet tokenized by words:  ['look'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1065 :\n",
      "\n",
      "\tTweet's text':  becaus sarcast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['becaus', 'sarcast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['becaus sarcast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1066 :\n",
      "\n",
      "\tTweet's text':  it i readi bed \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'i', 'readi', 'bed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it i readi bed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1067 :\n",
      "\n",
      "\tTweet's text':  ouch hurt \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ouch', 'hurt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ouch hurt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1068 :\n",
      "\n",
      "\tTweet's text':  eight australia \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Australia', '#children', '#killed', '#reported', '#mass', '#stabbing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['eight', 'australia'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['eight australia'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1069 :\n",
      "\n",
      "\tTweet's text':  the penguin cancel morn skate \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#butseriouslytheroadsarebad'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'penguin', 'cancel', 'morn', 'skate'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the penguin cancel morn skate'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1070 :\n",
      "\n",
      "\tTweet's text':  bad idea when you climb mountain \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bad', 'idea', 'when', 'you', 'climb', 'mountain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bad idea when you climb mountain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1071 :\n",
      "\n",
      "\tTweet's text':  i love math i amp final like hour i hardli studi face stuck tongu wink eyefac tear joypersev facefac open mouth cold sweattir faceconfound face \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth_and_smiling_eyes', 'face_with_tears_of_joy', 'face_with_stuck-out_tongue_and_winking_eye', 'face_with_open_mouth_and_cold_sweat', 'tired_face', 'persevering_face', 'confounded_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#IBeenDoingIntegralsSinceThe5thGrade'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'math', 'i', 'amp', 'final', 'like', 'hour', 'i', 'hardli', 'studi', 'face', 'stuck', 'tongu', 'wink', 'eyefac', 'tear', 'joypersev', 'facefac', 'open', 'mouth', 'cold', 'sweattir', 'faceconfound', 'face'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love math i amp final like hour i hardli studi face stuck tongu wink eyefac tear joypersev facefac open mouth cold sweattir faceconfound face'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1072 :\n",
      "\n",
      "\tTweet's text':  i afraid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'afraid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i afraid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1073 :\n",
      "\n",
      "\tTweet's text':  absolut shock lamestream media pick \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mediabias'] \n",
      "\n",
      "\tTweet tokenized by words:  ['absolut', 'shock', 'lamestream', 'media', 'pick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['absolut shock lamestream media pick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1074 :\n",
      "\n",
      "\tTweet's text':  speak like comedi spoken jokingli assassin funni guy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['speak', 'like', 'comedi', 'spoken', 'jokingli', 'assassin', 'funni', 'guy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['speak like comedi spoken jokingli assassin funni guy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1075 :\n",
      "\n",
      "\tTweet's text':  they even listen ur order talk great custom servic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_down_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'even', 'listen', 'ur', 'order', 'talk', 'great', 'custom', 'servic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they even listen ur order talk great custom servic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1076 :\n",
      "\n",
      "\tTweet's text':  black guy know money \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['black', 'guy', 'know', 'money'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['black guy know money'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1077 :\n",
      "\n",
      "\tTweet's text':  the day one minion carri sign say mother fat one mine \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'day', 'one', 'minion', 'carri', 'sign', 'say', 'mother', 'fat', 'one', 'mine'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the day one minion carri sign say mother fat one mine'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1078 :\n",
      "\n",
      "\tTweet's text':  i start think uk pretti good basketbal team \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BBN'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'start', 'think', 'uk', 'pretti', 'good', 'basketbal', 'team'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i start think uk pretti good basketbal team'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1079 :\n",
      "\n",
      "\tTweet's text':  i love told i gotten hire boss knew i pregnant \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ha'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'told', 'i', 'gotten', 'hire', 'boss', 'knew', 'i', 'pregnant'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love told i gotten hire boss knew i pregnant'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1080 :\n",
      "\n",
      "\tTweet's text':  im awar nye celebr usual laiden fals expect i happi close door kick ars thru \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['im', 'awar', 'nye', 'celebr', 'usual', 'laiden', 'fals', 'expect', 'i', 'happi', 'close', 'door', 'kick', 'ars', 'thru'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['im awar nye celebr usual laiden fals expect i happi close door kick ars thru'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1081 :\n",
      "\n",
      "\tTweet's text':  ooh look like much fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ooh', 'look', 'like', 'much', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ooh look like much fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1082 :\n",
      "\n",
      "\tTweet's text':  i love wake migrain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['loudly_crying_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wake', 'migrain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wake migrain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1083 :\n",
      "\n",
      "\tTweet's text':  hotdog \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hotdog'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hotdog'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1084 :\n",
      "\n",
      "\tTweet's text':  forget smart kind love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['forget', 'smart', 'kind', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['forget smart kind love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1085 :\n",
      "\n",
      "\tTweet's text':  taylor wrote nasti note car today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#we', '#are', '#friends'] \n",
      "\n",
      "\tTweet tokenized by words:  ['taylor', 'wrote', 'nasti', 'note', 'car', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['taylor wrote nasti note car today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1086 :\n",
      "\n",
      "\tTweet's text':  youtub keep big channel big littl channel irrelev sinc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoodJob'] \n",
      "\n",
      "\tTweet tokenized by words:  ['youtub', 'keep', 'big', 'channel', 'big', 'littl', 'channel', 'irrelev', 'sinc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['youtub keep big channel big littl channel irrelev sinc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1087 :\n",
      "\n",
      "\tTweet's text':  indian societi teach not get rape rather don rape \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sadhvi', '#MufflerMan', '#Indias30', '#Rohtak'] \n",
      "\n",
      "\tTweet tokenized by words:  ['indian', 'societi', 'teach', 'not', 'get', 'rape', 'rather', 'don', 'rape'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['indian societi teach not get rape rather don rape'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1088 :\n",
      "\n",
      "\tTweet's text':  i saw anoth person wear heavi winter coat hood encourag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'saw', 'anoth', 'person', 'wear', 'heavi', 'winter', 'coat', 'hood', 'encourag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i saw anoth person wear heavi winter coat hood encourag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1089 :\n",
      "\n",
      "\tTweet's text':  hi orgabeh meet i think soulmat smile face heart shape eye zzzzzzz \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes', 'tired_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#patience'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hi', 'orgabeh', 'meet', 'i', 'think', 'soulmat', 'smile', 'face', 'heart', 'shape', 'eye', 'zzzzzzz'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hi orgabeh meet i think soulmat smile face heart shape eye zzzzzzz'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1090 :\n",
      "\n",
      "\tTweet's text':  nah dude buddi puke steak shake \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nah', 'dude', 'buddi', 'puke', 'steak', 'shake'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nah dude buddi puke steak shake'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1091 :\n",
      "\n",
      "\tTweet's text':  ye offici tri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Gamergate'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'offici', 'tri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye offici tri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1092 :\n",
      "\n",
      "\tTweet's text':  there two thing need better draft player work ethic that \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'two', 'thing', 'need', 'better', 'draft', 'player', 'work', 'ethic', 'that'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there two thing need better draft player work ethic that'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1093 :\n",
      "\n",
      "\tTweet's text':  when someon confer call talk housekeep item grrr \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'someon', 'confer', 'call', 'talk', 'housekeep', 'item', 'grrr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when someon confer call talk housekeep item grrr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1094 :\n",
      "\n",
      "\tTweet's text':  your great person \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['your', 'great', 'person'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['your great person'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1095 :\n",
      "\n",
      "\tTweet's text':  saturday class wee \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['saturday', 'class', 'wee'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['saturday class wee'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1096 :\n",
      "\n",
      "\tTweet's text':  i recal dalai lama talk busti girl celeb apart \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'recal', 'dalai', 'lama', 'talk', 'busti', 'girl', 'celeb', 'apart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i recal dalai lama talk busti girl celeb apart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1097 :\n",
      "\n",
      "\tTweet's text':  went road morn english professor thank fsu concern commut \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['went', 'road', 'morn', 'english', 'professor', 'thank', 'fsu', 'concern', 'commut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['went road morn english professor thank fsu concern commut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1098 :\n",
      "\n",
      "\tTweet's text':  mani championship you tri say make worth saban \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mani', 'championship', 'you', 'tri', 'say', 'make', 'worth', 'saban'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mani championship you tri say make worth saban'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1099 :\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's text':  relat water first amen \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['relat', 'water', 'first', 'amen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['relat water first amen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1100 :\n",
      "\n",
      "\tTweet's text':  mock spiritu preciou holiday million courag \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#shameonyou'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mock', 'spiritu', 'preciou', 'holiday', 'million', 'courag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mock spiritu preciou holiday million courag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1101 :\n",
      "\n",
      "\tTweet's text':  got play w dog last night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'play', 'w', 'dog', 'last', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['got play w dog last night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1102 :\n",
      "\n",
      "\tTweet's text':  appar hang ashley day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['appar', 'hang', 'ashley', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['appar hang ashley day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1103 :\n",
      "\n",
      "\tTweet's text':  ye except farag back slow genocid palestinian isra use nazi method \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'except', 'farag', 'back', 'slow', 'genocid', 'palestinian', 'isra', 'use', 'nazi', 'method'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye except farag back slow genocid palestinian isra use nazi method'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1104 :\n",
      "\n",
      "\tTweet's text':  ok watch hurt parent kid decid elop definit make chang mind small cozi wed \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ok', 'watch', 'hurt', 'parent', 'kid', 'decid', 'elop', 'definit', 'make', 'chang', 'mind', 'small', 'cozi', 'wed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ok watch hurt parent kid decid elop definit make chang mind small cozi wed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1105 :\n",
      "\n",
      "\tTweet's text':  i truli peac \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'truli', 'peac'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i truli peac'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1106 :\n",
      "\n",
      "\tTweet's text':  learn play string note guitar \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pro', '#idiot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['learn', 'play', 'string', 'note', 'guitar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['learn play string note guitar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1107 :\n",
      "\n",
      "\tTweet's text':  morgan ask i want play game xbox usual i even look \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['morgan', 'ask', 'i', 'want', 'play', 'game', 'xbox', 'usual', 'i', 'even', 'look'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['morgan ask i want play game xbox usual i even look'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1108 :\n",
      "\n",
      "\tTweet's text':  the liber citi class intellig exud \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'liber', 'citi', 'class', 'intellig', 'exud'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the liber citi class intellig exud'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1109 :\n",
      "\n",
      "\tTweet's text':  come jhb play volleybal fake beach \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#work'] \n",
      "\n",
      "\tTweet tokenized by words:  ['come', 'jhb', 'play', 'volleybal', 'fake', 'beach'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['come jhb play volleybal fake beach'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1110 :\n",
      "\n",
      "\tTweet's text':  i think last time \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hobbit', '#onelasttime', '#cinema', '#ov', '#3d', '#48hfr'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'last', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think last time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1111 :\n",
      "\n",
      "\tTweet's text':  wow i realli best luck known man \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth_and_cold_sweat'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'realli', 'best', 'luck', 'known', 'man'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i realli best luck known man'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1112 :\n",
      "\n",
      "\tTweet's text':  i love run hour sleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['confused_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#ijustwannasleep'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'run', 'hour', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love run hour sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1113 :\n",
      "\n",
      "\tTweet's text':  there reason i tell parent anyth caus i alway get the posit respons \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'reason', 'i', 'tell', 'parent', 'anyth', 'caus', 'i', 'alway', 'get', 'the', 'posit', 'respons'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there reason i tell parent anyth caus i alway get the posit respons'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1114 :\n",
      "\n",
      "\tTweet's text':  how could kill best friend true \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#a', '#friend'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'could', 'kill', 'best', 'friend', 'true'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how could kill best friend true'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1115 :\n",
      "\n",
      "\tTweet's text':  my dad would shotgun readi my dad would offer beer my dad would ask join clan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'dad', 'would', 'shotgun', 'readi', 'my', 'dad', 'would', 'offer', 'beer', 'my', 'dad', 'would', 'ask', 'join', 'clan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my dad would shotgun readi my dad would offer beer my dad would ask join clan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1116 :\n",
      "\n",
      "\tTweet's text':  imma kill sob jk \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lol', '#RedEye'] \n",
      "\n",
      "\tTweet tokenized by words:  ['imma', 'kill', 'sob', 'jk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['imma kill sob jk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1117 :\n",
      "\n",
      "\tTweet's text':  is internet bit slow today blame thick wet cabl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'internet', 'bit', 'slow', 'today', 'blame', 'thick', 'wet', 'cabl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is internet bit slow today blame thick wet cabl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1118 :\n",
      "\n",
      "\tTweet's text':  omg fashion \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Berlin', '#vscocam'] \n",
      "\n",
      "\tTweet tokenized by words:  ['omg', 'fashion'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['omg fashion'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1119 :\n",
      "\n",
      "\tTweet's text':  road safeti campaign donkey kill car \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['road', 'safeti', 'campaign', 'donkey', 'kill', 'car'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['road safeti campaign donkey kill car'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1120 :\n",
      "\n",
      "\tTweet's text':  love game week i get go sleep like \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'game', 'week', 'i', 'get', 'go', 'sleep', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love game week i get go sleep like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1121 :\n",
      "\n",
      "\tTweet's text':  everi stori end life everi end ia new begin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#quoteoftheday', '#lifequotes'] \n",
      "\n",
      "\tTweet tokenized by words:  ['everi', 'stori', 'end', 'life', 'everi', 'end', 'ia', 'new', 'begin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everi stori end life everi end ia new begin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1122 :\n",
      "\n",
      "\tTweet's text':  don love say hi someon hallway complet ignor yeah i love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['fisted_hand_sign', 'unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'love', 'say', 'hi', 'someon', 'hallway', 'complet', 'ignor', 'yeah', 'i', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don love say hi someon hallway complet ignor yeah i love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1123 :\n",
      "\n",
      "\tTweet's text':  abraham actual modern day iraq ur chaldea \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['abraham', 'actual', 'modern', 'day', 'iraq', 'ur', 'chaldea'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['abraham actual modern day iraq ur chaldea'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1124 :\n",
      "\n",
      "\tTweet's text':  rain sleet hun yeah i total want get dress go work sound like fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#iwannagobacktobed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rain', 'sleet', 'hun', 'yeah', 'i', 'total', 'want', 'get', 'dress', 'go', 'work', 'sound', 'like', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rain sleet hun yeah i total want get dress go work sound like fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1125 :\n",
      "\n",
      "\tTweet's text':  help \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['help'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['help'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1126 :\n",
      "\n",
      "\tTweet's text':  studi narciss i read i afraid i disord \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#centeroftheuniverse'] \n",
      "\n",
      "\tTweet tokenized by words:  ['studi', 'narciss', 'i', 'read', 'i', 'afraid', 'i', 'disord'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['studi narciss i read i afraid i disord'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1127 :\n",
      "\n",
      "\tTweet's text':  i love i taken \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'i', 'taken'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love i taken'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1128 :\n",
      "\n",
      "\tTweet's text':  play golf day eri day perksofbeingold \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PerksOfBeingOld'] \n",
      "\n",
      "\tTweet tokenized by words:  ['play', 'golf', 'day', 'eri', 'day', 'perksofbeingold'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['play golf day eri day perksofbeingold'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1129 :\n",
      "\n",
      "\tTweet's text':  compar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#atlas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['compar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['compar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1130 :\n",
      "\n",
      "\tTweet's text':  brilliant news potenti young buyer \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['brilliant', 'news', 'potenti', 'young', 'buyer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['brilliant news potenti young buyer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1131 :\n",
      "\n",
      "\tTweet's text':  i guess i sleep tonight i want leav anyway \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'i', 'sleep', 'tonight', 'i', 'want', 'leav', 'anyway'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guess i sleep tonight i want leav anyway'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1132 :\n",
      "\n",
      "\tTweet's text':  i swear i stand littl fuck girl i want punch fuck face bitch need go home real \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'swear', 'i', 'stand', 'littl', 'fuck', 'girl', 'i', 'want', 'punch', 'fuck', 'face', 'bitch', 'need', 'go', 'home', 'real'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i swear i stand littl fuck girl i want punch fuck face bitch need go home real'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1133 :\n",
      "\n",
      "\tTweet's text':  flood basement alway fun thing deal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['flood', 'basement', 'alway', 'fun', 'thing', 'deal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['flood basement alway fun thing deal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1134 :\n",
      "\n",
      "\tTweet's text':  the two constabl veer pal singh yadav avnish yadav crimin record ndtv \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'two', 'constabl', 'veer', 'pal', 'singh', 'yadav', 'avnish', 'yadav', 'crimin', 'record', 'ndtv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the two constabl veer pal singh yadav avnish yadav crimin record ndtv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1135 :\n",
      "\n",
      "\tTweet's text':  hour sleep suffici tackl day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#timezoneproblems'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hour', 'sleep', 'suffici', 'tackl', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hour sleep suffici tackl day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1136 :\n",
      "\n",
      "\tTweet's text':  yeah i avoid wake am time pm i exhaust \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sucksimissedyou'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'i', 'avoid', 'wake', 'am', 'time', 'pm', 'i', 'exhaust'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah i avoid wake am time pm i exhaust'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1137 :\n",
      "\n",
      "\tTweet's text':  heh averag work sentenc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['heh', 'averag', 'work', 'sentenc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['heh averag work sentenc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1138 :\n",
      "\n",
      "\tTweet's text':  whi isi acronym word english \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'isi', 'acronym', 'word', 'english'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi isi acronym word english'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1139 :\n",
      "\n",
      "\tTweet's text':  i earli i need drive downtown take test bright earli morn yay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Torontotrafficisfun'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'earli', 'i', 'need', 'drive', 'downtown', 'take', 'test', 'bright', 'earli', 'morn', 'yay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i earli i need drive downtown take test bright earli morn yay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1140 :\n",
      "\n",
      "\tTweet's text':  rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#But', '#It8217s', '#Matters', '#Size', '#Style', '#That', '#wedding'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1141 :\n",
      "\n",
      "\tTweet's text':  go go central last minut present shop \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#soorganised'] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'go', 'central', 'last', 'minut', 'present', 'shop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go go central last minut present shop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1142 :\n",
      "\n",
      "\tTweet's text':  game \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1143 :\n",
      "\n",
      "\tTweet's text':  make enough bl ullr god hunt ski i assum hockey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['make', 'enough', 'bl', 'ullr', 'god', 'hunt', 'ski', 'i', 'assum', 'hockey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['make enough bl ullr god hunt ski i assum hockey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1144 :\n",
      "\n",
      "\tTweet's text':  i wish januari major withdraw fair wtfwasthat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Arrow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wish', 'januari', 'major', 'withdraw', 'fair', 'wtfwasthat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wish januari major withdraw fair wtfwasthat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1145 :\n",
      "\n",
      "\tTweet's text':  sorri femal i mean interrupt perfect littl man world \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sorri', 'femal', 'i', 'mean', 'interrupt', 'perfect', 'littl', 'man', 'world'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sorri femal i mean interrupt perfect littl man world'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1146 :\n",
      "\n",
      "\tTweet's text':  isabel send nicest text \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['broken_heart', 'confounded_face', 'persevering_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['isabel', 'send', 'nicest', 'text'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['isabel send nicest text'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1147 :\n",
      "\n",
      "\tTweet's text':  swag \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['swag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['swag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1148 :\n",
      "\n",
      "\tTweet's text':  free chocol free deliveri flower order bunch \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['free', 'chocol', 'free', 'deliveri', 'flower', 'order', 'bunch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['free chocol free deliveri flower order bunch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1149 :\n",
      "\n",
      "\tTweet's text':  to fair look like lost lot weight sinc amazingli success halcyon leed day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['to', 'fair', 'look', 'like', 'lost', 'lot', 'weight', 'sinc', 'amazingli', 'success', 'halcyon', 'leed', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['to fair look like lost lot weight sinc amazingli success halcyon leed day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1150 :\n",
      "\n",
      "\tTweet's text':  what correct word racism toward white peopl there none racism good anyon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#racism', '#is', '#good', '#4anyone'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'correct', 'word', 'racism', 'toward', 'white', 'peopl', 'there', 'none', 'racism', 'good', 'anyon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what correct word racism toward white peopl there none racism good anyon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1151 :\n",
      "\n",
      "\tTweet's text':  kiss bc lose wisdom abl face stuck tongu wink eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_stuck-out_tongue_and_winking_eye'] \n",
      "\n",
      "\tTweet's hashtags':  ['#clever'] \n",
      "\n",
      "\tTweet tokenized by words:  ['kiss', 'bc', 'lose', 'wisdom', 'abl', 'face', 'stuck', 'tongu', 'wink', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kiss bc lose wisdom abl face stuck tongu wink eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1152 :\n",
      "\n",
      "\tTweet's text':  where showtim homeland \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TortureReport'] \n",
      "\n",
      "\tTweet tokenized by words:  ['where', 'showtim', 'homeland'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['where showtim homeland'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1153 :\n",
      "\n",
      "\tTweet's text':  jesu mari joseph how sad go life suffer defici \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jesu', 'mari', 'joseph', 'how', 'sad', 'go', 'life', 'suffer', 'defici'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jesu mari joseph how sad go life suffer defici'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1154 :\n",
      "\n",
      "\tTweet's text':  good thing i gotta work today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'thing', 'i', 'got', 'ta', 'work', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good thing i gotta work today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1155 :\n",
      "\n",
      "\tTweet's text':  foxi ladi waynesworld \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes', 'smiling_face_with_smiling_eyes', 'white_smiling_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#waynesworld', '#excellent'] \n",
      "\n",
      "\tTweet tokenized by words:  ['foxi', 'ladi', 'waynesworld'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['foxi ladi waynesworld'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1156 :\n",
      "\n",
      "\tTweet's text':  wow realli touch tweet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'realli', 'touch', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow realli touch tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1157 :\n",
      "\n",
      "\tTweet's text':  i leav school i still bed \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fucktherain', '#wherearemyhunters', '#imgonnalooksocutetoday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'leav', 'school', 'i', 'still', 'bed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i leav school i still bed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1158 :\n",
      "\n",
      "\tTweet's text':  uh oh better head hill \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#storm', '#clouds', '#seekshelter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['uh', 'oh', 'better', 'head', 'hill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['uh oh better head hill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1159 :\n",
      "\n",
      "\tTweet's text':  plan use last batteri listen get day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#big'] \n",
      "\n",
      "\tTweet tokenized by words:  ['plan', 'use', 'last', 'batteri', 'listen', 'get', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['plan use last batteri listen get day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1160 :\n",
      "\n",
      "\tTweet's text':  just walk path p here \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Frodo', '#LOTR', '#LOTRO'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'walk', 'path', 'p', 'here'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just walk path p here'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1161 :\n",
      "\n",
      "\tTweet's text':  one essay submit start next one \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thirdyearlife', '#loveit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'essay', 'submit', 'start', 'next', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one essay submit start next one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1162 :\n",
      "\n",
      "\tTweet's text':  yara i restless soul well awar i like skin perspect comfort when expect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yara', 'i', 'restless', 'soul', 'well', 'awar', 'i', 'like', 'skin', 'perspect', 'comfort', 'when', 'expect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yara i restless soul well awar i like skin perspect comfort when expect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1163 :\n",
      "\n",
      "\tTweet's text':  if local theater physic marque letter rearrang duti chang the interview \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'local', 'theater', 'physic', 'marque', 'letter', 'rearrang', 'duti', 'chang', 'the', 'interview'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if local theater physic marque letter rearrang duti chang the interview'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1164 :\n",
      "\n",
      "\tTweet's text':  up night night row my job fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nightauditadventures', '#resortjobprobs', '#fb'] \n",
      "\n",
      "\tTweet tokenized by words:  ['up', 'night', 'night', 'row', 'my', 'job', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['up night night row my job fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1165 :\n",
      "\n",
      "\tTweet's text':  when girl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#it', '#is', '#everyday', '#Chezza', '#sometimes', '#do', '#work', '#andnotgetcaughtbyMR'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'girl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when girl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1166 :\n",
      "\n",
      "\tTweet's text':  with forward sure \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#confused'] \n",
      "\n",
      "\tTweet tokenized by words:  ['with', 'forward', 'sure'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['with forward sure'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1167 :\n",
      "\n",
      "\tTweet's text':  dentist oh joy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dentist', 'oh', 'joy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dentist oh joy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1168 :\n",
      "\n",
      "\tTweet's text':  return flight whi i love famili \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#familyvacation'] \n",
      "\n",
      "\tTweet tokenized by words:  ['return', 'flight', 'whi', 'i', 'love', 'famili'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['return flight whi i love famili'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1169 :\n",
      "\n",
      "\tTweet's text':  i love put christma tree fam \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#christmastree'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'put', 'christma', 'tree', 'fam'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love put christma tree fam'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1170 :\n",
      "\n",
      "\tTweet's text':  just snap chat sister time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#shelovesitwhenIsendthatmany'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'snap', 'chat', 'sister', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just snap chat sister time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1171 :\n",
      "\n",
      "\tTweet's text':  lagopod like rabbit foot not easi drop convers never know \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lagopod', 'like', 'rabbit', 'foot', 'not', 'easi', 'drop', 'convers', 'never', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lagopod like rabbit foot not easi drop convers never know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1172 :\n",
      "\n",
      "\tTweet's text':  standard christma newsfe diamond everywher everyon engag congratul \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#original', '#Christmas', '#engaged'] \n",
      "\n",
      "\tTweet tokenized by words:  ['standard', 'christma', 'newsfe', 'diamond', 'everywher', 'everyon', 'engag', 'congratul'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['standard christma newsfe diamond everywher everyon engag congratul'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1173 :\n",
      "\n",
      "\tTweet's text':  fit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1174 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#to', '#our', '#countries', '#special', '#dedication', '#to', '#ma', '#Syrian', '#friends', '#you', '#alone', '#instalisten', '#by', '#heart', '#voice'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1175 :\n",
      "\n",
      "\tTweet's text':  we peopl instagram put pointless hashtag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Can', '#you'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'peopl', 'instagram', 'put', 'pointless', 'hashtag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we peopl instagram put pointless hashtag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1176 :\n",
      "\n",
      "\tTweet's text':  current bu wanker i hate peopl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['confused_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#stinks', '#gobonastick', '#dickheads'] \n",
      "\n",
      "\tTweet tokenized by words:  ['current', 'bu', 'wanker', 'i', 'hate', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['current bu wanker i hate peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1177 :\n",
      "\n",
      "\tTweet's text':  ya listen talk hot girl favorit past time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ya', 'listen', 'talk', 'hot', 'girl', 'favorit', 'past', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ya listen talk hot girl favorit past time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1178 :\n",
      "\n",
      "\tTweet's text':  gee faculti nichol help \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gee', 'faculti', 'nichol', 'help'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gee faculti nichol help'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1179 :\n",
      "\n",
      "\tTweet's text':  stinker \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ahhhhhhhhh', '#Depression', '#CantWaitForTomorrow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['stinker'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stinker'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1180 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bitch', '#bitchy', '#badass', '#lol', '#laughing', '#jokes', '#funtime', '#funny', '#fun', '#ecards'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1181 :\n",
      "\n",
      "\tTweet's text':  twitter game perfect tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#amazingness'] \n",
      "\n",
      "\tTweet tokenized by words:  ['twitter', 'game', 'perfect', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['twitter game perfect tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1182 :\n",
      "\n",
      "\tTweet's text':  iiiiiiii best boyfriend everrrrrrrrr \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['iiiiiiii', 'best', 'boyfriend', 'everrrrrrrrr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['iiiiiiii best boyfriend everrrrrrrrr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1183 :\n",
      "\n",
      "\tTweet's text':  bombguy if you re a chelsea fan it natur to be sentiment if you an arsen fan it natur to be stupid spell \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bombguy', 'if', 'you', 're', 'a', 'chelsea', 'fan', 'it', 'natur', 'to', 'be', 'sentiment', 'if', 'you', 'an', 'arsen', 'fan', 'it', 'natur', 'to', 'be', 'stupid', 'spell'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bombguy if you re a chelsea fan it natur to be sentiment if you an arsen fan it natur to be stupid spell'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1184 :\n",
      "\n",
      "\tTweet's text':  not pass judgment been mani bind actual love creativ vodka versatil liquor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['not', 'pass', 'judgment', 'been', 'mani', 'bind', 'actual', 'love', 'creativ', 'vodka', 'versatil', 'liquor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['not pass judgment been mani bind actual love creativ vodka versatil liquor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1185 :\n",
      "\n",
      "\tTweet's text':  yet cant provid ani sourc show \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yet', 'cant', 'provid', 'ani', 'sourc', 'show'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yet cant provid ani sourc show'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1186 :\n",
      "\n",
      "\tTweet's text':  i love eu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'eu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love eu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1187 :\n",
      "\n",
      "\tTweet's text':  an answer one critic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#feminism', '#Uglygirlsclub', '#fourthwave'] \n",
      "\n",
      "\tTweet tokenized by words:  ['an', 'answer', 'one', 'critic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['an answer one critic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1188 :\n",
      "\n",
      "\tTweet's text':  now islam religion peac christian hurt anybodi get right d \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['now', 'islam', 'religion', 'peac', 'christian', 'hurt', 'anybodi', 'get', 'right', 'd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['now islam religion peac christian hurt anybodi get right d'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1189 :\n",
      "\n",
      "\tTweet's text':  am love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['am', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['am love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1190 :\n",
      "\n",
      "\tTweet's text':  close white folk i forc wit firsthand will ignor impact race racism bell hook \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ferguson'] \n",
      "\n",
      "\tTweet tokenized by words:  ['close', 'white', 'folk', 'i', 'forc', 'wit', 'firsthand', 'will', 'ignor', 'impact', 'race', 'racism', 'bell', 'hook'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['close white folk i forc wit firsthand will ignor impact race racism bell hook'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1191 :\n",
      "\n",
      "\tTweet's text':  wasn full noseble i sit fun crowd react joepa fav memori \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wasn', 'full', 'noseble', 'i', 'sit', 'fun', 'crowd', 'react', 'joepa', 'fav', 'memori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wasn full noseble i sit fun crowd react joepa fav memori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1192 :\n",
      "\n",
      "\tTweet's text':  we reboot server seem ok yey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#facepalm', '#devops'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'reboot', 'server', 'seem', 'ok', 'yey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we reboot server seem ok yey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1193 :\n",
      "\n",
      "\tTweet's text':  ppl keep snap i snap back i look good rn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ppl', 'keep', 'snap', 'i', 'snap', 'back', 'i', 'look', 'good', 'rn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ppl keep snap i snap back i look good rn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1194 :\n",
      "\n",
      "\tTweet's text':  at least i woke feel lot better today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['at', 'least', 'i', 'woke', 'feel', 'lot', 'better', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['at least i woke feel lot better today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1195 :\n",
      "\n",
      "\tTweet's text':  mayb miss world succeed predecessor fail obtain world peac \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MissWorld2014'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mayb', 'miss', 'world', 'succeed', 'predecessor', 'fail', 'obtain', 'world', 'peac'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mayb miss world succeed predecessor fail obtain world peac'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1196 :\n",
      "\n",
      "\tTweet's text':  countri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Dirt'] \n",
      "\n",
      "\tTweet tokenized by words:  ['countri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['countri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1197 :\n",
      "\n",
      "\tTweet's text':  cute teenag virgin play hotel room tight blue gstring underwear \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TeenAnalCasting', '#VIRGIN'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cute', 'teenag', 'virgin', 'play', 'hotel', 'room', 'tight', 'blue', 'gstring', 'underwear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cute teenag virgin play hotel room tight blue gstring underwear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1198 :\n",
      "\n",
      "\tTweet's text':  when acl tear happen \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'acl', 'tear', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when acl tear happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1199 :\n",
      "\n",
      "\tTweet's text':  vcac look like even bigger bag hurt vcd \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['vcac', 'look', 'like', 'even', 'bigger', 'bag', 'hurt', 'vcd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['vcac look like even bigger bag hurt vcd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1200 :\n",
      "\n",
      "\tTweet's text':  funni joke \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['funni', 'joke'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['funni joke'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1201 :\n",
      "\n",
      "\tTweet's text':  the moral polic vigilant quiet everi i suppos indian cultur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#rape', '#uber', '#DelhiRape'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'moral', 'polic', 'vigilant', 'quiet', 'everi', 'i', 'suppos', 'indian', 'cultur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the moral polic vigilant quiet everi i suppos indian cultur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1202 :\n",
      "\n",
      "\tTweet's text':  ben go pick pizza today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ben', 'go', 'pick', 'pizza', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ben go pick pizza today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1203 :\n",
      "\n",
      "\tTweet's text':  nope do everyth wrong cold hot hot cold gear seem ok today dip prob spoke soon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#orings'] \n",
      "\n",
      "\tTweet tokenized by words:  ['nope', 'do', 'everyth', 'wrong', 'cold', 'hot', 'hot', 'cold', 'gear', 'seem', 'ok', 'today', 'dip', 'prob', 'spoke', 'soon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nope do everyth wrong cold hot hot cold gear seem ok today dip prob spoke soon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1204 :\n",
      "\n",
      "\tTweet's text':  cut promo state face oh yay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cut', 'promo', 'state', 'face', 'oh', 'yay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cut promo state face oh yay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1205 :\n",
      "\n",
      "\tTweet's text':  rule parti power central state misus power pm speak foreign parliment pm visit side india session \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#central', '#state', '#misusing', '#PM', '#pm'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rule', 'parti', 'power', 'central', 'state', 'misus', 'power', 'pm', 'speak', 'foreign', 'parliment', 'pm', 'visit', 'side', 'india', 'session'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rule parti power central state misus power pm speak foreign parliment pm visit side india session'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1206 :\n",
      "\n",
      "\tTweet's text':  wow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#gymfanatic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1207 :\n",
      "\n",
      "\tTweet's text':  come love weather sleigh ride togeth ewe \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['come', 'love', 'weather', 'sleigh', 'ride', 'togeth', 'ewe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['come love weather sleigh ride togeth ewe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1208 :\n",
      "\n",
      "\tTweet's text':  total \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['total'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['total'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1209 :\n",
      "\n",
      "\tTweet's text':  final win champ leagu no team good year got solid draw \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#banter', '#stillgoingout'] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'win', 'champ', 'leagu', 'no', 'team', 'good', 'year', 'got', 'solid', 'draw'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final win champ leagu no team good year got solid draw'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1210 :\n",
      "\n",
      "\tTweet's text':  basic storylin carolin forb season call stefan great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['basic', 'storylin', 'carolin', 'forb', 'season', 'call', 'stefan', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['basic storylin carolin forb season call stefan great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1211 :\n",
      "\n",
      "\tTweet's text':  yay day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#coffee', '#HarryPotter', '#christmasbreak', '#morning'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1212 :\n",
      "\n",
      "\tTweet's text':  whilst recon safe cours \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SLabour', '#BlairMcDougal', '#DeputyDug', '#MeltDown', '#BetterTogether'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whilst', 'recon', 'safe', 'cours'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whilst recon safe cours'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1213 :\n",
      "\n",
      "\tTweet's text':  do think mari parent believ bubbemeinseh still virgin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['do', 'think', 'mari', 'parent', 'believ', 'bubbemeinseh', 'still', 'virgin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['do think mari parent believ bubbemeinseh still virgin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1214 :\n",
      "\n",
      "\tTweet's text':  i see peopl use term i believ i go say use incorrectli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GamerGate'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'see', 'peopl', 'use', 'term', 'i', 'believ', 'i', 'go', 'say', 'use', 'incorrectli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i see peopl use term i believ i go say use incorrectli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1215 :\n",
      "\n",
      "\tTweet's text':  i relax wait fact come but i listen blain hammer player similar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'relax', 'wait', 'fact', 'come', 'but', 'i', 'listen', 'blain', 'hammer', 'player', 'similar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i relax wait fact come but i listen blain hammer player similar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1216 :\n",
      "\n",
      "\tTweet's text':  i keep see need plan morn accordingli pleas advis \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'keep', 'see', 'need', 'plan', 'morn', 'accordingli', 'pleas', 'advis'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i keep see need plan morn accordingli pleas advis'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1217 :\n",
      "\n",
      "\tTweet's text':  appreci spare suspend account block us \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['appreci', 'spare', 'suspend', 'account', 'block', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['appreci spare suspend account block us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1218 :\n",
      "\n",
      "\tTweet's text':  delus peopl kill cuz obama black myth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['delus', 'peopl', 'kill', 'cuz', 'obama', 'black', 'myth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['delus peopl kill cuz obama black myth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1219 :\n",
      "\n",
      "\tTweet's text':  thei reight protest end right begin they cannot take right earn livelihood free movement \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thei', 'reight', 'protest', 'end', 'right', 'begin', 'they', 'can', 'not', 'take', 'right', 'earn', 'livelihood', 'free', 'movement'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thei reight protest end right begin they cannot take right earn livelihood free movement'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1220 :\n",
      "\n",
      "\tTweet's text':  bake bread hang glass wine leg sweatshirt footbal heaven if snow turn rain \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bake', 'bread', 'hang', 'glass', 'wine', 'leg', 'sweatshirt', 'footbal', 'heaven', 'if', 'snow', 'turn', 'rain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bake bread hang glass wine leg sweatshirt footbal heaven if snow turn rain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1221 :\n",
      "\n",
      "\tTweet's text':  imagin that never would guess \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['imagin', 'that', 'never', 'would', 'guess'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['imagin that never would guess'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1222 :\n",
      "\n",
      "\tTweet's text':  crime figur true pictur may wors fear say think tank report via \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['crime', 'figur', 'true', 'pictur', 'may', 'wors', 'fear', 'say', 'think', 'tank', 'report', 'via'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['crime figur true pictur may wors fear say think tank report via'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1223 :\n",
      "\n",
      "\tTweet's text':  so hamilton monday night thank even game give us saturday footbal overr \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'hamilton', 'monday', 'night', 'thank', 'even', 'game', 'give', 'us', 'saturday', 'footbal', 'overr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so hamilton monday night thank even game give us saturday footbal overr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1224 :\n",
      "\n",
      "\tTweet's text':  gotta love sound rain beat window christma day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whereswinter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'love', 'sound', 'rain', 'beat', 'window', 'christma', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta love sound rain beat window christma day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1225 :\n",
      "\n",
      "\tTweet's text':  leader baghdad an iraqi offici deni w \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Lebanon', '#detainee', '#is', '#ISIS', '#wife', '#Iraqi', '#official'] \n",
      "\n",
      "\tTweet tokenized by words:  ['leader', 'baghdad', 'an', 'iraqi', 'offici', 'deni', 'w'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['leader baghdad an iraqi offici deni w'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1226 :\n",
      "\n",
      "\tTweet's text':  i victoria secret model it secret even victoria know \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'victoria', 'secret', 'model', 'it', 'secret', 'even', 'victoria', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i victoria secret model it secret even victoria know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1227 :\n",
      "\n",
      "\tTweet's text':  half test group help today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['half', 'test', 'group', 'help', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['half test group help today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1228 :\n",
      "\n",
      "\tTweet's text':  they done work hard \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'done', 'work', 'hard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they done work hard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1229 :\n",
      "\n",
      "\tTweet's text':  amen if plan problem face stuck tongu wink eye emerg p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['person_with_folded_hands', 'face_with_stuck-out_tongue_and_winking_eye'] \n",
      "\n",
      "\tTweet's hashtags':  ['#truth'] \n",
      "\n",
      "\tTweet tokenized by words:  ['amen', 'if', 'plan', 'problem', 'face', 'stuck', 'tongu', 'wink', 'eye', 'emerg', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['amen if plan problem face stuck tongu wink eye emerg p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1230 :\n",
      "\n",
      "\tTweet's text':  whoop didn know i live peopl expect instead mine let fix \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sorrynotsorry', '#soz'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whoop', 'didn', 'know', 'i', 'live', 'peopl', 'expect', 'instead', 'mine', 'let', 'fix'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whoop didn know i live peopl expect instead mine let fix'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1231 :\n",
      "\n",
      "\tTweet's text':  can wait next year cyber month sale \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'next', 'year', 'cyber', 'month', 'sale'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait next year cyber month sale'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1232 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1233 :\n",
      "\n",
      "\tTweet's text':  let face mo delay day end \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#valueformoneynot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'face', 'mo', 'delay', 'day', 'end'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let face mo delay day end'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1234 :\n",
      "\n",
      "\tTweet's text':  best christma gift new album \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['best', 'christma', 'gift', 'new', 'album'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['best christma gift new album'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1235 :\n",
      "\n",
      "\tTweet's text':  i love femal express emphat manner alway attribut menstrual cycl mag \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PMS'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'femal', 'express', 'emphat', 'manner', 'alway', 'attribut', 'menstrual', 'cycl', 'mag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love femal express emphat manner alway attribut menstrual cycl mag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1236 :\n",
      "\n",
      "\tTweet's text':  i persuas lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'persuas', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i persuas lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1237 :\n",
      "\n",
      "\tTweet's text':  studi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#KMYB19HR'] \n",
      "\n",
      "\tTweet tokenized by words:  ['studi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['studi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1238 :\n",
      "\n",
      "\tTweet's text':  hospit new allergi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hospit', 'new', 'allergi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hospit new allergi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1239 :\n",
      "\n",
      "\tTweet's text':  even link servic alert \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['even', 'link', 'servic', 'alert'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['even link servic alert'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1240 :\n",
      "\n",
      "\tTweet's text':  hey look there \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'look', 'there'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey look there'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1241 :\n",
      "\n",
      "\tTweet's text':  and skip tbh do like much eras life someth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_look_of_triumph'] \n",
      "\n",
      "\tTweet's hashtags':  ['#awesome'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'skip', 'tbh', 'do', 'like', 'much', 'eras', 'life', 'someth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and skip tbh do like much eras life someth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1242 :\n",
      "\n",
      "\tTweet's text':  oh joy get even live room \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#putyourtoysaway', '#badboyfriend'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'joy', 'get', 'even', 'live', 'room'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh joy get even live room'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1243 :\n",
      "\n",
      "\tTweet's text':  human brain disappear everi day some never even appear brain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#brain', '#humanbrain'] \n",
      "\n",
      "\tTweet tokenized by words:  ['human', 'brain', 'disappear', 'everi', 'day', 'some', 'never', 'even', 'appear', 'brain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['human brain disappear everi day some never even appear brain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1244 :\n",
      "\n",
      "\tTweet's text':  happi new year twitter peopl hope happi success lot love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_throwing_a_kiss'] \n",
      "\n",
      "\tTweet's hashtags':  ['#2015season', '#2014sucks'] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'new', 'year', 'twitter', 'peopl', 'hope', 'happi', 'success', 'lot', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi new year twitter peopl hope happi success lot love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1245 :\n",
      "\n",
      "\tTweet's text':  turn sausag butti burger king burger realli enjoy eat half morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#feelshit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['turn', 'sausag', 'butti', 'burger', 'king', 'burger', 'realli', 'enjoy', 'eat', 'half', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['turn sausag butti burger king burger realli enjoy eat half morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1246 :\n",
      "\n",
      "\tTweet's text':  ma thing \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ma', 'thing'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ma thing'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1247 :\n",
      "\n",
      "\tTweet's text':  girl beauti short nose tall toshort selfieee \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#beautiful', '#short', '#nose', '#tall', '#but', '#toshort', '#selfieeee'] \n",
      "\n",
      "\tTweet tokenized by words:  ['girl', 'beauti', 'short', 'nose', 'tall', 'toshort', 'selfieee'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['girl beauti short nose tall toshort selfieee'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1248 :\n",
      "\n",
      "\tTweet's text':  miss hashtag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['miss', 'hashtag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['miss hashtag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1249 :\n",
      "\n",
      "\tTweet's text':  first nigga grab behind no homo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['first', 'nigga', 'grab', 'behind', 'no', 'homo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['first nigga grab behind no homo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1250 :\n",
      "\n",
      "\tTweet's text':  loooooool rt monday done friday around corner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['loooooool', 'rt', 'monday', 'done', 'friday', 'around', 'corner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['loooooool rt monday done friday around corner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1251 :\n",
      "\n",
      "\tTweet's text':  new homeschool year new market busi clickbank univers wealthi affili write book final \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#holyschedule', '#needanapp'] \n",
      "\n",
      "\tTweet tokenized by words:  ['new', 'homeschool', 'year', 'new', 'market', 'busi', 'clickbank', 'univers', 'wealthi', 'affili', 'write', 'book', 'final'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['new homeschool year new market busi clickbank univers wealthi affili write book final'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1252 :\n",
      "\n",
      "\tTweet's text':  scratch the night off my eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['scratch', 'the', 'night', 'off', 'my', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['scratch the night off my eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1253 :\n",
      "\n",
      "\tTweet's text':  work box day fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'box', 'day', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work box day fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1254 :\n",
      "\n",
      "\tTweet's text':  to u ur worth hair head tough least love me \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#deadbeatdads', '#kids', '#singlemom', '#beautiful', '#daughter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['to', 'u', 'ur', 'worth', 'hair', 'head', 'tough', 'least', 'love', 'me'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['to u ur worth hair head tough least love me'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1255 :\n",
      "\n",
      "\tTweet's text':  it bad happen look like realli good movi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TheInterview'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'bad', 'happen', 'look', 'like', 'realli', 'good', 'movi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it bad happen look like realli good movi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1256 :\n",
      "\n",
      "\tTweet's text':  gun law fix everyth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gun', 'law', 'fix', 'everyth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gun law fix everyth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1257 :\n",
      "\n",
      "\tTweet's text':  s o bengal suck yesterday total made worth stay hour yesterday come work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['s', 'o', 'bengal', 'suck', 'yesterday', 'total', 'made', 'worth', 'stay', 'hour', 'yesterday', 'come', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['s o bengal suck yesterday total made worth stay hour yesterday come work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1258 :\n",
      "\n",
      "\tTweet's text':  i mostli follow list i dip full feed randomli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'mostli', 'follow', 'list', 'i', 'dip', 'full', 'feed', 'randomli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i mostli follow list i dip full feed randomli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1259 :\n",
      "\n",
      "\tTweet's text':  matter messag board thread authorit sourc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['matter', 'messag', 'board', 'thread', 'authorit', 'sourc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['matter messag board thread authorit sourc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1260 :\n",
      "\n",
      "\tTweet's text':  bring movi tuesday night \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['weary_cat_face', 'face_screaming_in_fear', 'pistol', 'father_christmas', 'face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  ['#POPCORN'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bring', 'movi', 'tuesday', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bring movi tuesday night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1261 :\n",
      "\n",
      "\tTweet's text':  mom bring physic trainer dunckin donut ye bring donut fit fanat would make perfect sens \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mom', 'bring', 'physic', 'trainer', 'dunckin', 'donut', 'ye', 'bring', 'donut', 'fit', 'fanat', 'would', 'make', 'perfect', 'sens'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mom bring physic trainer dunckin donut ye bring donut fit fanat would make perfect sens'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1262 :\n",
      "\n",
      "\tTweet's text':  far funniest prick world moment can pleas come geelong we normal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['far', 'funniest', 'prick', 'world', 'moment', 'can', 'pleas', 'come', 'geelong', 'we', 'normal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['far funniest prick world moment can pleas come geelong we normal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1263 :\n",
      "\n",
      "\tTweet's text':  thank hard scienc depart give us minut final \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'hard', 'scienc', 'depart', 'give', 'us', 'minut', 'final'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank hard scienc depart give us minut final'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1264 :\n",
      "\n",
      "\tTweet's text':  i guess lost coupl million lambia \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#LudicrousStory'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'lost', 'coupl', 'million', 'lambia'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guess lost coupl million lambia'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1265 :\n",
      "\n",
      "\tTweet's text':  i move north jersey big ranger fan coyot came town where \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'move', 'north', 'jersey', 'big', 'ranger', 'fan', 'coyot', 'came', 'town', 'where'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i move north jersey big ranger fan coyot came town where'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1266 :\n",
      "\n",
      "\tTweet's text':  stl you will never win again rt new manag new striker new transfer committe cont \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stl', 'you', 'will', 'never', 'win', 'again', 'rt', 'new', 'manag', 'new', 'striker', 'new', 'transfer', 'committe', 'cont'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stl you will never win again rt new manag new striker new transfer committe cont'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1267 :\n",
      "\n",
      "\tTweet's text':  mayb go jump land someth technic ground \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mayb', 'go', 'jump', 'land', 'someth', 'technic', 'ground'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mayb go jump land someth technic ground'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1268 :\n",
      "\n",
      "\tTweet's text':  also sick name \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['also', 'sick', 'name'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['also sick name'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1269 :\n",
      "\n",
      "\tTweet's text':  babysit night hope car get tow bc idk park \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_open_mouth_and_cold_sweat'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['babysit', 'night', 'hope', 'car', 'get', 'tow', 'bc', 'idk', 'park'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['babysit night hope car get tow bc idk park'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1270 :\n",
      "\n",
      "\tTweet's text':  mean much hate \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mean', 'much', 'hate'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mean much hate'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1271 :\n",
      "\n",
      "\tTweet's text':  second prize two sign copi bori book \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#onlyKidding'] \n",
      "\n",
      "\tTweet tokenized by words:  ['second', 'prize', 'two', 'sign', 'copi', 'bori', 'book'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['second prize two sign copi bori book'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1272 :\n",
      "\n",
      "\tTweet's text':  wisdom i head cold i took advic motrin hydrat chang sock cold elimin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Corpsman', '#navy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wisdom', 'i', 'head', 'cold', 'i', 'took', 'advic', 'motrin', 'hydrat', 'chang', 'sock', 'cold', 'elimin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wisdom i head cold i took advic motrin hydrat chang sock cold elimin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1273 :\n",
      "\n",
      "\tTweet's text':  follow great tweet start onlin shop \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['follow', 'great', 'tweet', 'start', 'onlin', 'shop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['follow great tweet start onlin shop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1274 :\n",
      "\n",
      "\tTweet's text':  ok kev gurney bowl next \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ok', 'kev', 'gurney', 'bowl', 'next'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ok kev gurney bowl next'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1275 :\n",
      "\n",
      "\tTweet's text':  i take blaze hot shower i get use burn pit hell \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ifitsreal'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'take', 'blaze', 'hot', 'shower', 'i', 'get', 'use', 'burn', 'pit', 'hell'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i take blaze hot shower i get use burn pit hell'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1276 :\n",
      "\n",
      "\tTweet's text':  festiv \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ff'] \n",
      "\n",
      "\tTweet tokenized by words:  ['festiv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['festiv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1277 :\n",
      "\n",
      "\tTweet's text':  i love procrastin i hate cram \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'procrastin', 'i', 'hate', 'cram'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love procrastin i hate cram'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1278 :\n",
      "\n",
      "\tTweet's text':  entertain journalist collect fact annoy dentist \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Entertaining', '#Annoying', '#FactAboutDentist'] \n",
      "\n",
      "\tTweet tokenized by words:  ['entertain', 'journalist', 'collect', 'fact', 'annoy', 'dentist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['entertain journalist collect fact annoy dentist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1279 :\n",
      "\n",
      "\tTweet's text':  biggest task get look shall one look \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#your', '#how', '#none', '#cleverclogs', '#shld', '#know', '#my', '#nakhre'] \n",
      "\n",
      "\tTweet tokenized by words:  ['biggest', 'task', 'get', 'look', 'shall', 'one', 'look'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['biggest task get look shall one look'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1280 :\n",
      "\n",
      "\tTweet's text':  zuckerberg say wear grey shirt everyday want wast time thing matter he run facebook \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['zuckerberg', 'say', 'wear', 'grey', 'shirt', 'everyday', 'want', 'wast', 'time', 'thing', 'matter', 'he', 'run', 'facebook'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['zuckerberg say wear grey shirt everyday want wast time thing matter he run facebook'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1281 :\n",
      "\n",
      "\tTweet's text':  my stomach wonderland ga induc bacteria \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#blessed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'stomach', 'wonderland', 'ga', 'induc', 'bacteria'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my stomach wonderland ga induc bacteria'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1282 :\n",
      "\n",
      "\tTweet's text':  here come univers \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TMLtalk', '#Leafs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['here', 'come', 'univers'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['here come univers'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1283 :\n",
      "\n",
      "\tTweet's text':  thank god sign carmelo \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Knicks', '#TheBullsCanHaveHim'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'god', 'sign', 'carmelo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank god sign carmelo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1284 :\n",
      "\n",
      "\tTweet's text':  heaven know i miser \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TheSmiths', '#girl', '#old', '#ohwow', '#InstaSize', '#a', '#goodmood', '#weirdpose'] \n",
      "\n",
      "\tTweet tokenized by words:  ['heaven', 'know', 'i', 'miser'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['heaven know i miser'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1285 :\n",
      "\n",
      "\tTweet's text':  should balanc view \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['should', 'balanc', 'view'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['should balanc view'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1286 :\n",
      "\n",
      "\tTweet's text':  alon tonight caus person song help imagin beyond anoth world gosupersonicquikr aboveandbeyond \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoSupersonicQuikr'] \n",
      "\n",
      "\tTweet tokenized by words:  ['alon', 'tonight', 'caus', 'person', 'song', 'help', 'imagin', 'beyond', 'anoth', 'world', 'gosupersonicquikr', 'aboveandbeyond'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alon tonight caus person song help imagin beyond anoth world gosupersonicquikr aboveandbeyond'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1287 :\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's text':  thx if thri real dont friend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thx', 'if', 'thri', 'real', 'dont', 'friend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thx if thri real dont friend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1288 :\n",
      "\n",
      "\tTweet's text':  boon pratt the evolut will be televis direct by devin gibson \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['boon', 'pratt', 'the', 'evolut', 'will', 'be', 'televis', 'direct', 'by', 'devin', 'gibson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['boon pratt the evolut will be televis direct by devin gibson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1289 :\n",
      "\n",
      "\tTweet's text':  off brave tesco humung shop list hail outsid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ohbliss'] \n",
      "\n",
      "\tTweet tokenized by words:  ['off', 'brave', 'tesco', 'humung', 'shop', 'list', 'hail', 'outsid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['off brave tesco humung shop list hail outsid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1290 :\n",
      "\n",
      "\tTweet's text':  weird \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['weird'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['weird'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1291 :\n",
      "\n",
      "\tTweet's text':  break girl buy present lowbudget doe \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lowbudget', '#smartmove', '#a', '#good', '#idea', '#butscheming'] \n",
      "\n",
      "\tTweet tokenized by words:  ['break', 'girl', 'buy', 'present', 'lowbudget', 'doe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['break girl buy present lowbudget doe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1292 :\n",
      "\n",
      "\tTweet's text':  as citibik gear expand \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Comptroller', '#CitiBike', '#Stations', '#Bikes', '#Being', '#Properly', '#Maintained'] \n",
      "\n",
      "\tTweet tokenized by words:  ['as', 'citibik', 'gear', 'expand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['as citibik gear expand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1293 :\n",
      "\n",
      "\tTweet's text':  ooh someon know click unfollow button i impress \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#beforeCoffee'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ooh', 'someon', 'know', 'click', 'unfollow', 'button', 'i', 'impress'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ooh someon know click unfollow button i impress'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1294 :\n",
      "\n",
      "\tTweet's text':  i readi get drunk tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'readi', 'get', 'drunk', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i readi get drunk tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1295 :\n",
      "\n",
      "\tTweet's text':  i think new sweater i bought matern sweater oh well it super cozi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'new', 'sweater', 'i', 'bought', 'matern', 'sweater', 'oh', 'well', 'it', 'super', 'cozi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think new sweater i bought matern sweater oh well it super cozi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1296 :\n",
      "\n",
      "\tTweet's text':  doubl danc boy make monday worthwhil \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['doubl', 'danc', 'boy', 'make', 'monday', 'worthwhil'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['doubl danc boy make monday worthwhil'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1297 :\n",
      "\n",
      "\tTweet's text':  obama want closer relat marxist shock i tell shock \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cuba'] \n",
      "\n",
      "\tTweet tokenized by words:  ['obama', 'want', 'closer', 'relat', 'marxist', 'shock', 'i', 'tell', 'shock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['obama want closer relat marxist shock i tell shock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1298 :\n",
      "\n",
      "\tTweet's text':  oh haha even seen em \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'haha', 'even', 'seen', 'em'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh haha even seen em'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1299 :\n",
      "\n",
      "\tTweet's text':  be abl think self angri nice gift \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ItsACurse'] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'abl', 'think', 'self', 'angri', 'nice', 'gift'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be abl think self angri nice gift'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1300 :\n",
      "\n",
      "\tTweet's text':  paper support blackshirt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['paper', 'support', 'blackshirt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['paper support blackshirt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1301 :\n",
      "\n",
      "\tTweet's text':  one ly \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'ly'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one ly'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1302 :\n",
      "\n",
      "\tTweet's text':  cool know i peopl i talk shit night \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cool', 'know', 'i', 'peopl', 'i', 'talk', 'shit', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cool know i peopl i talk shit night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1303 :\n",
      "\n",
      "\tTweet's text':  osu oppon record much better baylor outright conf champ win tm win record baylor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['osu', 'oppon', 'record', 'much', 'better', 'baylor', 'outright', 'conf', 'champ', 'win', 'tm', 'win', 'record', 'baylor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['osu oppon record much better baylor outright conf champ win tm win record baylor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1304 :\n",
      "\n",
      "\tTweet's text':  happi new year thank repli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'new', 'year', 'thank', 'repli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi new year thank repli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1305 :\n",
      "\n",
      "\tTweet's text':  dress gown turkey buffalo sauc sandwich hand big fat quiz year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#moving', '#ever', '#again'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dress', 'gown', 'turkey', 'buffalo', 'sauc', 'sandwich', 'hand', 'big', 'fat', 'quiz', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dress gown turkey buffalo sauc sandwich hand big fat quiz year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1306 :\n",
      "\n",
      "\tTweet's text':  per day definit costco sock i must say funki sock movement kinda cool \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['per', 'day', 'definit', 'costco', 'sock', 'i', 'must', 'say', 'funki', 'sock', 'movement', 'kinda', 'cool'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['per day definit costco sock i must say funki sock movement kinda cool'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1307 :\n",
      "\n",
      "\tTweet's text':  a tire selfie yet look p aftr long work i love unii \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['P'] \n",
      "\n",
      "\tTweet's hashtags':  ['#freshh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'tire', 'selfie', 'yet', 'look', 'p', 'aftr', 'long', 'work', 'i', 'love', 'unii'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a tire selfie yet look p aftr long work i love unii'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1308 :\n",
      "\n",
      "\tTweet's text':  thi noth anyth i hate word fleek it sound like someth i name neopet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'noth', 'anyth', 'i', 'hate', 'word', 'fleek', 'it', 'sound', 'like', 'someth', 'i', 'name', 'neopet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi noth anyth i hate word fleek it sound like someth i name neopet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1309 :\n",
      "\n",
      "\tTweet's text':  oomf chow mom car \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oomf', 'chow', 'mom', 'car'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oomf chow mom car'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1310 :\n",
      "\n",
      "\tTweet's text':  stop live like king one so use real life \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ExodusMovie'] \n",
      "\n",
      "\tTweet tokenized by words:  ['stop', 'live', 'like', 'king', 'one', 'so', 'use', 'real', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stop live like king one so use real life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1311 :\n",
      "\n",
      "\tTweet's text':  i think i might artist \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#flowers', '#pretty', '#love', '#beautiful', '#painting', '#art', '#nature', '#lchs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'i', 'might', 'artist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think i might artist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1312 :\n",
      "\n",
      "\tTweet's text':  realli stoke go abroad fall well next week complet differ reason \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#imissmyboyfriend'] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'stoke', 'go', 'abroad', 'fall', 'well', 'next', 'week', 'complet', 'differ', 'reason'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli stoke go abroad fall well next week complet differ reason'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1313 :\n",
      "\n",
      "\tTweet's text':  look behind tara ella starbuck the omni santri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mytopgirls'] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'behind', 'tara', 'ella', 'starbuck', 'the', 'omni', 'santri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look behind tara ella starbuck the omni santri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1314 :\n",
      "\n",
      "\tTweet's text':  like yellow thing yellow hi kapitana nagaar kmi ni asdfghjkl huhuhu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['like', 'yellow', 'thing', 'yellow', 'hi', 'kapitana', 'nagaar', 'kmi', 'ni', 'asdfghjkl', 'huhuhu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['like yellow thing yellow hi kapitana nagaar kmi ni asdfghjkl huhuhu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1315 :\n",
      "\n",
      "\tTweet's text':  love ya jerri heck \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'ya', 'jerri', 'heck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love ya jerri heck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1316 :\n",
      "\n",
      "\tTweet's text':  i usual fan anyth omg these best cooki i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pumpkin', '#pumpkinspiced'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'usual', 'fan', 'anyth', 'omg', 'these', 'best', 'cooki', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i usual fan anyth omg these best cooki i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1317 :\n",
      "\n",
      "\tTweet's text':  imag via we heart it \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#boy', '#funny', '#girl', '#K', '#mad', '#ok'] \n",
      "\n",
      "\tTweet tokenized by words:  ['imag', 'via', 'we', 'heart', 'it'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['imag via we heart it'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1318 :\n",
      "\n",
      "\tTweet's text':  take time i want right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['take', 'time', 'i', 'want', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['take time i want right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1319 :\n",
      "\n",
      "\tTweet's text':  annnnddddddd opinion irrelev \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['annnnddddddd', 'opinion', 'irrelev'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['annnnddddddd opinion irrelev'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1320 :\n",
      "\n",
      "\tTweet's text':  it not finish it not end it onli the when is in it a \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Its', '#Over', '#Beginning', '#God', '#All', '#Things'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'not', 'finish', 'it', 'not', 'end', 'it', 'onli', 'the', 'when', 'is', 'in', 'it', 'a'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it not finish it not end it onli the when is in it a'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1321 :\n",
      "\n",
      "\tTweet's text':  i know big spot time i watch choke haha must mean suck right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'big', 'spot', 'time', 'i', 'watch', 'choke', 'haha', 'must', 'mean', 'suck', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know big spot time i watch choke haha must mean suck right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1322 :\n",
      "\n",
      "\tTweet's text':  oh finger stick togeth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'finger', 'stick', 'togeth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh finger stick togeth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1323 :\n",
      "\n",
      "\tTweet's text':  can wait work dream team today see evil monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['see-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  ['#delilyfe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'work', 'dream', 'team', 'today', 'see', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait work dream team today see evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1324 :\n",
      "\n",
      "\tTweet's text':  i love chaotic school run \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'chaotic', 'school', 'run'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love chaotic school run'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1325 :\n",
      "\n",
      "\tTweet's text':  new fave thing facebook \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sexpest'] \n",
      "\n",
      "\tTweet tokenized by words:  ['new', 'fave', 'thing', 'facebook'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['new fave thing facebook'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1326 :\n",
      "\n",
      "\tTweet's text':  pleas repli gentleman behalf us \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#jokles', '#gotrealworktodo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pleas', 'repli', 'gentleman', 'behalf', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pleas repli gentleman behalf us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1327 :\n",
      "\n",
      "\tTweet's text':  my luck keep get better better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'luck', 'keep', 'get', 'better', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my luck keep get better better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1328 :\n",
      "\n",
      "\tTweet's text':  deutsch misogynist toad shock bigot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HandsUpDontShoot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['deutsch', 'misogynist', 'toad', 'shock', 'bigot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['deutsch misogynist toad shock bigot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1329 :\n",
      "\n",
      "\tTweet's text':  googl drive review \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['googl', 'drive', 'review'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['googl drive review'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1330 :\n",
      "\n",
      "\tTweet's text':  say \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1331 :\n",
      "\n",
      "\tTweet's text':  ok hope rain soon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['confounded_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ok', 'hope', 'rain', 'soon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ok hope rain soon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1332 :\n",
      "\n",
      "\tTweet's text':  not fit definit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['not', 'fit', 'definit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['not fit definit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1333 :\n",
      "\n",
      "\tTweet's text':  second day row i late work thank servic definit worth fare hike \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['second', 'day', 'row', 'i', 'late', 'work', 'thank', 'servic', 'definit', 'worth', 'fare', 'hike'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['second day row i late work thank servic definit worth fare hike'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1334 :\n",
      "\n",
      "\tTweet's text':  yeah i diet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'i', 'diet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah i diet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1335 :\n",
      "\n",
      "\tTweet's text':  ebola leav hundr thousand face hunger three worst hit countri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcies', '#eu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ebola', 'leav', 'hundr', 'thousand', 'face', 'hunger', 'three', 'worst', 'hit', 'countri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ebola leav hundr thousand face hunger three worst hit countri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1336 :\n",
      "\n",
      "\tTweet's text':  don offend hear peopl refer the word holiday deriv holi day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HappyHolidays', '#Christmas', '#fb'] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'offend', 'hear', 'peopl', 'refer', 'the', 'word', 'holiday', 'deriv', 'holi', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don offend hear peopl refer the word holiday deriv holi day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1337 :\n",
      "\n",
      "\tTweet's text':  lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1338 :\n",
      "\n",
      "\tTweet's text':  wow doutzen look amaz babi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'doutzen', 'look', 'amaz', 'babi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow doutzen look amaz babi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1339 :\n",
      "\n",
      "\tTweet's text':  it alway nice i take cig break like hous i hear weird creepi nois realli dark \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'alway', 'nice', 'i', 'take', 'cig', 'break', 'like', 'hous', 'i', 'hear', 'weird', 'creepi', 'nois', 'realli', 'dark'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it alway nice i take cig break like hous i hear weird creepi nois realli dark'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1340 :\n",
      "\n",
      "\tTweet's text':  j cole song virgin virgin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#musicalgenius', '#innovation'] \n",
      "\n",
      "\tTweet tokenized by words:  ['j', 'cole', 'song', 'virgin', 'virgin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['j cole song virgin virgin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1341 :\n",
      "\n",
      "\tTweet's text':  thank updat spot i good w that if post stuff blog \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'updat', 'spot', 'i', 'good', 'w', 'that', 'if', 'post', 'stuff', 'blog'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank updat spot i good w that if post stuff blog'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1342 :\n",
      "\n",
      "\tTweet's text':  sz m \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sz', 'm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sz m'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1343 :\n",
      "\n",
      "\tTweet's text':  we great way start morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'great', 'way', 'start', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we great way start morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1344 :\n",
      "\n",
      "\tTweet's text':  now i see play review becaus even close \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['now', 'i', 'see', 'play', 'review', 'becaus', 'even', 'close'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['now i see play review becaus even close'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1345 :\n",
      "\n",
      "\tTweet's text':  catch rhoa love drama \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#love'] \n",
      "\n",
      "\tTweet tokenized by words:  ['catch', 'rhoa', 'love', 'drama'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['catch rhoa love drama'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1346 :\n",
      "\n",
      "\tTweet's text':  never depend govt money peopl spend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Australia', '#Sad', '#socialism', '#Unrealistic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['never', 'depend', 'govt', 'money', 'peopl', 'spend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['never depend govt money peopl spend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1347 :\n",
      "\n",
      "\tTweet's text':  one disturb dan tickl elf bite \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes', 'pistol'] \n",
      "\n",
      "\tTweet's hashtags':  ['#philisinnocent'] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'disturb', 'dan', 'tickl', 'elf', 'bite'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one disturb dan tickl elf bite'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1348 :\n",
      "\n",
      "\tTweet's text':  hit big issu champ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hit', 'big', 'issu', 'champ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hit big issu champ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1349 :\n",
      "\n",
      "\tTweet's text':  rt rumourisimadad \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt', 'rumourisimadad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt rumourisimadad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1350 :\n",
      "\n",
      "\tTweet's text':  least i could barg convo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['least', 'i', 'could', 'barg', 'convo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['least i could barg convo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1351 :\n",
      "\n",
      "\tTweet's text':  dog \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Video', '#Jesus', '#Bulldogs', '#deep', '#meaningful', '#dog', '#dogs', '#bulldog', '#religion', '#vlog'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dog'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dog'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1352 :\n",
      "\n",
      "\tTweet's text':  we live world even neighbor look alien \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'live', 'world', 'even', 'neighbor', 'look', 'alien'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we live world even neighbor look alien'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1353 :\n",
      "\n",
      "\tTweet's text':  plu memori short i delet pic share boom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['plu', 'memori', 'short', 'i', 'delet', 'pic', 'share', 'boom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['plu memori short i delet pic share boom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1354 :\n",
      "\n",
      "\tTweet's text':  nice weekend back work tonight over fuck moon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'weekend', 'back', 'work', 'tonight', 'over', 'fuck', 'moon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice weekend back work tonight over fuck moon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1355 :\n",
      "\n",
      "\tTweet's text':  bridal jewel excit rang hand made high qualiti jewelleri high street bespok custom \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#jewels', '#exciting', '#hand', '#high', '#bespoke', '#custom'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bridal', 'jewel', 'excit', 'rang', 'hand', 'made', 'high', 'qualiti', 'jewelleri', 'high', 'street', 'bespok', 'custom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bridal jewel excit rang hand made high qualiti jewelleri high street bespok custom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1356 :\n",
      "\n",
      "\tTweet's text':  s \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#boohackers'] \n",
      "\n",
      "\tTweet tokenized by words:  ['s'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1357 :\n",
      "\n",
      "\tTweet's text':  my current christma song obsess play non stop weekend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'current', 'christma', 'song', 'obsess', 'play', 'non', 'stop', 'weekend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my current christma song obsess play non stop weekend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1358 :\n",
      "\n",
      "\tTweet's text':  flight divert boil water incid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['flight', 'divert', 'boil', 'water', 'incid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['flight divert boil water incid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1359 :\n",
      "\n",
      "\tTweet's text':  for grand year definit get inform need practic class \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['for', 'grand', 'year', 'definit', 'get', 'inform', 'need', 'practic', 'class'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['for grand year definit get inform need practic class'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1360 :\n",
      "\n",
      "\tTweet's text':  happen i rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happen', 'i', 'rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happen i rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1361 :\n",
      "\n",
      "\tTweet's text':  sneak round mini golf \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hollywooddriveingolf', '#universal', '#citiwalk'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sneak', 'round', 'mini', 'golf'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sneak round mini golf'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1362 :\n",
      "\n",
      "\tTweet's text':  my twitter account worth accord social account worth calcul see much worth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'twitter', 'account', 'worth', 'accord', 'social', 'account', 'worth', 'calcul', 'see', 'much', 'worth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my twitter account worth accord social account worth calcul see much worth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1363 :\n",
      "\n",
      "\tTweet's text':  the take break read check social media \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#socialmedia'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'take', 'break', 'read', 'check', 'social', 'media'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the take break read check social media'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1364 :\n",
      "\n",
      "\tTweet's text':  video by dipmagazin drop today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wifeyseries', '#covermodels'] \n",
      "\n",
      "\tTweet tokenized by words:  ['video', 'by', 'dipmagazin', 'drop', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['video by dipmagazin drop today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1365 :\n",
      "\n",
      "\tTweet's text':  i hope peopl miss connect flight take joy wonder experi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sorrynotsorry'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hope', 'peopl', 'miss', 'connect', 'flight', 'take', 'joy', 'wonder', 'experi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hope peopl miss connect flight take joy wonder experi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1366 :\n",
      "\n",
      "\tTweet's text':  he caught gasp latin mass \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['he', 'caught', 'gasp', 'latin', 'mass'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['he caught gasp latin mass'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1367 :\n",
      "\n",
      "\tTweet's text':  i love stay tweet stay hang \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#truebro'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'stay', 'tweet', 'stay', 'hang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love stay tweet stay hang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1368 :\n",
      "\n",
      "\tTweet's text':  lol websit suspend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'websit', 'suspend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol websit suspend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1369 :\n",
      "\n",
      "\tTweet's text':  the worst consid thing like conserv tribun credibl sourc inform total bia \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'worst', 'consid', 'thing', 'like', 'conserv', 'tribun', 'credibl', 'sourc', 'inform', 'total', 'bia'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the worst consid thing like conserv tribun credibl sourc inform total bia'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1370 :\n",
      "\n",
      "\tTweet's text':  rt meanwhil cagua rusney castillo goe mammoth hr man alex cora love guy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#RedSox'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt', 'meanwhil', 'cagua', 'rusney', 'castillo', 'goe', 'mammoth', 'hr', 'man', 'alex', 'cora', 'love', 'guy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt meanwhil cagua rusney castillo goe mammoth hr man alex cora love guy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1371 :\n",
      "\n",
      "\tTweet's text':  i want thank e l e n tumblr spoil honestli fuck \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BOFA', '#martinfreeman'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'want', 'thank', 'e', 'l', 'e', 'n', 'tumblr', 'spoil', 'honestli', 'fuck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i want thank e l e n tumblr spoil honestli fuck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1372 :\n",
      "\n",
      "\tTweet's text':  i love wake five minut i \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wake', 'five', 'minut', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wake five minut i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1373 :\n",
      "\n",
      "\tTweet's text':  i alreadi wait julia come back \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'alreadi', 'wait', 'julia', 'come', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i alreadi wait julia come back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1374 :\n",
      "\n",
      "\tTweet's text':  it gonna loooong day yolo let fun smile face open mouth tightli close eye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's emojis':  ['smiling_face_with_open_mouth_and_tightly-closed_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'gon', 'na', 'loooong', 'day', 'yolo', 'let', 'fun', 'smile', 'face', 'open', 'mouth', 'tightli', 'close', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it gonna loooong day yolo let fun smile face open mouth tightli close eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1375 :\n",
      "\n",
      "\tTweet's text':  you slip back hate figur territori \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'slip', 'back', 'hate', 'figur', 'territori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you slip back hate figur territori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1376 :\n",
      "\n",
      "\tTweet's text':  be use great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'use', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be use great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1377 :\n",
      "\n",
      "\tTweet's text':  meanwhil zimbabw south african impos govern promis stamp corrupt \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['meanwhil', 'zimbabw', 'south', 'african', 'impos', 'govern', 'promis', 'stamp', 'corrupt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['meanwhil zimbabw south african impos govern promis stamp corrupt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1378 :\n",
      "\n",
      "\tTweet's text':  peopl love funk let keep tweet go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'love', 'funk', 'let', 'keep', 'tweet', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl love funk let keep tweet go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1379 :\n",
      "\n",
      "\tTweet's text':  where i boy town \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['where', 'i', 'boy', 'town'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['where i boy town'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1380 :\n",
      "\n",
      "\tTweet's text':  i footi sock tracki tee fluffi dress gown i wrap \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'footi', 'sock', 'tracki', 'tee', 'fluffi', 'dress', 'gown', 'i', 'wrap'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i footi sock tracki tee fluffi dress gown i wrap'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1381 :\n",
      "\n",
      "\tTweet's text':  my finger duck attract without bandag tbh \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'finger', 'duck', 'attract', 'without', 'bandag', 'tbh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my finger duck attract without bandag tbh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1382 :\n",
      "\n",
      "\tTweet's text':  accident break comput tech support haha talk employe month \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['personal_computer', 'floppy_disk', 'pistol'] \n",
      "\n",
      "\tTweet's hashtags':  ['#techSupport'] \n",
      "\n",
      "\tTweet tokenized by words:  ['accident', 'break', 'comput', 'tech', 'support', 'haha', 'talk', 'employe', 'month'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['accident break comput tech support haha talk employe month'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1383 :\n",
      "\n",
      "\tTweet's text':  so glad vote put good use \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'glad', 'vote', 'put', 'good', 'use'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so glad vote put good use'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1384 :\n",
      "\n",
      "\tTweet's text':  ppl make blanket statement whole race defens sick hear race \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ppl', 'make', 'blanket', 'statement', 'whole', 'race', 'defens', 'sick', 'hear', 'race'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ppl make blanket statement whole race defens sick hear race'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1385 :\n",
      "\n",
      "\tTweet's text':  i love wide awak \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wide', 'awak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wide awak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1386 :\n",
      "\n",
      "\tTweet's text':  the word taliban come root word talib mean student peshawarattack \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PeshawarAttack', '#DeathToTaliban', '#DeathToISIS'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'word', 'taliban', 'come', 'root', 'word', 'talib', 'mean', 'student', 'peshawarattack'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the word taliban come root word talib mean student peshawarattack'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1387 :\n",
      "\n",
      "\tTweet's text':  yay fuck monday life perfect magic i love everyth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'fuck', 'monday', 'life', 'perfect', 'magic', 'i', 'love', 'everyth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay fuck monday life perfect magic i love everyth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1388 :\n",
      "\n",
      "\tTweet's text':  event technolog session internet problem \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HSC2024'] \n",
      "\n",
      "\tTweet tokenized by words:  ['event', 'technolog', 'session', 'internet', 'problem'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['event technolog session internet problem'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1389 :\n",
      "\n",
      "\tTweet's text':  rt sourc tell dodger show seriou interest jon lester \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#marleyandme'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt', 'sourc', 'tell', 'dodger', 'show', 'seriou', 'interest', 'jon', 'lester'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt sourc tell dodger show seriou interest jon lester'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1390 :\n",
      "\n",
      "\tTweet's text':  can anyon tell iv upload item onto depop today lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lotsofdepopuploaded'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'anyon', 'tell', 'iv', 'upload', 'item', 'onto', 'depop', 'today', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can anyon tell iv upload item onto depop today lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1391 :\n",
      "\n",
      "\tTweet's text':  boot happi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['boot', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['boot happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1392 :\n",
      "\n",
      "\tTweet's text':  it scare i think thing like year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#2015'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'scare', 'i', 'think', 'thing', 'like', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it scare i think thing like year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1393 :\n",
      "\n",
      "\tTweet's text':  the last twolv game i jack right lockout vs okc rubio st game i wonder i i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'last', 'twolv', 'game', 'i', 'jack', 'right', 'lockout', 'vs', 'okc', 'rubio', 'st', 'game', 'i', 'wonder', 'i', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the last twolv game i jack right lockout vs okc rubio st game i wonder i i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1394 :\n",
      "\n",
      "\tTweet's text':  everybodi travel world i sit studi map last exam \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#jealousy', '#almostdone'] \n",
      "\n",
      "\tTweet tokenized by words:  ['everybodi', 'travel', 'world', 'i', 'sit', 'studi', 'map', 'last', 'exam'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everybodi travel world i sit studi map last exam'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1395 :\n",
      "\n",
      "\tTweet's text':  clean spew definit highlight job \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['clean', 'spew', 'definit', 'highlight', 'job'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['clean spew definit highlight job'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1396 :\n",
      "\n",
      "\tTweet's text':  right clearli po po play much call duti \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['right', 'clearli', 'po', 'po', 'play', 'much', 'call', 'duti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['right clearli po po play much call duti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1397 :\n",
      "\n",
      "\tTweet's text':  actual israel demand render antisemit acc mate favourit non definit antisem \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['actual', 'israel', 'demand', 'render', 'antisemit', 'acc', 'mate', 'favourit', 'non', 'definit', 'antisem'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['actual israel demand render antisemit acc mate favourit non definit antisem'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1398 :\n",
      "\n",
      "\tTweet's text':  thank strang vet husband bar remind i debt i die \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#studentloans'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'strang', 'vet', 'husband', 'bar', 'remind', 'i', 'debt', 'i', 'die'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank strang vet husband bar remind i debt i die'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1399 :\n",
      "\n",
      "\tTweet's text':  love i count peopl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'i', 'count', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love i count peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1400 :\n",
      "\n",
      "\tTweet's text':  i smash samsung galaxi run back car tri avoid park ticket \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'smash', 'samsung', 'galaxi', 'run', 'back', 'car', 'tri', 'avoid', 'park', 'ticket'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i smash samsung galaxi run back car tri avoid park ticket'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1401 :\n",
      "\n",
      "\tTweet's text':  yea i love alreadi throw tantrum upon wake total awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['ok_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yea', 'i', 'love', 'alreadi', 'throw', 'tantrum', 'upon', 'wake', 'total', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yea i love alreadi throw tantrum upon wake total awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1402 :\n",
      "\n",
      "\tTweet's text':  the winner goe stock they bribe \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'winner', 'goe', 'stock', 'they', 'bribe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the winner goe stock they bribe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1403 :\n",
      "\n",
      "\tTweet's text':  world villain climat crimin australia attempt heavi nation lima \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#auspol'] \n",
      "\n",
      "\tTweet tokenized by words:  ['world', 'villain', 'climat', 'crimin', 'australia', 'attempt', 'heavi', 'nation', 'lima'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['world villain climat crimin australia attempt heavi nation lima'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1404 :\n",
      "\n",
      "\tTweet's text':  i rather know upset hide question thing later \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'rather', 'know', 'upset', 'hide', 'question', 'thing', 'later'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i rather know upset hide question thing later'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1405 :\n",
      "\n",
      "\tTweet's text':  it almost i argu guy cute realli thi live come adult \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'almost', 'i', 'argu', 'guy', 'cute', 'realli', 'thi', 'live', 'come', 'adult'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it almost i argu guy cute realli thi live come adult'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1406 :\n",
      "\n",
      "\tTweet's text':  alway they found k home \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['alway', 'they', 'found', 'k', 'home'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alway they found k home'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1407 :\n",
      "\n",
      "\tTweet's text':  thank take we love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'take', 'we', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank take we love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1408 :\n",
      "\n",
      "\tTweet's text':  yeah so see i great success ladi and i total excit sex \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'so', 'see', 'i', 'great', 'success', 'ladi', 'and', 'i', 'total', 'excit', 'sex'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah so see i great success ladi and i total excit sex'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1409 :\n",
      "\n",
      "\tTweet's text':  senat just confirm new cabinet member that ha nd amend support furiou the senat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['senat', 'just', 'confirm', 'new', 'cabinet', 'member', 'that', 'ha', 'nd', 'amend', 'support', 'furiou', 'the', 'senat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['senat just confirm new cabinet member that ha nd amend support furiou the senat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1410 :\n",
      "\n",
      "\tTweet's text':  have noth studi test fckn greaaat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['have', 'noth', 'studi', 'test', 'fckn', 'greaaat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['have noth studi test fckn greaaat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1411 :\n",
      "\n",
      "\tTweet's text':  marti post fact proof make shit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['marti', 'post', 'fact', 'proof', 'make', 'shit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['marti post fact proof make shit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1412 :\n",
      "\n",
      "\tTweet's text':  fall asleep sound rain relax \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['umbrella_with_rain_drops'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fall', 'asleep', 'sound', 'rain', 'relax'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fall asleep sound rain relax'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1413 :\n",
      "\n",
      "\tTweet's text':  o \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AbsoluteFavs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['o'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['o'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1414 :\n",
      "\n",
      "\tTweet's text':  inde two peopl opposit polit divid sling insult what twitter come \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['inde', 'two', 'peopl', 'opposit', 'polit', 'divid', 'sling', 'insult', 'what', 'twitter', 'come'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['inde two peopl opposit polit divid sling insult what twitter come'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1415 :\n",
      "\n",
      "\tTweet's text':  the biggest gun school kid countri receiv nobel prize \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Taliban', '#Malala', '#Education', '#Ouch'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'biggest', 'gun', 'school', 'kid', 'countri', 'receiv', 'nobel', 'prize'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the biggest gun school kid countri receiv nobel prize'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1416 :\n",
      "\n",
      "\tTweet's text':  i think i ever even made weed browni \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'i', 'ever', 'even', 'made', 'weed', 'browni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think i ever even made weed browni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1417 :\n",
      "\n",
      "\tTweet's text':  what b e a uti day scotland lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#rain', '#gales'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'b', 'e', 'a', 'uti', 'day', 'scotland', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what b e a uti day scotland lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1418 :\n",
      "\n",
      "\tTweet's text':  nice we make pot butter himalayan salt sometim infus salt chang \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'we', 'make', 'pot', 'butter', 'himalayan', 'salt', 'sometim', 'infus', 'salt', 'chang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice we make pot butter himalayan salt sometim infus salt chang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1419 :\n",
      "\n",
      "\tTweet's text':  look forward page essay tonight seem like fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_savouring_delicious_food'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'forward', 'page', 'essay', 'tonight', 'seem', 'like', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look forward page essay tonight seem like fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1420 :\n",
      "\n",
      "\tTweet's text':  i grin ill grin there two way read name \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'grin', 'ill', 'grin', 'there', 'two', 'way', 'read', 'name'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i grin ill grin there two way read name'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1421 :\n",
      "\n",
      "\tTweet's text':  see on saturday whaddddddup \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#legend'] \n",
      "\n",
      "\tTweet tokenized by words:  ['see', 'on', 'saturday', 'whaddddddup'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['see on saturday whaddddddup'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1422 :\n",
      "\n",
      "\tTweet's text':  a new year start so mani peopl came mani went but alway wat gone better \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'new', 'year', 'start', 'so', 'mani', 'peopl', 'came', 'mani', 'went', 'but', 'alway', 'wat', 'gone', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a new year start so mani peopl came mani went but alway wat gone better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1423 :\n",
      "\n",
      "\tTweet's text':  yoga pant sweatshirt nike i yet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yoga', 'pant', 'sweatshirt', 'nike', 'i', 'yet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yoga pant sweatshirt nike i yet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1424 :\n",
      "\n",
      "\tTweet's text':  bitch where the fuck u think im go better sit on down with the rest of these bitch waittng for me to move \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bitch', 'where', 'the', 'fuck', 'u', 'think', 'im', 'go', 'better', 'sit', 'on', 'down', 'with', 'the', 'rest', 'of', 'these', 'bitch', 'waittng', 'for', 'me', 'to', 'move'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bitch where the fuck u think im go better sit on down with the rest of these bitch waittng for me to move'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1425 :\n",
      "\n",
      "\tTweet's text':  rt \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#great', '#A', '#All', '#Burst', '#Christmas', '#diy', '#crafts'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1426 :\n",
      "\n",
      "\tTweet's text':  take final go straight work i peachi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['take', 'final', 'go', 'straight', 'work', 'i', 'peachi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['take final go straight work i peachi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1427 :\n",
      "\n",
      "\tTweet's text':  may cold tomorrow decemb a low dress warm \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['may', 'cold', 'tomorrow', 'decemb', 'a', 'low', 'dress', 'warm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['may cold tomorrow decemb a low dress warm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1428 :\n",
      "\n",
      "\tTweet's text':  buuuut fast iter prototyp product readi code \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['buuuut', 'fast', 'iter', 'prototyp', 'product', 'readi', 'code'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['buuuut fast iter prototyp product readi code'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1429 :\n",
      "\n",
      "\tTweet's text':  you peopl who antagon me list \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'peopl', 'who', 'antagon', 'me', 'list'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you peopl who antagon me list'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1430 :\n",
      "\n",
      "\tTweet's text':  let go cav quicken loan arena \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cleveland', '#cavs', '#cavaliers', '#nba'] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'go', 'cav', 'quicken', 'loan', 'arena'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let go cav quicken loan arena'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1431 :\n",
      "\n",
      "\tTweet's text':  toronto man find woman ex girlfriend name free trip around world i chang name \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['toronto', 'man', 'find', 'woman', 'ex', 'girlfriend', 'name', 'free', 'trip', 'around', 'world', 'i', 'chang', 'name'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['toronto man find woman ex girlfriend name free trip around world i chang name'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1432 :\n",
      "\n",
      "\tTweet's text':  chenua acheb thing fall apart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['chenua', 'acheb', 'thing', 'fall', 'apart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['chenua acheb thing fall apart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1433 :\n",
      "\n",
      "\tTweet's text':  thank i think fill correctli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'i', 'think', 'fill', 'correctli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank i think fill correctli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1434 :\n",
      "\n",
      "\tTweet's text':  girl dip \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['girl', 'dip'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['girl dip'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1435 :\n",
      "\n",
      "\tTweet's text':  think good name hondolan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['think', 'good', 'name', 'hondolan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['think good name hondolan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1436 :\n",
      "\n",
      "\tTweet's text':  thi tsu websit worth million you get paid post \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['flag_for_Faroe_Islands'] \n",
      "\n",
      "\tTweet's hashtags':  ['#TSU'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'tsu', 'websit', 'worth', 'million', 'you', 'get', 'paid', 'post'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi tsu websit worth million you get paid post'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1437 :\n",
      "\n",
      "\tTweet's text':  monday morn fave \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['monday', 'morn', 'fave'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['monday morn fave'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1438 :\n",
      "\n",
      "\tTweet's text':  thank mum fart not twice dinner bf \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NiceOne'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'mum', 'fart', 'not', 'twice', 'dinner', 'bf'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank mum fart not twice dinner bf'] \n",
      "\n",
      "---------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet  1439 :\n",
      "\n",
      "\tTweet's text':  be alreadi pretti good also master \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#socialmedia'] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'alreadi', 'pretti', 'good', 'also', 'master'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be alreadi pretti good also master'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1440 :\n",
      "\n",
      "\tTweet's text':  let set record straight mccoist player legend fact the man held us togeth one els would won ever b forgotten \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'set', 'record', 'straight', 'mccoist', 'player', 'legend', 'fact', 'the', 'man', 'held', 'us', 'togeth', 'one', 'els', 'would', 'won', 'ever', 'b', 'forgotten'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let set record straight mccoist player legend fact the man held us togeth one els would won ever b forgotten'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1441 :\n",
      "\n",
      "\tTweet's text':  histori check anyon know \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['histori', 'check', 'anyon', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['histori check anyon know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1442 :\n",
      "\n",
      "\tTweet's text':  off town get bday prezzi rude birthday xma week \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BusyBee'] \n",
      "\n",
      "\tTweet tokenized by words:  ['off', 'town', 'get', 'bday', 'prezzi', 'rude', 'birthday', 'xma', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['off town get bday prezzi rude birthday xma week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1443 :\n",
      "\n",
      "\tTweet's text':  the worst film becom must see \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#films'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'worst', 'film', 'becom', 'must', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the worst film becom must see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1444 :\n",
      "\n",
      "\tTweet's text':  you freer bethlehem would anywher rest arab world much \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'freer', 'bethlehem', 'would', 'anywher', 'rest', 'arab', 'world', 'much'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you freer bethlehem would anywher rest arab world much'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1445 :\n",
      "\n",
      "\tTweet's text':  know cover point kept us win two week almost win rd \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'cover', 'point', 'kept', 'us', 'win', 'two', 'week', 'almost', 'win', 'rd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know cover point kept us win two week almost win rd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1446 :\n",
      "\n",
      "\tTweet's text':  i think i know x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'i', 'know', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think i know x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1447 :\n",
      "\n",
      "\tTweet's text':  thi kid right make happi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['heavy_black_heart'] \n",
      "\n",
      "\tTweet's hashtags':  ['#nephew'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'kid', 'right', 'make', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi kid right make happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1448 :\n",
      "\n",
      "\tTweet's text':  if love wanna love you pollut room filthi tongu \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#getscared'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'love', 'wan', 'na', 'love', 'you', 'pollut', 'room', 'filthi', 'tongu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if love wanna love you pollut room filthi tongu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1449 :\n",
      "\n",
      "\tTweet's text':  yeah thank \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1450 :\n",
      "\n",
      "\tTweet's text':  stop tri make post locat twitter i want post locat stop \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stop', 'tri', 'make', 'post', 'locat', 'twitter', 'i', 'want', 'post', 'locat', 'stop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stop tri make post locat twitter i want post locat stop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1451 :\n",
      "\n",
      "\tTweet's text':  just seen result what \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#saintsfc'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'seen', 'result', 'what'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just seen result what'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1452 :\n",
      "\n",
      "\tTweet's text':  get updat basant rai \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'updat', 'basant', 'rai'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get updat basant rai'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1453 :\n",
      "\n",
      "\tTweet's text':  ya welcom hunni \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ya', 'welcom', 'hunni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ya welcom hunni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1454 :\n",
      "\n",
      "\tTweet's text':  good thing day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'thing', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good thing day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1455 :\n",
      "\n",
      "\tTweet's text':  ye i want honor someon die i go steal tv xbox whatev els i feel entitl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'i', 'want', 'honor', 'someon', 'die', 'i', 'go', 'steal', 'tv', 'xbox', 'whatev', 'els', 'i', 'feel', 'entitl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye i want honor someon die i go steal tv xbox whatev els i feel entitl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1456 :\n",
      "\n",
      "\tTweet's text':  long gold layer pipe necklac set leav email invoic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['long', 'gold', 'layer', 'pipe', 'necklac', 'set', 'leav', 'email', 'invoic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['long gold layer pipe necklac set leav email invoic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1457 :\n",
      "\n",
      "\tTweet's text':  dang selfi game point i drink \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#actuallysorry'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dang', 'selfi', 'game', 'point', 'i', 'drink'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dang selfi game point i drink'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1458 :\n",
      "\n",
      "\tTweet's text':  lot laugh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lot', 'laugh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lot laugh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1459 :\n",
      "\n",
      "\tTweet's text':  so three geek bring whole microsoft soni \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'three', 'geek', 'bring', 'whole', 'microsoft', 'soni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so three geek bring whole microsoft soni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1460 :\n",
      "\n",
      "\tTweet's text':  good news thank husband insur premium jump one year hooray \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ACA', '#ThanksObama'] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'news', 'thank', 'husband', 'insur', 'premium', 'jump', 'one', 'year', 'hooray'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good news thank husband insur premium jump one year hooray'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1461 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1462 :\n",
      "\n",
      "\tTweet's text':  i text now i go sleep ignor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'text', 'now', 'i', 'go', 'sleep', 'ignor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i text now i go sleep ignor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1463 :\n",
      "\n",
      "\tTweet's text':  noth better class \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['noth', 'better', 'class'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noth better class'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1464 :\n",
      "\n",
      "\tTweet's text':  more \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Net', '#neutrality', '#Cisco', '#Intel', '#IBM', '#warn', '#FCC', '#to', '#crack', '#down', '#on', '#ISPs', '#technology'] \n",
      "\n",
      "\tTweet tokenized by words:  ['more'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['more'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1465 :\n",
      "\n",
      "\tTweet's text':  cluck rt most transpar administr ever send password protect document oversight \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Gruber'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cluck', 'rt', 'most', 'transpar', 'administr', 'ever', 'send', 'password', 'protect', 'document', 'oversight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cluck rt most transpar administr ever send password protect document oversight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1466 :\n",
      "\n",
      "\tTweet's text':  sometim forget feel rememb deserv \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sometim', 'forget', 'feel', 'rememb', 'deserv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sometim forget feel rememb deserv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1467 :\n",
      "\n",
      "\tTweet's text':  work super earli friday weakest pure treat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tired', '#stormageddon', '#ArrowMidSeasonFinale'] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'super', 'earli', 'friday', 'weakest', 'pure', 'treat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work super earli friday weakest pure treat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1468 :\n",
      "\n",
      "\tTweet's text':  i like peopl freak hear i still get paid i week join militari duh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'like', 'peopl', 'freak', 'hear', 'i', 'still', 'get', 'paid', 'i', 'week', 'join', 'militari', 'duh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i like peopl freak hear i still get paid i week join militari duh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1469 :\n",
      "\n",
      "\tTweet's text':  so fave tweet what reaction \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'fave', 'tweet', 'what', 'reaction'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so fave tweet what reaction'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1470 :\n",
      "\n",
      "\tTweet's text':  miss u i leav th \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['weary_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['miss', 'u', 'i', 'leav', 'th'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['miss u i leav th'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1471 :\n",
      "\n",
      "\tTweet's text':  went fade orang mess dark brown red streak i cours forgot take pictur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['went', 'fade', 'orang', 'mess', 'dark', 'brown', 'red', 'streak', 'i', 'cours', 'forgot', 'take', 'pictur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['went fade orang mess dark brown red streak i cours forgot take pictur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1472 :\n",
      "\n",
      "\tTweet's text':  concern \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MY', '#Husband', '#StopTxtnHim', '#NotOk', '#youknowwhoyouare'] \n",
      "\n",
      "\tTweet tokenized by words:  ['concern'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['concern'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1473 :\n",
      "\n",
      "\tTweet's text':  you hope film like would lose relev coupl decad nope \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'hope', 'film', 'like', 'would', 'lose', 'relev', 'coupl', 'decad', 'nope'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you hope film like would lose relev coupl decad nope'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1474 :\n",
      "\n",
      "\tTweet's text':  noth like wake sweet sound cat tri chew shoelac husband new boot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['noth', 'like', 'wake', 'sweet', 'sound', 'cat', 'tri', 'chew', 'shoelac', 'husband', 'new', 'boot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noth like wake sweet sound cat tri chew shoelac husband new boot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1475 :\n",
      "\n",
      "\tTweet's text':  each snooz button tempt last \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['squared_sos', 'sleeping_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['each', 'snooz', 'button', 'tempt', 'last'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['each snooz button tempt last'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1476 :\n",
      "\n",
      "\tTweet's text':  fuck mood \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fuck', 'mood'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fuck mood'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1477 :\n",
      "\n",
      "\tTweet's text':  coin watcheronawal anyon els find sad remind conserv republican tortur wrong \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TortureReport'] \n",
      "\n",
      "\tTweet tokenized by words:  ['coin', 'watcheronawal', 'anyon', 'els', 'find', 'sad', 'remind', 'conserv', 'republican', 'tortur', 'wrong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['coin watcheronawal anyon els find sad remind conserv republican tortur wrong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1478 :\n",
      "\n",
      "\tTweet's text':  tamir rice memori today hi famili plan see grow not gun polic polic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tamir', 'rice', 'memori', 'today', 'hi', 'famili', 'plan', 'see', 'grow', 'not', 'gun', 'polic', 'polic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tamir rice memori today hi famili plan see grow not gun polic polic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1479 :\n",
      "\n",
      "\tTweet's text':  eat sweet pe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['eat', 'sweet', 'pe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['eat sweet pe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1480 :\n",
      "\n",
      "\tTweet's text':  no need act like i fav child i know alreadi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'need', 'act', 'like', 'i', 'fav', 'child', 'i', 'know', 'alreadi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no need act like i fav child i know alreadi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1481 :\n",
      "\n",
      "\tTweet's text':  funni broken one im one need save \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['funni', 'broken', 'one', 'im', 'one', 'need', 'save'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['funni broken one im one need save'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1482 :\n",
      "\n",
      "\tTweet's text':  babi cap teeth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#negative'] \n",
      "\n",
      "\tTweet tokenized by words:  ['babi', 'cap', 'teeth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['babi cap teeth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1483 :\n",
      "\n",
      "\tTweet's text':  i come ridicul scenario head \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['thought_balloon'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'come', 'ridicul', 'scenario', 'head'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i come ridicul scenario head'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1484 :\n",
      "\n",
      "\tTweet's text':  love i still kid still wake earli christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#justkiddingIlovethem'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'i', 'still', 'kid', 'still', 'wake', 'earli', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love i still kid still wake earli christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1485 :\n",
      "\n",
      "\tTweet's text':  okay trade better get darn good packag better divis \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['okay', 'trade', 'better', 'get', 'darn', 'good', 'packag', 'better', 'divis'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['okay trade better get darn good packag better divis'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1486 :\n",
      "\n",
      "\tTweet's text':  my com professor keep talk twitter lel \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'com', 'professor', 'keep', 'talk', 'twitter', 'lel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my com professor keep talk twitter lel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1487 :\n",
      "\n",
      "\tTweet's text':  oh i love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'i', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh i love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1488 :\n",
      "\n",
      "\tTweet's text':  friski that noth new \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['friski', 'that', 'noth', 'new'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['friski that noth new'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1489 :\n",
      "\n",
      "\tTweet's text':  love buse everi half hour \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'buse', 'everi', 'half', 'hour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love buse everi half hour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1490 :\n",
      "\n",
      "\tTweet's text':  all reason competit breed innov consum win \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['all', 'reason', 'competit', 'breed', 'innov', 'consum', 'win'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['all reason competit breed innov consum win'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1491 :\n",
      "\n",
      "\tTweet's text':  size small christma sweater cardi basic edit holiday vintag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['size', 'small', 'christma', 'sweater', 'cardi', 'basic', 'edit', 'holiday', 'vintag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['size small christma sweater cardi basic edit holiday vintag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1492 :\n",
      "\n",
      "\tTweet's text':  i love test patienc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['white_smiling_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'test', 'patienc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love test patienc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1493 :\n",
      "\n",
      "\tTweet's text':  welcom twitter n r ur servic ur twitter coach \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['welcom', 'twitter', 'n', 'r', 'ur', 'servic', 'ur', 'twitter', 'coach'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['welcom twitter n r ur servic ur twitter coach'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1494 :\n",
      "\n",
      "\tTweet's text':  napalm hotw love show real \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ThingsBetterThanTitansJags', '#bigjoefavorite', '#keep'] \n",
      "\n",
      "\tTweet tokenized by words:  ['napalm', 'hotw', 'love', 'show', 'real'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['napalm hotw love show real'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1495 :\n",
      "\n",
      "\tTweet's text':  sometim i make funni comment \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#boyfriend', '#text', '#justgothomefromdinner', '#smiles', '#funny', '#lovehim'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sometim', 'i', 'make', 'funni', 'comment'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sometim i make funni comment'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1496 :\n",
      "\n",
      "\tTweet's text':  dayum i realli got hous brother still school week \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_sunglasses'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dayum', 'i', 'realli', 'got', 'hous', 'brother', 'still', 'school', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dayum i realli got hous brother still school week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1497 :\n",
      "\n",
      "\tTweet's text':  bad idea \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bad', 'idea'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bad idea'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1498 :\n",
      "\n",
      "\tTweet's text':  you know send present friend live far away never get handmad stuff yay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'know', 'send', 'present', 'friend', 'live', 'far', 'away', 'never', 'get', 'handmad', 'stuff', 'yay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you know send present friend live far away never get handmad stuff yay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1499 :\n",
      "\n",
      "\tTweet's text':  i use joke around cat abl open door never expect happen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'use', 'joke', 'around', 'cat', 'abl', 'open', 'door', 'never', 'expect', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i use joke around cat abl open door never expect happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1500 :\n",
      "\n",
      "\tTweet's text':  we buy liber individu see individu fate black peopl way link collect fate bell hook \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ferguson'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'buy', 'liber', 'individu', 'see', 'individu', 'fate', 'black', 'peopl', 'way', 'link', 'collect', 'fate', 'bell', 'hook'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we buy liber individu see individu fate black peopl way link collect fate bell hook'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1501 :\n",
      "\n",
      "\tTweet's text':  draw draw go lose pell bench fantasi fuck shit night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['draw', 'draw', 'go', 'lose', 'pell', 'bench', 'fantasi', 'fuck', 'shit', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['draw draw go lose pell bench fantasi fuck shit night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1502 :\n",
      "\n",
      "\tTweet's text':  half world suffer obes half die famin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['half', 'world', 'suffer', 'obes', 'half', 'die', 'famin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['half world suffer obes half die famin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1503 :\n",
      "\n",
      "\tTweet's text':  i got meet real csi tonight littl jerk broke offic cool \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cool'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'got', 'meet', 'real', 'csi', 'tonight', 'littl', 'jerk', 'broke', 'offic', 'cool'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i got meet real csi tonight littl jerk broke offic cool'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1504 :\n",
      "\n",
      "\tTweet's text':  if twitter account sign book look must read id rather read twilight \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'twitter', 'account', 'sign', 'book', 'look', 'must', 'read', 'id', 'rather', 'read', 'twilight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if twitter account sign book look must read id rather read twilight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1505 :\n",
      "\n",
      "\tTweet's text':  uk pm make sure child abus brought justic i assum peopl brought justic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lies'] \n",
      "\n",
      "\tTweet tokenized by words:  ['uk', 'pm', 'make', 'sure', 'child', 'abus', 'brought', 'justic', 'i', 'assum', 'peopl', 'brought', 'justic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['uk pm make sure child abus brought justic i assum peopl brought justic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1506 :\n",
      "\n",
      "\tTweet's text':  balak balaam come curs peopl curs curs \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['balak', 'balaam', 'come', 'curs', 'peopl', 'curs', 'curs'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['balak balaam come curs peopl curs curs'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1507 :\n",
      "\n",
      "\tTweet's text':  guru newbi everyon get you need see right now \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['guru', 'newbi', 'everyon', 'get', 'you', 'need', 'see', 'right', 'now'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['guru newbi everyon get you need see right now'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1508 :\n",
      "\n",
      "\tTweet's text':  mental calcul realiz chanc pass modul slim none fantast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mental', 'calcul', 'realiz', 'chanc', 'pass', 'modul', 'slim', 'none', 'fantast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mental calcul realiz chanc pass modul slim none fantast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1509 :\n",
      "\n",
      "\tTweet's text':  ti season unwant gift \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ti', 'season', 'unwant', 'gift'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ti season unwant gift'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1510 :\n",
      "\n",
      "\tTweet's text':  my futur i still enjoy play footbal much i play passion t \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#asroma'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'futur', 'i', 'still', 'enjoy', 'play', 'footbal', 'much', 'i', 'play', 'passion', 't'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my futur i still enjoy play footbal much i play passion t'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1511 :\n",
      "\n",
      "\tTweet's text':  awh i love repli get feel type way \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#noreplies', '#StoryOfMyLife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['awh', 'i', 'love', 'repli', 'get', 'feel', 'type', 'way'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['awh i love repli get feel type way'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1512 :\n",
      "\n",
      "\tTweet's text':  there alway one friend motiv make feel better el amdellah la wjoodch fe ayati yaa dctortna el jameela \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'alway', 'one', 'friend', 'motiv', 'make', 'feel', 'better', 'el', 'amdellah', 'la', 'wjoodch', 'fe', 'ayati', 'yaa', 'dctortna', 'el', 'jameela'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there alway one friend motiv make feel better el amdellah la wjoodch fe ayati yaa dctortna el jameela'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1513 :\n",
      "\n",
      "\tTweet's text':  ok thank one question comput scientist take salari comput commun engin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ok', 'thank', 'one', 'question', 'comput', 'scientist', 'take', 'salari', 'comput', 'commun', 'engin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ok thank one question comput scientist take salari comput commun engin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1514 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1515 :\n",
      "\n",
      "\tTweet's text':  huge congrat sign couldn happier fam how view everest originalpatneshekfanclubmemb \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OriginalPatNeshekFanClubMember'] \n",
      "\n",
      "\tTweet tokenized by words:  ['huge', 'congrat', 'sign', 'couldn', 'happier', 'fam', 'how', 'view', 'everest', 'originalpatneshekfanclubmemb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['huge congrat sign couldn happier fam how view everest originalpatneshekfanclubmemb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1516 :\n",
      "\n",
      "\tTweet's text':  pleas dont fuck i first wake morn person \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pleas', 'dont', 'fuck', 'i', 'first', 'wake', 'morn', 'person'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pleas dont fuck i first wake morn person'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1517 :\n",
      "\n",
      "\tTweet's text':  are allow touch kneecap like \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#questionable', '#NOA', '#onuchapel'] \n",
      "\n",
      "\tTweet tokenized by words:  ['are', 'allow', 'touch', 'kneecap', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['are allow touch kneecap like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1518 :\n",
      "\n",
      "\tTweet's text':  produc kind creativ design \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hypebeast'] \n",
      "\n",
      "\tTweet tokenized by words:  ['produc', 'kind', 'creativ', 'design'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['produc kind creativ design'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1519 :\n",
      "\n",
      "\tTweet's text':  i see i search \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#catfish', '#fishsitter', '#goldfish', '#LoveLife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'see', 'i', 'search'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i see i search'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1520 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#page', '#found', '#404'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1521 :\n",
      "\n",
      "\tTweet's text':  know would make break x time better practic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'would', 'make', 'break', 'x', 'time', 'better', 'practic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know would make break x time better practic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1522 :\n",
      "\n",
      "\tTweet's text':  sec bia right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sec', 'bia', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sec bia right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1523 :\n",
      "\n",
      "\tTweet's text':  it \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#If', '#careful', '#literacy', '#will', '#become', '#a', '#historical', '#blip'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1524 :\n",
      "\n",
      "\tTweet's text':  hikethegam playstat everyth is awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hikethegam', 'playstat', 'everyth', 'is', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hikethegam playstat everyth is awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1525 :\n",
      "\n",
      "\tTweet's text':  haha cannot wait monday best cheer \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'can', 'not', 'wait', 'monday', 'best', 'cheer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha cannot wait monday best cheer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1526 :\n",
      "\n",
      "\tTweet's text':  peopl look upon one come defens thi race rape \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BillCosby'] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'look', 'upon', 'one', 'come', 'defens', 'thi', 'race', 'rape'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl look upon one come defens thi race rape'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1527 :\n",
      "\n",
      "\tTweet's text':  i good \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1528 :\n",
      "\n",
      "\tTweet's text':  just yell \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#someone', '#telling', '#something', '#youre', '#mum', '#mistake'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'yell'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just yell'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1529 :\n",
      "\n",
      "\tTweet's text':  also top lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['also', 'top', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['also top lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1530 :\n",
      "\n",
      "\tTweet's text':  chanc till januari good alway make smile \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#chance', '#till', '#January', '#this', '#you', '#smile'] \n",
      "\n",
      "\tTweet tokenized by words:  ['chanc', 'till', 'januari', 'good', 'alway', 'make', 'smile'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['chanc till januari good alway make smile'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1531 :\n",
      "\n",
      "\tTweet's text':  convey i want though \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#twitterproblemsforme'] \n",
      "\n",
      "\tTweet tokenized by words:  ['convey', 'i', 'want', 'though'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['convey i want though'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1532 :\n",
      "\n",
      "\tTweet's text':  it hard take peopl serious spell think grammar type cracker \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'hard', 'take', 'peopl', 'serious', 'spell', 'think', 'grammar', 'type', 'cracker'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it hard take peopl serious spell think grammar type cracker'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1533 :\n",
      "\n",
      "\tTweet's text':  what ironi the polic divid us the terrorist unit us \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Terrorism', '#PoliceBrutality'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'ironi', 'the', 'polic', 'divid', 'us', 'the', 'terrorist', 'unit', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what ironi the polic divid us the terrorist unit us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1534 :\n",
      "\n",
      "\tTweet's text':  tamir know mike brown rais hand shot dead he want cop see bb gun still shot dead \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tamir', 'know', 'mike', 'brown', 'rais', 'hand', 'shot', 'dead', 'he', 'want', 'cop', 'see', 'bb', 'gun', 'still', 'shot', 'dead'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tamir know mike brown rais hand shot dead he want cop see bb gun still shot dead'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1535 :\n",
      "\n",
      "\tTweet's text':  give chanc win pass follow detail superdaylineup \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoSupersonic', '#Goa', '#SuperDayLineup'] \n",
      "\n",
      "\tTweet tokenized by words:  ['give', 'chanc', 'win', 'pass', 'follow', 'detail', 'superdaylineup'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['give chanc win pass follow detail superdaylineup'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1536 :\n",
      "\n",
      "\tTweet's text':  let put bet whoever would take action think oliva howsam easi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'put', 'bet', 'whoever', 'would', 'take', 'action', 'think', 'oliva', 'howsam', 'easi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let put bet whoever would take action think oliva howsam easi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1537 :\n",
      "\n",
      "\tTweet's text':  no pa n no ga n fit no \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['flexed_biceps', 'fisted_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Fit', '#Fitness', '#gym', '#No', '#Give', '#Up'] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'pa', 'n', 'no', 'ga', 'n', 'fit', 'no'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no pa n no ga n fit no'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1538 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BBC', '#News', '#Denmark', '#challenges', '#Russia', '#Canada', '#over', '#North', '#Pole'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1539 :\n",
      "\n",
      "\tTweet's text':  first visit comment section \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['first', 'visit', 'comment', 'section'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['first visit comment section'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1540 :\n",
      "\n",
      "\tTweet's text':  i shun workplac chit chat look happen twitter \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#randomtweet'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'shun', 'workplac', 'chit', 'chat', 'look', 'happen', 'twitter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i shun workplac chit chat look happen twitter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1541 :\n",
      "\n",
      "\tTweet's text':  shoe make done i readi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shoe', 'make', 'done', 'i', 'readi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shoe make done i readi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1542 :\n",
      "\n",
      "\tTweet's text':  love watch enjoy ta \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#latenightfilms', '#MockingjayPart1', '#didsbury', '#Grateful', '#goodfriend'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'watch', 'enjoy', 'ta'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love watch enjoy ta'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1543 :\n",
      "\n",
      "\tTweet's text':  steve steve steve that data you never win heart mind appeal poor polar bear \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['steve', 'steve', 'steve', 'that', 'data', 'you', 'never', 'win', 'heart', 'mind', 'appeal', 'poor', 'polar', 'bear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['steve steve steve that data you never win heart mind appeal poor polar bear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1544 :\n",
      "\n",
      "\tTweet's text':  glad i bought diesel car year ago \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['glad', 'i', 'bought', 'diesel', 'car', 'year', 'ago'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['glad i bought diesel car year ago'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1545 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ninja', '#KO'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1546 :\n",
      "\n",
      "\tTweet's text':  like group unsuccess idiot even manag scroung quarter that pretti cool i guess chri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['like', 'group', 'unsuccess', 'idiot', 'even', 'manag', 'scroung', 'quarter', 'that', 'pretti', 'cool', 'i', 'guess', 'chri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['like group unsuccess idiot even manag scroung quarter that pretti cool i guess chri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1547 :\n",
      "\n",
      "\tTweet's text':  i wait jump bed tonight sleep \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sotired'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wait', 'jump', 'bed', 'tonight', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wait jump bed tonight sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1548 :\n",
      "\n",
      "\tTweet's text':  next person want educ point pleas bloodi educ speak get bore \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['next', 'person', 'want', 'educ', 'point', 'pleas', 'bloodi', 'educ', 'speak', 'get', 'bore'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['next person want educ point pleas bloodi educ speak get bore'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1549 :\n",
      "\n",
      "\tTweet's text':  sat yet anoth stationari train minut explan driver your servic top drawer \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sat', 'yet', 'anoth', 'stationari', 'train', 'minut', 'explan', 'driver', 'your', 'servic', 'top', 'drawer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sat yet anoth stationari train minut explan driver your servic top drawer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1550 :\n",
      "\n",
      "\tTweet's text':  u simpli cant win twitter fight p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['u', 'simpli', 'cant', 'win', 'twitter', 'fight', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['u simpli cant win twitter fight p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1551 :\n",
      "\n",
      "\tTweet's text':  ohhhh yeaah girl favorit coupl want come hang lol bruh wtf lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ohhhh', 'yeaah', 'girl', 'favorit', 'coupl', 'want', 'come', 'hang', 'lol', 'bruh', 'wtf', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ohhhh yeaah girl favorit coupl want come hang lol bruh wtf lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1552 :\n",
      "\n",
      "\tTweet's text':  proof lack read comprehens skill \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['proof', 'lack', 'read', 'comprehens', 'skill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['proof lack read comprehens skill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1553 :\n",
      "\n",
      "\tTweet's text':  mmmm rt fave if southampton win i post nude \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mmmm', 'rt', 'fave', 'if', 'southampton', 'win', 'i', 'post', 'nude'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mmmm rt fave if southampton win i post nude'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1554 :\n",
      "\n",
      "\tTweet's text':  you know wrong \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EUVAT'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'know', 'wrong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you know wrong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1555 :\n",
      "\n",
      "\tTweet's text':  agre it cool place and i love rock \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['agre', 'it', 'cool', 'place', 'and', 'i', 'love', 'rock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['agre it cool place and i love rock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1556 :\n",
      "\n",
      "\tTweet's text':  thank retweet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TopForm'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'retweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank retweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1557 :\n",
      "\n",
      "\tTweet's text':  anymor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['persevering_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['anymor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anymor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1558 :\n",
      "\n",
      "\tTweet's text':  grown women act like children favorit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dramatic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['grown', 'women', 'act', 'like', 'children', 'favorit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['grown women act like children favorit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1559 :\n",
      "\n",
      "\tTweet's text':  come conclus appl is skynet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#terminator', '#apocalypseiscoming', '#warofthemachines'] \n",
      "\n",
      "\tTweet tokenized by words:  ['come', 'conclus', 'appl', 'is', 'skynet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['come conclus appl is skynet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1560 :\n",
      "\n",
      "\tTweet's text':  work hard right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'hard', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work hard right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1561 :\n",
      "\n",
      "\tTweet's text':  interest stat po good the bad appl ruin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tcot', '#Ferguson', '#EricGarner'] \n",
      "\n",
      "\tTweet tokenized by words:  ['interest', 'stat', 'po', 'good', 'the', 'bad', 'appl', 'ruin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['interest stat po good the bad appl ruin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1562 :\n",
      "\n",
      "\tTweet's text':  that much nicer idea actual \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'much', 'nicer', 'idea', 'actual'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that much nicer idea actual'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1563 :\n",
      "\n",
      "\tTweet's text':  she show you \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['she', 'show', 'you'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['she show you'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1564 :\n",
      "\n",
      "\tTweet's text':  i like video style by dani \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'like', 'video', 'style', 'by', 'dani'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i like video style by dani'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1565 :\n",
      "\n",
      "\tTweet's text':  husband come home earli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mongkok', '#kowloon', '#hongkong', '#dongiotravels', '#50thfloor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['husband', 'come', 'home', 'earli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['husband come home earli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1566 :\n",
      "\n",
      "\tTweet's text':  illridewithy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['illridewithy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['illridewithy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1567 :\n",
      "\n",
      "\tTweet's text':  thi team covington ky pretti much suck \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#gosteelers'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'team', 'covington', 'ky', 'pretti', 'much', 'suck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi team covington ky pretti much suck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1568 :\n",
      "\n",
      "\tTweet's text':  song day the light buzz jack mannequin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['song', 'day', 'the', 'light', 'buzz', 'jack', 'mannequin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['song day the light buzz jack mannequin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1569 :\n",
      "\n",
      "\tTweet's text':  readi conquer day face stuck tongu wink eye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#leavemealonemom', '#my2fave', '#bahhumbug'] \n",
      "\n",
      "\tTweet tokenized by words:  ['readi', 'conquer', 'day', 'face', 'stuck', 'tongu', 'wink', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['readi conquer day face stuck tongu wink eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1570 :\n",
      "\n",
      "\tTweet's text':  ml transact tfc make wave b fair take player fix \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MLS', '#TFC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ml', 'transact', 'tfc', 'make', 'wave', 'b', 'fair', 'take', 'player', 'fix'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ml transact tfc make wave b fair take player fix'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1571 :\n",
      "\n",
      "\tTweet's text':  bush govt prosecut geneva convent tortur cia method vp admiss expos \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bush', 'govt', 'prosecut', 'geneva', 'convent', 'tortur', 'cia', 'method', 'vp', 'admiss', 'expos'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bush govt prosecut geneva convent tortur cia method vp admiss expos'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1572 :\n",
      "\n",
      "\tTweet's text':  just got email law school say peopl infring copyright referenc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'got', 'email', 'law', 'school', 'say', 'peopl', 'infring', 'copyright', 'referenc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just got email law school say peopl infring copyright referenc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1573 :\n",
      "\n",
      "\tTweet's text':  be mom tonight refresh real tbt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'mom', 'tonight', 'refresh', 'real', 'tbt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be mom tonight refresh real tbt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1574 :\n",
      "\n",
      "\tTweet's text':  mean ha squar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mean', 'ha', 'squar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mean ha squar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1575 :\n",
      "\n",
      "\tTweet's text':  the bold bakeri sarah brockett \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bakery'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'bold', 'bakeri', 'sarah', 'brockett'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the bold bakeri sarah brockett'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1576 :\n",
      "\n",
      "\tTweet's text':  maldiv water yet experienc water shortag \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['maldiv', 'water', 'yet', 'experienc', 'water', 'shortag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['maldiv water yet experienc water shortag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1577 :\n",
      "\n",
      "\tTweet's text':  get night heli shot \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nh', '#skiing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'night', 'heli', 'shot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get night heli shot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1578 :\n",
      "\n",
      "\tTweet's text':  my ex husband autopsi report coron took age seem slow machin process \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'ex', 'husband', 'autopsi', 'report', 'coron', 'took', 'age', 'seem', 'slow', 'machin', 'process'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my ex husband autopsi report coron took age seem slow machin process'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1579 :\n",
      "\n",
      "\tTweet's text':  sometim i wonder i mous i experiment \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sometim', 'i', 'wonder', 'i', 'mous', 'i', 'experiment'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sometim i wonder i mous i experiment'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1580 :\n",
      "\n",
      "\tTweet's text':  rush take which christma cooki i person test \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rush', 'take', 'which', 'christma', 'cooki', 'i', 'person', 'test'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rush take which christma cooki i person test'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1581 :\n",
      "\n",
      "\tTweet's text':  fun night girl it may look like eat dessert show \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fun', 'night', 'girl', 'it', 'may', 'look', 'like', 'eat', 'dessert', 'show'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fun night girl it may look like eat dessert show'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1582 :\n",
      "\n",
      "\tTweet's text':  break news rt mario balotelli team player accord adel taarabt \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['break', 'news', 'rt', 'mario', 'balotelli', 'team', 'player', 'accord', 'adel', 'taarabt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['break news rt mario balotelli team player accord adel taarabt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1583 :\n",
      "\n",
      "\tTweet's text':  isn point learn craft realiti what i miss should differ \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wat'] \n",
      "\n",
      "\tTweet tokenized by words:  ['isn', 'point', 'learn', 'craft', 'realiti', 'what', 'i', 'miss', 'should', 'differ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['isn point learn craft realiti what i miss should differ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1584 :\n",
      "\n",
      "\tTweet's text':  zozeebo the stuff press write liter ridicul would harsh point lack literaci \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ghostwriter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['zozeebo', 'the', 'stuff', 'press', 'write', 'liter', 'ridicul', 'would', 'harsh', 'point', 'lack', 'literaci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['zozeebo the stuff press write liter ridicul would harsh point lack literaci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1585 :\n",
      "\n",
      "\tTweet's text':  it yr sinc west industri revolut st cent ghana industri de revolut happen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'yr', 'sinc', 'west', 'industri', 'revolut', 'st', 'cent', 'ghana', 'industri', 'de', 'revolut', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it yr sinc west industri revolut st cent ghana industri de revolut happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1586 :\n",
      "\n",
      "\tTweet's text':  origin content hard come anonym \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#writingtips', '#quoteoftheday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['origin', 'content', 'hard', 'come', 'anonym'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['origin content hard come anonym'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1587 :\n",
      "\n",
      "\tTweet's text':  law way lawmak whould av gone gain entranc break law kind \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['law', 'way', 'lawmak', 'whould', 'av', 'gone', 'gain', 'entranc', 'break', 'law', 'kind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['law way lawmak whould av gone gain entranc break law kind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1588 :\n",
      "\n",
      "\tTweet's text':  congrat cute \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['congrat', 'cute'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['congrat cute'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1589 :\n",
      "\n",
      "\tTweet's text':  i guess i eat leftov breakfast again other get black bear \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign', 'unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#cuzididntwantgoodfood', '#truth', '#hungry'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'i', 'eat', 'leftov', 'breakfast', 'again', 'other', 'get', 'black', 'bear'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by sentences:  ['i guess i eat leftov breakfast again other get black bear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1590 :\n",
      "\n",
      "\tTweet's text':  peopl beauti look \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#people', '#beautiful', '#look', '#walk', '#talk', '#personality', '#love', '#care', '#share'] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'beauti', 'look'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl beauti look'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1591 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Laundrymatfun', '#LOL', '#YesIsaidNOT', '#spincycle', '#youspinmeround', '#recordplayer', '#thatsmykid', '#80smusic', '#teachingth'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1592 :\n",
      "\n",
      "\tTweet's text':  connacht camogi champion year row hon hrc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['trophy', 'baseball', 'person_raising_both_hands_in_celebration', 'smiling_face_with_open_mouth_and_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  ['#MountbellewIsAHurlingStronghold', '#HolyRosary4life', '#SeniorB'] \n",
      "\n",
      "\tTweet tokenized by words:  ['connacht', 'camogi', 'champion', 'year', 'row', 'hon', 'hrc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['connacht camogi champion year row hon hrc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1593 :\n",
      "\n",
      "\tTweet's text':  go rec tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#beingproductive'] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'rec', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go rec tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1594 :\n",
      "\n",
      "\tTweet's text':  but someon sell pack cigarett get death penalti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EricGarner'] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'someon', 'sell', 'pack', 'cigarett', 'get', 'death', 'penalti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but someon sell pack cigarett get death penalti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1595 :\n",
      "\n",
      "\tTweet's text':  rememb pre spoke great america strong peopl work togeth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rememb', 'pre', 'spoke', 'great', 'america', 'strong', 'peopl', 'work', 'togeth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rememb pre spoke great america strong peopl work togeth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1596 :\n",
      "\n",
      "\tTweet's text':  off bed wait feel hangov \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['off', 'bed', 'wait', 'feel', 'hangov'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['off bed wait feel hangov'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1597 :\n",
      "\n",
      "\tTweet's text':  america releas cuban spi get cuba releas american spi caught cuban spi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['america', 'releas', 'cuban', 'spi', 'get', 'cuba', 'releas', 'american', 'spi', 'caught', 'cuban', 'spi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['america releas cuban spi get cuba releas american spi caught cuban spi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1598 :\n",
      "\n",
      "\tTweet's text':  whi i hear chicken thi fulham god sake \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'i', 'hear', 'chicken', 'thi', 'fulham', 'god', 'sake'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi i hear chicken thi fulham god sake'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1599 :\n",
      "\n",
      "\tTweet's text':  day two \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'two'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day two'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1600 :\n",
      "\n",
      "\tTweet's text':  need becom part the religion piec my heart goe victim \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Daesh', '#Taliban', '#PeshawarAttack'] \n",
      "\n",
      "\tTweet tokenized by words:  ['need', 'becom', 'part', 'the', 'religion', 'piec', 'my', 'heart', 'goe', 'victim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['need becom part the religion piec my heart goe victim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1601 :\n",
      "\n",
      "\tTweet's text':  cock hungri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TeensAnalyzed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cock', 'hungri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cock hungri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1602 :\n",
      "\n",
      "\tTweet's text':  gotta studi i like care \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_down_sign'] \n",
      "\n",
      "\tTweet's hashtags':  ['#perksofbeingasenior'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'studi', 'i', 'like', 'care'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta studi i like care'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1603 :\n",
      "\n",
      "\tTweet's text':  stephenfri oooh bust superior understand crestfallen shame \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stephenfri', 'oooh', 'bust', 'superior', 'understand', 'crestfallen', 'shame'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stephenfri oooh bust superior understand crestfallen shame'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1604 :\n",
      "\n",
      "\tTweet's text':  i deff miss mom yell stair chanel wake jk love u cuz prob see \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lmao', '#stfu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'deff', 'miss', 'mom', 'yell', 'stair', 'chanel', 'wake', 'jk', 'love', 'u', 'cuz', 'prob', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i deff miss mom yell stair chanel wake jk love u cuz prob see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1605 :\n",
      "\n",
      "\tTweet's text':  seri a is real \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['seri', 'a', 'is', 'real'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['seri a is real'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1606 :\n",
      "\n",
      "\tTweet's text':  a year ago cat hit today great quot \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'year', 'ago', 'cat', 'hit', 'today', 'great', 'quot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a year ago cat hit today great quot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1607 :\n",
      "\n",
      "\tTweet's text':  time continu clean closet happi happi joy joy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'continu', 'clean', 'closet', 'happi', 'happi', 'joy', 'joy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time continu clean closet happi happi joy joy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1608 :\n",
      "\n",
      "\tTweet's text':  see aday followm followngain teamtofollow teamfollowback retweet gain follow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#1000ADAY', '#FOLLOWME', '#FOLLOWNGAIN', '#TEAMTOFOLLOW', '#TEAMFOLLOWBACK'] \n",
      "\n",
      "\tTweet tokenized by words:  ['see', 'aday', 'followm', 'followngain', 'teamtofollow', 'teamfollowback', 'retweet', 'gain', 'follow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['see aday followm followngain teamtofollow teamfollowback retweet gain follow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1609 :\n",
      "\n",
      "\tTweet's text':  fav part abt xma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#kys', '#idontcare'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fav', 'part', 'abt', 'xma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fav part abt xma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1610 :\n",
      "\n",
      "\tTweet's text':  a whole day ns w client yay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'whole', 'day', 'ns', 'w', 'client', 'yay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a whole day ns w client yay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1611 :\n",
      "\n",
      "\tTweet's text':  nice see take time visit poorli fan hospit phil jone \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Alwaysinjured', '#MUFC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'see', 'take', 'time', 'visit', 'poorli', 'fan', 'hospit', 'phil', 'jone'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice see take time visit poorli fan hospit phil jone'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1612 :\n",
      "\n",
      "\tTweet's text':  conselho europeu dezembro click date inform e \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcias', '#eu', '#europ'] \n",
      "\n",
      "\tTweet tokenized by words:  ['conselho', 'europeu', 'dezembro', 'click', 'date', 'inform', 'e'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['conselho europeu dezembro click date inform e'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1613 :\n",
      "\n",
      "\tTweet's text':  it comfort thought everi tax payer b remind ram law answer question tax form \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OCARE'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'comfort', 'thought', 'everi', 'tax', 'payer', 'b', 'remind', 'ram', 'law', 'answer', 'question', 'tax', 'form'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it comfort thought everi tax payer b remind ram law answer question tax form'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1614 :\n",
      "\n",
      "\tTweet's text':  oh noe the night train berlin malm run summer plan long comfort train trip \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'noe', 'the', 'night', 'train', 'berlin', 'malm', 'run', 'summer', 'plan', 'long', 'comfort', 'train', 'trip'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh noe the night train berlin malm run summer plan long comfort train trip'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1615 :\n",
      "\n",
      "\tTweet's text':  gee good thing \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#LRT', '#WarOnWomen'] \n",
      "\n",
      "\tTweet tokenized by words:  ['gee', 'good', 'thing'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gee good thing'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1616 :\n",
      "\n",
      "\tTweet's text':  so let get straight go sign ufc matter wifey said \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HappyMarriage'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'let', 'get', 'straight', 'go', 'sign', 'ufc', 'matter', 'wifey', 'said'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so let get straight go sign ufc matter wifey said'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1617 :\n",
      "\n",
      "\tTweet's text':  doe impli get facebook use crack cocain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['doe', 'impli', 'get', 'facebook', 'use', 'crack', 'cocain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['doe impli get facebook use crack cocain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1618 :\n",
      "\n",
      "\tTweet's text':  respons abil respond to control charg life \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['respons', 'abil', 'respond', 'to', 'control', 'charg', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['respons abil respond to control charg life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1619 :\n",
      "\n",
      "\tTweet's text':  hahahah donna inspir shit great \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hahahah', 'donna', 'inspir', 'shit', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hahahah donna inspir shit great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1620 :\n",
      "\n",
      "\tTweet's text':  morn peopl long know keep work hard \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#monday', '#MakeSussexSafe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['morn', 'peopl', 'long', 'know', 'keep', 'work', 'hard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['morn peopl long know keep work hard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1621 :\n",
      "\n",
      "\tTweet's text':  so \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#LFC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1622 :\n",
      "\n",
      "\tTweet's text':  aaaaaand read big sleep get \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aaaaaand', 'read', 'big', 'sleep', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aaaaaand read big sleep get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1623 :\n",
      "\n",
      "\tTweet's text':  stuck behind someon speed limit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lateforwork', '#fuck', '#happymonday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['stuck', 'behind', 'someon', 'speed', 'limit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stuck behind someon speed limit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1624 :\n",
      "\n",
      "\tTweet's text':  what last pictur took phone pic syresatt vatten ikea bottl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'last', 'pictur', 'took', 'phone', 'pic', 'syresatt', 'vatten', 'ikea', 'bottl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what last pictur took phone pic syresatt vatten ikea bottl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1625 :\n",
      "\n",
      "\tTweet's text':  gotta love friend i hahahah \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nosuchthing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'love', 'friend', 'i', 'hahahah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta love friend i hahahah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1626 :\n",
      "\n",
      "\tTweet's text':  flatteri get everywher taliahaletw \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['flatteri', 'get', 'everywher', 'taliahaletw'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['flatteri get everywher taliahaletw'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1627 :\n",
      "\n",
      "\tTweet's text':  wow i afford holiday i alway want \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'afford', 'holiday', 'i', 'alway', 'want'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i afford holiday i alway want'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1628 :\n",
      "\n",
      "\tTweet's text':  time trip home perfectli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#drenched', '#sydney', '#storm', '#wet'] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'trip', 'home', 'perfectli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time trip home perfectli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1629 :\n",
      "\n",
      "\tTweet's text':  snow cancel vball tournament \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ball', '#is', '#life'] \n",
      "\n",
      "\tTweet tokenized by words:  ['snow', 'cancel', 'vball', 'tournament'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['snow cancel vball tournament'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1630 :\n",
      "\n",
      "\tTweet's text':  thi i respond more movi heterosexu i realli wish would stop shove lifestyl throat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'i', 'respond', 'more', 'movi', 'heterosexu', 'i', 'realli', 'wish', 'would', 'stop', 'shove', 'lifestyl', 'throat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi i respond more movi heterosexu i realli wish would stop shove lifestyl throat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1631 :\n",
      "\n",
      "\tTweet's text':  true definit host confer extremist \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Iran'] \n",
      "\n",
      "\tTweet tokenized by words:  ['true', 'definit', 'host', 'confer', 'extremist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['true definit host confer extremist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1632 :\n",
      "\n",
      "\tTweet's text':  h shea phil taylor v raymond van b \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#DartsWorldChampionship', '#PDC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['h', 'shea', 'phil', 'taylor', 'v', 'raymond', 'van', 'b'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['h shea phil taylor v raymond van b'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1633 :\n",
      "\n",
      "\tTweet's text':  fltness let go workout that jiggl go jiggl away us \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ThingsYouSayToYourBestFriend'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fltness', 'let', 'go', 'workout', 'that', 'jiggl', 'go', 'jiggl', 'away', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fltness let go workout that jiggl go jiggl away us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1634 :\n",
      "\n",
      "\tTweet's text':  said retard nonsens \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['said', 'retard', 'nonsens'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['said retard nonsens'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1635 :\n",
      "\n",
      "\tTweet's text':  hope great year destini pc p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['p'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hope', 'great', 'year', 'destini', 'pc', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hope great year destini pc p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1636 :\n",
      "\n",
      "\tTweet's text':  assur recommend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['assur', 'recommend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['assur recommend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1637 :\n",
      "\n",
      "\tTweet's text':  even \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Hunger', '#has', '#vanished', '#from', '#our', '#affluent', '#overweight', '#society'] \n",
      "\n",
      "\tTweet tokenized by words:  ['even'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['even'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1638 :\n",
      "\n",
      "\tTweet's text':  great christma present unreal alcohol industri lure young peopl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sad', '#nosocialconscience'] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'christma', 'present', 'unreal', 'alcohol', 'industri', 'lure', 'young', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great christma present unreal alcohol industri lure young peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1639 :\n",
      "\n",
      "\tTweet's text':  such great damn day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['such', 'great', 'damn', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['such great damn day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1640 :\n",
      "\n",
      "\tTweet's text':  even bring read \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#rip'] \n",
      "\n",
      "\tTweet tokenized by words:  ['even', 'bring', 'read'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['even bring read'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1641 :\n",
      "\n",
      "\tTweet's text':  you know love author figur book end long wait see author actual end \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'know', 'love', 'author', 'figur', 'book', 'end', 'long', 'wait', 'see', 'author', 'actual', 'end'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you know love author figur book end long wait see author actual end'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1642 :\n",
      "\n",
      "\tTweet's text':  father sent buy ingredi co wanna fri noodl rememb everyth els noodl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#somuchwin'] \n",
      "\n",
      "\tTweet tokenized by words:  ['father', 'sent', 'buy', 'ingredi', 'co', 'wan', 'na', 'fri', 'noodl', 'rememb', 'everyth', 'els', 'noodl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['father sent buy ingredi co wanna fri noodl rememb everyth els noodl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1643 :\n",
      "\n",
      "\tTweet's text':  i still love newsroom regardless everyon els think \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'still', 'love', 'newsroom', 'regardless', 'everyon', 'els', 'think'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i still love newsroom regardless everyon els think'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1644 :\n",
      "\n",
      "\tTweet's text':  thi moon pictur like moon made light bulb \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#the', '#moon'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'moon', 'pictur', 'like', 'moon', 'made', 'light', 'bulb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi moon pictur like moon made light bulb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1645 :\n",
      "\n",
      "\tTweet's text':  schmidtstl thank i think i back playoff playoff matchup tacocorp v gronkey punch \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['schmidtstl', 'thank', 'i', 'think', 'i', 'back', 'playoff', 'playoff', 'matchup', 'tacocorp', 'v', 'gronkey', 'punch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['schmidtstl thank i think i back playoff playoff matchup tacocorp v gronkey punch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1646 :\n",
      "\n",
      "\tTweet's text':  oh yeah offici \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#im', '#crazy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'yeah', 'offici'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh yeah offici'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1647 :\n",
      "\n",
      "\tTweet's text':  oh well look like back squar bati bridg thi go go well \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BoldandBeautiful'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'well', 'look', 'like', 'back', 'squar', 'bati', 'bridg', 'thi', 'go', 'go', 'well'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh well look like back squar bati bridg thi go go well'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1648 :\n",
      "\n",
      "\tTweet's text':  antoinerap fuck ho saturnalia nigga \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['antoinerap', 'fuck', 'ho', 'saturnalia', 'nigga'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['antoinerap fuck ho saturnalia nigga'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1649 :\n",
      "\n",
      "\tTweet's text':  ad make statement \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#traditional', '#legit', '#justbecause'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ad', 'make', 'statement'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ad make statement'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1650 :\n",
      "\n",
      "\tTweet's text':  to offic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BlackLivesMatter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['to', 'offic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['to offic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1651 :\n",
      "\n",
      "\tTweet's text':  dad call name often go fight you want fight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smirking_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dad', 'call', 'name', 'often', 'go', 'fight', 'you', 'want', 'fight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dad call name often go fight you want fight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1652 :\n",
      "\n",
      "\tTweet's text':  jlpt tomorrow i feel vagu confid but vagu \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jlpt', 'tomorrow', 'i', 'feel', 'vagu', 'confid', 'but', 'vagu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jlpt tomorrow i feel vagu confid but vagu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1653 :\n",
      "\n",
      "\tTweet's text':  rt spoiler alert haven call expert predict winner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt', 'spoiler', 'alert', 'haven', 'call', 'expert', 'predict', 'winner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt spoiler alert haven call expert predict winner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1654 :\n",
      "\n",
      "\tTweet's text':  in case heard happen \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WingedWarriors'] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'case', 'heard', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in case heard happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1655 :\n",
      "\n",
      "\tTweet's text':  believ shit past day final \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['believ', 'shit', 'past', 'day', 'final'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['believ shit past day final'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1656 :\n",
      "\n",
      "\tTweet's text':  session lavin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#why', '#scary', '#canary', '#sydney', '#australia'] \n",
      "\n",
      "\tTweet tokenized by words:  ['session', 'lavin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['session lavin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1657 :\n",
      "\n",
      "\tTweet's text':  how dare pass legisl forc peopl catch buse rout should life jail \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'dare', 'pass', 'legisl', 'forc', 'peopl', 'catch', 'buse', 'rout', 'should', 'life', 'jail'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how dare pass legisl forc peopl catch buse rout should life jail'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1658 :\n",
      "\n",
      "\tTweet's text':  christma shop take weekend attempt wast time let tri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CantWait'] \n",
      "\n",
      "\tTweet tokenized by words:  ['christma', 'shop', 'take', 'weekend', 'attempt', 'wast', 'time', 'let', 'tri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['christma shop take weekend attempt wast time let tri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1659 :\n",
      "\n",
      "\tTweet's text':  she said nope i get gift \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['she', 'said', 'nope', 'i', 'get', 'gift'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['she said nope i get gift'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1660 :\n",
      "\n",
      "\tTweet's text':  happi birthday boo love great day smile cat face heart shape eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['heavy_black_heart', 'party_popper'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'birthday', 'boo', 'love', 'great', 'day', 'smile', 'cat', 'face', 'heart', 'shape', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi birthday boo love great day smile cat face heart shape eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1661 :\n",
      "\n",
      "\tTweet's text':  nice smile \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'smile'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice smile'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1662 :\n",
      "\n",
      "\tTweet's text':  i glad i sick today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bullcrap'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'glad', 'i', 'sick', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i glad i sick today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1663 :\n",
      "\n",
      "\tTweet's text':  walk fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['walk', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['walk fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1664 :\n",
      "\n",
      "\tTweet's text':  we hold kid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#RUT340'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'hold', 'kid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we hold kid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1665 :\n",
      "\n",
      "\tTweet's text':  there person respons anymor you expect anyon think \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'person', 'respons', 'anymor', 'you', 'expect', 'anyon', 'think'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there person respons anymor you expect anyon think'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1666 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1667 :\n",
      "\n",
      "\tTweet's text':  i hate mind keep drift someon longer matter life \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dislike'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hate', 'mind', 'keep', 'drift', 'someon', 'longer', 'matter', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hate mind keep drift someon longer matter life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1668 :\n",
      "\n",
      "\tTweet's text':  solid leg day felt great hit max can wait squat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['flexed_biceps'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['solid', 'leg', 'day', 'felt', 'great', 'hit', 'max', 'can', 'wait', 'squat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['solid leg day felt great hit max can wait squat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1669 :\n",
      "\n",
      "\tTweet's text':  i love charg comp music \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'charg', 'comp', 'music'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love charg comp music'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1670 :\n",
      "\n",
      "\tTweet's text':  whi babi constantli sick everywher it like u keep food eat ur belli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#on', '#the', '#floor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'babi', 'constantli', 'sick', 'everywher', 'it', 'like', 'u', 'keep', 'food', 'eat', 'ur', 'belli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi babi constantli sick everywher it like u keep food eat ur belli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1671 :\n",
      "\n",
      "\tTweet's text':  hangov \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hangov'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hangov'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1672 :\n",
      "\n",
      "\tTweet's text':  when someon tri play alreadi know game \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#stepoff'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'someon', 'tri', 'play', 'alreadi', 'know', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when someon tri play alreadi know game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1673 :\n",
      "\n",
      "\tTweet's text':  lol imagin gay work fudg pack factori \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'imagin', 'gay', 'work', 'fudg', 'pack', 'factori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol imagin gay work fudg pack factori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1674 :\n",
      "\n",
      "\tTweet's text':  listen guy decim team explain anoth build \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tragedy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['listen', 'guy', 'decim', 'team', 'explain', 'anoth', 'build'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['listen guy decim team explain anoth build'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1675 :\n",
      "\n",
      "\tTweet's text':  miss u lot lot like jelli tot \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['miss', 'u', 'lot', 'lot', 'like', 'jelli', 'tot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['miss u lot lot like jelli tot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1676 :\n",
      "\n",
      "\tTweet's text':  lawyer train lawyer talk ceil ad would even read no one go notic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lawyer', 'train', 'lawyer', 'talk', 'ceil', 'ad', 'would', 'even', 'read', 'no', 'one', 'go', 'notic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lawyer train lawyer talk ceil ad would even read no one go notic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1677 :\n",
      "\n",
      "\tTweet's text':  shawn still follow okay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shawn', 'still', 'follow', 'okay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shawn still follow okay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1678 :\n",
      "\n",
      "\tTweet's text':  and i wanna blast music get readi trip second roommat sleep i suffer consider \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'i', 'wan', 'na', 'blast', 'music', 'get', 'readi', 'trip', 'second', 'roommat', 'sleep', 'i', 'suffer', 'consider'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and i wanna blast music get readi trip second roommat sleep i suffer consider'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1679 :\n",
      "\n",
      "\tTweet's text':  how santa juncker bring gift healthier eu \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcies', '#eu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'santa', 'juncker', 'bring', 'gift', 'healthier', 'eu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how santa juncker bring gift healthier eu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1680 :\n",
      "\n",
      "\tTweet's text':  carbon everywher \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#carbon', '#hood', '#sticker', '#strips', '#down', '#red', '#automotive', '#dope', '#cars'] \n",
      "\n",
      "\tTweet tokenized by words:  ['carbon', 'everywher'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['carbon everywher'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1681 :\n",
      "\n",
      "\tTweet's text':  will put corpor racism sexism back belong face face exec think twice \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['will', 'put', 'corpor', 'racism', 'sexism', 'back', 'belong', 'face', 'face', 'exec', 'think', 'twice'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['will put corpor racism sexism back belong face face exec think twice'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1682 :\n",
      "\n",
      "\tTweet's text':  the answer often lay right infront problem seek distanc realiti answer simpl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'answer', 'often', 'lay', 'right', 'infront', 'problem', 'seek', 'distanc', 'realiti', 'answer', 'simpl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the answer often lay right infront problem seek distanc realiti answer simpl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1683 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Uniform', '#unity', '#LMFAIR14'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1684 :\n",
      "\n",
      "\tTweet's text':  nsroadspol oh look audi driver break \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nsroadspol', 'oh', 'look', 'audi', 'driver', 'break'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nsroadspol oh look audi driver break'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1685 :\n",
      "\n",
      "\tTweet's text':  peac protest infront lancast hous greet pm respect \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PTIUKGoNawazGoCampaign'] \n",
      "\n",
      "\tTweet tokenized by words:  ['peac', 'protest', 'infront', 'lancast', 'hous', 'greet', 'pm', 'respect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peac protest infront lancast hous greet pm respect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1686 :\n",
      "\n",
      "\tTweet's text':  true sissi well said fit live \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['true', 'sissi', 'well', 'said', 'fit', 'live'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['true sissi well said fit live'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1687 :\n",
      "\n",
      "\tTweet's text':  is even math cell work ahhh hahaha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mathisfun'] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'even', 'math', 'cell', 'work', 'ahhh', 'hahaha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is even math cell work ahhh hahaha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1688 :\n",
      "\n",
      "\tTweet's text':  kitti aaaaint happi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cat', '#happy', '#today'] \n",
      "\n",
      "\tTweet tokenized by words:  ['kitti', 'aaaaint', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kitti aaaaint happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1689 :\n",
      "\n",
      "\tTweet's text':  woke cri nightmar i \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['woke', 'cri', 'nightmar', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['woke cri nightmar i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1690 :\n",
      "\n",
      "\tTweet's text':  i love work christma spend alon hour away famili \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'work', 'christma', 'spend', 'alon', 'hour', 'away', 'famili'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love work christma spend alon hour away famili'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1691 :\n",
      "\n",
      "\tTweet's text':  first day ski \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#killedit', '#iwasshit', '#tignes', '#seasonlife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['first', 'day', 'ski'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['first day ski'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1692 :\n",
      "\n",
      "\tTweet's text':  oh materi i miss \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'materi', 'i', 'miss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh materi i miss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1693 :\n",
      "\n",
      "\tTweet's text':  girl put record tell favorit song \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#inasong', '#myfav'] \n",
      "\n",
      "\tTweet tokenized by words:  ['girl', 'put', 'record', 'tell', 'favorit', 'song'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['girl put record tell favorit song'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1694 :\n",
      "\n",
      "\tTweet's text':  thank ed make news crew i welcom morn alway film \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TeamIpswich', '#BlackFriday', '#ItWasQuiet'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'ed', 'make', 'news', 'crew', 'i', 'welcom', 'morn', 'alway', 'film'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank ed make news crew i welcom morn alway film'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1695 :\n",
      "\n",
      "\tTweet's text':  i love get woken bodi say i know comfort sleep but someth want anyway \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'get', 'woken', 'bodi', 'say', 'i', 'know', 'comfort', 'sleep', 'but', 'someth', 'want', 'anyway'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love get woken bodi say i know comfort sleep but someth want anyway'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1696 :\n",
      "\n",
      "\tTweet's text':  american love gun ever \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Chicago', '#Detroit', '#gunlaws'] \n",
      "\n",
      "\tTweet tokenized by words:  ['american', 'love', 'gun', 'ever'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['american love gun ever'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1697 :\n",
      "\n",
      "\tTweet's text':  a guid to coffe espresso time went mapl leaf fan fest \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['ok_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'guid', 'to', 'coffe', 'espresso', 'time', 'went', 'mapl', 'leaf', 'fan', 'fest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a guid to coffe espresso time went mapl leaf fan fest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1698 :\n",
      "\n",
      "\tTweet's text':  new shoe kinda love inanim object \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['new', 'shoe', 'kinda', 'love', 'inanim', 'object'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['new shoe kinda love inanim object'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1699 :\n",
      "\n",
      "\tTweet's text':  probabl nigerian \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['probabl', 'nigerian'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['probabl nigerian'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1700 :\n",
      "\n",
      "\tTweet's text':  go go go go i get \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OrionLaunch'] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'go', 'go', 'go', 'i', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go go go go i get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1701 :\n",
      "\n",
      "\tTweet's text':  andrew luck kind qb wowzer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#INDvsCLE'] \n",
      "\n",
      "\tTweet tokenized by words:  ['andrew', 'luck', 'kind', 'qb', 'wowzer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['andrew luck kind qb wowzer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1702 :\n",
      "\n",
      "\tTweet's text':  lol game napoli win better juve \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'game', 'napoli', 'win', 'better', 'juve'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol game napoli win better juve'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1703 :\n",
      "\n",
      "\tTweet's text':  hahaha u talk abt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hahaha', 'u', 'talk', 'abt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hahaha u talk abt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1704 :\n",
      "\n",
      "\tTweet's text':  oh god i happen love realli love slow internet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#slowinternet'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'god', 'i', 'happen', 'love', 'realli', 'love', 'slow', 'internet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh god i happen love realli love slow internet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1705 :\n",
      "\n",
      "\tTweet's text':  twitter dead \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ThanksFinals'] \n",
      "\n",
      "\tTweet tokenized by words:  ['twitter', 'dead'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['twitter dead'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1706 :\n",
      "\n",
      "\tTweet's text':  make hour sound fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['make', 'hour', 'sound', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['make hour sound fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1707 :\n",
      "\n",
      "\tTweet's text':  alright back bing watch legend korra like muthafukn gangster \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['alright', 'back', 'bing', 'watch', 'legend', 'korra', 'like', 'muthafukn', 'gangster'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alright back bing watch legend korra like muthafukn gangster'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1708 :\n",
      "\n",
      "\tTweet's text':  when advanc peopl actual think \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#stupid'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'advanc', 'peopl', 'actual', 'think'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when advanc peopl actual think'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1709 :\n",
      "\n",
      "\tTweet's text':  what kill make i see evil monkey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['see-no-evil_monkey', 'ok_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  ['#stronger', '#perfect', '#mybody'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'kill', 'make', 'i', 'see', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what kill make i see evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1710 :\n",
      "\n",
      "\tTweet's text':  yeah i get activ social life get away \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'i', 'get', 'activ', 'social', 'life', 'get', 'away'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah i get activ social life get away'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1711 :\n",
      "\n",
      "\tTweet's text':  oh gonna wait till new year start work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thatscool'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'gon', 'na', 'wait', 'till', 'new', 'year', 'start', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh gonna wait till new year start work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1712 :\n",
      "\n",
      "\tTweet's text':  protect namesak \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PalinSpawn'] \n",
      "\n",
      "\tTweet tokenized by words:  ['protect', 'namesak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['protect namesak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1713 :\n",
      "\n",
      "\tTweet's text':  anoth day livin dream \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#needmoremoney'] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'day', 'livin', 'dream'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth day livin dream'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1714 :\n",
      "\n",
      "\tTweet's text':  prepar get muck \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#imissedu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['prepar', 'get', 'muck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['prepar get muck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1715 :\n",
      "\n",
      "\tTweet's text':  you afford stock teacher make so much money crazi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'afford', 'stock', 'teacher', 'make', 'so', 'much', 'money', 'crazi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you afford stock teacher make so much money crazi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1716 :\n",
      "\n",
      "\tTweet's text':  two hour drive morn instructor oh ye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#scaredshitless', '#yikes'] \n",
      "\n",
      "\tTweet tokenized by words:  ['two', 'hour', 'drive', 'morn', 'instructor', 'oh', 'ye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['two hour drive morn instructor oh ye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1717 :\n",
      "\n",
      "\tTweet's text':  if i believ sort thing i canon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#selfpraise'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'i', 'believ', 'sort', 'thing', 'i', 'canon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if i believ sort thing i canon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1718 :\n",
      "\n",
      "\tTweet's text':  wait ga i crush email told great class smile face heart shape eyesheavi black heartfac throw kiss total love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes', 'heavy_black_heart', 'face_throwing_a_kiss'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wait', 'ga', 'i', 'crush', 'email', 'told', 'great', 'class', 'smile', 'face', 'heart', 'shape', 'eyesheavi', 'black', 'heartfac', 'throw', 'kiss', 'total', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wait ga i crush email told great class smile face heart shape eyesheavi black heartfac throw kiss total love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1719 :\n",
      "\n",
      "\tTweet's text':  woke find vehicl insur went month merri christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['woke', 'find', 'vehicl', 'insur', 'went', 'month', 'merri', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['woke find vehicl insur went month merri christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1720 :\n",
      "\n",
      "\tTweet's text':  hahaha town \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hahaha', 'town'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hahaha town'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1721 :\n",
      "\n",
      "\tTweet's text':  i lose full day work system updat happen yesterday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fuckingwindows'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'lose', 'full', 'day', 'work', 'system', 'updat', 'happen', 'yesterday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i lose full day work system updat happen yesterday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1722 :\n",
      "\n",
      "\tTweet's text':  peopl day love accept nonjudgment it great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'day', 'love', 'accept', 'nonjudgment', 'it', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl day love accept nonjudgment it great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1723 :\n",
      "\n",
      "\tTweet's text':  simpl way n contribut thousand \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fashionable', '#empower', '#women', '#weavers', '#KhadiGaatha', '#GoGreen'] \n",
      "\n",
      "\tTweet tokenized by words:  ['simpl', 'way', 'n', 'contribut', 'thousand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['simpl way n contribut thousand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1724 :\n",
      "\n",
      "\tTweet's text':  get \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#indiefilm', '#miboxzombie'] \n",
      "\n",
      "\tTweet tokenized by words:  ['get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1725 :\n",
      "\n",
      "\tTweet's text':  i love work tell need come \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'information_desk_person', 'loudly_crying_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'work', 'tell', 'need', 'come'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love work tell need come'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1726 :\n",
      "\n",
      "\tTweet's text':  look girl broken smile ask want stay love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['musical_note', 'two_hearts'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'girl', 'broken', 'smile', 'ask', 'want', 'stay', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look girl broken smile ask want stay love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1727 :\n",
      "\n",
      "\tTweet's text':  i feel nap near futur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NapTime'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'feel', 'nap', 'near', 'futur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i feel nap near futur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1728 :\n",
      "\n",
      "\tTweet's text':  when vapour emit cleans solvent emit contamin chemic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Cleansing', '#Contaminating', '#Vapour'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'vapour', 'emit', 'cleans', 'solvent', 'emit', 'contamin', 'chemic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when vapour emit cleans solvent emit contamin chemic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1729 :\n",
      "\n",
      "\tTweet's text':  time babygirl i get beauti sleep \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'babygirl', 'i', 'get', 'beauti', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time babygirl i get beauti sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1730 :\n",
      "\n",
      "\tTweet's text':  the ugli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#abuse', '#enough', '#words'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'ugli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the ugli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1731 :\n",
      "\n",
      "\tTweet's text':  oh crap mean what mean see last rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'crap', 'mean', 'what', 'mean', 'see', 'last', 'rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh crap mean what mean see last rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1732 :\n",
      "\n",
      "\tTweet's text':  excit gonna good year music ur gonna smash \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['excit', 'gon', 'na', 'good', 'year', 'music', 'ur', 'gon', 'na', 'smash'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by sentences:  ['excit gonna good year music ur gonna smash'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1733 :\n",
      "\n",
      "\tTweet's text':  name game \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['name', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['name game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1734 :\n",
      "\n",
      "\tTweet's text':  cardal jone third string qb big champion mvp \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SC3stars'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cardal', 'jone', 'third', 'string', 'qb', 'big', 'champion', 'mvp'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cardal jone third string qb big champion mvp'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1735 :\n",
      "\n",
      "\tTweet's text':  need hybrid plu app db scom \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HybridCloud'] \n",
      "\n",
      "\tTweet tokenized by words:  ['need', 'hybrid', 'plu', 'app', 'db', 'scom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['need hybrid plu app db scom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1736 :\n",
      "\n",
      "\tTweet's text':  think make go enough \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['think', 'make', 'go', 'enough'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['think make go enough'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1737 :\n",
      "\n",
      "\tTweet's text':  day next two week new yr love work xma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#needthemoney'] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'next', 'two', 'week', 'new', 'yr', 'love', 'work', 'xma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day next two week new yr love work xma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1738 :\n",
      "\n",
      "\tTweet's text':  good time start vote fifth harmoni \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BestNewArtist'] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'time', 'start', 'vote', 'fifth', 'harmoni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good time start vote fifth harmoni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1739 :\n",
      "\n",
      "\tTweet's text':  comcast greatest custom servic planet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#comcastistheworst'] \n",
      "\n",
      "\tTweet tokenized by words:  ['comcast', 'greatest', 'custom', 'servic', 'planet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['comcast greatest custom servic planet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1740 :\n",
      "\n",
      "\tTweet's text':  by bt at dipmagazin me traviiiii don forget t \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bts', '#PhotoShoot', '#WIFEYSERIES'] \n",
      "\n",
      "\tTweet tokenized by words:  ['by', 'bt', 'at', 'dipmagazin', 'me', 'traviiiii', 'don', 'forget', 't'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['by bt at dipmagazin me traviiiii don forget t'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1741 :\n",
      "\n",
      "\tTweet's text':  in know imp anyth come b w u n ur even \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Business', '#SayNo', '#dreams', '#money', '#entrepreneur', '#tips'] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'know', 'imp', 'anyth', 'come', 'b', 'w', 'u', 'n', 'ur', 'even'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in know imp anyth come b w u n ur even'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1742 :\n",
      "\n",
      "\tTweet's text':  dear gov catalan polic congrat manag accomplish imposs go even lower \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Spain', '#Greece', '#OperaciónPandora'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dear', 'gov', 'catalan', 'polic', 'congrat', 'manag', 'accomplish', 'imposs', 'go', 'even', 'lower'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dear gov catalan polic congrat manag accomplish imposs go even lower'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1743 :\n",
      "\n",
      "\tTweet's text':  miss bant work today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ha', '#ha', '#ha', '#shitbants'] \n",
      "\n",
      "\tTweet tokenized by words:  ['miss', 'bant', 'work', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['miss bant work today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1744 :\n",
      "\n",
      "\tTweet's text':  lost \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lost'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lost'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1745 :\n",
      "\n",
      "\tTweet's text':  get readi ship surplu ink cartridg nunavut commun yup great use time resourc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sofulfilled'] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'readi', 'ship', 'surplu', 'ink', 'cartridg', 'nunavut', 'commun', 'yup', 'great', 'use', 'time', 'resourc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get readi ship surplu ink cartridg nunavut commun yup great use time resourc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1746 :\n",
      "\n",
      "\tTweet's text':  rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#But', '#Buy', '#Couch', '#Enveloppe', '#If', '#Its', '#HomeDecor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1747 :\n",
      "\n",
      "\tTweet's text':  selfish narcissist onli woman matter child matter father matter no one els matter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['selfish', 'narcissist', 'onli', 'woman', 'matter', 'child', 'matter', 'father', 'matter', 'no', 'one', 'els', 'matter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['selfish narcissist onli woman matter child matter father matter no one els matter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1748 :\n",
      "\n",
      "\tTweet's text':  so kind occ health book tb skin test day uni i thrill \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'kind', 'occ', 'health', 'book', 'tb', 'skin', 'test', 'day', 'uni', 'i', 'thrill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so kind occ health book tb skin test day uni i thrill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1749 :\n",
      "\n",
      "\tTweet's text':  wickedli ignor bout black american see racism everyth figment imagin cannot trump j hypocrisi nnn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Cannot', '#NNN'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wickedli', 'ignor', 'bout', 'black', 'american', 'see', 'racism', 'everyth', 'figment', 'imagin', 'can', 'not', 'trump', 'j', 'hypocrisi', 'nnn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wickedli ignor bout black american see racism everyth figment imagin cannot trump j hypocrisi nnn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1750 :\n",
      "\n",
      "\tTweet's text':  founder w dancer ricki gracey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bibotour', '#champwithin', '#chicago', '#women'] \n",
      "\n",
      "\tTweet tokenized by words:  ['founder', 'w', 'dancer', 'ricki', 'gracey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['founder w dancer ricki gracey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1751 :\n",
      "\n",
      "\tTweet's text':  you moment everi second everi scent everi flower as girl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'moment', 'everi', 'second', 'everi', 'scent', 'everi', 'flower', 'as', 'girl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you moment everi second everi scent everi flower as girl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1752 :\n",
      "\n",
      "\tTweet's text':  find one local pd report drop \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['find', 'one', 'local', 'pd', 'report', 'drop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['find one local pd report drop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1753 :\n",
      "\n",
      "\tTweet's text':  thi fun next spring \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'fun', 'next', 'spring'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi fun next spring'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1754 :\n",
      "\n",
      "\tTweet's text':  chillax bitch face stuck tongu tightli close eye face squish \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_stuck-out_tongue_and_tightly-closed_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  ['#fireball'] \n",
      "\n",
      "\tTweet tokenized by words:  ['chillax', 'bitch', 'face', 'stuck', 'tongu', 'tightli', 'close', 'eye', 'face', 'squish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['chillax bitch face stuck tongu tightli close eye face squish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1755 :\n",
      "\n",
      "\tTweet's text':  obamanom fs unemploy insur econom stimulu ft pt work free us follow dream \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['obamanom', 'fs', 'unemploy', 'insur', 'econom', 'stimulu', 'ft', 'pt', 'work', 'free', 'us', 'follow', 'dream'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['obamanom fs unemploy insur econom stimulu ft pt work free us follow dream'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1756 :\n",
      "\n",
      "\tTweet's text':  realli well done anoth short format i get stand rd day row kel ll thank \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'well', 'done', 'anoth', 'short', 'format', 'i', 'get', 'stand', 'rd', 'day', 'row', 'kel', 'll', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli well done anoth short format i get stand rd day row kel ll thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1757 :\n",
      "\n",
      "\tTweet's text':  more win sweet hamper christma fete day jellybean damag tooth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['more', 'win', 'sweet', 'hamper', 'christma', 'fete', 'day', 'jellybean', 'damag', 'tooth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['more win sweet hamper christma fete day jellybean damag tooth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1758 :\n",
      "\n",
      "\tTweet's text':  get shit togeth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#2015isthenewturnup', '#myboos', '#funtimes', '#makingmemories'] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'shit', 'togeth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get shit togeth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1759 :\n",
      "\n",
      "\tTweet's text':  ahhh final throw kegger hous survivor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['skull'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Motivating', '#RIP'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ahhh', 'final', 'throw', 'kegger', 'hous', 'survivor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ahhh final throw kegger hous survivor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1760 :\n",
      "\n",
      "\tTweet's text':  such fun day lib studi econ hour wait tomorrow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ThisIsMiserable'] \n",
      "\n",
      "\tTweet tokenized by words:  ['such', 'fun', 'day', 'lib', 'studi', 'econ', 'hour', 'wait', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['such fun day lib studi econ hour wait tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1761 :\n",
      "\n",
      "\tTweet's text':  as black listen racewar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#RaceWars'] \n",
      "\n",
      "\tTweet tokenized by words:  ['as', 'black', 'listen', 'racewar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['as black listen racewar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1762 :\n",
      "\n",
      "\tTweet's text':  dear dr diaz graviti exist einstein got wrong i wrote book explain theori let know want read \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dear', 'dr', 'diaz', 'graviti', 'exist', 'einstein', 'got', 'wrong', 'i', 'wrote', 'book', 'explain', 'theori', 'let', 'know', 'want', 'read'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dear dr diaz graviti exist einstein got wrong i wrote book explain theori let know want read'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1763 :\n",
      "\n",
      "\tTweet's text':  outta boardroom i partay \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#luvvit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['outta', 'boardroom', 'i', 'partay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['outta boardroom i partay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1764 :\n",
      "\n",
      "\tTweet's text':  lot love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Miranda'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lot', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lot love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1765 :\n",
      "\n",
      "\tTweet's text':  i earn photogen brew level badg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'earn', 'photogen', 'brew', 'level', 'badg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i earn photogen brew level badg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1766 :\n",
      "\n",
      "\tTweet's text':  talk home all talk new owner destabilis pf club could \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mot', '#lufc'] \n",
      "\n",
      "\tTweet tokenized by words:  ['talk', 'home', 'all', 'talk', 'new', 'owner', 'destabilis', 'pf', 'club', 'could'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['talk home all talk new owner destabilis pf club could'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1767 :\n",
      "\n",
      "\tTweet's text':  workahol sick let stop bring germ offic we appreci commit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['workahol', 'sick', 'let', 'stop', 'bring', 'germ', 'offic', 'we', 'appreci', 'commit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['workahol sick let stop bring germ offic we appreci commit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1768 :\n",
      "\n",
      "\tTweet's text':  jame burk connect episod a special place \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#This', '#DRILL'] \n",
      "\n",
      "\tTweet tokenized by words:  ['jame', 'burk', 'connect', 'episod', 'a', 'special', 'place'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jame burk connect episod a special place'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1769 :\n",
      "\n",
      "\tTweet's text':  i love jojo kept \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'jojo', 'kept'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love jojo kept'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1770 :\n",
      "\n",
      "\tTweet's text':  quel domag rt no canada bill to seri coloss flop cancel \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CFL', '#NFL'] \n",
      "\n",
      "\tTweet tokenized by words:  ['quel', 'domag', 'rt', 'no', 'canada', 'bill', 'to', 'seri', 'coloss', 'flop', 'cancel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['quel domag rt no canada bill to seri coloss flop cancel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1771 :\n",
      "\n",
      "\tTweet's text':  strut boot \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['strut', 'boot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['strut boot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1772 :\n",
      "\n",
      "\tTweet's text':  hold hand sing kumbaya hate us \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hold', 'hand', 'sing', 'kumbaya', 'hate', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hold hand sing kumbaya hate us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1773 :\n",
      "\n",
      "\tTweet's text':  there thing much ammo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'thing', 'much', 'ammo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there thing much ammo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1774 :\n",
      "\n",
      "\tTweet's text':  those amarillo hop make right drink tour de fall memphi pint dram \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#goldilocks', '#photo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['those', 'amarillo', 'hop', 'make', 'right', 'drink', 'tour', 'de', 'fall', 'memphi', 'pint', 'dram'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['those amarillo hop make right drink tour de fall memphi pint dram'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1775 :\n",
      "\n",
      "\tTweet's text':  accept \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#spinless', '#gutless'] \n",
      "\n",
      "\tTweet tokenized by words:  ['accept'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['accept'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1776 :\n",
      "\n",
      "\tTweet's text':  good see toma rosicki play tdae \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ARSvQPR'] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'see', 'toma', 'rosicki', 'play', 'tdae'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good see toma rosicki play tdae'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1777 :\n",
      "\n",
      "\tTweet's text':  realli love five minut late cold day feel like metro \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'love', 'five', 'minut', 'late', 'cold', 'day', 'feel', 'like', 'metro'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli love five minut late cold day feel like metro'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1778 :\n",
      "\n",
      "\tTweet's text':  bad happi pred danc first thought donni speak evil monkey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes', 'speak-no-evil_monkey', 'party_popper'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bad', 'happi', 'pred', 'danc', 'first', 'thought', 'donni', 'speak', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bad happi pred danc first thought donni speak evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1779 :\n",
      "\n",
      "\tTweet's text':  bestproadvic replac one mam \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bestproadvic', 'replac', 'one', 'mam'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bestproadvic replac one mam'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1780 :\n",
      "\n",
      "\tTweet's text':  photo cheer \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#vodka', '#mother', '#energy', '#drink', '#tipsy', '#on', '#one', '#drink', '#Cadbury', '#alcoholic', '#Friday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['photo', 'cheer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photo cheer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1781 :\n",
      "\n",
      "\tTweet's text':  just bear use top pick qb posit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'bear', 'use', 'top', 'pick', 'qb', 'posit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just bear use top pick qb posit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1782 :\n",
      "\n",
      "\tTweet's text':  take \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['take'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['take'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1783 :\n",
      "\n",
      "\tTweet's text':  wow thank good vibe right exam parent \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'thank', 'good', 'vibe', 'right', 'exam', 'parent'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow thank good vibe right exam parent'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1784 :\n",
      "\n",
      "\tTweet's text':  for mass i love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['for', 'mass', 'i', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['for mass i love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1785 :\n",
      "\n",
      "\tTweet's text':  i never studi lolz i work present that due tomorrow i start \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'never', 'studi', 'lolz', 'i', 'work', 'present', 'that', 'due', 'tomorrow', 'i', 'start'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i never studi lolz i work present that due tomorrow i start'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1786 :\n",
      "\n",
      "\tTweet's text':  i dont know i love product christma heaven \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['green_heart', 'bath', 'thumbs_up_sign'] \n",
      "\n",
      "\tTweet's hashtags':  ['#love', '#skincare', '#beauty'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'dont', 'know', 'i', 'love', 'product', 'christma', 'heaven'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i dont know i love product christma heaven'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1787 :\n",
      "\n",
      "\tTweet's text':  wow u brought xbox live arnt amaz someth product like grow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'u', 'brought', 'xbox', 'live', 'arnt', 'amaz', 'someth', 'product', 'like', 'grow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow u brought xbox live arnt amaz someth product like grow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1788 :\n",
      "\n",
      "\tTweet's text':  on good note day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['crying_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Scandal'] \n",
      "\n",
      "\tTweet tokenized by words:  ['on', 'good', 'note', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['on good note day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1789 :\n",
      "\n",
      "\tTweet's text':  wow i love essay due next week \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'love', 'essay', 'due', 'next', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i love essay due next week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1790 :\n",
      "\n",
      "\tTweet's text':  sig ni fi cant witter \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sig', 'ni', 'fi', 'cant', 'witter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sig ni fi cant witter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1791 :\n",
      "\n",
      "\tTweet's text':  fuse blown media room too much hallway vacuum chao break loos \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CanCup'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fuse', 'blown', 'media', 'room', 'too', 'much', 'hallway', 'vacuum', 'chao', 'break', 'loos'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fuse blown media room too much hallway vacuum chao break loos'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1792 :\n",
      "\n",
      "\tTweet's text':  porn where move nake woman i see porn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#games'] \n",
      "\n",
      "\tTweet tokenized by words:  ['porn', 'where', 'move', 'nake', 'woman', 'i', 'see', 'porn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['porn where move nake woman i see porn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1793 :\n",
      "\n",
      "\tTweet's text':  whi zayn look like spanish flamingo dancer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'zayn', 'look', 'like', 'spanish', 'flamingo', 'dancer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi zayn look like spanish flamingo dancer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1794 :\n",
      "\n",
      "\tTweet's text':  shawnatova comput internet person comput smart phone invent pond scum \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shawnatova', 'comput', 'internet', 'person', 'comput', 'smart', 'phone', 'invent', 'pond', 'scum'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shawnatova comput internet person comput smart phone invent pond scum'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1795 :\n",
      "\n",
      "\tTweet's text':  the kind stranger \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'kind', 'stranger'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the kind stranger'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1796 :\n",
      "\n",
      "\tTweet's text':  wow i love school \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'love', 'school'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i love school'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1797 :\n",
      "\n",
      "\tTweet's text':  everyon want sooooo cool \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['everyon', 'want', 'sooooo', 'cool'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everyon want sooooo cool'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1798 :\n",
      "\n",
      "\tTweet's text':  final taken to gir love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#heartbroken'] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'taken', 'to', 'gir', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final taken to gir love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1799 :\n",
      "\n",
      "\tTweet's text':  watch elf prime decis tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'elf', 'prime', 'decis', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch elf prime decis tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1800 :\n",
      "\n",
      "\tTweet's text':  how badli do you need that burrito that sound naughti \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#burrito'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'badli', 'do', 'you', 'need', 'that', 'burrito', 'that', 'sound', 'naughti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how badli do you need that burrito that sound naughti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1801 :\n",
      "\n",
      "\tTweet's text':  i love wake late sick dead week \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thebest'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wake', 'late', 'sick', 'dead', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wake late sick dead week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1802 :\n",
      "\n",
      "\tTweet's text':  way prove women breast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['way', 'prove', 'women', 'breast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['way prove women breast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1803 :\n",
      "\n",
      "\tTweet's text':  wake congest abl breath great feel \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['expressionless_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wake', 'congest', 'abl', 'breath', 'great', 'feel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wake congest abl breath great feel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1804 :\n",
      "\n",
      "\tTweet's text':  life complet i meet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['two_hearts'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['life', 'complet', 'i', 'meet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['life complet i meet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1805 :\n",
      "\n",
      "\tTweet's text':  just got messag i need start work anoth locat brilliant rush toward second locat oh god i hate monday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'got', 'messag', 'i', 'need', 'start', 'work', 'anoth', 'locat', 'brilliant', 'rush', 'toward', 'second', 'locat', 'oh', 'god', 'i', 'hate', 'monday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just got messag i need start work anoth locat brilliant rush toward second locat oh god i hate monday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1806 :\n",
      "\n",
      "\tTweet's text':  thank kany mccartney final get big break wait no dumpster dive \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#caring'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'kany', 'mccartney', 'final', 'get', 'big', 'break', 'wait', 'no', 'dumpster', 'dive'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank kany mccartney final get big break wait no dumpster dive'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1807 :\n",
      "\n",
      "\tTweet's text':  clever jack chang word big go bed feel like made differ societi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#youareagenius'] \n",
      "\n",
      "\tTweet tokenized by words:  ['clever', 'jack', 'chang', 'word', 'big', 'go', 'bed', 'feel', 'like', 'made', 'differ', 'societi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['clever jack chang word big go bed feel like made differ societi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1808 :\n",
      "\n",
      "\tTweet's text':  gasp the girl rehears studio today you littl mix \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['hot_beverage', 'frog_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#MTVStars'] \n",
      "\n",
      "\tTweet tokenized by words:  ['gasp', 'the', 'girl', 'rehears', 'studio', 'today', 'you', 'littl', 'mix'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gasp the girl rehears studio today you littl mix'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1809 :\n",
      "\n",
      "\tTweet's text':  yeah bad asleep back play strong painkil knock see evil monkey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['see-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'bad', 'asleep', 'back', 'play', 'strong', 'painkil', 'knock', 'see', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah bad asleep back play strong painkil knock see evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1810 :\n",
      "\n",
      "\tTweet's text':  there noth better feel love lol noth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign', 'unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'noth', 'better', 'feel', 'love', 'lol', 'noth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there noth better feel love lol noth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1811 :\n",
      "\n",
      "\tTweet's text':  i pledg anytim \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'pledg', 'anytim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i pledg anytim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1812 :\n",
      "\n",
      "\tTweet's text':  a \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Meme', '#Monday', '#MemeMonday', '#Obama', '#Obamacare', '#AcidReflux', '#StandUpShot', '#JokeoftheDay', '#Comedy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1813 :\n",
      "\n",
      "\tTweet's text':  digit drumstick thank grandma grandpa \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['digit', 'drumstick', 'thank', 'grandma', 'grandpa'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['digit drumstick thank grandma grandpa'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1814 :\n",
      "\n",
      "\tTweet's text':  wise leadership ii \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Congratulations', '#Hashemite', '#Kingdom', '#Jordan', '#His', '#Majesty', '#King', '#Abdullah', '#New', '#Year'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wise', 'leadership', 'ii'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wise leadership ii'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1815 :\n",
      "\n",
      "\tTweet's text':  gotta go back work tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'go', 'back', 'work', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta go back work tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1816 :\n",
      "\n",
      "\tTweet's text':  math present ap histori test ap scienc test whatev hell a \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['math', 'present', 'ap', 'histori', 'test', 'ap', 'scienc', 'test', 'whatev', 'hell', 'a'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['math present ap histori test ap scienc test whatev hell a'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1817 :\n",
      "\n",
      "\tTweet's text':  if man u best much bigger problem us then still th \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#saintsfc', '#noproblem'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'man', 'u', 'best', 'much', 'bigger', 'problem', 'us', 'then', 'still', 'th'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if man u best much bigger problem us then still th'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1818 :\n",
      "\n",
      "\tTweet's text':  even soweto tv bother show fvcken \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['even', 'soweto', 'tv', 'bother', 'show', 'fvcken'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['even soweto tv bother show fvcken'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1819 :\n",
      "\n",
      "\tTweet's text':  pain inevit suffer option anonym \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Anonymous'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pain', 'inevit', 'suffer', 'option', 'anonym'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pain inevit suffer option anonym'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1820 :\n",
      "\n",
      "\tTweet's text':  how dare somebodi exercis freedom protest freedom speech \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'dare', 'somebodi', 'exercis', 'freedom', 'protest', 'freedom', 'speech'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how dare somebodi exercis freedom protest freedom speech'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1821 :\n",
      "\n",
      "\tTweet's text':  what i learn today you choos live fearless life \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#iam', '#fearfree', '#fearfull'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'i', 'learn', 'today', 'you', 'choos', 'live', 'fearless', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what i learn today you choos live fearless life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1822 :\n",
      "\n",
      "\tTweet's text':  fit motiv i learn want make bad enough matter bad make gale sayer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Wise'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fit', 'motiv', 'i', 'learn', 'want', 'make', 'bad', 'enough', 'matter', 'bad', 'make', 'gale', 'sayer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fit motiv i learn want make bad enough matter bad make gale sayer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1823 :\n",
      "\n",
      "\tTweet's text':  sec crew qualiti offici penn state game how miss terribl block back \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sec', 'crew', 'qualiti', 'offici', 'penn', 'state', 'game', 'how', 'miss', 'terribl', 'block', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sec crew qualiti offici penn state game how miss terribl block back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1824 :\n",
      "\n",
      "\tTweet's text':  say stand front mirror say i even time girl appear give pumpkin spice latt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Legend', '#yogapants'] \n",
      "\n",
      "\tTweet tokenized by words:  ['say', 'stand', 'front', 'mirror', 'say', 'i', 'even', 'time', 'girl', 'appear', 'give', 'pumpkin', 'spice', 'latt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['say stand front mirror say i even time girl appear give pumpkin spice latt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1825 :\n",
      "\n",
      "\tTweet's text':  photo invoic sent \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['photo', 'invoic', 'sent'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photo invoic sent'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1826 :\n",
      "\n",
      "\tTweet's text':  read media \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Media', '#Struggle', '#to', '#Save', '#Obama', '#the', '#Country'] \n",
      "\n",
      "\tTweet tokenized by words:  ['read', 'media'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['read media'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1827 :\n",
      "\n",
      "\tTweet's text':  lol well done swan \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'well', 'done', 'swan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol well done swan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1828 :\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's text':  just found pictur lisazamorano tri kill moutain meadow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bff', '#seniorbrunch'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'found', 'pictur', 'lisazamorano', 'tri', 'kill', 'moutain', 'meadow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just found pictur lisazamorano tri kill moutain meadow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1829 :\n",
      "\n",
      "\tTweet's text':  unfortun hey daddi think daughter game fifa youraveragedaddysgirl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['unfortun', 'hey', 'daddi', 'think', 'daughter', 'game', 'fifa', 'youraveragedaddysgirl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['unfortun hey daddi think daughter game fifa youraveragedaddysgirl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1830 :\n",
      "\n",
      "\tTweet's text':  my dream celebr christma smile face heart shape eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'dream', 'celebr', 'christma', 'smile', 'face', 'heart', 'shape', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my dream celebr christma smile face heart shape eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1831 :\n",
      "\n",
      "\tTweet's text':  yup few week nz muck time fiji dodg shark \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yup', 'few', 'week', 'nz', 'muck', 'time', 'fiji', 'dodg', 'shark'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yup few week nz muck time fiji dodg shark'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1832 :\n",
      "\n",
      "\tTweet's text':  my dog like nice toasti relax home \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#adorable', '#puppy', '#socute', '#icant'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'dog', 'like', 'nice', 'toasti', 'relax', 'home'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my dog like nice toasti relax home'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1833 :\n",
      "\n",
      "\tTweet's text':  hashtag great idk everyon stop use \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#jk', '#bye'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hashtag', 'great', 'idk', 'everyon', 'stop', 'use'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hashtag great idk everyon stop use'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1834 :\n",
      "\n",
      "\tTweet's text':  come graham thoma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['come', 'graham', 'thoma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['come graham thoma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1835 :\n",
      "\n",
      "\tTweet's text':  today stat follow unfollow follow peopl via \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'stat', 'follow', 'unfollow', 'follow', 'peopl', 'via'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today stat follow unfollow follow peopl via'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1836 :\n",
      "\n",
      "\tTweet's text':  i best new year spent peopl i love i fuck love smile face heart shape eye such happi camper right face stuck tongu tightli close eyesgreen heartheavi black heart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes', 'heavy_black_heart', 'green_heart', 'face_with_stuck-out_tongue_and_tightly-closed_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'best', 'new', 'year', 'spent', 'peopl', 'i', 'love', 'i', 'fuck', 'love', 'smile', 'face', 'heart', 'shape', 'eye', 'such', 'happi', 'camper', 'right', 'face', 'stuck', 'tongu', 'tightli', 'close', 'eyesgreen', 'heartheavi', 'black', 'heart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i best new year spent peopl i love i fuck love smile face heart shape eye such happi camper right face stuck tongu tightli close eyesgreen heartheavi black heart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1837 :\n",
      "\n",
      "\tTweet's text':  haha i also \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'i', 'also'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha i also'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1838 :\n",
      "\n",
      "\tTweet's text':  even better let see wadi camacho man fight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['even', 'better', 'let', 'see', 'wadi', 'camacho', 'man', 'fight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['even better let see wadi camacho man fight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1839 :\n",
      "\n",
      "\tTweet's text':  lol peopl say turn year i start follow kid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sorry'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'peopl', 'say', 'turn', 'year', 'i', 'start', 'follow', 'kid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol peopl say turn year i start follow kid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1840 :\n",
      "\n",
      "\tTweet's text':  on tl i see somerhol unfollow tweet retweet somerhol see mani allow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['on', 'tl', 'i', 'see', 'somerhol', 'unfollow', 'tweet', 'retweet', 'somerhol', 'see', 'mani', 'allow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['on tl i see somerhol unfollow tweet retweet somerhol see mani allow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1841 :\n",
      "\n",
      "\tTweet's text':  i three boy breastf year never i necessari \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'three', 'boy', 'breastf', 'year', 'never', 'i', 'necessari'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i three boy breastf year never i necessari'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1842 :\n",
      "\n",
      "\tTweet's text':  i would love touch anaconda jump thang ride like hors \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EatenAlive'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'would', 'love', 'touch', 'anaconda', 'jump', 'thang', 'ride', 'like', 'hors'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i would love touch anaconda jump thang ride like hors'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1843 :\n",
      "\n",
      "\tTweet's text':  photo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whynot', '#why', '#pop', '#art', '#artist', '#whirleyshot', '#whirleystudio', '#sharpie', '#acrylics'] \n",
      "\n",
      "\tTweet tokenized by words:  ['photo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1844 :\n",
      "\n",
      "\tTweet's text':  a man must have f to get a in life fortitud focu financ \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'man', 'must', 'have', 'f', 'to', 'get', 'a', 'in', 'life', 'fortitud', 'focu', 'financ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a man must have f to get a in life fortitud focu financ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1845 :\n",
      "\n",
      "\tTweet's text':  aaand hit keep come \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BadDay'] \n",
      "\n",
      "\tTweet tokenized by words:  ['aaand', 'hit', 'keep', 'come'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aaand hit keep come'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1846 :\n",
      "\n",
      "\tTweet's text':  janicedean michael bloomberg wear speedo bodyguard \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GlobalWarming'] \n",
      "\n",
      "\tTweet tokenized by words:  ['janicedean', 'michael', 'bloomberg', 'wear', 'speedo', 'bodyguard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['janicedean michael bloomberg wear speedo bodyguard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1847 :\n",
      "\n",
      "\tTweet's text':  cuoco sweet kaley cuoco sweet pictur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Kaley', '#apologises', '#for', '#saying', '#a', '#feminist'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cuoco', 'sweet', 'kaley', 'cuoco', 'sweet', 'pictur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cuoco sweet kaley cuoco sweet pictur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1848 :\n",
      "\n",
      "\tTweet's text':  obama taxpay fund cost attend polit fundrais lo angel san francisco \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['obama', 'taxpay', 'fund', 'cost', 'attend', 'polit', 'fundrais', 'lo', 'angel', 'san', 'francisco'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['obama taxpay fund cost attend polit fundrais lo angel san francisco'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1849 :\n",
      "\n",
      "\tTweet's text':  say someth stupid o \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['say', 'someth', 'stupid', 'o'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['say someth stupid o'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1850 :\n",
      "\n",
      "\tTweet's text':  end fish discard delay end fish discard delay copyright ep from eu report v \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcies', '#eu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['end', 'fish', 'discard', 'delay', 'end', 'fish', 'discard', 'delay', 'copyright', 'ep', 'from', 'eu', 'report', 'v'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['end fish discard delay end fish discard delay copyright ep from eu report v'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1851 :\n",
      "\n",
      "\tTweet's text':  i realli sure i still aliv write paper right nap instead sleep weekend cut \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#finals'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'realli', 'sure', 'i', 'still', 'aliv', 'write', 'paper', 'right', 'nap', 'instead', 'sleep', 'weekend', 'cut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i realli sure i still aliv write paper right nap instead sleep weekend cut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1852 :\n",
      "\n",
      "\tTweet's text':  rest well stuart man grace courag may famili find peac \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rest', 'well', 'stuart', 'man', 'grace', 'courag', 'may', 'famili', 'find', 'peac'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rest well stuart man grace courag may famili find peac'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1853 :\n",
      "\n",
      "\tTweet's text':  apricot pear boozi belgian good a winter warmer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['apricot', 'pear', 'boozi', 'belgian', 'good', 'a', 'winter', 'warmer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['apricot pear boozi belgian good a winter warmer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1854 :\n",
      "\n",
      "\tTweet's text':  couldn ask better night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['couldn', 'ask', 'better', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['couldn ask better night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1855 :\n",
      "\n",
      "\tTweet's text':  patio tumbler good \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Mac12days'] \n",
      "\n",
      "\tTweet tokenized by words:  ['patio', 'tumbler', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['patio tumbler good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1856 :\n",
      "\n",
      "\tTweet's text':  he look decent bowler not realli th bowler balanc side potenti th bowler styri hsohail \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pakvnz'] \n",
      "\n",
      "\tTweet tokenized by words:  ['he', 'look', 'decent', 'bowler', 'not', 'realli', 'th', 'bowler', 'balanc', 'side', 'potenti', 'th', 'bowler', 'styri', 'hsohail'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['he look decent bowler not realli th bowler balanc side potenti th bowler styri hsohail'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1857 :\n",
      "\n",
      "\tTweet's text':  hit follow instagram ive offici made life \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hit', 'follow', 'instagram', 'ive', 'offici', 'made', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hit follow instagram ive offici made life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1858 :\n",
      "\n",
      "\tTweet's text':  look it white christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MinnesotaProblems'] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'it', 'white', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look it white christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1859 :\n",
      "\n",
      "\tTweet's text':  color don prefer negro \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['color', 'don', 'prefer', 'negro'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['color don prefer negro'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1860 :\n",
      "\n",
      "\tTweet's text':  it possibl enough time \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'possibl', 'enough', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it possibl enough time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1861 :\n",
      "\n",
      "\tTweet's text':  librari comput frozen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#shocker'] \n",
      "\n",
      "\tTweet tokenized by words:  ['librari', 'comput', 'frozen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['librari comput frozen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1862 :\n",
      "\n",
      "\tTweet's text':  bjp congress nt disclos detail cr donat receiv still media bhakt question aap \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MufflerMan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bjp', 'congress', 'nt', 'disclos', 'detail', 'cr', 'donat', 'receiv', 'still', 'media', 'bhakt', 'question', 'aap'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bjp congress nt disclos detail cr donat receiv still media bhakt question aap'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1863 :\n",
      "\n",
      "\tTweet's text':  my last final today straight surgeon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WhatAGoodWeek'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'last', 'final', 'today', 'straight', 'surgeon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my last final today straight surgeon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1864 :\n",
      "\n",
      "\tTweet's text':  ariana grand makeup alway sooo flawless speak evil monkey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['speak-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ariana', 'grand', 'makeup', 'alway', 'sooo', 'flawless', 'speak', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ariana grand makeup alway sooo flawless speak evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1865 :\n",
      "\n",
      "\tTweet's text':  rememb i ran mile min sleep summer i got hour day two hour sleep thi fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rememb', 'i', 'ran', 'mile', 'min', 'sleep', 'summer', 'i', 'got', 'hour', 'day', 'two', 'hour', 'sleep', 'thi', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rememb i ran mile min sleep summer i got hour day two hour sleep thi fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1866 :\n",
      "\n",
      "\tTweet's text':  i go post opinion obama cuba save till \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#obama', '#cuba', '#speech', '#peacemaker'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'go', 'post', 'opinion', 'obama', 'cuba', 'save', 'till'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i go post opinion obama cuba save till'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1867 :\n",
      "\n",
      "\tTweet's text':  light setup water tomorrow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Malawi', '#Aquarium', '#Cichlids', '#NoFilter', '#MarineWhite'] \n",
      "\n",
      "\tTweet tokenized by words:  ['light', 'setup', 'water', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['light setup water tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1868 :\n",
      "\n",
      "\tTweet's text':  good thing ace like clay bucholz proven durabl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'thing', 'ace', 'like', 'clay', 'bucholz', 'proven', 'durabl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good thing ace like clay bucholz proven durabl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1869 :\n",
      "\n",
      "\tTweet's text':  ok ok geez i know alreadi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#totally', '#repetetive'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ok', 'ok', 'geez', 'i', 'know', 'alreadi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ok ok geez i know alreadi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1870 :\n",
      "\n",
      "\tTweet's text':  i e strength number focus movement appeal countri use pen paper chang way live drastic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'e', 'strength', 'number', 'focus', 'movement', 'appeal', 'countri', 'use', 'pen', 'paper', 'chang', 'way', 'live', 'drastic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i e strength number focus movement appeal countri use pen paper chang way live drastic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1871 :\n",
      "\n",
      "\tTweet's text':  kbj thing complain christma day i pimpl ear \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ThanksObama', '#LegitReasonToComplain'] \n",
      "\n",
      "\tTweet tokenized by words:  ['kbj', 'thing', 'complain', 'christma', 'day', 'i', 'pimpl', 'ear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kbj thing complain christma day i pimpl ear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1872 :\n",
      "\n",
      "\tTweet's text':  someon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['hot_beverage', 'frog_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['someon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['someon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1873 :\n",
      "\n",
      "\tTweet's text':  left home still tri get work i want cri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#happymonday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['left', 'home', 'still', 'tri', 'get', 'work', 'i', 'want', 'cri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['left home still tri get work i want cri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1874 :\n",
      "\n",
      "\tTweet's text':  it pretti amaz the land free peopl debat feel safe around polic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'pretti', 'amaz', 'the', 'land', 'free', 'peopl', 'debat', 'feel', 'safe', 'around', 'polic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it pretti amaz the land free peopl debat feel safe around polic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1875 :\n",
      "\n",
      "\tTweet's text':  true patriot packer bronco could suddenli need new coach \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#itshappening'] \n",
      "\n",
      "\tTweet tokenized by words:  ['true', 'patriot', 'packer', 'bronco', 'could', 'suddenli', 'need', 'new', 'coach'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['true patriot packer bronco could suddenli need new coach'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1876 :\n",
      "\n",
      "\tTweet's text':  swim \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sopping', '#wet', '#Squishing', '#mud', '#between', '#toes', '#Swimming', '#mud', '#puddle'] \n",
      "\n",
      "\tTweet tokenized by words:  ['swim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['swim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1877 :\n",
      "\n",
      "\tTweet's text':  i know fun cx i could probabl think find yeah no xd \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'fun', 'cx', 'i', 'could', 'probabl', 'think', 'find', 'yeah', 'no', 'xd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know fun cx i could probabl think find yeah no xd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1878 :\n",
      "\n",
      "\tTweet's text':  former chairwoman us commiss civil right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['former', 'chairwoman', 'us', 'commiss', 'civil', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['former chairwoman us commiss civil right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1879 :\n",
      "\n",
      "\tTweet's text':  tomorrow day i come back florida good unless someth chang next hr i doubt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ready'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tomorrow', 'day', 'i', 'come', 'back', 'florida', 'good', 'unless', 'someth', 'chang', 'next', 'hr', 'i', 'doubt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tomorrow day i come back florida good unless someth chang next hr i doubt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1880 :\n",
      "\n",
      "\tTweet's text':  by definit place money outcom anyth gambl choos deni self delus \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['by', 'definit', 'place', 'money', 'outcom', 'anyth', 'gambl', 'choos', 'deni', 'self', 'delus'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['by definit place money outcom anyth gambl choos deni self delus'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1881 :\n",
      "\n",
      "\tTweet's text':  such long day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wrecked'] \n",
      "\n",
      "\tTweet tokenized by words:  ['such', 'long', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['such long day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1882 :\n",
      "\n",
      "\tTweet's text':  the downsid work fisheri conserv rare afford cool thing promot job \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'downsid', 'work', 'fisheri', 'conserv', 'rare', 'afford', 'cool', 'thing', 'promot', 'job'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the downsid work fisheri conserv rare afford cool thing promot job'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1883 :\n",
      "\n",
      "\tTweet's text':  lol ironi commit suicid jump adani jet orphan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#adanisJet', '#LoveJihad', '#Gharwapsi'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'ironi', 'commit', 'suicid', 'jump', 'adani', 'jet', 'orphan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol ironi commit suicid jump adani jet orphan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1884 :\n",
      "\n",
      "\tTweet's text':  just gave imperfecto rate \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'gave', 'imperfecto', 'rate'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just gave imperfecto rate'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1885 :\n",
      "\n",
      "\tTweet's text':  your understand someth make expert field \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['your', 'understand', 'someth', 'make', 'expert', 'field'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['your understand someth make expert field'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1886 :\n",
      "\n",
      "\tTweet's text':  one mani reason i dislik fan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Alabama', '#auburn', '#RollTide', '#myass', '#jakellmitchell'] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'mani', 'reason', 'i', 'dislik', 'fan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one mani reason i dislik fan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1887 :\n",
      "\n",
      "\tTweet's text':  i glad i work doubl new year eve new year d \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pissed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'glad', 'i', 'work', 'doubl', 'new', 'year', 'eve', 'new', 'year', 'd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i glad i work doubl new year eve new year d'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1888 :\n",
      "\n",
      "\tTweet's text':  yeah ignor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'ignor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah ignor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1889 :\n",
      "\n",
      "\tTweet's text':  lol cours best \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'cours', 'best'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol cours best'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1890 :\n",
      "\n",
      "\tTweet's text':  would said whi gop african brought do want pick cotton \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['would', 'said', 'whi', 'gop', 'african', 'brought', 'do', 'want', 'pick', 'cotton'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['would said whi gop african brought do want pick cotton'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1891 :\n",
      "\n",
      "\tTweet's text':  oh come give chanc trust worthi sn warrior follow uber right wing portal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'come', 'give', 'chanc', 'trust', 'worthi', 'sn', 'warrior', 'follow', 'uber', 'right', 'wing', 'portal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh come give chanc trust worthi sn warrior follow uber right wing portal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1892 :\n",
      "\n",
      "\tTweet's text':  so went well \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'went', 'well'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so went well'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1893 :\n",
      "\n",
      "\tTweet's text':  wow fluent finnish \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'fluent', 'finnish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow fluent finnish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1894 :\n",
      "\n",
      "\tTweet's text':  where perfectli normal talk peopl pictur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SocialMedia'] \n",
      "\n",
      "\tTweet tokenized by words:  ['where', 'perfectli', 'normal', 'talk', 'peopl', 'pictur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['where perfectli normal talk peopl pictur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1895 :\n",
      "\n",
      "\tTweet's text':  hey doe word ban home page like two three time though \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AcknowledgementIsFirstStep'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'doe', 'word', 'ban', 'home', 'page', 'like', 'two', 'three', 'time', 'though'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey doe word ban home page like two three time though'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1896 :\n",
      "\n",
      "\tTweet's text':  re xma christma abbrevi christ mass \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['re', 'xma', 'christma', 'abbrevi', 'christ', 'mass'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['re xma christma abbrevi christ mass'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1897 :\n",
      "\n",
      "\tTweet's text':  mean \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sorrynotsorry'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mean'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mean'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1898 :\n",
      "\n",
      "\tTweet's text':  how end talk \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cutestcouple'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'end', 'talk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how end talk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1899 :\n",
      "\n",
      "\tTweet's text':  a year ago would write shirt anymor thank \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MerryXmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'year', 'ago', 'would', 'write', 'shirt', 'anymor', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a year ago would write shirt anymor thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1900 :\n",
      "\n",
      "\tTweet's text':  goodi bag nd grade done \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whatsnext'] \n",
      "\n",
      "\tTweet tokenized by words:  ['goodi', 'bag', 'nd', 'grade', 'done'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['goodi bag nd grade done'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1901 :\n",
      "\n",
      "\tTweet's text':  but nooooo religi freedom one ever get control oppress domin religion \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'nooooo', 'religi', 'freedom', 'one', 'ever', 'get', 'control', 'oppress', 'domin', 'religion'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but nooooo religi freedom one ever get control oppress domin religion'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1902 :\n",
      "\n",
      "\tTweet's text':  good luck today dj durkin it not great florida gator fuckuf \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fuckUF'] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'luck', 'today', 'dj', 'durkin', 'it', 'not', 'great', 'florida', 'gator', 'fuckuf'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good luck today dj durkin it not great florida gator fuckuf'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1903 :\n",
      "\n",
      "\tTweet's text':  and none goodby beard sort \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MensFashion'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'none', 'goodby', 'beard', 'sort'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and none goodby beard sort'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1904 :\n",
      "\n",
      "\tTweet's text':  hors hornless unicorn o enlighten \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['O'] \n",
      "\n",
      "\tTweet's hashtags':  ['#enlightened', '#mystical', '#wow', '#on', '#drugs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hors', 'hornless', 'unicorn', 'o', 'enlighten'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hors hornless unicorn o enlighten'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1905 :\n",
      "\n",
      "\tTweet's text':  last day work week let see bad get \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#positive'] \n",
      "\n",
      "\tTweet tokenized by words:  ['last', 'day', 'work', 'week', 'let', 'see', 'bad', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['last day work week let see bad get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1906 :\n",
      "\n",
      "\tTweet's text':  i wish mf would day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['fisted_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wish', 'mf', 'would', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wish mf would day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1907 :\n",
      "\n",
      "\tTweet's text':  it awak right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cute'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'awak', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it awak right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1908 :\n",
      "\n",
      "\tTweet's text':  angri face \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Leo', '#Kids', '#Fun', '#Face', '#Angry'] \n",
      "\n",
      "\tTweet tokenized by words:  ['angri', 'face'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['angri face'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1909 :\n",
      "\n",
      "\tTweet's text':  children home statu woohoo isn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['children', 'home', 'statu', 'woohoo', 'isn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['children home statu woohoo isn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1910 :\n",
      "\n",
      "\tTweet's text':  what wonder weather \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_sunglasses'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'wonder', 'weather'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what wonder weather'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1911 :\n",
      "\n",
      "\tTweet's text':  but groceri store pharmaci sensibl grpress offic apart owner monro avenu factori ponder option \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'groceri', 'store', 'pharmaci', 'sensibl', 'grpress', 'offic', 'apart', 'owner', 'monro', 'avenu', 'factori', 'ponder', 'option'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but groceri store pharmaci sensibl grpress offic apart owner monro avenu factori ponder option'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1912 :\n",
      "\n",
      "\tTweet's text':  at least tan look good need learn appreci pale skin see evil monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'see-no-evil_monkey', 'flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['at', 'least', 'tan', 'look', 'good', 'need', 'learn', 'appreci', 'pale', 'skin', 'see', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['at least tan look good need learn appreci pale skin see evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1913 :\n",
      "\n",
      "\tTweet's text':  well today gonna great day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['ok_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'today', 'gon', 'na', 'great', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well today gonna great day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1914 :\n",
      "\n",
      "\tTweet's text':  complex word understand \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['complex', 'word', 'understand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['complex word understand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1915 :\n",
      "\n",
      "\tTweet's text':  beauti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#manitibaprobs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['beauti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['beauti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1916 :\n",
      "\n",
      "\tTweet's text':  cramp front husband knee back yeah sleep seem possibl tonight \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#suckitmothernature'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cramp', 'front', 'husband', 'knee', 'back', 'yeah', 'sleep', 'seem', 'possibl', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cramp front husband knee back yeah sleep seem possibl tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1917 :\n",
      "\n",
      "\tTweet's text':  for shame third time pregnant duchess wear design dress third time new york \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['for', 'shame', 'third', 'time', 'pregnant', 'duchess', 'wear', 'design', 'dress', 'third', 'time', 'new', 'york'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['for shame third time pregnant duchess wear design dress third time new york'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1918 :\n",
      "\n",
      "\tTweet's text':  nah i think say f ck enough album \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#angryman', '#oldschool'] \n",
      "\n",
      "\tTweet tokenized by words:  ['nah', 'i', 'think', 'say', 'f', 'ck', 'enough', 'album'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nah i think say f ck enough album'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1919 :\n",
      "\n",
      "\tTweet's text':  gotta record favorit show tamar vinc season final \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'record', 'favorit', 'show', 'tamar', 'vinc', 'season', 'final'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta record favorit show tamar vinc season final'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1920 :\n",
      "\n",
      "\tTweet's text':  photo abstract tribal bubbl jumpsuit size xl cost \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['photo', 'abstract', 'tribal', 'bubbl', 'jumpsuit', 'size', 'xl', 'cost'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photo abstract tribal bubbl jumpsuit size xl cost'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1921 :\n",
      "\n",
      "\tTweet's text':  sum week realli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NursingLife', '#WorkingDaysAndNights'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sum', 'week', 'realli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sum week realli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1922 :\n",
      "\n",
      "\tTweet's text':  the pace kcroyal activ winter meet give vertigo \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'pace', 'kcroyal', 'activ', 'winter', 'meet', 'give', 'vertigo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the pace kcroyal activ winter meet give vertigo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1923 :\n",
      "\n",
      "\tTweet's text':  say women black differ speci \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['say', 'women', 'black', 'differ', 'speci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['say women black differ speci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1924 :\n",
      "\n",
      "\tTweet's text':  i liter get pamper day tomorrow get cray julia raven bay \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whatmorecouldaguyaskfor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'liter', 'get', 'pamper', 'day', 'tomorrow', 'get', 'cray', 'julia', 'raven', 'bay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i liter get pamper day tomorrow get cray julia raven bay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1925 :\n",
      "\n",
      "\tTweet's text':  so excit spend next hour school \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'excit', 'spend', 'next', 'hour', 'school'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so excit spend next hour school'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1926 :\n",
      "\n",
      "\tTweet's text':  the er suck tonight urgent care tomorrow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fml', '#ugh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'er', 'suck', 'tonight', 'urgent', 'care', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the er suck tonight urgent care tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1927 :\n",
      "\n",
      "\tTweet's text':  too bless stress so hype next year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HAILSTATE'] \n",
      "\n",
      "\tTweet tokenized by words:  ['too', 'bless', 'stress', 'so', 'hype', 'next', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['too bless stress so hype next year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1928 :\n",
      "\n",
      "\tTweet's text':  who dare play game lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Shots', '#Sex', '#Fine', '#Tipsy', '#Drunk', '#Dead', '#NeedAGoodLaugh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['who', 'dare', 'play', 'game', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['who dare play game lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1929 :\n",
      "\n",
      "\tTweet's text':  still time enter sampl channel check \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#giveaway', '#modere', '#bbloggers', '#beauty'] \n",
      "\n",
      "\tTweet tokenized by words:  ['still', 'time', 'enter', 'sampl', 'channel', 'check'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['still time enter sampl channel check'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1930 :\n",
      "\n",
      "\tTweet's text':  love wake grumpi peopl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'wake', 'grumpi', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love wake grumpi peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1931 :\n",
      "\n",
      "\tTweet's text':  t mobil ceo think appl watch go huge i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['t', 'mobil', 'ceo', 'think', 'appl', 'watch', 'go', 'huge', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['t mobil ceo think appl watch go huge i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1932 :\n",
      "\n",
      "\tTweet's text':  so incept episod down tangerin spin top subtl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'incept', 'episod', 'down', 'tangerin', 'spin', 'top', 'subtl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so incept episod down tangerin spin top subtl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1933 :\n",
      "\n",
      "\tTweet's text':  alway count freshmen make librari loud thank \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['alway', 'count', 'freshmen', 'make', 'librari', 'loud', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alway count freshmen make librari loud thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1934 :\n",
      "\n",
      "\tTweet's text':  play minut field steal foul done \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['play', 'minut', 'field', 'steal', 'foul', 'done'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['play minut field steal foul done'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1935 :\n",
      "\n",
      "\tTweet's text':  break bulli major problem nation high school \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#realjournalist'] \n",
      "\n",
      "\tTweet tokenized by words:  ['break', 'bulli', 'major', 'problem', 'nation', 'high', 'school'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['break bulli major problem nation high school'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1936 :\n",
      "\n",
      "\tTweet's text':  look forward nice long km tomorrow minu degre weather \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cycle', '#fool', '#festive500'] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'forward', 'nice', 'long', 'km', 'tomorrow', 'minu', 'degre', 'weather'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look forward nice long km tomorrow minu degre weather'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1937 :\n",
      "\n",
      "\tTweet's text':  might go back bed easier make effort \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'loudly_crying_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#wrong'] \n",
      "\n",
      "\tTweet tokenized by words:  ['might', 'go', 'back', 'bed', 'easier', 'make', 'effort'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['might go back bed easier make effort'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1938 :\n",
      "\n",
      "\tTweet's text':  ya histori told us anyth bet sport great way make money \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ya', 'histori', 'told', 'us', 'anyth', 'bet', 'sport', 'great', 'way', 'make', 'money'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ya histori told us anyth bet sport great way make money'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1939 :\n",
      "\n",
      "\tTweet's text':  stun today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stun', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stun today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1940 :\n",
      "\n",
      "\tTweet's text':  ya caus countri calm peac everyon arm \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ya', 'caus', 'countri', 'calm', 'peac', 'everyon', 'arm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ya caus countri calm peac everyon arm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1941 :\n",
      "\n",
      "\tTweet's text':  priori contract wear huge popular priori ultra \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#does', '#count', '#xxx'] \n",
      "\n",
      "\tTweet tokenized by words:  ['priori', 'contract', 'wear', 'huge', 'popular', 'priori', 'ultra'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['priori contract wear huge popular priori ultra'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1942 :\n",
      "\n",
      "\tTweet's text':  white peopl irrelev point the black commun need rise abov control \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#truth'] \n",
      "\n",
      "\tTweet tokenized by words:  ['white', 'peopl', 'irrelev', 'point', 'the', 'black', 'commun', 'need', 'rise', 'abov', 'control'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['white peopl irrelev point the black commun need rise abov control'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1943 :\n",
      "\n",
      "\tTweet's text':  great start day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'start', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great start day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1944 :\n",
      "\n",
      "\tTweet's text':  i fricken peachi today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'fricken', 'peachi', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i fricken peachi today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1945 :\n",
      "\n",
      "\tTweet's text':  even think religi freedom restor act michigan ridicul \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['even', 'think', 'religi', 'freedom', 'restor', 'act', 'michigan', 'ridicul'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['even think religi freedom restor act michigan ridicul'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1946 :\n",
      "\n",
      "\tTweet's text':  term time smile face open mouth tightli close eyessmil face sunglass \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_sunglasses', 'smiling_face_with_open_mouth_and_tightly-closed_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['term', 'time', 'smile', 'face', 'open', 'mouth', 'tightli', 'close', 'eyessmil', 'face', 'sunglass'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['term time smile face open mouth tightli close eyessmil face sunglass'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1947 :\n",
      "\n",
      "\tTweet's text':  worth read on persecut face \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Christians', '#equality', '#respect', '#sectarianviolence', '#countyourblessings'] \n",
      "\n",
      "\tTweet tokenized by words:  ['worth', 'read', 'on', 'persecut', 'face'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['worth read on persecut face'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1948 :\n",
      "\n",
      "\tTweet's text':  i may may obsess grinch \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smirking_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'may', 'may', 'obsess', 'grinch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i may may obsess grinch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1949 :\n",
      "\n",
      "\tTweet's text':  money church smartphon app pay see go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['money', 'church', 'smartphon', 'app', 'pay', 'see', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['money church smartphon app pay see go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1950 :\n",
      "\n",
      "\tTweet's text':  and overpay talent get stuck w talent which perpetu lose cycl cub \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'overpay', 'talent', 'get', 'stuck', 'w', 'talent', 'which', 'perpetu', 'lose', 'cycl', 'cub'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and overpay talent get stuck w talent which perpetu lose cycl cub'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1951 :\n",
      "\n",
      "\tTweet's text':  say joe who would imagin govern program fraught fraud ha ever happen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['say', 'joe', 'who', 'would', 'imagin', 'govern', 'program', 'fraught', 'fraud', 'ha', 'ever', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['say joe who would imagin govern program fraught fraud ha ever happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1952 :\n",
      "\n",
      "\tTweet's text':  i think gay wrong like peopl chose gay piss magic old man live sky \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'gay', 'wrong', 'like', 'peopl', 'chose', 'gay', 'piss', 'magic', 'old', 'man', 'live', 'sky'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think gay wrong like peopl chose gay piss magic old man live sky'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1953 :\n",
      "\n",
      "\tTweet's text':  critic promo special featur rape victim air \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BillCosby', '#rape', '#Hypocrites'] \n",
      "\n",
      "\tTweet tokenized by words:  ['critic', 'promo', 'special', 'featur', 'rape', 'victim', 'air'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['critic promo special featur rape victim air'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1954 :\n",
      "\n",
      "\tTweet's text':  if get reelect r possibl cheat collect doom \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PMHarper', '#CPC', '#Canada', '#StockholmSyndrome'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'get', 'reelect', 'r', 'possibl', 'cheat', 'collect', 'doom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if get reelect r possibl cheat collect doom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1955 :\n",
      "\n",
      "\tTweet's text':  trivia crack take life \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['trivia', 'crack', 'take', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['trivia crack take life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1956 :\n",
      "\n",
      "\tTweet's text':  awesom \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1957 :\n",
      "\n",
      "\tTweet's text':  what amaz start weekend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ohgoditsfridayagain'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'amaz', 'start', 'weekend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what amaz start weekend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1958 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1959 :\n",
      "\n",
      "\tTweet's text':  canni wait get new phone sneak cloth thursday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#payday', '#would', '#be', '#rude', '#too'] \n",
      "\n",
      "\tTweet tokenized by words:  ['canni', 'wait', 'get', 'new', 'phone', 'sneak', 'cloth', 'thursday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['canni wait get new phone sneak cloth thursday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1960 :\n",
      "\n",
      "\tTweet's text':  rock christma sock work it littl thing like make happi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['christmas_tree', 'father_christmas'] \n",
      "\n",
      "\tTweet's hashtags':  ['#essentialservice'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rock', 'christma', 'sock', 'work', 'it', 'littl', 'thing', 'like', 'make', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rock christma sock work it littl thing like make happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1961 :\n",
      "\n",
      "\tTweet's text':  not felt i sinc i ko eugh great end great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#beenshite', '#killme'] \n",
      "\n",
      "\tTweet tokenized by words:  ['not', 'felt', 'i', 'sinc', 'i', 'ko', 'eugh', 'great', 'end', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['not felt i sinc i ko eugh great end great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1962 :\n",
      "\n",
      "\tTweet's text':  my grandma gulp hot coco loudli mom goe gulp my grandma i queef \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HAHA'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'grandma', 'gulp', 'hot', 'coco', 'loudli', 'mom', 'goe', 'gulp', 'my', 'grandma', 'i', 'queef'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my grandma gulp hot coco loudli mom goe gulp my grandma i queef'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1963 :\n",
      "\n",
      "\tTweet's text':  so glad found way make gospel social relev klingon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'glad', 'found', 'way', 'make', 'gospel', 'social', 'relev', 'klingon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so glad found way make gospel social relev klingon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1964 :\n",
      "\n",
      "\tTweet's text':  o like rt redskin from famili safe \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HappyThanksgiving'] \n",
      "\n",
      "\tTweet tokenized by words:  ['o', 'like', 'rt', 'redskin', 'from', 'famili', 'safe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['o like rt redskin from famili safe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1965 :\n",
      "\n",
      "\tTweet's text':  my death like caus wrong time \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'death', 'like', 'caus', 'wrong', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my death like caus wrong time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1966 :\n",
      "\n",
      "\tTweet's text':  everybodi keep say gronk larg conting patriot who els rob \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['everybodi', 'keep', 'say', 'gronk', 'larg', 'conting', 'patriot', 'who', 'els', 'rob'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everybodi keep say gronk larg conting patriot who els rob'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1967 :\n",
      "\n",
      "\tTweet's text':  dad step mom bitch christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_smiling_eyes', 'christmas_tree', 'face_with_look_of_triumph'] \n",
      "\n",
      "\tTweet's hashtags':  ['#ugh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dad', 'step', 'mom', 'bitch', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dad step mom bitch christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1968 :\n",
      "\n",
      "\tTweet's text':  internet got like \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['weary_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#stillalive'] \n",
      "\n",
      "\tTweet tokenized by words:  ['internet', 'got', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['internet got like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1969 :\n",
      "\n",
      "\tTweet's text':  the joy i overnight stakeout \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'joy', 'i', 'overnight', 'stakeout'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the joy i overnight stakeout'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1970 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1971 :\n",
      "\n",
      "\tTweet's text':  gut doyl gone back i think saw capabl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wwfc', '#cpfc'] \n",
      "\n",
      "\tTweet tokenized by words:  ['gut', 'doyl', 'gone', 'back', 'i', 'think', 'saw', 'capabl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gut doyl gone back i think saw capabl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1972 :\n",
      "\n",
      "\tTweet's text':  it call \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'call'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it call'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1973 :\n",
      "\n",
      "\tTweet's text':  sunset januari pm temperatur it partli cloudi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sunset', 'januari', 'pm', 'temperatur', 'it', 'partli', 'cloudi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sunset januari pm temperatur it partli cloudi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1974 :\n",
      "\n",
      "\tTweet's text':  can wait boyfriend come home kick butt see evil monkeyfac tear joy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'see-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'boyfriend', 'come', 'home', 'kick', 'butt', 'see', 'evil', 'monkeyfac', 'tear', 'joy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait boyfriend come home kick butt see evil monkeyfac tear joy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1975 :\n",
      "\n",
      "\tTweet's text':  hmmm dinner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hmmm', 'dinner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hmmm dinner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1976 :\n",
      "\n",
      "\tTweet's text':  when challah french toast christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'challah', 'french', 'toast', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when challah french toast christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1977 :\n",
      "\n",
      "\tTweet's text':  far a room \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['far', 'a', 'room'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['far a room'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1978 :\n",
      "\n",
      "\tTweet's text':  would \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#superman', '#childagain'] \n",
      "\n",
      "\tTweet tokenized by words:  ['would'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['would'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1979 :\n",
      "\n",
      "\tTweet's text':  woohoo admit someon liter need noth med refil \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['woohoo', 'admit', 'someon', 'liter', 'need', 'noth', 'med', 'refil'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['woohoo admit someon liter need noth med refil'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1980 :\n",
      "\n",
      "\tTweet's text':  easi part give man money go grab mine tomorrow morn deal town stressful \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['easi', 'part', 'give', 'man', 'money', 'go', 'grab', 'mine', 'tomorrow', 'morn', 'deal', 'town', 'stressful'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['easi part give man money go grab mine tomorrow morn deal town stressful'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1981 :\n",
      "\n",
      "\tTweet's text':  famili time nice i readi back work fine morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['famili', 'time', 'nice', 'i', 'readi', 'back', 'work', 'fine', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['famili time nice i readi back work fine morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1982 :\n",
      "\n",
      "\tTweet's text':  if loos lip sink ship loos tweet sink fleet nasni theatr coronado ca \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'loos', 'lip', 'sink', 'ship', 'loos', 'tweet', 'sink', 'fleet', 'nasni', 'theatr', 'coronado', 'ca'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if loos lip sink ship loos tweet sink fleet nasni theatr coronado ca'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1983 :\n",
      "\n",
      "\tTweet's text':  serious tho need anytim winter break shoot text probabl respond cuz i like eat hey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['serious', 'tho', 'need', 'anytim', 'winter', 'break', 'shoot', 'text', 'probabl', 'respond', 'cuz', 'i', 'like', 'eat', 'hey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['serious tho need anytim winter break shoot text probabl respond cuz i like eat hey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1984 :\n",
      "\n",
      "\tTweet's text':  scream messag we want secur footag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AntonioMartin', '#Ferguson', '#EndRacism', '#SocialJustice', '#BlackLivesMatter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['scream', 'messag', 'we', 'want', 'secur', 'footag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['scream messag we want secur footag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1985 :\n",
      "\n",
      "\tTweet's text':  oh david cameron you would need take twitter peddl piffl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'david', 'cameron', 'you', 'would', 'need', 'take', 'twitter', 'peddl', 'piffl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh david cameron you would need take twitter peddl piffl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1986 :\n",
      "\n",
      "\tTweet's text':  love first day friend famili swim sort cleans curri less time social media time other \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#startasyoumeantogoon'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'first', 'day', 'friend', 'famili', 'swim', 'sort', 'cleans', 'curri', 'less', 'time', 'social', 'media', 'time', 'other'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love first day friend famili swim sort cleans curri less time social media time other'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1987 :\n",
      "\n",
      "\tTweet's text':  left blue bin per calendar lift check websit indic green bin happi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['left', 'blue', 'bin', 'per', 'calendar', 'lift', 'check', 'websit', 'indic', 'green', 'bin', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['left blue bin per calendar lift check websit indic green bin happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1988 :\n",
      "\n",
      "\tTweet's text':  well i face peyton today one leagu i hope td pass d thoma lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'i', 'face', 'peyton', 'today', 'one', 'leagu', 'i', 'hope', 'td', 'pass', 'd', 'thoma', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well i face peyton today one leagu i hope td pass d thoma lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1989 :\n",
      "\n",
      "\tTweet's text':  whi i good game bad game good game bad game \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pouting_face', 'expressionless_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'i', 'good', 'game', 'bad', 'game', 'good', 'game', 'bad', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi i good game bad game good game bad game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1990 :\n",
      "\n",
      "\tTweet's text':  half hour walk \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Proud'] \n",
      "\n",
      "\tTweet tokenized by words:  ['half', 'hour', 'walk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['half hour walk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1991 :\n",
      "\n",
      "\tTweet's text':  anyon he zen oh wait but silli all make sens \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NoodleScene', '#deadHenry', '#bouncebackAnnie'] \n",
      "\n",
      "\tTweet tokenized by words:  ['anyon', 'he', 'zen', 'oh', 'wait', 'but', 'silli', 'all', 'make', 'sens'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anyon he zen oh wait but silli all make sens'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1992 :\n",
      "\n",
      "\tTweet's text':  my year end perfectli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'year', 'end', 'perfectli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my year end perfectli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1993 :\n",
      "\n",
      "\tTweet's text':  to fair deblasio ask folk stop protest post funer so polic protest cool \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BlackLivesMatter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['to', 'fair', 'deblasio', 'ask', 'folk', 'stop', 'protest', 'post', 'funer', 'so', 'polic', 'protest', 'cool'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['to fair deblasio ask folk stop protest post funer so polic protest cool'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1994 :\n",
      "\n",
      "\tTweet's text':  actual go contact rather apologis via twitter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['actual', 'go', 'contact', 'rather', 'apologis', 'via', 'twitter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['actual go contact rather apologis via twitter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1995 :\n",
      "\n",
      "\tTweet's text':  go get broke ass bitch fault \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'get', 'broke', 'ass', 'bitch', 'fault'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go get broke ass bitch fault'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1996 :\n",
      "\n",
      "\tTweet's text':  the thing i see bath bodi work cute \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WorstOutfit', '#WTF'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'thing', 'i', 'see', 'bath', 'bodi', 'work', 'cute'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the thing i see bath bodi work cute'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1997 :\n",
      "\n",
      "\tTweet's text':  seem want endors linkedin thought crowd \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OMCchat'] \n",
      "\n",
      "\tTweet tokenized by words:  ['seem', 'want', 'endors', 'linkedin', 'thought', 'crowd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['seem want endors linkedin thought crowd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1998 :\n",
      "\n",
      "\tTweet's text':  christma part two began parent hous today mani gift mountain wrap paper excit nephew miss batteri veggi chilli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['christma', 'part', 'two', 'began', 'parent', 'hous', 'today', 'mani', 'gift', 'mountain', 'wrap', 'paper', 'excit', 'nephew', 'miss', 'batteri', 'veggi', 'chilli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['christma part two began parent hous today mani gift mountain wrap paper excit nephew miss batteri veggi chilli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  1999 :\n",
      "\n",
      "\tTweet's text':  you great keep convers \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'great', 'keep', 'convers'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you great keep convers'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2000 :\n",
      "\n",
      "\tTweet's text':  men shave head perceiv inch taller stronger men hair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['men', 'shave', 'head', 'perceiv', 'inch', 'taller', 'stronger', 'men', 'hair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['men shave head perceiv inch taller stronger men hair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2001 :\n",
      "\n",
      "\tTweet's text':  i tempt i want one tat mine \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'tempt', 'i', 'want', 'one', 'tat', 'mine'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i tempt i want one tat mine'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2002 :\n",
      "\n",
      "\tTweet's text':  awesom raini day track \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['awesom', 'raini', 'day', 'track'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['awesom raini day track'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2003 :\n",
      "\n",
      "\tTweet's text':  i love work sunday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'work', 'sunday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love work sunday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2004 :\n",
      "\n",
      "\tTweet's text':  burger king hack weirdest funniest definet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['burger', 'king', 'hack', 'weirdest', 'funniest', 'definet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['burger king hack weirdest funniest definet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2005 :\n",
      "\n",
      "\tTweet's text':  whi hard peopl cover mouth cough special old peopl wtf common curtesi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#coveryomouf', '#nasty'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'hard', 'peopl', 'cover', 'mouth', 'cough', 'special', 'old', 'peopl', 'wtf', 'common', 'curtesi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi hard peopl cover mouth cough special old peopl wtf common curtesi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2006 :\n",
      "\n",
      "\tTweet's text':  i know love also freak hate someon much \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'love', 'also', 'freak', 'hate', 'someon', 'much'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know love also freak hate someon much'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2007 :\n",
      "\n",
      "\tTweet's text':  love peopl act like adult \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'peopl', 'act', 'like', 'adult'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love peopl act like adult'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2008 :\n",
      "\n",
      "\tTweet's text':  the spici cali roll cali roll dab sauc w t f \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'spici', 'cali', 'roll', 'cali', 'roll', 'dab', 'sauc', 'w', 't', 'f'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the spici cali roll cali roll dab sauc w t f'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2009 :\n",
      "\n",
      "\tTweet's text':  but time capsul it current time \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'time', 'capsul', 'it', 'current', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but time capsul it current time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2010 :\n",
      "\n",
      "\tTweet's text':  azealia bank call iggi igloo australian wooow incred rapper diss anoth one \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['azealia', 'bank', 'call', 'iggi', 'igloo', 'australian', 'wooow', 'incred', 'rapper', 'diss', 'anoth', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['azealia bank call iggi igloo australian wooow incred rapper diss anoth one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2011 :\n",
      "\n",
      "\tTweet's text':  what call chines millionair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'call', 'chines', 'millionair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what call chines millionair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2012 :\n",
      "\n",
      "\tTweet's text':  custom christma time so nice \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['custom', 'christma', 'time', 'so', 'nice'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['custom christma time so nice'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2013 :\n",
      "\n",
      "\tTweet's text':  first day christma shop tomorrow can wait \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['first', 'day', 'christma', 'shop', 'tomorrow', 'can', 'wait'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['first day christma shop tomorrow can wait'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2014 :\n",
      "\n",
      "\tTweet's text':  visit mani time sez \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pakistan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['visit', 'mani', 'time', 'sez'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['visit mani time sez'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2015 :\n",
      "\n",
      "\tTweet's text':  fut ofc corner faaaantast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fut', 'ofc', 'corner', 'faaaantast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fut ofc corner faaaantast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2016 :\n",
      "\n",
      "\tTweet's text':  small amount lad bird nest hair cut \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ha', '#3allover'] \n",
      "\n",
      "\tTweet tokenized by words:  ['small', 'amount', 'lad', 'bird', 'nest', 'hair', 'cut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['small amount lad bird nest hair cut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2017 :\n",
      "\n",
      "\tTweet's text':  you keep cop civilian account bodi camera rip eric gardner camera keep peopl account peopl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'keep', 'cop', 'civilian', 'account', 'bodi', 'camera', 'rip', 'eric', 'gardner', 'camera', 'keep', 'peopl', 'account', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you keep cop civilian account bodi camera rip eric gardner camera keep peopl account peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2018 :\n",
      "\n",
      "\tTweet's text':  mani servic i offer ask question \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#one', '#people', '#stupid'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mani', 'servic', 'i', 'offer', 'ask', 'question'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mani servic i offer ask question'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2019 :\n",
      "\n",
      "\tTweet's text':  what awesom perform choral student tonight they develop young star futur right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#yeg'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'awesom', 'perform', 'choral', 'student', 'tonight', 'they', 'develop', 'young', 'star', 'futur', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what awesom perform choral student tonight they develop young star futur right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2020 :\n",
      "\n",
      "\tTweet's text':  everi parent want child get ahead help child sponsorship grant \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#charity'] \n",
      "\n",
      "\tTweet tokenized by words:  ['everi', 'parent', 'want', 'child', 'get', 'ahead', 'help', 'child', 'sponsorship', 'grant'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everi parent want child get ahead help child sponsorship grant'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2021 :\n",
      "\n",
      "\tTweet's text':  when one ear break headphon frustrat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#today'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'one', 'ear', 'break', 'headphon', 'frustrat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when one ear break headphon frustrat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2022 :\n",
      "\n",
      "\tTweet's text':  sound like flat wonder morn hah \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HAH', '#WOTWOT'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sound', 'like', 'flat', 'wonder', 'morn', 'hah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sound like flat wonder morn hah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2023 :\n",
      "\n",
      "\tTweet's text':  tri pizza tonight got great job \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Pensacola', '#YUMMY'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tri', 'pizza', 'tonight', 'got', 'great', 'job'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tri pizza tonight got great job'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2024 :\n",
      "\n",
      "\tTweet's text':  so happen acorn voter fraud peopl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'happen', 'acorn', 'voter', 'fraud', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so happen acorn voter fraud peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2025 :\n",
      "\n",
      "\tTweet's text':  wow i glad i cycl weather \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'glad', 'i', 'cycl', 'weather'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i glad i cycl weather'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2026 :\n",
      "\n",
      "\tTweet's text':  yeah honour pictur lyric sketch \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'honour', 'pictur', 'lyric', 'sketch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah honour pictur lyric sketch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2027 :\n",
      "\n",
      "\tTweet's text':  great time learn male reproduct system biggest brightest power point slide ever \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#biology'] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'time', 'learn', 'male', 'reproduct', 'system', 'biggest', 'brightest', 'power', 'point', 'slide', 'ever'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great time learn male reproduct system biggest brightest power point slide ever'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2028 :\n",
      "\n",
      "\tTweet's text':  mvp goe concordia wifi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mvp', 'goe', 'concordia', 'wifi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mvp goe concordia wifi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2029 :\n",
      "\n",
      "\tTweet's text':  such good lie \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['such', 'good', 'lie'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['such good lie'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2030 :\n",
      "\n",
      "\tTweet's text':  i wait go post offic get bent ship fee mail folk gift montana \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Christmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wait', 'go', 'post', 'offic', 'get', 'bent', 'ship', 'fee', 'mail', 'folk', 'gift', 'montana'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wait go post offic get bent ship fee mail folk gift montana'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2031 :\n",
      "\n",
      "\tTweet's text':  can wait weekend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HateSchmoozing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'weekend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait weekend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2032 :\n",
      "\n",
      "\tTweet's text':  the silenc last night broken siren watch ifussss app \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TimesSquare', '#EricGarner', '#NYPD'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'silenc', 'last', 'night', 'broken', 'siren', 'watch', 'ifussss', 'app'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the silenc last night broken siren watch ifussss app'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2033 :\n",
      "\n",
      "\tTweet's text':  tow compani commut car tow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tow', 'compani', 'commut', 'car', 'tow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tow compani commut car tow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2034 :\n",
      "\n",
      "\tTweet's text':  must realli bad game superb comedian like philli phil squeez humor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['must', 'realli', 'bad', 'game', 'superb', 'comedian', 'like', 'philli', 'phil', 'squeez', 'humor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['must realli bad game superb comedian like philli phil squeez humor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2035 :\n",
      "\n",
      "\tTweet's text':  i love happen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2036 :\n",
      "\n",
      "\tTweet's text':  lol it rss agenda modi bribe un offic make yoga day intern \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#secularindia', '#AntiConversionLaw', '#hypocrites'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'it', 'rss', 'agenda', 'modi', 'bribe', 'un', 'offic', 'make', 'yoga', 'day', 'intern'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol it rss agenda modi bribe un offic make yoga day intern'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2037 :\n",
      "\n",
      "\tTweet's text':  what life \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2038 :\n",
      "\n",
      "\tTweet's text':  i found i th grade educ i must slept entir year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'found', 'i', 'th', 'grade', 'educ', 'i', 'must', 'slept', 'entir', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i found i th grade educ i must slept entir year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2039 :\n",
      "\n",
      "\tTweet's text':  keep deficit how success eu budget surveil mechan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcies', '#eu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['keep', 'deficit', 'how', 'success', 'eu', 'budget', 'surveil', 'mechan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['keep deficit how success eu budget surveil mechan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2040 :\n",
      "\n",
      "\tTweet's text':  these girl wake peopl dead \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#worth', '#watching'] \n",
      "\n",
      "\tTweet tokenized by words:  ['these', 'girl', 'wake', 'peopl', 'dead'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['these girl wake peopl dead'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2041 :\n",
      "\n",
      "\tTweet's text':  im done final thursday would nice lol leav friday time \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['airplane'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['im', 'done', 'final', 'thursday', 'would', 'nice', 'lol', 'leav', 'friday', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['im done final thursday would nice lol leav friday time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2042 :\n",
      "\n",
      "\tTweet's text':  sex \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sex'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sex'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2043 :\n",
      "\n",
      "\tTweet's text':  simpli wonder christma time d \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['D'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['simpli', 'wonder', 'christma', 'time', 'd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['simpli wonder christma time d'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2044 :\n",
      "\n",
      "\tTweet's text':  aguero long time citi could buy boni januari \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aguero', 'long', 'time', 'citi', 'could', 'buy', 'boni', 'januari'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aguero long time citi could buy boni januari'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2045 :\n",
      "\n",
      "\tTweet's text':  i happi two hour sleep i got last night \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['weary_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'happi', 'two', 'hour', 'sleep', 'i', 'got', 'last', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i happi two hour sleep i got last night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2046 :\n",
      "\n",
      "\tTweet's text':  the secret focu energi fight old build new sourc unknown quot qvaw \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#change', '#Quotes', '#QvAW'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'secret', 'focu', 'energi', 'fight', 'old', 'build', 'new', 'sourc', 'unknown', 'quot', 'qvaw'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the secret focu energi fight old build new sourc unknown quot qvaw'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2047 :\n",
      "\n",
      "\tTweet's text':  rdey brand ha design the accessori for your easi to carri and comfort \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rdey', 'brand', 'ha', 'design', 'the', 'accessori', 'for', 'your', 'easi', 'to', 'carri', 'and', 'comfort'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rdey brand ha design the accessori for your easi to carri and comfort'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2048 :\n",
      "\n",
      "\tTweet's text':  i check \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'check'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i check'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2049 :\n",
      "\n",
      "\tTweet's text':  last day sew selfi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fashionmajor', '#rough', '#sewing', '#weresogood'] \n",
      "\n",
      "\tTweet tokenized by words:  ['last', 'day', 'sew', 'selfi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['last day sew selfi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2050 :\n",
      "\n",
      "\tTweet's text':  if bjpee hv ball dare lift ristrict mro ahead modi visit kashmiri wl show u much thi love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Kashmir', '#Modi'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'bjpee', 'hv', 'ball', 'dare', 'lift', 'ristrict', 'mro', 'ahead', 'modi', 'visit', 'kashmiri', 'wl', 'show', 'u', 'much', 'thi', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if bjpee hv ball dare lift ristrict mro ahead modi visit kashmiri wl show u much thi love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2051 :\n",
      "\n",
      "\tTweet's text':  she got someth trust it someth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['she', 'got', 'someth', 'trust', 'it', 'someth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['she got someth trust it someth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2052 :\n",
      "\n",
      "\tTweet's text':  if blue ribbon panel good \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'blue', 'ribbon', 'panel', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if blue ribbon panel good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2053 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Indonesia', '#Four', '#large', '#parts', '#crashed', '#AirAsia', '#jet', '#found', '#on', '#sea', '#floor'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2054 :\n",
      "\n",
      "\tTweet's text':  paul believ rubbi webster kelli etc bad player base project i believ upsid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['paul', 'believ', 'rubbi', 'webster', 'kelli', 'etc', 'bad', 'player', 'base', 'project', 'i', 'believ', 'upsid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['paul believ rubbi webster kelli etc bad player base project i believ upsid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2055 :\n",
      "\n",
      "\tTweet's text':  crop child pictur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#motheroftheyear'] \n",
      "\n",
      "\tTweet tokenized by words:  ['crop', 'child', 'pictur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['crop child pictur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2056 :\n",
      "\n",
      "\tTweet's text':  rt of place get stuck traffic jam \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt', 'of', 'place', 'get', 'stuck', 'traffic', 'jam'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt of place get stuck traffic jam'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2057 :\n",
      "\n",
      "\tTweet's text':  oh yess dean smith ref plu side thompson \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#improved'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'yess', 'dean', 'smith', 'ref', 'plu', 'side', 'thompson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh yess dean smith ref plu side thompson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2058 :\n",
      "\n",
      "\tTweet's text':  dark grass rustl www monstermmorpg com \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#brakiest', '#MonsterMMORPG', '#mt121'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dark', 'grass', 'rustl', 'www', 'monstermmorpg', 'com'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dark grass rustl www monstermmorpg com'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2059 :\n",
      "\n",
      "\tTweet's text':  what i food spanish parti \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'i', 'food', 'spanish', 'parti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what i food spanish parti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2060 :\n",
      "\n",
      "\tTweet's text':  street light day clayvil olifantsfontein thi happen problem \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#loadshedding'] \n",
      "\n",
      "\tTweet tokenized by words:  ['street', 'light', 'day', 'clayvil', 'olifantsfontein', 'thi', 'happen', 'problem'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['street light day clayvil olifantsfontein thi happen problem'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2061 :\n",
      "\n",
      "\tTweet's text':  fight endlessli chang system atleast i go anywher irrespect result \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AK4Delhi'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fight', 'endlessli', 'chang', 'system', 'atleast', 'i', 'go', 'anywher', 'irrespect', 'result'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fight endlessli chang system atleast i go anywher irrespect result'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2062 :\n",
      "\n",
      "\tTweet's text':  next day makeup look hawt \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['kiss_mark'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['next', 'day', 'makeup', 'look', 'hawt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['next day makeup look hawt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2063 :\n",
      "\n",
      "\tTweet's text':  the good thing colleg ask even odd even back page worksheet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'good', 'thing', 'colleg', 'ask', 'even', 'odd', 'even', 'back', 'page', 'worksheet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the good thing colleg ask even odd even back page worksheet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2064 :\n",
      "\n",
      "\tTweet's text':  a great day one pour rain walk apart without car apart key \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'great', 'day', 'one', 'pour', 'rain', 'walk', 'apart', 'without', 'car', 'apart', 'key'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a great day one pour rain walk apart without car apart key'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2065 :\n",
      "\n",
      "\tTweet's text':  yep famili feel realli joy right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EricGarner', '#BlackLivesMatter', '#ShutItDown'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yep', 'famili', 'feel', 'realli', 'joy', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yep famili feel realli joy right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2066 :\n",
      "\n",
      "\tTweet's text':  sing live sure hella good look \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#smh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sing', 'live', 'sure', 'hella', 'good', 'look'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sing live sure hella good look'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2067 :\n",
      "\n",
      "\tTweet's text':  noseble morn favorit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['noseble', 'morn', 'favorit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noseble morn favorit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2068 :\n",
      "\n",
      "\tTweet's text':  night realli lol say xxx \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  ['#late', '#shopping', '#bullringbirmingham', '#sunglasses', '#sayyes'] \n",
      "\n",
      "\tTweet tokenized by words:  ['night', 'realli', 'lol', 'say', 'xxx'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['night realli lol say xxx'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2069 :\n",
      "\n",
      "\tTweet's text':  real life believ \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['real', 'life', 'believ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['real life believ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2070 :\n",
      "\n",
      "\tTweet's text':  i hardli think give shite fan tbh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hardli', 'think', 'give', 'shite', 'fan', 'tbh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hardli think give shite fan tbh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2071 :\n",
      "\n",
      "\tTweet's text':  watch wog head i christma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#last', '#hair', '#cut', '#for', '#christmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'wog', 'head', 'i', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch wog head i christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2072 :\n",
      "\n",
      "\tTweet's text':  today fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2073 :\n",
      "\n",
      "\tTweet's text':  get sourc ispr \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'sourc', 'ispr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get sourc ispr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2074 :\n",
      "\n",
      "\tTweet's text':  thank i check anoth store calgari \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'i', 'check', 'anoth', 'store', 'calgari'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank i check anoth store calgari'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2075 :\n",
      "\n",
      "\tTweet's text':  much right brother i done i still car i done prais allah i still \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['much', 'right', 'brother', 'i', 'done', 'i', 'still', 'car', 'i', 'done', 'prais', 'allah', 'i', 'still'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['much right brother i done i still car i done prais allah i still'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2076 :\n",
      "\n",
      "\tTweet's text':  one day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2077 :\n",
      "\n",
      "\tTweet's text':  i thought peopl holiday stream holiday cube day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'thought', 'peopl', 'holiday', 'stream', 'holiday', 'cube', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i thought peopl holiday stream holiday cube day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2078 :\n",
      "\n",
      "\tTweet's text':  thi legendari anfield european cup atmospher great hey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'legendari', 'anfield', 'european', 'cup', 'atmospher', 'great', 'hey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi legendari anfield european cup atmospher great hey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2079 :\n",
      "\n",
      "\tTweet's text':  did invent pueril attack rw press provok led \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lyntoncrosby', '#CameronMustGo', '#webackEd', '#CameronMustGo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['did', 'invent', 'pueril', 'attack', 'rw', 'press', 'provok', 'led'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['did invent pueril attack rw press provok led'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2080 :\n",
      "\n",
      "\tTweet's text':  afford treatment po goe way \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['afford', 'treatment', 'po', 'goe', 'way'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['afford treatment po goe way'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2081 :\n",
      "\n",
      "\tTweet's text':  on page hogfath terri pratchett \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['on', 'page', 'hogfath', 'terri', 'pratchett'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['on page hogfath terri pratchett'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2082 :\n",
      "\n",
      "\tTweet's text':  public hammer steeler week juici \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['public', 'hammer', 'steeler', 'week', 'juici'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['public hammer steeler week juici'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2083 :\n",
      "\n",
      "\tTweet's text':  occupi rent free space cranial caviti lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['occupi', 'rent', 'free', 'space', 'cranial', 'caviti', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['occupi rent free space cranial caviti lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2084 :\n",
      "\n",
      "\tTweet's text':  in fight overtim firefight dc view rule control board perman appeal court say \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fb'] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'fight', 'overtim', 'firefight', 'dc', 'view', 'rule', 'control', 'board', 'perman', 'appeal', 'court', 'say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in fight overtim firefight dc view rule control board perman appeal court say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2085 :\n",
      "\n",
      "\tTweet's text':  that great hour sleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'great', 'hour', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that great hour sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2086 :\n",
      "\n",
      "\tTweet's text':  anamorphosi place object view certain angl creat imag by french artist bernard pra \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['anamorphosi', 'place', 'object', 'view', 'certain', 'angl', 'creat', 'imag', 'by', 'french', 'artist', 'bernard', 'pra'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anamorphosi place object view certain angl creat imag by french artist bernard pra'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2087 :\n",
      "\n",
      "\tTweet's text':  long victim white knight tri save damsel distress \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['long', 'victim', 'white', 'knight', 'tri', 'save', 'damsel', 'distress'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['long victim white knight tri save damsel distress'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2088 :\n",
      "\n",
      "\tTweet's text':  are soror upset sister make organ look bad world see act sororitysist \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SororitySisters'] \n",
      "\n",
      "\tTweet tokenized by words:  ['are', 'soror', 'upset', 'sister', 'make', 'organ', 'look', 'bad', 'world', 'see', 'act', 'sororitysist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['are soror upset sister make organ look bad world see act sororitysist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2089 :\n",
      "\n",
      "\tTweet's text':  mid speech christma lacross ball grand cafe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#flattering'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mid', 'speech', 'christma', 'lacross', 'ball', 'grand', 'cafe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mid speech christma lacross ball grand cafe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2090 :\n",
      "\n",
      "\tTweet's text':  coin lecoincanard coin lecoincanard coin lecoincanard coin deanbcfc wasalrahman question i ask everyday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['coin', 'lecoincanard', 'coin', 'lecoincanard', 'coin', 'lecoincanard', 'coin', 'deanbcfc', 'wasalrahman', 'question', 'i', 'ask', 'everyday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['coin lecoincanard coin lecoincanard coin lecoincanard coin deanbcfc wasalrahman question i ask everyday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2091 :\n",
      "\n",
      "\tTweet's text':  a decent christma parti chang ad bonu miss last train chang \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'decent', 'christma', 'parti', 'chang', 'ad', 'bonu', 'miss', 'last', 'train', 'chang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a decent christma parti chang ad bonu miss last train chang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2092 :\n",
      "\n",
      "\tTweet's text':  love fact i sick birthday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'fact', 'i', 'sick', 'birthday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love fact i sick birthday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2093 :\n",
      "\n",
      "\tTweet's text':  i knit scarf ye knit a scarf becaus manual dexter i like knit problem \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'knit', 'scarf', 'ye', 'knit', 'a', 'scarf', 'becaus', 'manual', 'dexter', 'i', 'like', 'knit', 'problem'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i knit scarf ye knit a scarf becaus manual dexter i like knit problem'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2094 :\n",
      "\n",
      "\tTweet's text':  well \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wrestling', '#SportsEntertainment', '#wwe', '#raw', '#smackdown', '#co'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2095 :\n",
      "\n",
      "\tTweet's text':  black elit enough die hospit rememb that reserv polic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['black', 'elit', 'enough', 'die', 'hospit', 'rememb', 'that', 'reserv', 'polic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['black elit enough die hospit rememb that reserv polic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2096 :\n",
      "\n",
      "\tTweet's text':  serjeym thi year class pictur awesom realli awesom hahahahaha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'fisted_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['serjeym', 'thi', 'year', 'class', 'pictur', 'awesom', 'realli', 'awesom', 'hahahahaha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['serjeym thi year class pictur awesom realli awesom hahahahaha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2097 :\n",
      "\n",
      "\tTweet's text':  am i surpris cowork go show today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Flurries'] \n",
      "\n",
      "\tTweet tokenized by words:  ['am', 'i', 'surpris', 'cowork', 'go', 'show', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['am i surpris cowork go show today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2098 :\n",
      "\n",
      "\tTweet's text':  get readi futur where interview \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'readi', 'futur', 'where', 'interview'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get readi futur where interview'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2099 :\n",
      "\n",
      "\tTweet's text':  enjoy exit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ambition', '#amazing', '#saintsfc', '#ChampionsLeague'] \n",
      "\n",
      "\tTweet tokenized by words:  ['enjoy', 'exit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['enjoy exit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2100 :\n",
      "\n",
      "\tTweet's text':  mayb delet facebook tab caus probabl get stuff done less distract \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mayb', 'delet', 'facebook', 'tab', 'caus', 'probabl', 'get', 'stuff', 'done', 'less', 'distract'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mayb delet facebook tab caus probabl get stuff done less distract'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2101 :\n",
      "\n",
      "\tTweet's text':  realli wanna get ahead i see light end tunnel \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Rangers'] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'wan', 'na', 'get', 'ahead', 'i', 'see', 'light', 'end', 'tunnel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli wanna get ahead i see light end tunnel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2102 :\n",
      "\n",
      "\tTweet's text':  also verb i forgot forget \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['also', 'verb', 'i', 'forgot', 'forget'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['also verb i forgot forget'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2103 :\n",
      "\n",
      "\tTweet's text':  if join pdp cm pdp onli way take support abdullah famili \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BJP', '#HINDU', '#CM'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'join', 'pdp', 'cm', 'pdp', 'onli', 'way', 'take', 'support', 'abdullah', 'famili'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if join pdp cm pdp onli way take support abdullah famili'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2104 :\n",
      "\n",
      "\tTweet's text':  tweet i got back run \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tweet', 'i', 'got', 'back', 'run'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tweet i got back run'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2105 :\n",
      "\n",
      "\tTweet's text':  ay hour narec ko rin yung messag haha thank globe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ay', 'hour', 'narec', 'ko', 'rin', 'yung', 'messag', 'haha', 'thank', 'globe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ay hour narec ko rin yung messag haha thank globe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2106 :\n",
      "\n",
      "\tTweet's text':  what price like \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'price', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what price like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2107 :\n",
      "\n",
      "\tTweet's text':  that wanna tell person fuckin someon els caus might go fuck els lol o \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#moment', '#truth'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'wan', 'na', 'tell', 'person', 'fuckin', 'someon', 'els', 'caus', 'might', 'go', 'fuck', 'els', 'lol', 'o'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that wanna tell person fuckin someon els caus might go fuck els lol o'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2108 :\n",
      "\n",
      "\tTweet's text':  sooooooo look offens coordin well thi bode well next season \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bears', '#whatamess'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sooooooo', 'look', 'offens', 'coordin', 'well', 'thi', 'bode', 'well', 'next', 'season'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sooooooo look offens coordin well thi bode well next season'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2109 :\n",
      "\n",
      "\tTweet's text':  ani hindu tri defend religion commun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Gharwapsi'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ani', 'hindu', 'tri', 'defend', 'religion', 'commun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ani hindu tri defend religion commun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2110 :\n",
      "\n",
      "\tTweet's text':  m think i suit person neil caffrey tvquot whitecollar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TvQuotes', '#WhiteCollar'] \n",
      "\n",
      "\tTweet tokenized by words:  ['m', 'think', 'i', 'suit', 'person', 'neil', 'caffrey', 'tvquot', 'whitecollar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['m think i suit person neil caffrey tvquot whitecollar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2111 :\n",
      "\n",
      "\tTweet's text':  cram psych page brain even though learnt cram effect \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cram', 'psych', 'page', 'brain', 'even', 'though', 'learnt', 'cram', 'effect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cram psych page brain even though learnt cram effect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2112 :\n",
      "\n",
      "\tTweet's text':  i love date show my favourit strictli come danc good work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'date', 'show', 'my', 'favourit', 'strictli', 'come', 'danc', 'good', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love date show my favourit strictli come danc good work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2113 :\n",
      "\n",
      "\tTweet's text':  barakravid break pm netanyahu slam eu countri the european hypocrit learn noth holocaust \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['barakravid', 'break', 'pm', 'netanyahu', 'slam', 'eu', 'countri', 'the', 'european', 'hypocrit', 'learn', 'noth', 'holocaust'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['barakravid break pm netanyahu slam eu countri the european hypocrit learn noth holocaust'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2114 :\n",
      "\n",
      "\tTweet's text':  cooper busi today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cooper', 'busi', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cooper busi today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2115 :\n",
      "\n",
      "\tTweet's text':  merri christma love instagram \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  ['#gifts', '#spam'] \n",
      "\n",
      "\tTweet tokenized by words:  ['merri', 'christma', 'love', 'instagram'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['merri christma love instagram'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2116 :\n",
      "\n",
      "\tTweet's text':  i love i write tweet wrong \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'i', 'write', 'tweet', 'wrong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love i write tweet wrong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2117 :\n",
      "\n",
      "\tTweet's text':  thechicago firehous restaur goe flame \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#chicago', '#fire', '#cfd', '#workingpress', '#cbs', '#wbbm'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thechicago', 'firehous', 'restaur', 'goe', 'flame'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thechicago firehous restaur goe flame'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2118 :\n",
      "\n",
      "\tTweet's text':  nail \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#yesimreadingthisbook', '#catsofinstagram', '#catstagram', '#ilovemycat', '#pawproject'] \n",
      "\n",
      "\tTweet tokenized by words:  ['nail'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nail'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2119 :\n",
      "\n",
      "\tTweet's text':  we prefer lose derbi vs fight ligna trophi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SuC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'prefer', 'lose', 'derbi', 'vs', 'fight', 'ligna', 'trophi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we prefer lose derbi vs fight ligna trophi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2120 :\n",
      "\n",
      "\tTweet's text':  i got manual retweet zach harper \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#internetcelebrity'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'got', 'manual', 'retweet', 'zach', 'harper'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i got manual retweet zach harper'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2121 :\n",
      "\n",
      "\tTweet's text':  thank live tweet morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'live', 'tweet', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank live tweet morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2122 :\n",
      "\n",
      "\tTweet's text':  you look die hard fan \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'look', 'die', 'hard', 'fan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you look die hard fan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2123 :\n",
      "\n",
      "\tTweet's text':  happi stfx day lost it found mo later glisten th green lost creek golf club \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Xring', '#xringmiracle'] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'stfx', 'day', 'lost', 'it', 'found', 'mo', 'later', 'glisten', 'th', 'green', 'lost', 'creek', 'golf', 'club'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi stfx day lost it found mo later glisten th green lost creek golf club'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2124 :\n",
      "\n",
      "\tTweet's text':  piss k rn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['piss', 'k', 'rn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['piss k rn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2125 :\n",
      "\n",
      "\tTweet's text':  i love song \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'song'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love song'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2126 :\n",
      "\n",
      "\tTweet's text':  in music music depart quit unimport \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#umitsaMUSICAL'] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'music', 'music', 'depart', 'quit', 'unimport'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in music music depart quit unimport'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2127 :\n",
      "\n",
      "\tTweet's text':  love come school know i test day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'come', 'school', 'know', 'i', 'test', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love come school know i test day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2128 :\n",
      "\n",
      "\tTweet's text':  long time see \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#long', '#along', '#time', '#times', '#no', '#see', '#me', '#you', '#i', '#your', '#say', '#hi', '#hello', '#want', '#wanna', '#to', '#meet'] \n",
      "\n",
      "\tTweet tokenized by words:  ['long', 'time', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['long time see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2129 :\n",
      "\n",
      "\tTweet's text':  caffein free coffe yeah i next time i slice sugar free p \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['P'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['caffein', 'free', 'coffe', 'yeah', 'i', 'next', 'time', 'i', 'slice', 'sugar', 'free', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['caffein free coffe yeah i next time i slice sugar free p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2130 :\n",
      "\n",
      "\tTweet's text':  in desper need train partner knowledg insight infam candid appli within \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'desper', 'need', 'train', 'partner', 'knowledg', 'insight', 'infam', 'candid', 'appli', 'within'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in desper need train partner knowledg insight infam candid appli within'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2131 :\n",
      "\n",
      "\tTweet's text':  look blackboard call life alert help grade fallen get \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'blackboard', 'call', 'life', 'alert', 'help', 'grade', 'fallen', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look blackboard call life alert help grade fallen get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2132 :\n",
      "\n",
      "\tTweet's text':  i tweet danger glasgow glaswegian parti venu follow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#win'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'tweet', 'danger', 'glasgow', 'glaswegian', 'parti', 'venu', 'follow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i tweet danger glasgow glaswegian parti venu follow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2133 :\n",
      "\n",
      "\tTweet's text':  learn final fuck amaz \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['learn', 'final', 'fuck', 'amaz'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['learn final fuck amaz'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2134 :\n",
      "\n",
      "\tTweet's text':  peopl drink drive pleas \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'drink', 'drive', 'pleas'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl drink drive pleas'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2135 :\n",
      "\n",
      "\tTweet's text':  no i rare drink got stomach bug \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'i', 'rare', 'drink', 'got', 'stomach', 'bug'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no i rare drink got stomach bug'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2136 :\n",
      "\n",
      "\tTweet's text':  some guy chattin shit bu say i look like snoop dogg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#KMT', '#again'] \n",
      "\n",
      "\tTweet tokenized by words:  ['some', 'guy', 'chattin', 'shit', 'bu', 'say', 'i', 'look', 'like', 'snoop', 'dogg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['some guy chattin shit bu say i look like snoop dogg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2137 :\n",
      "\n",
      "\tTweet's text':  allanhawco final chanc watch doyl final thank great season ye i cri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['allanhawco', 'final', 'chanc', 'watch', 'doyl', 'final', 'thank', 'great', 'season', 'ye', 'i', 'cri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['allanhawco final chanc watch doyl final thank great season ye i cri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2138 :\n",
      "\n",
      "\tTweet's text':  peopl lie realli help trust issu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#twittereantaboutlife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'lie', 'realli', 'help', 'trust', 'issu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl lie realli help trust issu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2139 :\n",
      "\n",
      "\tTweet's text':  h n hospit hard \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#badincentives', '#flu', '#healthcare', '#finance', '#SPS'] \n",
      "\n",
      "\tTweet tokenized by words:  ['h', 'n', 'hospit', 'hard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['h n hospit hard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2140 :\n",
      "\n",
      "\tTweet's text':  i care second i got distract \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'care', 'second', 'i', 'got', 'distract'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i care second i got distract'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2141 :\n",
      "\n",
      "\tTweet's text':  explos nice done appar joker i lot common that \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Batman', '#StarTrek'] \n",
      "\n",
      "\tTweet tokenized by words:  ['explos', 'nice', 'done', 'appar', 'joker', 'i', 'lot', 'common', 'that'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['explos nice done appar joker i lot common that'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2142 :\n",
      "\n",
      "\tTweet's text':  session local \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#1stPhoto', '#rektek', '#bmx', '#lookMamNoHands', '#flying', '#fallingWithStyle'] \n",
      "\n",
      "\tTweet tokenized by words:  ['session', 'local'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['session local'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2143 :\n",
      "\n",
      "\tTweet's text':  jesu i watch much look get \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TheNewsroom', '#SonyHack'] \n",
      "\n",
      "\tTweet tokenized by words:  ['jesu', 'i', 'watch', 'much', 'look', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jesu i watch much look get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2144 :\n",
      "\n",
      "\tTweet's text':  nose stuf awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nose', 'stuf', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nose stuf awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2145 :\n",
      "\n",
      "\tTweet's text':  grabe afford na afford \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['grabe', 'afford', 'na', 'afford'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['grabe afford na afford'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2146 :\n",
      "\n",
      "\tTweet's text':  negat sometim peac achiev way accept content constant sear \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['negat', 'sometim', 'peac', 'achiev', 'way', 'accept', 'content', 'constant', 'sear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['negat sometim peac achiev way accept content constant sear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2147 :\n",
      "\n",
      "\tTweet's text':  perti sunris timelaps mountain \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fs100'] \n",
      "\n",
      "\tTweet tokenized by words:  ['perti', 'sunris', 'timelaps', 'mountain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['perti sunris timelaps mountain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2148 :\n",
      "\n",
      "\tTweet's text':  well alway good time lose b \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'alway', 'good', 'time', 'lose', 'b'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well alway good time lose b'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2149 :\n",
      "\n",
      "\tTweet's text':  i promot would i add jazz some ppl anyth b popular \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EDM', '#SoObvious', '#WTF', '#AttentionWhore', '#keepitreal'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'promot', 'would', 'i', 'add', 'jazz', 'some', 'ppl', 'anyth', 'b', 'popular'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i promot would i add jazz some ppl anyth b popular'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2150 :\n",
      "\n",
      "\tTweet's text':  wow rickman realli look lot differ blond hair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'rickman', 'realli', 'look', 'lot', 'differ', 'blond', 'hair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow rickman realli look lot differ blond hair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2151 :\n",
      "\n",
      "\tTweet's text':  my grandma tell made ravioli eat you know i yell back fuck i want ravioli nigga \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'grandma', 'tell', 'made', 'ravioli', 'eat', 'you', 'know', 'i', 'yell', 'back', 'fuck', 'i', 'want', 'ravioli', 'nigga'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my grandma tell made ravioli eat you know i yell back fuck i want ravioli nigga'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2152 :\n",
      "\n",
      "\tTweet's text':  reason someon bio moron so everyon els \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SoDemocratic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['reason', 'someon', 'bio', 'moron', 'so', 'everyon', 'els'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['reason someon bio moron so everyon els'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2153 :\n",
      "\n",
      "\tTweet's text':  so excit whole new episod rhoa love show \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'excit', 'whole', 'new', 'episod', 'rhoa', 'love', 'show'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so excit whole new episod rhoa love show'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2154 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#take', '#a', '#deep', '#breath', '#it', '#just', '#a', '#bad', '#day', '#a', '#bad', '#life'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2155 :\n",
      "\n",
      "\tTweet's text':  munro facial express facial express right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#But', '#I', '#giving', '#up', '#on'] \n",
      "\n",
      "\tTweet tokenized by words:  ['munro', 'facial', 'express', 'facial', 'express', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['munro facial express facial express right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2156 :\n",
      "\n",
      "\tTweet's text':  followup ferguson stereotyp talk audio kid want hood rat stuff \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['followup', 'ferguson', 'stereotyp', 'talk', 'audio', 'kid', 'want', 'hood', 'rat', 'stuff'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['followup ferguson stereotyp talk audio kid want hood rat stuff'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2157 :\n",
      "\n",
      "\tTweet's text':  ass ohh yeaa \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ass', 'ohh', 'yeaa'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ass ohh yeaa'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2158 :\n",
      "\n",
      "\tTweet's text':  i m not gonna ask you for follow your decis \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'm', 'not', 'gon', 'na', 'ask', 'you', 'for', 'follow', 'your', 'decis'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i m not gonna ask you for follow your decis'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2159 :\n",
      "\n",
      "\tTweet's text':  i think joke \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'joke'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think joke'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2160 :\n",
      "\n",
      "\tTweet's text':  it could jihadist hello it jihadist radic islamist terrorist sydneysieg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sydneysiege', '#Daesh'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by words:  ['it', 'could', 'jihadist', 'hello', 'it', 'jihadist', 'radic', 'islamist', 'terrorist', 'sydneysieg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it could jihadist hello it jihadist radic islamist terrorist sydneysieg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2161 :\n",
      "\n",
      "\tTweet's text':  becaus bill make much money make speech honest \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['becaus', 'bill', 'make', 'much', 'money', 'make', 'speech', 'honest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['becaus bill make much money make speech honest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2162 :\n",
      "\n",
      "\tTweet's text':  well today start great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'today', 'start', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well today start great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2163 :\n",
      "\n",
      "\tTweet's text':  just friendli remind \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#motto', '#advice', '#you', '#are', '#defined', '#by', '#your', '#past'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'friendli', 'remind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just friendli remind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2164 :\n",
      "\n",
      "\tTweet's text':  aren love snow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Stockport'] \n",
      "\n",
      "\tTweet tokenized by words:  ['aren', 'love', 'snow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aren love snow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2165 :\n",
      "\n",
      "\tTweet's text':  go subscrib youtub \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'subscrib', 'youtub'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go subscrib youtub'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2166 :\n",
      "\n",
      "\tTweet's text':  when bish defollow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#disney', '#belle', '#MoreFollowersPlease'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'bish', 'defollow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when bish defollow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2167 :\n",
      "\n",
      "\tTweet's text':  horribl day cambuslang christmasi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['horribl', 'day', 'cambuslang', 'christmasi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['horribl day cambuslang christmasi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2168 :\n",
      "\n",
      "\tTweet's text':  ooooo touch odb greatest giant player ever play \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ooooo', 'touch', 'odb', 'greatest', 'giant', 'player', 'ever', 'play'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ooooo touch odb greatest giant player ever play'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2169 :\n",
      "\n",
      "\tTweet's text':  shame on jacksonvil and \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#JAGS', '#SHADKHAN', '#Police', '#stooges'] \n",
      "\n",
      "\tTweet tokenized by words:  ['shame', 'on', 'jacksonvil', 'and'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shame on jacksonvil and'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2170 :\n",
      "\n",
      "\tTweet's text':  at \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#beastside', '#tahiti'] \n",
      "\n",
      "\tTweet tokenized by words:  ['at'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['at'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2171 :\n",
      "\n",
      "\tTweet's text':  i sure hope ev vaccin date \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoBolts'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'sure', 'hope', 'ev', 'vaccin', 'date'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i sure hope ev vaccin date'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2172 :\n",
      "\n",
      "\tTweet's text':  so beauti get follow speak evil monkey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'beauti', 'get', 'follow', 'speak', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so beauti get follow speak evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2173 :\n",
      "\n",
      "\tTweet's text':  just book back massag hope stop groan crimbo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['wrapped_present', 'thumbs_up_sign', 'father_christmas'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'book', 'back', 'massag', 'hope', 'stop', 'groan', 'crimbo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just book back massag hope stop groan crimbo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2174 :\n",
      "\n",
      "\tTweet's text':  i mad matter min i stand talk \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'mad', 'matter', 'min', 'i', 'stand', 'talk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i mad matter min i stand talk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2175 :\n",
      "\n",
      "\tTweet's text':  alway forget good f e a r ian brown \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['headphone'] \n",
      "\n",
      "\tTweet's hashtags':  ['#singingoutloud', '#TUNE'] \n",
      "\n",
      "\tTweet tokenized by words:  ['alway', 'forget', 'good', 'f', 'e', 'a', 'r', 'ian', 'brown'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alway forget good f e a r ian brown'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2176 :\n",
      "\n",
      "\tTweet's text':  complet sensation infer cub seriou win wednesday joke \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['complet', 'sensation', 'infer', 'cub', 'seriou', 'win', 'wednesday', 'joke'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['complet sensation infer cub seriou win wednesday joke'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2177 :\n",
      "\n",
      "\tTweet's text':  so excit christma parti snobbi side fammm \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'excit', 'christma', 'parti', 'snobbi', 'side', 'fammm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so excit christma parti snobbi side fammm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2178 :\n",
      "\n",
      "\tTweet's text':  ikr thi true battlefield game \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ikr', 'thi', 'true', 'battlefield', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ikr thi true battlefield game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2179 :\n",
      "\n",
      "\tTweet's text':  how propos determin side i black white famili member \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#racewar', '#LoveNotWar'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'propos', 'determin', 'side', 'i', 'black', 'white', 'famili', 'member'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how propos determin side i black white famili member'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2180 :\n",
      "\n",
      "\tTweet's text':  okay back studi math final \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['okay', 'back', 'studi', 'math', 'final'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['okay back studi math final'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2181 :\n",
      "\n",
      "\tTweet's text':  yesss what make wors look gorgeou say i got face beat wtf \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Contradiction'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yesss', 'what', 'make', 'wors', 'look', 'gorgeou', 'say', 'i', 'got', 'face', 'beat', 'wtf'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yesss what make wors look gorgeou say i got face beat wtf'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2182 :\n",
      "\n",
      "\tTweet's text':  jack understand twitter thought \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jack', 'understand', 'twitter', 'thought'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jack understand twitter thought'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2183 :\n",
      "\n",
      "\tTweet's text':  alaska flowtron what thi world come to rizzl p boon pratt token r \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HipHop'] \n",
      "\n",
      "\tTweet tokenized by words:  ['alaska', 'flowtron', 'what', 'thi', 'world', 'come', 'to', 'rizzl', 'p', 'boon', 'pratt', 'token', 'r'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alaska flowtron what thi world come to rizzl p boon pratt token r'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2184 :\n",
      "\n",
      "\tTweet's text':  oh man you get everyon sing readi i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'man', 'you', 'get', 'everyon', 'sing', 'readi', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh man you get everyon sing readi i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2185 :\n",
      "\n",
      "\tTweet's text':  happi holiday boy carl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_sunglasses', 'christmas_tree', 'smirking_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#lrs', '#holiday', '#party'] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'holiday', 'boy', 'carl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi holiday boy carl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2186 :\n",
      "\n",
      "\tTweet's text':  thank amaz candl new seri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#atmosphere'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'amaz', 'candl', 'new', 'seri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank amaz candl new seri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2187 :\n",
      "\n",
      "\tTweet's text':  dissect rat first period great start day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['mouse'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dissect', 'rat', 'first', 'period', 'great', 'start', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dissect rat first period great start day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2188 :\n",
      "\n",
      "\tTweet's text':  buzz school monday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['buzz', 'school', 'monday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['buzz school monday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2189 :\n",
      "\n",
      "\tTweet's text':  thi point along tc prove best advertis teen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ecigs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'point', 'along', 'tc', 'prove', 'best', 'advertis', 'teen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi point along tc prove best advertis teen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2190 :\n",
      "\n",
      "\tTweet's text':  obvi everi jesuit heret \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['information_desk_person'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['obvi', 'everi', 'jesuit', 'heret'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['obvi everi jesuit heret'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2191 :\n",
      "\n",
      "\tTweet's text':  it much fun drive front wheel drive car snow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'much', 'fun', 'drive', 'front', 'wheel', 'drive', 'car', 'snow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it much fun drive front wheel drive car snow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2192 :\n",
      "\n",
      "\tTweet's text':  aah ye rajneesh saab lol controversi figur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aah', 'ye', 'rajneesh', 'saab', 'lol', 'controversi', 'figur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aah ye rajneesh saab lol controversi figur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2193 :\n",
      "\n",
      "\tTweet's text':  nowaday everyth somebodi ever want still get play mxm men \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nowaday', 'everyth', 'somebodi', 'ever', 'want', 'still', 'get', 'play', 'mxm', 'men'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nowaday everyth somebodi ever want still get play mxm men'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2194 :\n",
      "\n",
      "\tTweet's text':  drink imperi ipa \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#photo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['drink', 'imperi', 'ipa'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['drink imperi ipa'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2195 :\n",
      "\n",
      "\tTweet's text':  lunch today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fakelobster', '#lifestyleoftherichandfamous', '#worldofswede'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lunch', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lunch today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2196 :\n",
      "\n",
      "\tTweet's text':  laboureoin few politician get import patient digniti right die \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['laboureoin', 'few', 'politician', 'get', 'import', 'patient', 'digniti', 'right', 'die'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['laboureoin few politician get import patient digniti right die'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2197 :\n",
      "\n",
      "\tTweet's text':  by ideiasdebolosdocesedelicia such differ twist regular cake we love one \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ff', '#frozen'] \n",
      "\n",
      "\tTweet tokenized by words:  ['by', 'ideiasdebolosdocesedelicia', 'such', 'differ', 'twist', 'regular', 'cake', 'we', 'love', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['by ideiasdebolosdocesedelicia such differ twist regular cake we love one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2198 :\n",
      "\n",
      "\tTweet's text':  we monitor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'monitor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we monitor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2199 :\n",
      "\n",
      "\tTweet's text':  woman put man iron support iron \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['woman', 'put', 'man', 'iron', 'support', 'iron'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['woman put man iron support iron'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2200 :\n",
      "\n",
      "\tTweet's text':  filmmak writer nicol franklin twitter pl follow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EConvo', '#Film', '#Director'] \n",
      "\n",
      "\tTweet tokenized by words:  ['filmmak', 'writer', 'nicol', 'franklin', 'twitter', 'pl', 'follow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['filmmak writer nicol franklin twitter pl follow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2201 :\n",
      "\n",
      "\tTweet's text':  he perfect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['he', 'perfect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['he perfect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2202 :\n",
      "\n",
      "\tTweet's text':  substitut for chicken nugget \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['substitut', 'for', 'chicken', 'nugget'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['substitut for chicken nugget'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2203 :\n",
      "\n",
      "\tTweet's text':  i wait \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wait'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wait'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2204 :\n",
      "\n",
      "\tTweet's text':  work done gym done steak tea friday tomorrow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth', 'thumbs_up_sign'] \n",
      "\n",
      "\tTweet's hashtags':  ['#woohoo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'done', 'gym', 'done', 'steak', 'tea', 'friday', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work done gym done steak tea friday tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2205 :\n",
      "\n",
      "\tTweet's text':  it \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2206 :\n",
      "\n",
      "\tTweet's text':  eeeek cinema date boo weekend see evil monkeytwo heart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['eeeek', 'cinema', 'date', 'boo', 'weekend', 'see', 'evil', 'monkeytwo', 'heart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['eeeek cinema date boo weekend see evil monkeytwo heart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2207 :\n",
      "\n",
      "\tTweet's text':  highway clean section highway peopl express freedom speech \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['highway', 'clean', 'section', 'highway', 'peopl', 'express', 'freedom', 'speech'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['highway clean section highway peopl express freedom speech'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2208 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ukraine', '#President', '#meet', '#Russian', '#French', '#German', '#leaders', '#rules', '#out', '#offensive'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2209 :\n",
      "\n",
      "\tTweet's text':  i definit caught sister flu feel chesti cough brew best start week tgim \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'definit', 'caught', 'sister', 'flu', 'feel', 'chesti', 'cough', 'brew', 'best', 'start', 'week', 'tgim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i definit caught sister flu feel chesti cough brew best start week tgim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2210 :\n",
      "\n",
      "\tTweet's text':  air passeng duti abolish at last someth help homeless impoverish \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AutumnStatement'] \n",
      "\n",
      "\tTweet tokenized by words:  ['air', 'passeng', 'duti', 'abolish', 'at', 'last', 'someth', 'help', 'homeless', 'impoverish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['air passeng duti abolish at last someth help homeless impoverish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2211 :\n",
      "\n",
      "\tTweet's text':  i alway forget mani earnest look back fondli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#activists', '#radicals', '#classwar'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'alway', 'forget', 'mani', 'earnest', 'look', 'back', 'fondli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i alway forget mani earnest look back fondli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2212 :\n",
      "\n",
      "\tTweet's text':  ooh i probabl watch replay launch point oh wonder that sooo excit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#orion', '#nothanks'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ooh', 'i', 'probabl', 'watch', 'replay', 'launch', 'point', 'oh', 'wonder', 'that', 'sooo', 'excit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ooh i probabl watch replay launch point oh wonder that sooo excit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2213 :\n",
      "\n",
      "\tTweet's text':  love fact school smell like sewer \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_medical_mask'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'fact', 'school', 'smell', 'like', 'sewer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love fact school smell like sewer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2214 :\n",
      "\n",
      "\tTweet's text':  is display given time ryerson \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'display', 'given', 'time', 'ryerson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is display given time ryerson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2215 :\n",
      "\n",
      "\tTweet's text':  day sun sunni today decemberphotochalleng \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['cloud'] \n",
      "\n",
      "\tTweet's hashtags':  ['#DecemberPhotoChallenge', '#france', '#sun', '#or', '#today', '#day3'] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'sun', 'sunni', 'today', 'decemberphotochalleng'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day sun sunni today decemberphotochalleng'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2216 :\n",
      "\n",
      "\tTweet's text':  insult piano song shut fuck man bet thought \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#JeremyNortham', '#epic', '#GosfordPark'] \n",
      "\n",
      "\tTweet tokenized by words:  ['insult', 'piano', 'song', 'shut', 'fuck', 'man', 'bet', 'thought'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['insult piano song shut fuck man bet thought'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2217 :\n",
      "\n",
      "\tTweet's text':  exactli i want start day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#shitty'] \n",
      "\n",
      "\tTweet tokenized by words:  ['exactli', 'i', 'want', 'start', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['exactli i want start day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2218 :\n",
      "\n",
      "\tTweet's text':  thank much such gener display kind side \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'much', 'such', 'gener', 'display', 'kind', 'side'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank much such gener display kind side'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2219 :\n",
      "\n",
      "\tTweet's text':  when u callin i tappin lol sorri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'u', 'callin', 'i', 'tappin', 'lol', 'sorri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when u callin i tappin lol sorri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2220 :\n",
      "\n",
      "\tTweet's text':  i know fact sam gonna school today realli cherri top perfect monday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'fact', 'sam', 'gon', 'na', 'school', 'today', 'realli', 'cherri', 'top', 'perfect', 'monday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know fact sam gonna school today realli cherri top perfect monday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2221 :\n",
      "\n",
      "\tTweet's text':  it christma miracl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'christma', 'miracl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it christma miracl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2222 :\n",
      "\n",
      "\tTweet's text':  work fun today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'fun', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work fun today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2223 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#euphemism', '#CoerciveControl', '#coined', '#MAN', '#lovingly', '#appropriated', '#radical', '#feminist', '#agenda'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2224 :\n",
      "\n",
      "\tTweet's text':  my bed time stori awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#theyllgiveyounightmares', '#ohwell', '#youaskedforit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'bed', 'time', 'stori', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my bed time stori awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2225 :\n",
      "\n",
      "\tTweet's text':  thank stat teacher drop lowest quiz \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lifesaved'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'stat', 'teacher', 'drop', 'lowest', 'quiz'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank stat teacher drop lowest quiz'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2226 :\n",
      "\n",
      "\tTweet's text':  thi sound like load freez drizzl rain km h \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'sound', 'like', 'load', 'freez', 'drizzl', 'rain', 'km', 'h'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi sound like load freez drizzl rain km h'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2227 :\n",
      "\n",
      "\tTweet's text':  well done you twitter follow you succeed life \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'done', 'you', 'twitter', 'follow', 'you', 'succeed', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well done you twitter follow you succeed life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2228 :\n",
      "\n",
      "\tTweet's text':  still work gonna prime \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['still', 'work', 'gon', 'na', 'prime'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['still work gonna prime'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2229 :\n",
      "\n",
      "\tTweet's text':  rt babi name \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dataviz'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt', 'babi', 'name'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt babi name'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2230 :\n",
      "\n",
      "\tTweet's text':  let pretend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'pretend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let pretend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2231 :\n",
      "\n",
      "\tTweet's text':  what import thing today breath \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'import', 'thing', 'today', 'breath'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what import thing today breath'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2232 :\n",
      "\n",
      "\tTweet's text':  just seen bike bike \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'seen', 'bike', 'bike'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just seen bike bike'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2233 :\n",
      "\n",
      "\tTweet's text':  happi christma may bring good health happi everi success wish \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'christma', 'may', 'bring', 'good', 'health', 'happi', 'everi', 'success', 'wish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi christma may bring good health happi everi success wish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2234 :\n",
      "\n",
      "\tTweet's text':  i love hold especi music great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'hold', 'especi', 'music', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love hold especi music great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2235 :\n",
      "\n",
      "\tTweet's text':  peshawar school massacr pak must know greater enemi terror india peshawarattack \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Peshawarattack'] \n",
      "\n",
      "\tTweet tokenized by words:  ['peshawar', 'school', 'massacr', 'pak', 'must', 'know', 'greater', 'enemi', 'terror', 'india', 'peshawarattack'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peshawar school massacr pak must know greater enemi terror india peshawarattack'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2236 :\n",
      "\n",
      "\tTweet's text':  of cours one lectur happen bar restaur birthday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['of', 'cours', 'one', 'lectur', 'happen', 'bar', 'restaur', 'birthday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['of cours one lectur happen bar restaur birthday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2237 :\n",
      "\n",
      "\tTweet's text':  hate anti american anti constitut polici action fix \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hate', 'anti', 'american', 'anti', 'constitut', 'polici', 'action', 'fix'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hate anti american anti constitut polici action fix'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2238 :\n",
      "\n",
      "\tTweet's text':  guess brett mom year gotta love famili \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['guess', 'brett', 'mom', 'year', 'got', 'ta', 'love', 'famili'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['guess brett mom year gotta love famili'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2239 :\n",
      "\n",
      "\tTweet's text':  word mockeri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['persevering_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['word', 'mockeri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['word mockeri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2240 :\n",
      "\n",
      "\tTweet's text':  i think go get check \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'go', 'get', 'check'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think go get check'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2241 :\n",
      "\n",
      "\tTweet's text':  becauseee i miss youu coffe later \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['becauseee', 'i', 'miss', 'youu', 'coffe', 'later'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['becauseee i miss youu coffe later'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2242 :\n",
      "\n",
      "\tTweet's text':  never way round \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#IndiawithPakistan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['never', 'way', 'round'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['never way round'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2243 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TeenAnalCasting', '#She'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2244 :\n",
      "\n",
      "\tTweet's text':  and freez yay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'freez', 'yay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and freez yay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2245 :\n",
      "\n",
      "\tTweet's text':  back kill today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grimacing_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#tramadol'] \n",
      "\n",
      "\tTweet tokenized by words:  ['back', 'kill', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['back kill today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2246 :\n",
      "\n",
      "\tTweet's text':  i need misadventur form i broke hand practis rewrit english essay time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'need', 'misadventur', 'form', 'i', 'broke', 'hand', 'practis', 'rewrit', 'english', 'essay', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i need misadventur form i broke hand practis rewrit english essay time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2247 :\n",
      "\n",
      "\tTweet's text':  am christma day heat pizza breadstick \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#theboysarebackintown'] \n",
      "\n",
      "\tTweet tokenized by words:  ['am', 'christma', 'day', 'heat', 'pizza', 'breadstick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['am christma day heat pizza breadstick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2248 :\n",
      "\n",
      "\tTweet's text':  beauti day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['beauti', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['beauti day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2249 :\n",
      "\n",
      "\tTweet's text':  nypd comment provid intern w involv info given fbi sinc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['skull', 's'] \n",
      "\n",
      "\tTweet's hashtags':  ['#NYPD', '#statistics'] \n",
      "\n",
      "\tTweet tokenized by words:  ['nypd', 'comment', 'provid', 'intern', 'w', 'involv', 'info', 'given', 'fbi', 'sinc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nypd comment provid intern w involv info given fbi sinc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2250 :\n",
      "\n",
      "\tTweet's text':  those mini nap i night sneez cough blow nose super rest \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fluday4'] \n",
      "\n",
      "\tTweet tokenized by words:  ['those', 'mini', 'nap', 'i', 'night', 'sneez', 'cough', 'blow', 'nose', 'super', 'rest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['those mini nap i night sneez cough blow nose super rest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2251 :\n",
      "\n",
      "\tTweet's text':  dress style \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#kimk', '#balenciaga', '#kimkardashianwest', '#kimkardashian', '#vestito', '#moda', '#2014', '#go'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dress', 'style'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dress style'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2252 :\n",
      "\n",
      "\tTweet's text':  legisl list legisl accomplis past year short \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['legisl', 'list', 'legisl', 'accomplis', 'past', 'year', 'short'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['legisl list legisl accomplis past year short'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2253 :\n",
      "\n",
      "\tTweet's text':  the number play awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'number', 'play', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the number play awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2254 :\n",
      "\n",
      "\tTweet's text':  draw littl believ draw good \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#drawing', '#daughter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['draw', 'littl', 'believ', 'draw', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['draw littl believ draw good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2255 :\n",
      "\n",
      "\tTweet's text':  downplay social media use hashtag \n",
      "\n",
      "\tTweet's score':  1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#givepresence'] \n",
      "\n",
      "\tTweet tokenized by words:  ['downplay', 'social', 'media', 'use', 'hashtag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['downplay social media use hashtag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2256 :\n",
      "\n",
      "\tTweet's text':  journal best \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['journal', 'best'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['journal best'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2257 :\n",
      "\n",
      "\tTweet's text':  loadshed eissh wonder eskom cell c partner both get paid servic suck dialinginthedark \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dialinginthedark'] \n",
      "\n",
      "\tTweet tokenized by words:  ['loadshed', 'eissh', 'wonder', 'eskom', 'cell', 'c', 'partner', 'both', 'get', 'paid', 'servic', 'suck', 'dialinginthedark'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['loadshed eissh wonder eskom cell c partner both get paid servic suck dialinginthedark'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2258 :\n",
      "\n",
      "\tTweet's text':  i went europ \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'went', 'europ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i went europ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2259 :\n",
      "\n",
      "\tTweet's text':  us look sexi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MehRockingMyBluMonsoonT'] \n",
      "\n",
      "\tTweet tokenized by words:  ['us', 'look', 'sexi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['us look sexi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2260 :\n",
      "\n",
      "\tTweet's text':  check \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['check'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['check'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2261 :\n",
      "\n",
      "\tTweet's text':  will probabl get write show \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['will', 'probabl', 'get', 'write', 'show'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['will probabl get write show'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2262 :\n",
      "\n",
      "\tTweet's text':  rush rush rush done pow footbal window glasseverywher \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#glasseverywhere', '#boyswillbeboys'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rush', 'rush', 'rush', 'done', 'pow', 'footbal', 'window', 'glasseverywher'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rush rush rush done pow footbal window glasseverywher'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2263 :\n",
      "\n",
      "\tTweet's text':  thi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2264 :\n",
      "\n",
      "\tTweet's text':  welcom metro rt thank seattl prep final remov starter left \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['welcom', 'metro', 'rt', 'thank', 'seattl', 'prep', 'final', 'remov', 'starter', 'left'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['welcom metro rt thank seattl prep final remov starter left'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2265 :\n",
      "\n",
      "\tTweet's text':  haha love i accident spray perfum eye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_ok_gesture'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'love', 'i', 'accident', 'spray', 'perfum', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha love i accident spray perfum eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2266 :\n",
      "\n",
      "\tTweet's text':  i what prize \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'what', 'prize'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i what prize'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2267 :\n",
      "\n",
      "\tTweet's text':  predict putin ditch rubl adopt bitcoin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['predict', 'putin', 'ditch', 'rubl', 'adopt', 'bitcoin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['predict putin ditch rubl adopt bitcoin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2268 :\n",
      "\n",
      "\tTweet's text':  sarcasm thing like \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sarcasticbitch'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sarcasm', 'thing', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sarcasm thing like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2269 :\n",
      "\n",
      "\tTweet's text':  the long commut work \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#KeyboardCowboy', '#anyonecancode'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'long', 'commut', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the long commut work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2270 :\n",
      "\n",
      "\tTweet's text':  i keep see need build global societi person i rather american societi back \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tcot', '#EricGarner', '#Ferguson'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'keep', 'see', 'need', 'build', 'global', 'societi', 'person', 'i', 'rather', 'american', 'societi', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i keep see need build global societi person i rather american societi back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2271 :\n",
      "\n",
      "\tTweet's text':  whi must i pay car insur i don get rip trust goskippi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'must', 'i', 'pay', 'car', 'insur', 'i', 'don', 'get', 'rip', 'trust', 'goskippi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi must i pay car insur i don get rip trust goskippi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2272 :\n",
      "\n",
      "\tTweet's text':  malay mo real name haha still nice joke na richard two bagong bago hahahhaah jk \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['malay', 'mo', 'real', 'name', 'haha', 'still', 'nice', 'joke', 'na', 'richard', 'two', 'bagong', 'bago', 'hahahhaah', 'jk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['malay mo real name haha still nice joke na richard two bagong bago hahahhaah jk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2273 :\n",
      "\n",
      "\tTweet's text':  i tell ceaccp book make crack bonfir \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#frca', '#freedom'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'tell', 'ceaccp', 'book', 'make', 'crack', 'bonfir'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i tell ceaccp book make crack bonfir'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2274 :\n",
      "\n",
      "\tTweet's text':  s play non electron game \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['s', 'play', 'non', 'electron', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['s play non electron game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2275 :\n",
      "\n",
      "\tTweet's text':  thi song aw \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'song', 'aw'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi song aw'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2276 :\n",
      "\n",
      "\tTweet's text':  what shock duke johnson hurt import game \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#canes'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'shock', 'duke', 'johnson', 'hurt', 'import', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what shock duke johnson hurt import game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2277 :\n",
      "\n",
      "\tTweet's text':  my five day share \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Christmas', '#infosec', '#hirefriday', '#humor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'five', 'day', 'share'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my five day share'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2278 :\n",
      "\n",
      "\tTweet's text':  omg want one i easypay express thi would mean i would use ride path \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['omg', 'want', 'one', 'i', 'easypay', 'express', 'thi', 'would', 'mean', 'i', 'would', 'use', 'ride', 'path'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['omg want one i easypay express thi would mean i would use ride path'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2279 :\n",
      "\n",
      "\tTweet's text':  i differ i back \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#rowdy', '#banter', '#toomuchlove', '#360family'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'differ', 'i', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i differ i back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2280 :\n",
      "\n",
      "\tTweet's text':  dear next person seek educ anyth pleas educ mean know multipl point view http \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dear', 'next', 'person', 'seek', 'educ', 'anyth', 'pleas', 'educ', 'mean', 'know', 'multipl', 'point', 'view', 'http'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dear next person seek educ anyth pleas educ mean know multipl point view http'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2281 :\n",
      "\n",
      "\tTweet's text':  i think appl make icloud servic option littl confus it realli get good \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'appl', 'make', 'icloud', 'servic', 'option', 'littl', 'confus', 'it', 'realli', 'get', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think appl make icloud servic option littl confus it realli get good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2282 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GapeLand', '#Super', '#8230'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2283 :\n",
      "\n",
      "\tTweet's text':  spoil rancid food and gun aisl rat great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GroceriesNotGuns'] \n",
      "\n",
      "\tTweet tokenized by words:  ['spoil', 'rancid', 'food', 'and', 'gun', 'aisl', 'rat', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['spoil rancid food and gun aisl rat great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2284 :\n",
      "\n",
      "\tTweet's text':  never end pointless cunt win tit tat zero account hunner finger point \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['never', 'end', 'pointless', 'cunt', 'win', 'tit', 'tat', 'zero', 'account', 'hunner', 'finger', 'point'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['never end pointless cunt win tit tat zero account hunner finger point'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2285 :\n",
      "\n",
      "\tTweet's text':  anoth fantast day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'fantast', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth fantast day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2286 :\n",
      "\n",
      "\tTweet's text':  cloth black \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['bomb'] \n",
      "\n",
      "\tTweet's hashtags':  ['#noshame'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cloth', 'black'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cloth black'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2287 :\n",
      "\n",
      "\tTweet's text':  hey know one wit support darren wilson stori lie and racist mind blown \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'know', 'one', 'wit', 'support', 'darren', 'wilson', 'stori', 'lie', 'and', 'racist', 'mind', 'blown'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey know one wit support darren wilson stori lie and racist mind blown'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2288 :\n",
      "\n",
      "\tTweet's text':  ye i time it easi thing i common knowledg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'i', 'time', 'it', 'easi', 'thing', 'i', 'common', 'knowledg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye i time it easi thing i common knowledg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2289 :\n",
      "\n",
      "\tTweet's text':  due damn near \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#LOL', '#Respect', '#KobeBryant', '#MJ', '#Close', '#Legends'] \n",
      "\n",
      "\tTweet tokenized by words:  ['due', 'damn', 'near'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['due damn near'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2290 :\n",
      "\n",
      "\tTweet's text':  sound like jack kerouac \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sound', 'like', 'jack', 'kerouac'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sound like jack kerouac'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2291 :\n",
      "\n",
      "\tTweet's text':  dutch northern there combo speak yr mind \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dutch', 'northern', 'there', 'combo', 'speak', 'yr', 'mind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dutch northern there combo speak yr mind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2292 :\n",
      "\n",
      "\tTweet's text':  bring will look forward easter one funnili enough crave salad fruit round xma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bring', 'will', 'look', 'forward', 'easter', 'one', 'funnili', 'enough', 'crave', 'salad', 'fruit', 'round', 'xma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bring will look forward easter one funnili enough crave salad fruit round xma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2293 :\n",
      "\n",
      "\tTweet's text':  indonesia blasphemi law ministri religi affair also happen corrupt ministri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['indonesia', 'blasphemi', 'law', 'ministri', 'religi', 'affair', 'also', 'happen', 'corrupt', 'ministri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['indonesia blasphemi law ministri religi affair also happen corrupt ministri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2294 :\n",
      "\n",
      "\tTweet's text':  woww thank help alot hahaha saddd \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['woww', 'thank', 'help', 'alot', 'hahaha', 'saddd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['woww thank help alot hahaha saddd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2295 :\n",
      "\n",
      "\tTweet's text':  it work enjoy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#eh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'work', 'enjoy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it work enjoy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2296 :\n",
      "\n",
      "\tTweet's text':  when els \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#relationships', '#needs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'els'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when els'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2297 :\n",
      "\n",
      "\tTweet's text':  gonna shittest christma ever without mum gonna get drunk \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['tropical_drink'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gon', 'na', 'shittest', 'christma', 'ever', 'without', 'mum', 'gon', 'na', 'get', 'drunk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gonna shittest christma ever without mum gonna get drunk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2298 :\n",
      "\n",
      "\tTweet's text':  im sorri chode phone broke \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['im', 'sorri', 'chode', 'phone', 'broke'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['im sorri chode phone broke'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2299 :\n",
      "\n",
      "\tTweet's text':  anoth moment we bother fix broadband problem would like buy iphon us hell no \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'moment', 'we', 'bother', 'fix', 'broadband', 'problem', 'would', 'like', 'buy', 'iphon', 'us', 'hell', 'no'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth moment we bother fix broadband problem would like buy iphon us hell no'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2300 :\n",
      "\n",
      "\tTweet's text':  hope ambit john caus one els seem \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hope', 'ambit', 'john', 'caus', 'one', 'els', 'seem'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hope ambit john caus one els seem'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2301 :\n",
      "\n",
      "\tTweet's text':  now seem afford good thing materi thing \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['now', 'seem', 'afford', 'good', 'thing', 'materi', 'thing'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['now seem afford good thing materi thing'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2302 :\n",
      "\n",
      "\tTweet's text':  younger sibl okay but irrit thing wake open present and awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['younger', 'sibl', 'okay', 'but', 'irrit', 'thing', 'wake', 'open', 'present', 'and', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['younger sibl okay but irrit thing wake open present and awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2303 :\n",
      "\n",
      "\tTweet's text':  alway fun buse turn it favorit wait outsid freez cold like half hour \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smirking_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['alway', 'fun', 'buse', 'turn', 'it', 'favorit', 'wait', 'outsid', 'freez', 'cold', 'like', 'half', 'hour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alway fun buse turn it favorit wait outsid freez cold like half hour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2304 :\n",
      "\n",
      "\tTweet's text':  hahaha good might stadium rather local council \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hahaha', 'good', 'might', 'stadium', 'rather', 'local', 'council'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hahaha good might stadium rather local council'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2305 :\n",
      "\n",
      "\tTweet's text':  talk rubbish system twitter chang anyth action speak louder word \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['talk', 'rubbish', 'system', 'twitter', 'chang', 'anyth', 'action', 'speak', 'louder', 'word'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['talk rubbish system twitter chang anyth action speak louder word'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2306 :\n",
      "\n",
      "\tTweet's text':  who accept challeng who next end soon be a ten execut found member \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['who', 'accept', 'challeng', 'who', 'next', 'end', 'soon', 'be', 'a', 'ten', 'execut', 'found', 'member'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['who accept challeng who next end soon be a ten execut found member'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2307 :\n",
      "\n",
      "\tTweet's text':  go sleep solid minut earlier last night \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#success', '#justwhatiwanted'] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'sleep', 'solid', 'minut', 'earlier', 'last', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go sleep solid minut earlier last night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2308 :\n",
      "\n",
      "\tTweet's text':  great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Disgrace', '#OngoingProblem'] \n",
      "\n",
      "\tTweet tokenized by words:  ['great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2309 :\n",
      "\n",
      "\tTweet's text':  thank god get anymor ellielippitt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#barber', '#hairdresser', '#blondie'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'god', 'get', 'anymor', 'ellielippitt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank god get anymor ellielippitt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2310 :\n",
      "\n",
      "\tTweet's text':  tri luck tom you one free passer makatanggap ng free item david okay na yun ta uwi haha \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tri', 'luck', 'tom', 'you', 'one', 'free', 'passer', 'makatanggap', 'ng', 'free', 'item', 'david', 'okay', 'na', 'yun', 'ta', 'uwi', 'haha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tri luck tom you one free passer makatanggap ng free item david okay na yun ta uwi haha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2311 :\n",
      "\n",
      "\tTweet's text':  love feel like i lie \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dontwanttobehere'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'feel', 'like', 'i', 'lie'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love feel like i lie'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2312 :\n",
      "\n",
      "\tTweet's text':  who look so much alik omg lashwkaywiduwb \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['who', 'look', 'so', 'much', 'alik', 'omg', 'lashwkaywiduwb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['who look so much alik omg lashwkaywiduwb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2313 :\n",
      "\n",
      "\tTweet's text':  boooooom goal minut \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ThatsArsenal'] \n",
      "\n",
      "\tTweet tokenized by words:  ['boooooom', 'goal', 'minut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['boooooom goal minut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2314 :\n",
      "\n",
      "\tTweet's text':  aye love lip tri sound creepi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aye', 'love', 'lip', 'tri', 'sound', 'creepi'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by sentences:  ['aye love lip tri sound creepi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2315 :\n",
      "\n",
      "\tTweet's text':  say \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2316 :\n",
      "\n",
      "\tTweet's text':  world greatest \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['world', 'greatest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['world greatest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2317 :\n",
      "\n",
      "\tTweet's text':  from upstair neighbor decid load laundri freight train fall asleep work great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['from', 'upstair', 'neighbor', 'decid', 'load', 'laundri', 'freight', 'train', 'fall', 'asleep', 'work', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['from upstair neighbor decid load laundri freight train fall asleep work great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2318 :\n",
      "\n",
      "\tTweet's text':  commit privaci open web pleas turn javascript display page correctli firefox homepag \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['commit', 'privaci', 'open', 'web', 'pleas', 'turn', 'javascript', 'display', 'page', 'correctli', 'firefox', 'homepag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['commit privaci open web pleas turn javascript display page correctli firefox homepag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2319 :\n",
      "\n",
      "\tTweet's text':  day want everyon leav alon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#in', '#a', '#good', '#mood', '#noHunting'] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'want', 'everyon', 'leav', 'alon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day want everyon leav alon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2320 :\n",
      "\n",
      "\tTweet's text':  when trauma kid suffer fact remain you apologis tell truth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#stuism'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'trauma', 'kid', 'suffer', 'fact', 'remain', 'you', 'apologis', 'tell', 'truth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when trauma kid suffer fact remain you apologis tell truth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2321 :\n",
      "\n",
      "\tTweet's text':  how excit walk \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#amazing', '#strength', '#hardwork', '#love'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'excit', 'walk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how excit walk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2322 :\n",
      "\n",
      "\tTweet's text':  so excit work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'excit', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so excit work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2323 :\n",
      "\n",
      "\tTweet's text':  the quest ticket continu \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoSupersonic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'quest', 'ticket', 'continu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the quest ticket continu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2324 :\n",
      "\n",
      "\tTweet's text':  i love spend five hour night homework pleas assign teacher \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'spend', 'five', 'hour', 'night', 'homework', 'pleas', 'assign', 'teacher'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love spend five hour night homework pleas assign teacher'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2325 :\n",
      "\n",
      "\tTweet's text':  watch christma movi alon like much fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'christma', 'movi', 'alon', 'like', 'much', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch christma movi alon like much fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2326 :\n",
      "\n",
      "\tTweet's text':  stomach flu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face', 'face_with_medical_mask'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stomach', 'flu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stomach flu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2327 :\n",
      "\n",
      "\tTweet's text':  line \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WatchOutForThis'] \n",
      "\n",
      "\tTweet tokenized by words:  ['line'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['line'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2328 :\n",
      "\n",
      "\tTweet's text':  all i say i lucki \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['all', 'i', 'say', 'i', 'lucki'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['all i say i lucki'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2329 :\n",
      "\n",
      "\tTweet's text':  i actual kinda surpris peopl still say not iron statement \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'actual', 'kinda', 'surpris', 'peopl', 'still', 'say', 'not', 'iron', 'statement'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i actual kinda surpris peopl still say not iron statement'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2330 :\n",
      "\n",
      "\tTweet's text':  love wake face lick puppi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'wake', 'face', 'lick', 'puppi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love wake face lick puppi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2331 :\n",
      "\n",
      "\tTweet's text':  what whi it christma it forbidden to do such terribil thing give it back to us \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#YouAndIBackToYoutube'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'whi', 'it', 'christma', 'it', 'forbidden', 'to', 'do', 'such', 'terribil', 'thing', 'give', 'it', 'back', 'to', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what whi it christma it forbidden to do such terribil thing give it back to us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2332 :\n",
      "\n",
      "\tTweet's text':  let fuckboy get way happi never and never lmao \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#DontBelieveMeJustWatch'] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'fuckboy', 'get', 'way', 'happi', 'never', 'and', 'never', 'lmao'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let fuckboy get way happi never and never lmao'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2333 :\n",
      "\n",
      "\tTweet's text':  hi i receiv photo dear parcel china amaz travel around world \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hi', 'i', 'receiv', 'photo', 'dear', 'parcel', 'china', 'amaz', 'travel', 'around', 'world'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hi i receiv photo dear parcel china amaz travel around world'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2334 :\n",
      "\n",
      "\tTweet's text':  serious cloth section f f \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['serious', 'cloth', 'section', 'f', 'f'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['serious cloth section f f'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2335 :\n",
      "\n",
      "\tTweet's text':  find pair would fit see evil monkeyspeak evil monkeyspeak evil monkeyfac tear joy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'see-no-evil_monkey', 'speak-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['find', 'pair', 'would', 'fit', 'see', 'evil', 'monkeyspeak', 'evil', 'monkeyspeak', 'evil', 'monkeyfac', 'tear', 'joy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['find pair would fit see evil monkeyspeak evil monkeyspeak evil monkeyfac tear joy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2336 :\n",
      "\n",
      "\tTweet's text':  whale morn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whale', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whale morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2337 :\n",
      "\n",
      "\tTweet's text':  she get raw \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['she', 'get', 'raw'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['she get raw'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2338 :\n",
      "\n",
      "\tTweet's text':  haha noo i need new boob old one fabul face stuck tongu tightli close eyesfac stuck tongu tightli close eyesfac stuck tongu tightli close eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_stuck-out_tongue_and_tightly-closed_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'noo', 'i', 'need', 'new', 'boob', 'old', 'one', 'fabul', 'face', 'stuck', 'tongu', 'tightli', 'close', 'eyesfac', 'stuck', 'tongu', 'tightli', 'close', 'eyesfac', 'stuck', 'tongu', 'tightli', 'close', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha noo i need new boob old one fabul face stuck tongu tightli close eyesfac stuck tongu tightli close eyesfac stuck tongu tightli close eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2339 :\n",
      "\n",
      "\tTweet's text':  well week great start \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fml'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'week', 'great', 'start'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well week great start'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2340 :\n",
      "\n",
      "\tTweet's text':  gg give us amaz collect yr in fact plan u prospict \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gg', 'give', 'us', 'amaz', 'collect', 'yr', 'in', 'fact', 'plan', 'u', 'prospict'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gg give us amaz collect yr in fact plan u prospict'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2341 :\n",
      "\n",
      "\tTweet's text':  pleas rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#All', '#Cute', '#Dude', '#Girlygirl', '#I039m', '#Into', '#Is'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pleas', 'rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pleas rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2342 :\n",
      "\n",
      "\tTweet's text':  i keep tell friend i busi need stop blow stop \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'keep', 'tell', 'friend', 'i', 'busi', 'need', 'stop', 'blow', 'stop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i keep tell friend i busi need stop blow stop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2343 :\n",
      "\n",
      "\tTweet's text':  fade public appli gambl do exact opposit good shape \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fade', 'public', 'appli', 'gambl', 'do', 'exact', 'opposit', 'good', 'shape'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fade public appli gambl do exact opposit good shape'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2344 :\n",
      "\n",
      "\tTweet's text':  secret santa one hotter work colleagu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['secret', 'santa', 'one', 'hotter', 'work', 'colleagu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['secret santa one hotter work colleagu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2345 :\n",
      "\n",
      "\tTweet's text':  the excit follow answer simpl question win pass gig getench \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EVC14', '#GetEnchanted'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'excit', 'follow', 'answer', 'simpl', 'question', 'win', 'pass', 'gig', 'getench'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the excit follow answer simpl question win pass gig getench'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2346 :\n",
      "\n",
      "\tTweet's text':  as red sox follow i vouch gome clubhous leader such fun teammat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['as', 'red', 'sox', 'follow', 'i', 'vouch', 'gome', 'clubhous', 'leader', 'such', 'fun', 'teammat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['as red sox follow i vouch gome clubhous leader such fun teammat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2347 :\n",
      "\n",
      "\tTweet's text':  enrol member leg l r then help person enrol member get execut w diamond pkg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['enrol', 'member', 'leg', 'l', 'r', 'then', 'help', 'person', 'enrol', 'member', 'get', 'execut', 'w', 'diamond', 'pkg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['enrol member leg l r then help person enrol member get execut w diamond pkg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2348 :\n",
      "\n",
      "\tTweet's text':  yay longer vehicl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['pensive_face', 'disappointed_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'longer', 'vehicl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay longer vehicl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2349 :\n",
      "\n",
      "\tTweet's text':  get readi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#yesterday', '#christmaseve', '#lastnight'] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'readi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get readi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2350 :\n",
      "\n",
      "\tTweet's text':  eu back top earli career research million \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcies', '#eu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['eu', 'back', 'top', 'earli', 'career', 'research', 'million'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['eu back top earli career research million'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2351 :\n",
      "\n",
      "\tTweet's text':  damn socialist \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['damn', 'socialist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['damn socialist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2352 :\n",
      "\n",
      "\tTweet's text':  i love see guy got \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'see', 'guy', 'got'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love see guy got'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2353 :\n",
      "\n",
      "\tTweet's text':  me i think i cartwheel \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['me', 'i', 'think', 'i', 'cartwheel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['me i think i cartwheel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2354 :\n",
      "\n",
      "\tTweet's text':  i like clown i go one \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'like', 'clown', 'i', 'go', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i like clown i go one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2355 :\n",
      "\n",
      "\tTweet's text':  can someon pleas tell video \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'someon', 'pleas', 'tell', 'video'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can someon pleas tell video'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2356 :\n",
      "\n",
      "\tTweet's text':  drink mercuri the wing messeng planet seri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#photo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['drink', 'mercuri', 'the', 'wing', 'messeng', 'planet', 'seri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['drink mercuri the wing messeng planet seri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2357 :\n",
      "\n",
      "\tTweet's text':  just found i make babi final thursday good thing i much time studi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'found', 'i', 'make', 'babi', 'final', 'thursday', 'good', 'thing', 'i', 'much', 'time', 'studi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just found i make babi final thursday good thing i much time studi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2358 :\n",
      "\n",
      "\tTweet's text':  good morn hank saturday im starv \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'morn', 'hank', 'saturday', 'im', 'starv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good morn hank saturday im starv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2359 :\n",
      "\n",
      "\tTweet's text':  long wait till releas co turn temperatur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['long', 'wait', 'till', 'releas', 'co', 'turn', 'temperatur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['long wait till releas co turn temperatur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2360 :\n",
      "\n",
      "\tTweet's text':  can wait rd draw \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#facup'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'rd', 'draw'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait rd draw'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2361 :\n",
      "\n",
      "\tTweet's text':  peopl commit crime resist cop attack cop endang live no respect law peopl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'commit', 'crime', 'resist', 'cop', 'attack', 'cop', 'endang', 'live', 'no', 'respect', 'law', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl commit crime resist cop attack cop endang live no respect law peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2362 :\n",
      "\n",
      "\tTweet's text':  fleuri shut out far season he still good though \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fleuri', 'shut', 'out', 'far', 'season', 'he', 'still', 'good', 'though'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fleuri shut out far season he still good though'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2363 :\n",
      "\n",
      "\tTweet's text':  i type lisp hahah \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'type', 'lisp', 'hahah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i type lisp hahah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2364 :\n",
      "\n",
      "\tTweet's text':  when santa look name sassi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_no_good_gesture', 'smirking_face', 'crown'] \n",
      "\n",
      "\tTweet's hashtags':  ['#sassy', '#naughty', '#or', '#nice', '#instagood', '#instadaily', '#Christmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'santa', 'look', 'name', 'sassi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when santa look name sassi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2365 :\n",
      "\n",
      "\tTweet's text':  i wanna hate religi peopl co one i religi music \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ahaa'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wan', 'na', 'hate', 'religi', 'peopl', 'co', 'one', 'i', 'religi', 'music'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wanna hate religi peopl co one i religi music'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2366 :\n",
      "\n",
      "\tTweet's text':  there million autobot troll account twitter post dumb sh rt peopl call stupid naiv \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'million', 'autobot', 'troll', 'account', 'twitter', 'post', 'dumb', 'sh', 'rt', 'peopl', 'call', 'stupid', 'naiv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there million autobot troll account twitter post dumb sh rt peopl call stupid naiv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2367 :\n",
      "\n",
      "\tTweet's text':  keep run problem that alway work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['keep', 'run', 'problem', 'that', 'alway', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['keep run problem that alway work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2368 :\n",
      "\n",
      "\tTweet's text':  would like thank nephew give horribl cold sore throat etc much appreci \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['would', 'like', 'thank', 'nephew', 'give', 'horribl', 'cold', 'sore', 'throat', 'etc', 'much', 'appreci'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['would like thank nephew give horribl cold sore throat etc much appreci'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2369 :\n",
      "\n",
      "\tTweet's text':  enabl window firewal perfectli reason thing packag softwar instal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SCCMAdmininHealthcare'] \n",
      "\n",
      "\tTweet tokenized by words:  ['enabl', 'window', 'firewal', 'perfectli', 'reason', 'thing', 'packag', 'softwar', 'instal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['enabl window firewal perfectli reason thing packag softwar instal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2370 :\n",
      "\n",
      "\tTweet's text':  just microphon fail if convers year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WebRTC', '#WebRTCParis'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'microphon', 'fail', 'if', 'convers', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just microphon fail if convers year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2371 :\n",
      "\n",
      "\tTweet's text':  welp there goe buck drain thank ku student hous get me out \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['welp', 'there', 'goe', 'buck', 'drain', 'thank', 'ku', 'student', 'hous', 'get', 'me', 'out'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['welp there goe buck drain thank ku student hous get me out'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2372 :\n",
      "\n",
      "\tTweet's text':  thi pressur unreal keep \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'pressur', 'unreal', 'keep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi pressur unreal keep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2373 :\n",
      "\n",
      "\tTweet's text':  same dl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Soundcloud', '#ATL', '#ConsciousMusic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['same', 'dl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['same dl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2374 :\n",
      "\n",
      "\tTweet's text':  i absolut love move hous \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'absolut', 'love', 'move', 'hous'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i absolut love move hous'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2375 :\n",
      "\n",
      "\tTweet's text':  power pictur taken the real \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#protester', '#night', '#christmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['power', 'pictur', 'taken', 'the', 'real'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['power pictur taken the real'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2376 :\n",
      "\n",
      "\tTweet's text':  listen gimm shelter drive rain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['listen', 'gimm', 'shelter', 'drive', 'rain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['listen gimm shelter drive rain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2377 :\n",
      "\n",
      "\tTweet's text':  take over mansion mexican \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['take', 'over', 'mansion', 'mexican'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['take over mansion mexican'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2378 :\n",
      "\n",
      "\tTweet's text':  go shark hair look like council cut \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'shark', 'hair', 'look', 'like', 'council', 'cut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go shark hair look like council cut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2379 :\n",
      "\n",
      "\tTweet's text':  liverpool worker miscarriag justic victim \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcies', '#eu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['liverpool', 'worker', 'miscarriag', 'justic', 'victim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['liverpool worker miscarriag justic victim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2380 :\n",
      "\n",
      "\tTweet's text':  ha i hater just misguid soul thought mention bulletin board issu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ha', 'i', 'hater', 'just', 'misguid', 'soul', 'thought', 'mention', 'bulletin', 'board', 'issu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ha i hater just misguid soul thought mention bulletin board issu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2381 :\n",
      "\n",
      "\tTweet's text':  yip like next time i get anotheron face stuck tongu wink eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_stuck-out_tongue_and_winking_eye'] \n",
      "\n",
      "\tTweet's hashtags':  ['#suckered', '#making'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yip', 'like', 'next', 'time', 'i', 'get', 'anotheron', 'face', 'stuck', 'tongu', 'wink', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yip like next time i get anotheron face stuck tongu wink eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2382 :\n",
      "\n",
      "\tTweet's text':  i love hear peopl explan date world america librari i studi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'hear', 'peopl', 'explan', 'date', 'world', 'america', 'librari', 'i', 'studi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love hear peopl explan date world america librari i studi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2383 :\n",
      "\n",
      "\tTweet's text':  eskom load shed hammer rand r \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#VivaANCviva'] \n",
      "\n",
      "\tTweet tokenized by words:  ['eskom', 'load', 'shed', 'hammer', 'rand', 'r'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['eskom load shed hammer rand r'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2384 :\n",
      "\n",
      "\tTweet's text':  what great person \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'great', 'person'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what great person'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2385 :\n",
      "\n",
      "\tTweet's text':  wait see ya \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wait', 'see', 'ya'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wait see ya'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2386 :\n",
      "\n",
      "\tTweet's text':  wow i feel great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'feel', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i feel great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2387 :\n",
      "\n",
      "\tTweet's text':  twitter slam austin strang fruit pr firm spur drop name share song lynch \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['twitter', 'slam', 'austin', 'strang', 'fruit', 'pr', 'firm', 'spur', 'drop', 'name', 'share', 'song', 'lynch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['twitter slam austin strang fruit pr firm spur drop name share song lynch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2388 :\n",
      "\n",
      "\tTweet's text':  look forward time i traips stair posti babi attach nippl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'forward', 'time', 'i', 'traips', 'stair', 'posti', 'babi', 'attach', 'nippl'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by sentences:  ['look forward time i traips stair posti babi attach nippl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2389 :\n",
      "\n",
      "\tTweet's text':  they r less bcci arnab keep bash news hour \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'r', 'less', 'bcci', 'arnab', 'keep', 'bash', 'news', 'hour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they r less bcci arnab keep bash news hour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2390 :\n",
      "\n",
      "\tTweet's text':  yep true patriot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yep', 'true', 'patriot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yep true patriot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2391 :\n",
      "\n",
      "\tTweet's text':  wa head mather bat power intimid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#powerful', '#intimidating'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wa', 'head', 'mather', 'bat', 'power', 'intimid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wa head mather bat power intimid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2392 :\n",
      "\n",
      "\tTweet's text':  i prefer slew protestor across us \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ferguson'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'prefer', 'slew', 'protestor', 'across', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i prefer slew protestor across us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2393 :\n",
      "\n",
      "\tTweet's text':  think i may use ad \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['think', 'i', 'may', 'use', 'ad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['think i may use ad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2394 :\n",
      "\n",
      "\tTweet's text':  it bcoz love gosupersonicquikr \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Nasty', '#GoSupersonicQuikr'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'bcoz', 'love', 'gosupersonicquikr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it bcoz love gosupersonicquikr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2395 :\n",
      "\n",
      "\tTweet's text':  i believ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'believ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i believ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2396 :\n",
      "\n",
      "\tTweet's text':  noth like hr swing back day walker make feel like million \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#shiftworkerlife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['noth', 'like', 'hr', 'swing', 'back', 'day', 'walker', 'make', 'feel', 'like', 'million'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noth like hr swing back day walker make feel like million'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2397 :\n",
      "\n",
      "\tTweet's text':  i respect belief i respect right atheist \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#atheist', '#atheism'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'respect', 'belief', 'i', 'respect', 'right', 'atheist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i respect belief i respect right atheist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2398 :\n",
      "\n",
      "\tTweet's text':  mmmm \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mmmm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mmmm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2399 :\n",
      "\n",
      "\tTweet's text':  speakeasi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['speakeasi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['speakeasi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2400 :\n",
      "\n",
      "\tTweet's text':  wow rt dick cheney cia tortur i minut \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#shocker'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'rt', 'dick', 'cheney', 'cia', 'tortur', 'i', 'minut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow rt dick cheney cia tortur i minut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2401 :\n",
      "\n",
      "\tTweet's text':  one season togo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OneTreeHill'] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'season', 'togo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one season togo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2402 :\n",
      "\n",
      "\tTweet's text':  the late howi carr wd amus see granni warren put wood bow tie bum kisser \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'late', 'howi', 'carr', 'wd', 'amus', 'see', 'granni', 'warren', 'put', 'wood', 'bow', 'tie', 'bum', 'kisser'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the late howi carr wd amus see granni warren put wood bow tie bum kisser'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2403 :\n",
      "\n",
      "\tTweet's text':  michael sexi face cough \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['michael', 'sexi', 'face', 'cough'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['michael sexi face cough'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2404 :\n",
      "\n",
      "\tTweet's text':  love made fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'made', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love made fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2405 :\n",
      "\n",
      "\tTweet's text':  feel good get go straight school \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'good', 'get', 'go', 'straight', 'school'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel good get go straight school'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2406 :\n",
      "\n",
      "\tTweet's text':  hey can send one \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GTX980'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'can', 'send', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey can send one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2407 :\n",
      "\n",
      "\tTweet's text':  pretti sure satan babi apart next door stay howl not cri howl all day night ugh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#killmenow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pretti', 'sure', 'satan', 'babi', 'apart', 'next', 'door', 'stay', 'howl', 'not', 'cri', 'howl', 'all', 'day', 'night', 'ugh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pretti sure satan babi apart next door stay howl not cri howl all day night ugh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2408 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GapingAngels', '#Georgeous'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2409 :\n",
      "\n",
      "\tTweet's text':  wear pin i sent rest video yesterday made day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#daymade', '#addicted'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wear', 'pin', 'i', 'sent', 'rest', 'video', 'yesterday', 'made', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wear pin i sent rest video yesterday made day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2410 :\n",
      "\n",
      "\tTweet's text':  win em i ever look like \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['win', 'em', 'i', 'ever', 'look', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['win em i ever look like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2411 :\n",
      "\n",
      "\tTweet's text':  what think salt n pepa geico commerci i think pretti terribl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'think', 'salt', 'n', 'pepa', 'geico', 'commerci', 'i', 'think', 'pretti', 'terribl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what think salt n pepa geico commerci i think pretti terribl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2412 :\n",
      "\n",
      "\tTweet's text':  i offici twitter sure pound sign \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'offici', 'twitter', 'sure', 'pound', 'sign'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i offici twitter sure pound sign'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2413 :\n",
      "\n",
      "\tTweet's text':  the moment realiz done whole year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'moment', 'realiz', 'done', 'whole', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the moment realiz done whole year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2414 :\n",
      "\n",
      "\tTweet's text':  yeah prom import event life \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'prom', 'import', 'event', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah prom import event life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2415 :\n",
      "\n",
      "\tTweet's text':  wish relationship real \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wish', 'relationship', 'real'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wish relationship real'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2416 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Exclusive', '#Indonesia', '#AirAsia', '#crash', '#probe', '#focuses', '#timing', '#request', '#climb', '#weather'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2417 :\n",
      "\n",
      "\tTweet's text':  marvel sound noth like jingl bell song ever heard i see mismatch sock tight cricket gear \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['marvel', 'sound', 'noth', 'like', 'jingl', 'bell', 'song', 'ever', 'heard', 'i', 'see', 'mismatch', 'sock', 'tight', 'cricket', 'gear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['marvel sound noth like jingl bell song ever heard i see mismatch sock tight cricket gear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2418 :\n",
      "\n",
      "\tTweet's text':  indian urdu daili advoc murder apost after extremist hindu group convert muslim the f \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['indian', 'urdu', 'daili', 'advoc', 'murder', 'apost', 'after', 'extremist', 'hindu', 'group', 'convert', 'muslim', 'the', 'f'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['indian urdu daili advoc murder apost after extremist hindu group convert muslim the f'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2419 :\n",
      "\n",
      "\tTweet's text':  compani profil not twin ventur llc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TWINS', '#VENTURES', '#LLC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['compani', 'profil', 'not', 'twin', 'ventur', 'llc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['compani profil not twin ventur llc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2420 :\n",
      "\n",
      "\tTweet's text':  photo pc lace corset size small xl price leav size email invoic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['photo', 'pc', 'lace', 'corset', 'size', 'small', 'xl', 'price', 'leav', 'size', 'email', 'invoic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photo pc lace corset size small xl price leav size email invoic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2421 :\n",
      "\n",
      "\tTweet's text':  it much easier write i feel actual speak i get nervou stumbl word heart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'much', 'easier', 'write', 'i', 'feel', 'actual', 'speak', 'i', 'get', 'nervou', 'stumbl', 'word', 'heart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it much easier write i feel actual speak i get nervou stumbl word heart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2422 :\n",
      "\n",
      "\tTweet's text':  bacon that that tweet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bacon', 'that', 'that', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bacon that that tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2423 :\n",
      "\n",
      "\tTweet's text':  yup amaz isnt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yup', 'amaz', 'isnt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yup amaz isnt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2424 :\n",
      "\n",
      "\tTweet's text':  photo danc icon sport bra short bikini lingeri one size leav email invoic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['photo', 'danc', 'icon', 'sport', 'bra', 'short', 'bikini', 'lingeri', 'one', 'size', 'leav', 'email', 'invoic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photo danc icon sport bra short bikini lingeri one size leav email invoic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2425 :\n",
      "\n",
      "\tTweet's text':  better score not better one \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['better', 'score', 'not', 'better', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['better score not better one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2426 :\n",
      "\n",
      "\tTweet's text':  put soap shampoo it healthi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['put', 'soap', 'shampoo', 'it', 'healthi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['put soap shampoo it healthi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2427 :\n",
      "\n",
      "\tTweet's text':  how score someon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'score', 'someon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how score someon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2428 :\n",
      "\n",
      "\tTweet's text':  it calam true truth come deni \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'calam', 'true', 'truth', 'come', 'deni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it calam true truth come deni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2429 :\n",
      "\n",
      "\tTweet's text':  take christma light swamp blast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['take', 'christma', 'light', 'swamp', 'blast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['take christma light swamp blast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2430 :\n",
      "\n",
      "\tTweet's text':  it freshman semest first \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ohanya', '#finalsamiright'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'freshman', 'semest', 'first'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it freshman semest first'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2431 :\n",
      "\n",
      "\tTweet's text':  i know open christma day peopl actual eat right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'open', 'christma', 'day', 'peopl', 'actual', 'eat', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know open christma day peopl actual eat right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2432 :\n",
      "\n",
      "\tTweet's text':  i love bodi handl school stress make physic sick \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'bodi', 'handl', 'school', 'stress', 'make', 'physic', 'sick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love bodi handl school stress make physic sick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2433 :\n",
      "\n",
      "\tTweet's text':  final go bed definit look forward wake hour \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'go', 'bed', 'definit', 'look', 'forward', 'wake', 'hour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final go bed definit look forward wake hour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2434 :\n",
      "\n",
      "\tTweet's text':  aww bless ya enjoy break babe yeah great thank final recov how ya tash go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_throwing_a_kiss'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aww', 'bless', 'ya', 'enjoy', 'break', 'babe', 'yeah', 'great', 'thank', 'final', 'recov', 'how', 'ya', 'tash', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aww bless ya enjoy break babe yeah great thank final recov how ya tash go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2435 :\n",
      "\n",
      "\tTweet's text':  platoon strategi bad i mean line armi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mets'] \n",
      "\n",
      "\tTweet tokenized by words:  ['platoon', 'strategi', 'bad', 'i', 'mean', 'line', 'armi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['platoon strategi bad i mean line armi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2436 :\n",
      "\n",
      "\tTweet's text':  day go dr caus i sure strep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#2', '#awesome'] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'go', 'dr', 'caus', 'i', 'sure', 'strep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day go dr caus i sure strep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2437 :\n",
      "\n",
      "\tTweet's text':  huh it graphic represent happen noth take photo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['huh', 'it', 'graphic', 'represent', 'happen', 'noth', 'take', 'photo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['huh it graphic represent happen noth take photo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2438 :\n",
      "\n",
      "\tTweet's text':  but time face \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'time', 'face'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but time face'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2439 :\n",
      "\n",
      "\tTweet's text':  thi guy start jack hammer morn right outsid window stop anytim \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sleepingbeauty'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'guy', 'start', 'jack', 'hammer', 'morn', 'right', 'outsid', 'window', 'stop', 'anytim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi guy start jack hammer morn right outsid window stop anytim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2440 :\n",
      "\n",
      "\tTweet's text':  way start new year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['way', 'start', 'new', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['way start new year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2441 :\n",
      "\n",
      "\tTweet's text':  as girl reason put makeup i satisfi face unlik bitch \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#winter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['as', 'girl', 'reason', 'put', 'makeup', 'i', 'satisfi', 'face', 'unlik', 'bitch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['as girl reason put makeup i satisfi face unlik bitch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2442 :\n",
      "\n",
      "\tTweet's text':  oh look wrap present so video prove \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'look', 'wrap', 'present', 'so', 'video', 'prove'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh look wrap present so video prove'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2443 :\n",
      "\n",
      "\tTweet's text':  write cover page thesi laptop commit suicid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thankgodforbackups'] \n",
      "\n",
      "\tTweet tokenized by words:  ['write', 'cover', 'page', 'thesi', 'laptop', 'commit', 'suicid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['write cover page thesi laptop commit suicid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2444 :\n",
      "\n",
      "\tTweet's text':  talk day cool i guess \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['talk', 'day', 'cool', 'i', 'guess'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['talk day cool i guess'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2445 :\n",
      "\n",
      "\tTweet's text':  the interview cancel north korea immens comedi would blow mortal mind \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'interview', 'cancel', 'north', 'korea', 'immens', 'comedi', 'would', 'blow', 'mortal', 'mind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the interview cancel north korea immens comedi would blow mortal mind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2446 :\n",
      "\n",
      "\tTweet's text':  the sky look so beauti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'sky', 'look', 'so', 'beauti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the sky look so beauti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2447 :\n",
      "\n",
      "\tTweet's text':  hey make money yet thi clip explain \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Russia', '#TWEETING', '#FOXNews'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'make', 'money', 'yet', 'thi', 'clip', 'explain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey make money yet thi clip explain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2448 :\n",
      "\n",
      "\tTweet's text':  aww i seen pictur today how recoveri go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#getwellsoon'] \n",
      "\n",
      "\tTweet tokenized by words:  ['aww', 'i', 'seen', 'pictur', 'today', 'how', 'recoveri', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aww i seen pictur today how recoveri go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2449 :\n",
      "\n",
      "\tTweet's text':  what the team playoff pick peopl solv school still piss i shock \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CFBPlayoff'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'the', 'team', 'playoff', 'pick', 'peopl', 'solv', 'school', 'still', 'piss', 'i', 'shock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what the team playoff pick peopl solv school still piss i shock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2450 :\n",
      "\n",
      "\tTweet's text':  ye man properti privileg \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ironagethinking'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'man', 'properti', 'privileg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye man properti privileg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2451 :\n",
      "\n",
      "\tTweet's text':  day ski school instructor patrick soon i readi black slope \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'ski', 'school', 'instructor', 'patrick', 'soon', 'i', 'readi', 'black', 'slope'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day ski school instructor patrick soon i readi black slope'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2452 :\n",
      "\n",
      "\tTweet's text':  everyon full ruddi xma cheer \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['everyon', 'full', 'ruddi', 'xma', 'cheer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everyon full ruddi xma cheer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2453 :\n",
      "\n",
      "\tTweet's text':  becaus know hous hermet seal environ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['becaus', 'know', 'hous', 'hermet', 'seal', 'environ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['becaus know hous hermet seal environ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2454 :\n",
      "\n",
      "\tTweet's text':  one thing sure ima make folk rememb \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'thing', 'sure', 'ima', 'make', 'folk', 'rememb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one thing sure ima make folk rememb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2455 :\n",
      "\n",
      "\tTweet's text':  send best wish cowork am morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['send', 'best', 'wish', 'cowork', 'am', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['send best wish cowork am morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2456 :\n",
      "\n",
      "\tTweet's text':  they be allow refuge among potenti \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CAN', '#IDENTIFIED', '#UK', '#SYRIAN', '#ENTRY', '#ISLAMISTS', '#TERRORISTS'] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'be', 'allow', 'refuge', 'among', 'potenti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they be allow refuge among potenti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2457 :\n",
      "\n",
      "\tTweet's text':  when continuationist demand prooftext cessation beauti observ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'continuationist', 'demand', 'prooftext', 'cessation', 'beauti', 'observ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when continuationist demand prooftext cessation beauti observ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2458 :\n",
      "\n",
      "\tTweet's text':  yep exactli audi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Audi', '#R8', '#Carporn'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yep', 'exactli', 'audi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yep exactli audi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2459 :\n",
      "\n",
      "\tTweet's text':  can u use smartphon smartphon app pay see go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'u', 'use', 'smartphon', 'smartphon', 'app', 'pay', 'see', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can u use smartphon smartphon app pay see go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2460 :\n",
      "\n",
      "\tTweet's text':  how fuck u come commerci injuri break w delay game \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Redskins'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'fuck', 'u', 'come', 'commerci', 'injuri', 'break', 'w', 'delay', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how fuck u come commerci injuri break w delay game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2461 :\n",
      "\n",
      "\tTweet's text':  how santa juncker bring gift healthier eu \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcias', '#eu', '#europ'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'santa', 'juncker', 'bring', 'gift', 'healthier', 'eu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how santa juncker bring gift healthier eu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2462 :\n",
      "\n",
      "\tTweet's text':  fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2463 :\n",
      "\n",
      "\tTweet's text':  ironi die time climax sholay polic urg thakur take law hand \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bollywood'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ironi', 'die', 'time', 'climax', 'sholay', 'polic', 'urg', 'thakur', 'take', 'law', 'hand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ironi die time climax sholay polic urg thakur take law hand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2464 :\n",
      "\n",
      "\tTweet's text':  done much \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['done', 'much'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['done much'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2465 :\n",
      "\n",
      "\tTweet's text':  bdutt best report frm field not bad studio field true stori teller \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bdutt', 'best', 'report', 'frm', 'field', 'not', 'bad', 'studio', 'field', 'true', 'stori', 'teller'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bdutt best report frm field not bad studio field true stori teller'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2466 :\n",
      "\n",
      "\tTweet's text':  yay knee machin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'knee', 'machin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay knee machin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2467 :\n",
      "\n",
      "\tTweet's text':  so condon murder rude peopl file nincompoop updat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'condon', 'murder', 'rude', 'peopl', 'file', 'nincompoop', 'updat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so condon murder rude peopl file nincompoop updat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2468 :\n",
      "\n",
      "\tTweet's text':  a florida judg rule friday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Minivan', '#Mom', '#Ebony', '#Wilkerson', '#Guilty', '#By', '#Reason', '#of', '#Insanity', '#Judge'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'florida', 'judg', 'rule', 'friday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a florida judg rule friday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2469 :\n",
      "\n",
      "\tTweet's text':  long yeah director cut longer need see penguin madagascar btw \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['long', 'yeah', 'director', 'cut', 'longer', 'need', 'see', 'penguin', 'madagascar', 'btw'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['long yeah director cut longer need see penguin madagascar btw'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2470 :\n",
      "\n",
      "\tTweet's text':  well today go fuck \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'today', 'go', 'fuck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well today go fuck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2471 :\n",
      "\n",
      "\tTweet's text':  i love work hour get paid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'work', 'hour', 'get', 'paid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love work hour get paid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2472 :\n",
      "\n",
      "\tTweet's text':  i love i wake grumpi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#effroommates', '#yourtooloud', '#personalalarmclock', '#notnecessary', '#bequieter', '#ugh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'i', 'wake', 'grumpi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love i wake grumpi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2473 :\n",
      "\n",
      "\tTweet's text':  lfc worst start year still efc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WishWeHadA28MilStriker'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lfc', 'worst', 'start', 'year', 'still', 'efc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lfc worst start year still efc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2474 :\n",
      "\n",
      "\tTweet's text':  are kid unaccept \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['are', 'kid', 'unaccept'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['are kid unaccept'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2475 :\n",
      "\n",
      "\tTweet's text':  well nmu comput took poop hope start back later \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['expressionless_face', 'unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#whatDoIExpect', '#NMUComputersAreTheBest'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'nmu', 'comput', 'took', 'poop', 'hope', 'start', 'back', 'later'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well nmu comput took poop hope start back later'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2476 :\n",
      "\n",
      "\tTweet's text':  it one year eye twitch \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SoFun'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'one', 'year', 'eye', 'twitch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it one year eye twitch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2477 :\n",
      "\n",
      "\tTweet's text':  in case somebodi break apart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['dizzy_face', 'hocho'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'case', 'somebodi', 'break', 'apart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in case somebodi break apart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2478 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#greatcustomerrelations'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2479 :\n",
      "\n",
      "\tTweet's text':  among children none one \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#duleepSingh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['among', 'children', 'none', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['among children none one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2480 :\n",
      "\n",
      "\tTweet's text':  dead support famili i got \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dead', 'support', 'famili', 'i', 'got'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dead support famili i got'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2481 :\n",
      "\n",
      "\tTweet's text':  saturday d \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['saturday', 'd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['saturday d'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2482 :\n",
      "\n",
      "\tTweet's text':  yeah happen everi time i want like video \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'happen', 'everi', 'time', 'i', 'want', 'like', 'video'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah happen everi time i want like video'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2483 :\n",
      "\n",
      "\tTweet's text':  could happen anyon your time come critic oop apolog a typic love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Brit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['could', 'happen', 'anyon', 'your', 'time', 'come', 'critic', 'oop', 'apolog', 'a', 'typic', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['could happen anyon your time come critic oop apolog a typic love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2484 :\n",
      "\n",
      "\tTweet's text':  babysit i like saturday \n",
      "\n",
      "\tTweet's score':  1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['babysit', 'i', 'like', 'saturday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['babysit i like saturday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2485 :\n",
      "\n",
      "\tTweet's text':  hafeez slider too much mess bowl back palm kph requir extens \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hafeez', 'slider', 'too', 'much', 'mess', 'bowl', 'back', 'palm', 'kph', 'requir', 'extens'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hafeez slider too much mess bowl back palm kph requir extens'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2486 :\n",
      "\n",
      "\tTweet's text':  justin bieber net \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MTVStars', '#net', '#fast'] \n",
      "\n",
      "\tTweet tokenized by words:  ['justin', 'bieber', 'net'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['justin bieber net'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2487 :\n",
      "\n",
      "\tTweet's text':  squirt squat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['squirt', 'squat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['squirt squat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2488 :\n",
      "\n",
      "\tTweet's text':  how i make money busi loral langemeir best seller the millionair maker get copi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'i', 'make', 'money', 'busi', 'loral', 'langemeir', 'best', 'seller', 'the', 'millionair', 'maker', 'get', 'copi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how i make money busi loral langemeir best seller the millionair maker get copi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2489 :\n",
      "\n",
      "\tTweet's text':  u dnt hav p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['u', 'dnt', 'hav', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['u dnt hav p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2490 :\n",
      "\n",
      "\tTweet's text':  blackpool today interview weather beach \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['blackpool', 'today', 'interview', 'weather', 'beach'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['blackpool today interview weather beach'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2491 :\n",
      "\n",
      "\tTweet's text':  you familiar matt bubsi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#then'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'familiar', 'matt', 'bubsi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you familiar matt bubsi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2492 :\n",
      "\n",
      "\tTweet's text':  dirgahayu corp corp w tari eni other pic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['fisted_hand_sign', 'musical_score', 'smiling_face_with_sunglasses', 'clapping_hands_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dirgahayu', 'corp', 'corp', 'w', 'tari', 'eni', 'other', 'pic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dirgahayu corp corp w tari eni other pic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2493 :\n",
      "\n",
      "\tTweet's text':  not room pleas i want \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['not', 'room', 'pleas', 'i', 'want'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['not room pleas i want'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2494 :\n",
      "\n",
      "\tTweet's text':  pleas give follow back \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pleas', 'give', 'follow', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pleas give follow back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2495 :\n",
      "\n",
      "\tTweet's text':  be narrow knife might find target answer sarcast \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'narrow', 'knife', 'might', 'find', 'target', 'answer', 'sarcast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be narrow knife might find target answer sarcast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2496 :\n",
      "\n",
      "\tTweet's text':  i tri type parksid turn paradis \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#coincidence', '#i', '#think'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'tri', 'type', 'parksid', 'turn', 'paradis'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i tri type parksid turn paradis'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2497 :\n",
      "\n",
      "\tTweet's text':  a woman wear shirt say act like ladi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'woman', 'wear', 'shirt', 'say', 'act', 'like', 'ladi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a woman wear shirt say act like ladi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2498 :\n",
      "\n",
      "\tTweet's text':  grandma come yay money \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lol', '#kidding'] \n",
      "\n",
      "\tTweet tokenized by words:  ['grandma', 'come', 'yay', 'money'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['grandma come yay money'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2499 :\n",
      "\n",
      "\tTweet's text':  at one point almost believ law attract effect \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['at', 'one', 'point', 'almost', 'believ', 'law', 'attract', 'effect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['at one point almost believ law attract effect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2500 :\n",
      "\n",
      "\tTweet's text':  yup gotta keep frantic parti lifestyl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yup', 'got', 'ta', 'keep', 'frantic', 'parti', 'lifestyl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yup gotta keep frantic parti lifestyl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2501 :\n",
      "\n",
      "\tTweet's text':  how dare you have fun as christian we are suppos to be bore and have zero fun horribl christian lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MISFIT'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'dare', 'you', 'have', 'fun', 'as', 'christian', 'we', 'are', 'suppos', 'to', 'be', 'bore', 'and', 'have', 'zero', 'fun', 'horribl', 'christian', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how dare you have fun as christian we are suppos to be bore and have zero fun horribl christian lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2502 :\n",
      "\n",
      "\tTweet's text':  i watch bird fli photo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'watch', 'bird', 'fli', 'photo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i watch bird fli photo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2503 :\n",
      "\n",
      "\tTweet's text':  feel like relev worri word limit man least \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'like', 'relev', 'worri', 'word', 'limit', 'man', 'least'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel like relev worri word limit man least'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2504 :\n",
      "\n",
      "\tTweet's text':  yup servic deliveri impecc diesel suppli cash flow problem ineptitud \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#eskom'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yup', 'servic', 'deliveri', 'impecc', 'diesel', 'suppli', 'cash', 'flow', 'problem', 'ineptitud'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yup servic deliveri impecc diesel suppli cash flow problem ineptitud'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2505 :\n",
      "\n",
      "\tTweet's text':  sarcasm incom thi weekend go great time ground noth homework gunna blast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sarcasm', 'incom', 'thi', 'weekend', 'go', 'great', 'time', 'ground', 'noth', 'homework', 'gunna', 'blast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sarcasm incom thi weekend go great time ground noth homework gunna blast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2506 :\n",
      "\n",
      "\tTweet's text':  i wait enjoy christma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wait', 'enjoy', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wait enjoy christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2507 :\n",
      "\n",
      "\tTweet's text':  glad know friend support \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['glad', 'know', 'friend', 'support'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['glad know friend support'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2508 :\n",
      "\n",
      "\tTweet's text':  sound like la end day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sound', 'like', 'la', 'end', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sound like la end day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2509 :\n",
      "\n",
      "\tTweet's text':  erasur perciv everett pym mat j \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ChangetheCanon'] \n",
      "\n",
      "\tTweet tokenized by words:  ['erasur', 'perciv', 'everett', 'pym', 'mat', 'j'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['erasur perciv everett pym mat j'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2510 :\n",
      "\n",
      "\tTweet's text':  chick realli pimp male day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#the', '#look', '#yallknowthatsnotcoolright'] \n",
      "\n",
      "\tTweet tokenized by words:  ['chick', 'realli', 'pimp', 'male', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['chick realli pimp male day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2511 :\n",
      "\n",
      "\tTweet's text':  a power statement rob hustl grow crisi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ICantBreathe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'power', 'statement', 'rob', 'hustl', 'grow', 'crisi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a power statement rob hustl grow crisi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2512 :\n",
      "\n",
      "\tTweet's text':  i guess pictur answer still answer abov beyond quiksilvergoessuperson \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#QuiksilverGoesSupersonic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'pictur', 'answer', 'still', 'answer', 'abov', 'beyond', 'quiksilvergoessuperson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guess pictur answer still answer abov beyond quiksilvergoessuperson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2513 :\n",
      "\n",
      "\tTweet's text':  they percey got pair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#do', '#worry'] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'percey', 'got', 'pair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they percey got pair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2514 :\n",
      "\n",
      "\tTweet's text':  all best \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['all', 'best'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['all best'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2515 :\n",
      "\n",
      "\tTweet's text':  when look nurtur statuesqu beauti nurtur skinniest supermodel \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Statuesque', '#Skinny', '#Look'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'look', 'nurtur', 'statuesqu', 'beauti', 'nurtur', 'skinniest', 'supermodel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when look nurtur statuesqu beauti nurtur skinniest supermodel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2516 :\n",
      "\n",
      "\tTweet's text':  what earth mean cloud vs mobil it cloud mobil basic client server \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'earth', 'mean', 'cloud', 'vs', 'mobil', 'it', 'cloud', 'mobil', 'basic', 'client', 'server'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what earth mean cloud vs mobil it cloud mobil basic client server'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2517 :\n",
      "\n",
      "\tTweet's text':  i would never hire trestman rt i would fire trestman tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'would', 'never', 'hire', 'trestman', 'rt', 'i', 'would', 'fire', 'trestman', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i would never hire trestman rt i would fire trestman tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2518 :\n",
      "\n",
      "\tTweet's text':  when someon extrem selfish dramat wonder peopl selfish \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'someon', 'extrem', 'selfish', 'dramat', 'wonder', 'peopl', 'selfish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when someon extrem selfish dramat wonder peopl selfish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2519 :\n",
      "\n",
      "\tTweet's text':  thank stay tom \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'stay', 'tom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank stay tom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2520 :\n",
      "\n",
      "\tTweet's text':  detect lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OrTypeCast'] \n",
      "\n",
      "\tTweet tokenized by words:  ['detect', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['detect lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2521 :\n",
      "\n",
      "\tTweet's text':  drive ferrari right beauti clever woman \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['drive', 'ferrari', 'right', 'beauti', 'clever', 'woman'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['drive ferrari right beauti clever woman'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2522 :\n",
      "\n",
      "\tTweet's text':  wheel bu broken broken broken \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fml', '#omwtothemet'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wheel', 'bu', 'broken', 'broken', 'broken'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wheel bu broken broken broken'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2523 :\n",
      "\n",
      "\tTweet's text':  your cyber monday sale got extend no fuck way \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#stfu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['your', 'cyber', 'monday', 'sale', 'got', 'extend', 'no', 'fuck', 'way'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['your cyber monday sale got extend no fuck way'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2524 :\n",
      "\n",
      "\tTweet's text':  i get notif though i know we play bad \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'get', 'notif', 'though', 'i', 'know', 'we', 'play', 'bad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i get notif though i know we play bad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2525 :\n",
      "\n",
      "\tTweet's text':  i back chill i keep contact hit get mad i shit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pedestrian'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'back', 'chill', 'i', 'keep', 'contact', 'hit', 'get', 'mad', 'i', 'shit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i back chill i keep contact hit get mad i shit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2526 :\n",
      "\n",
      "\tTweet's text':  dusti usual \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#redbucket'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dusti', 'usual'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dusti usual'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2527 :\n",
      "\n",
      "\tTweet's text':  sorri i forgot lmao \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sorri', 'i', 'forgot', 'lmao'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sorri i forgot lmao'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2528 :\n",
      "\n",
      "\tTweet's text':  mt darth vader poll higher potenti us presidenti candid are surpris \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mt', 'darth', 'vader', 'poll', 'higher', 'potenti', 'us', 'presidenti', 'candid', 'are', 'surpris'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mt darth vader poll higher potenti us presidenti candid are surpris'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2529 :\n",
      "\n",
      "\tTweet's text':  probabl folk like buy game \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FullMcIntosh', '#gamergate'] \n",
      "\n",
      "\tTweet tokenized by words:  ['probabl', 'folk', 'like', 'buy', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['probabl folk like buy game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2530 :\n",
      "\n",
      "\tTweet's text':  hahahahahahahhahaha i one happen ya \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hahahahahahahhahaha', 'i', 'one', 'happen', 'ya'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hahahahahahahhahaha i one happen ya'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2531 :\n",
      "\n",
      "\tTweet's text':  the wonder advantag ppl pleas daft noth worri chang perspect adjust \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'wonder', 'advantag', 'ppl', 'pleas', 'daft', 'noth', 'worri', 'chang', 'perspect', 'adjust'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the wonder advantag ppl pleas daft noth worri chang perspect adjust'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2532 :\n",
      "\n",
      "\tTweet's text':  alot still suss yo keep touch peop e via twittertwitterversari \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['alot', 'still', 'suss', 'yo', 'keep', 'touch', 'peop', 'e', 'via', 'twittertwitterversari'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alot still suss yo keep touch peop e via twittertwitterversari'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2533 :\n",
      "\n",
      "\tTweet's text':  sure let go back work day leav four hour ago whi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fb'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sure', 'let', 'go', 'back', 'work', 'day', 'leav', 'four', 'hour', 'ago', 'whi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sure let go back work day leav four hour ago whi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2534 :\n",
      "\n",
      "\tTweet's text':  python tweeter send \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['python', 'tweeter', 'send'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['python tweeter send'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2535 :\n",
      "\n",
      "\tTweet's text':  absolut i life hard thing haha \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['absolut', 'i', 'life', 'hard', 'thing', 'haha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['absolut i life hard thing haha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2536 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2537 :\n",
      "\n",
      "\tTweet's text':  thank help load \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'help', 'load'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank help load'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2538 :\n",
      "\n",
      "\tTweet's text':  russia say rubl crisi reserv dive inflat climb \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['russia', 'say', 'rubl', 'crisi', 'reserv', 'dive', 'inflat', 'climb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['russia say rubl crisi reserv dive inflat climb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2539 :\n",
      "\n",
      "\tTweet's text':  accus twitter count though i heard tale talk replac grad juri sy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['accus', 'twitter', 'count', 'though', 'i', 'heard', 'tale', 'talk', 'replac', 'grad', 'juri', 'sy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['accus twitter count though i heard tale talk replac grad juri sy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2540 :\n",
      "\n",
      "\tTweet's text':  think i lock phone away night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ifyoudonthaveanythingnicetosaydontsayanythingatall'] \n",
      "\n",
      "\tTweet tokenized by words:  ['think', 'i', 'lock', 'phone', 'away', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['think i lock phone away night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2541 :\n",
      "\n",
      "\tTweet's text':  so matt natasha sex \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WhatASuprise', '#WhatElseIsNew'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'matt', 'natasha', 'sex'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so matt natasha sex'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2542 :\n",
      "\n",
      "\tTweet's text':  know remov m a overpow o \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['O'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'remov', 'm', 'a', 'overpow', 'o'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know remov m a overpow o'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2543 :\n",
      "\n",
      "\tTweet's text':  have guy tri unplug server wait second plug back \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#psndown'] \n",
      "\n",
      "\tTweet tokenized by words:  ['have', 'guy', 'tri', 'unplug', 'server', 'wait', 'second', 'plug', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['have guy tri unplug server wait second plug back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2544 :\n",
      "\n",
      "\tTweet's text':  warwick davi twice man toni blair \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['warwick', 'davi', 'twice', 'man', 'toni', 'blair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['warwick davi twice man toni blair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2545 :\n",
      "\n",
      "\tTweet's text':  in scotland littl countri attach north england \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['flag_for_United_Kingdom', 'snowflake'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'scotland', 'littl', 'countri', 'attach', 'north', 'england'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in scotland littl countri attach north england'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2546 :\n",
      "\n",
      "\tTweet's text':  girl put area code instagram \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#stupidsauce', '#mymomcoulddobetter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['girl', 'put', 'area', 'code', 'instagram'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['girl put area code instagram'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2547 :\n",
      "\n",
      "\tTweet's text':  progress social liber must push victim hood idea order continu \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by words:  ['progress', 'social', 'liber', 'must', 'push', 'victim', 'hood', 'idea', 'order', 'continu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['progress social liber must push victim hood idea order continu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2548 :\n",
      "\n",
      "\tTweet's text':  cheer anoth good \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cheer', 'anoth', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cheer anoth good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2549 :\n",
      "\n",
      "\tTweet's text':  lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'smiling_face_with_open_mouth'] \n",
      "\n",
      "\tTweet's hashtags':  ['#nuffsaid', '#stupidity', '#hadenough'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2550 :\n",
      "\n",
      "\tTweet's text':  oh end well rt militari style tech find way into school district safeti measur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'end', 'well', 'rt', 'militari', 'style', 'tech', 'find', 'way', 'into', 'school', 'district', 'safeti', 'measur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh end well rt militari style tech find way into school district safeti measur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2551 :\n",
      "\n",
      "\tTweet's text':  oh i miss middl school drama \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'i', 'miss', 'middl', 'school', 'drama'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh i miss middl school drama'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2552 :\n",
      "\n",
      "\tTweet's text':  ski new say die like drop dead hospit lol real honest report \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ski', 'new', 'say', 'die', 'like', 'drop', 'dead', 'hospit', 'lol', 'real', 'honest', 'report'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ski new say die like drop dead hospit lol real honest report'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2553 :\n",
      "\n",
      "\tTweet's text':  togepi shed www monstermmorpg com falli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#shell', '#MonsterMMORPG', '#bagon'] \n",
      "\n",
      "\tTweet tokenized by words:  ['togepi', 'shed', 'www', 'monstermmorpg', 'com', 'falli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['togepi shed www monstermmorpg com falli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2554 :\n",
      "\n",
      "\tTweet's text':  so week get better better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['loudly_crying_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'week', 'get', 'better', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so week get better better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2555 :\n",
      "\n",
      "\tTweet's text':  i ate even done dessert \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'ate', 'even', 'done', 'dessert'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i ate even done dessert'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2556 :\n",
      "\n",
      "\tTweet's text':  good old jk land peopl troubl ff william thought savvi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'old', 'jk', 'land', 'peopl', 'troubl', 'ff', 'william', 'thought', 'savvi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good old jk land peopl troubl ff william thought savvi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2557 :\n",
      "\n",
      "\tTweet's text':  halt heroin overdos instantli how music film industri block one wonder \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['halt', 'heroin', 'overdos', 'instantli', 'how', 'music', 'film', 'industri', 'block', 'one', 'wonder'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['halt heroin overdos instantli how music film industri block one wonder'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2558 :\n",
      "\n",
      "\tTweet's text':  at last i quit work enjoy life lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['at', 'last', 'i', 'quit', 'work', 'enjoy', 'life', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['at last i quit work enjoy life lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2559 :\n",
      "\n",
      "\tTweet's text':  lol boy want fuck relationship tri sound like hoe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'boy', 'want', 'fuck', 'relationship', 'tri', 'sound', 'like', 'hoe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol boy want fuck relationship tri sound like hoe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2560 :\n",
      "\n",
      "\tTweet's text':  grandtheftauto five troller \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sotrue', '#ihavenolife', '#misshim', '#lovehim', '#haveabetterone', '#Justin', '#no', '#justinbeiber'] \n",
      "\n",
      "\tTweet tokenized by words:  ['grandtheftauto', 'five', 'troller'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['grandtheftauto five troller'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2561 :\n",
      "\n",
      "\tTweet's text':  like u go williamsvil east ur parent hand u money ur much better everyon els hahaha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['like', 'u', 'go', 'williamsvil', 'east', 'ur', 'parent', 'hand', 'u', 'money', 'ur', 'much', 'better', 'everyon', 'els', 'hahaha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['like u go williamsvil east ur parent hand u money ur much better everyon els hahaha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2562 :\n",
      "\n",
      "\tTweet's text':  amaz mani american slag capit comfort armchair sip decaf skinni pumpkin spice latt \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['amaz', 'mani', 'american', 'slag', 'capit', 'comfort', 'armchair', 'sip', 'decaf', 'skinni', 'pumpkin', 'spice', 'latt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['amaz mani american slag capit comfort armchair sip decaf skinni pumpkin spice latt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2563 :\n",
      "\n",
      "\tTweet's text':  don know i super excit get clean car shovel deal fool road oh yeah \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'know', 'i', 'super', 'excit', 'get', 'clean', 'car', 'shovel', 'deal', 'fool', 'road', 'oh', 'yeah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don know i super excit get clean car shovel deal fool road oh yeah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2564 :\n",
      "\n",
      "\tTweet's text':  and warmli ment you \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'warmli', 'ment', 'you'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and warmli ment you'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2565 :\n",
      "\n",
      "\tTweet's text':  the link say the request page could found wa intent \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'link', 'say', 'the', 'request', 'page', 'could', 'found', 'wa', 'intent'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the link say the request page could found wa intent'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2566 :\n",
      "\n",
      "\tTweet's text':  realli thi absolut belt especi toward tom boon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#DeepRespect'] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'thi', 'absolut', 'belt', 'especi', 'toward', 'tom', 'boon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli thi absolut belt especi toward tom boon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2567 :\n",
      "\n",
      "\tTweet's text':  well brightest bulb chandeli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'brightest', 'bulb', 'chandeli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well brightest bulb chandeli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2568 :\n",
      "\n",
      "\tTweet's text':  i know \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2569 :\n",
      "\n",
      "\tTweet's text':  rememb one episod santana want dancer forgot altogeth good time good time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Glee'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rememb', 'one', 'episod', 'santana', 'want', 'dancer', 'forgot', 'altogeth', 'good', 'time', 'good', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rememb one episod santana want dancer forgot altogeth good time good time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2570 :\n",
      "\n",
      "\tTweet's text':  sound like room lester batteri mate david ross \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Cubs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sound', 'like', 'room', 'lester', 'batteri', 'mate', 'david', 'ross'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sound like room lester batteri mate david ross'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2571 :\n",
      "\n",
      "\tTweet's text':  bruh i realiz i wear shirt the chick dump lmfao \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bruh', 'i', 'realiz', 'i', 'wear', 'shirt', 'the', 'chick', 'dump', 'lmfao'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bruh i realiz i wear shirt the chick dump lmfao'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2572 :\n",
      "\n",
      "\tTweet's text':  oh wow talk skype cool \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'wow', 'talk', 'skype', 'cool'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh wow talk skype cool'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2573 :\n",
      "\n",
      "\tTweet's text':  tri internet month now i know ethiopian feel \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tri', 'internet', 'month', 'now', 'i', 'know', 'ethiopian', 'feel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tri internet month now i know ethiopian feel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2574 :\n",
      "\n",
      "\tTweet's text':  histor imag that normal toler \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Breastfeeding'] \n",
      "\n",
      "\tTweet tokenized by words:  ['histor', 'imag', 'that', 'normal', 'toler'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['histor imag that normal toler'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2575 :\n",
      "\n",
      "\tTweet's text':  two year ago got binocular parent caus i need look futur i like cool tweet year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['two', 'year', 'ago', 'got', 'binocular', 'parent', 'caus', 'i', 'need', 'look', 'futur', 'i', 'like', 'cool', 'tweet', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['two year ago got binocular parent caus i need look futur i like cool tweet year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2576 :\n",
      "\n",
      "\tTweet's text':  just watch pretzel made \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#interesinglife', '#whatamidoingwithmylife', '#longesthashtagnotneededbutYOLO'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'watch', 'pretzel', 'made'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just watch pretzel made'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2577 :\n",
      "\n",
      "\tTweet's text':  lineup full goal offens intent \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#LFC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lineup', 'full', 'goal', 'offens', 'intent'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lineup full goal offens intent'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2578 :\n",
      "\n",
      "\tTweet's text':  love trust get peopl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['ok_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'trust', 'get', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love trust get peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2579 :\n",
      "\n",
      "\tTweet's text':  fact liber school system ye i conserv no make racist accus \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fact', 'liber', 'school', 'system', 'ye', 'i', 'conserv', 'no', 'make', 'racist', 'accus'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fact liber school system ye i conserv no make racist accus'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2580 :\n",
      "\n",
      "\tTweet's text':  injur suspici explos \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#A', '#TERROR', '#ORGANIZATION', '#Hamas', '#Gaza', '#Israel'] \n",
      "\n",
      "\tTweet tokenized by words:  ['injur', 'suspici', 'explos'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['injur suspici explos'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2581 :\n",
      "\n",
      "\tTweet's text':  redefin network mean lone moron talk youtub \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['redefin', 'network', 'mean', 'lone', 'moron', 'talk', 'youtub'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['redefin network mean lone moron talk youtub'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2582 :\n",
      "\n",
      "\tTweet's text':  a voic reason cri wilder hysteria \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'voic', 'reason', 'cri', 'wilder', 'hysteria'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a voic reason cri wilder hysteria'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2583 :\n",
      "\n",
      "\tTweet's text':  i love nh \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'nh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love nh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2584 :\n",
      "\n",
      "\tTweet's text':  the world s biggest onlin job click get start now \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'world', 's', 'biggest', 'onlin', 'job', 'click', 'get', 'start', 'now'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the world s biggest onlin job click get start now'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2585 :\n",
      "\n",
      "\tTweet's text':  carphon warehous call centr employe classi peopl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['carphon', 'warehous', 'call', 'centr', 'employe', 'classi', 'peopl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['carphon warehous call centr employe classi peopl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2586 :\n",
      "\n",
      "\tTweet's text':  be publicli call heartless arsehol go day usual \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'publicli', 'call', 'heartless', 'arsehol', 'go', 'day', 'usual'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be publicli call heartless arsehol go day usual'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2587 :\n",
      "\n",
      "\tTweet's text':  oh brother bar journal high day follow retard \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'brother', 'bar', 'journal', 'high', 'day', 'follow', 'retard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh brother bar journal high day follow retard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2588 :\n",
      "\n",
      "\tTweet's text':  add your babi can read dvd \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['add', 'your', 'babi', 'can', 'read', 'dvd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['add your babi can read dvd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2589 :\n",
      "\n",
      "\tTweet's text':  about girl nirvana cover \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TeenAnalCasting', '#Katarro', '#8211'] \n",
      "\n",
      "\tTweet tokenized by words:  ['about', 'girl', 'nirvana', 'cover'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['about girl nirvana cover'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2590 :\n",
      "\n",
      "\tTweet's text':  yeah stress isnt word could easili punch someon face right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'stress', 'isnt', 'word', 'could', 'easili', 'punch', 'someon', 'face', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah stress isnt word could easili punch someon face right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2591 :\n",
      "\n",
      "\tTweet's text':  it super duper fun wake immedi shovel car driveway minut \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fuckinsnow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'super', 'duper', 'fun', 'wake', 'immedi', 'shovel', 'car', 'driveway', 'minut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it super duper fun wake immedi shovel car driveway minut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2592 :\n",
      "\n",
      "\tTweet's text':  technic aint muzlam believ guy lost cellar saviour truestoryfam \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TrueStoryFam'] \n",
      "\n",
      "\tTweet tokenized by words:  ['technic', 'aint', 'muzlam', 'believ', 'guy', 'lost', 'cellar', 'saviour', 'truestoryfam'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['technic aint muzlam believ guy lost cellar saviour truestoryfam'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2593 :\n",
      "\n",
      "\tTweet's text':  one reason shop they make feel america \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Walmart', '#shopping', '#Islam', '#tcot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'reason', 'shop', 'they', 'make', 'feel', 'america'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one reason shop they make feel america'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2594 :\n",
      "\n",
      "\tTweet's text':  def understand ok tri find anyth imposs \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['def', 'understand', 'ok', 'tri', 'find', 'anyth', 'imposs'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['def understand ok tri find anyth imposs'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2595 :\n",
      "\n",
      "\tTweet's text':  go th centuri fox copi st centuri fox i hasten add unlitigi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'th', 'centuri', 'fox', 'copi', 'st', 'centuri', 'fox', 'i', 'hasten', 'add', 'unlitigi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go th centuri fox copi st centuri fox i hasten add unlitigi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2596 :\n",
      "\n",
      "\tTweet's text':  i plan i feel sick what surpris turn event \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'plan', 'i', 'feel', 'sick', 'what', 'surpris', 'turn', 'event'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i plan i feel sick what surpris turn event'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2597 :\n",
      "\n",
      "\tTweet's text':  pepe hair rt palacio bombguy ronaldo hair ms nini messi hair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['black_heart_suit'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pepe', 'hair', 'rt', 'palacio', 'bombguy', 'ronaldo', 'hair', 'ms', 'nini', 'messi', 'hair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pepe hair rt palacio bombguy ronaldo hair ms nini messi hair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2598 :\n",
      "\n",
      "\tTweet's text':  if foreign power hit japan embassi nyc missil realli attack us in sens i agre \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'foreign', 'power', 'hit', 'japan', 'embassi', 'nyc', 'missil', 'realli', 'attack', 'us', 'in', 'sens', 'i', 'agre'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if foreign power hit japan embassi nyc missil realli attack us in sens i agre'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2599 :\n",
      "\n",
      "\tTweet's text':  buzz go home tonight back month \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['buzz', 'go', 'home', 'tonight', 'back', 'month'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['buzz go home tonight back month'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2600 :\n",
      "\n",
      "\tTweet's text':  yeah import the man realli prize prat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'import', 'the', 'man', 'realli', 'prize', 'prat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah import the man realli prize prat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2601 :\n",
      "\n",
      "\tTweet's text':  there noth intimid serv chavvi lanki year old acn bum fluff \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cringe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'noth', 'intimid', 'serv', 'chavvi', 'lanki', 'year', 'old', 'acn', 'bum', 'fluff'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there noth intimid serv chavvi lanki year old acn bum fluff'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2602 :\n",
      "\n",
      "\tTweet's text':  when j need mailman come late when i wait mail come p \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'j', 'need', 'mailman', 'come', 'late', 'when', 'i', 'wait', 'mail', 'come', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when j need mailman come late when i wait mail come p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2603 :\n",
      "\n",
      "\tTweet's text':  fnc like either repeat stuff \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fnc', 'like', 'either', 'repeat', 'stuff'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fnc like either repeat stuff'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2604 :\n",
      "\n",
      "\tTweet's text':  join promoteam offici fan list receiv news event \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['join', 'promoteam', 'offici', 'fan', 'list', 'receiv', 'news', 'event'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['join promoteam offici fan list receiv news event'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2605 :\n",
      "\n",
      "\tTweet's text':  oh back xd justcodth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AdvancedWarfare', '#JustCODThing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'back', 'xd', 'justcodth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh back xd justcodth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2606 :\n",
      "\n",
      "\tTweet's text':  glad excit see \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['glad', 'excit', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['glad excit see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2607 :\n",
      "\n",
      "\tTweet's text':  wow realli homework weekend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#talkingabout', '#theteachers'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'realli', 'homework', 'weekend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow realli homework weekend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2608 :\n",
      "\n",
      "\tTweet's text':  studi histori read \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#gameofthrones', '#asongofice'] \n",
      "\n",
      "\tTweet tokenized by words:  ['studi', 'histori', 'read'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['studi histori read'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2609 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Israel', '#freezes', '#funds', '#Palestinians', '#over', '#ICC', '#approach'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2610 :\n",
      "\n",
      "\tTweet's text':  i never heard i quit like \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'never', 'heard', 'i', 'quit', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i never heard i quit like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2611 :\n",
      "\n",
      "\tTweet's text':  control junta genocid peac protest miner \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Venezuela', '#Moscow', '#Chechen', '#Grozny'] \n",
      "\n",
      "\tTweet tokenized by words:  ['control', 'junta', 'genocid', 'peac', 'protest', 'miner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['control junta genocid peac protest miner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2612 :\n",
      "\n",
      "\tTweet's text':  what great start morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#smh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'great', 'start', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what great start morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2613 :\n",
      "\n",
      "\tTweet's text':  got noth muslim fuck islam cunt disgust \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sydneysiege'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'noth', 'muslim', 'fuck', 'islam', 'cunt', 'disgust'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['got noth muslim fuck islam cunt disgust'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2614 :\n",
      "\n",
      "\tTweet's text':  lol drunk mom christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['pistol', 'cocktail_glass', 'white_smiling_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#thisisadisaster'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'drunk', 'mom', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol drunk mom christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2615 :\n",
      "\n",
      "\tTweet's text':  thank good holiday help work i love think know \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#annoyed', '#relieved', '#gone'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'good', 'holiday', 'help', 'work', 'i', 'love', 'think', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank good holiday help work i love think know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2616 :\n",
      "\n",
      "\tTweet's text':  pre work shenanigan lmbo alissamari b \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#letswork', '#kiddingnotkidding', '#funtimes', '#sheseriouslyrocks'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pre', 'work', 'shenanigan', 'lmbo', 'alissamari', 'b'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pre work shenanigan lmbo alissamari b'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2617 :\n",
      "\n",
      "\tTweet's text':  good luck afternoon month inact ring rusti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'luck', 'afternoon', 'month', 'inact', 'ring', 'rusti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good luck afternoon month inact ring rusti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2618 :\n",
      "\n",
      "\tTweet's text':  agre peopl sigh other hear my husband sigh time around \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Curious'] \n",
      "\n",
      "\tTweet tokenized by words:  ['agre', 'peopl', 'sigh', 'other', 'hear', 'my', 'husband', 'sigh', 'time', 'around'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['agre peopl sigh other hear my husband sigh time around'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2619 :\n",
      "\n",
      "\tTweet's text':  i bet gonna outsid today soooo warm t shirt short weather \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smirking_face', 'flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Funny'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'bet', 'gon', 'na', 'outsid', 'today', 'soooo', 'warm', 't', 'shirt', 'short', 'weather'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i bet gonna outsid today soooo warm t shirt short weather'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2620 :\n",
      "\n",
      "\tTweet's text':  produc mobil app \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bluedream'] \n",
      "\n",
      "\tTweet tokenized by words:  ['produc', 'mobil', 'app'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['produc mobil app'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2621 :\n",
      "\n",
      "\tTweet's text':  sip chicken cuppa soup watch excit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Jezza'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sip', 'chicken', 'cuppa', 'soup', 'watch', 'excit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sip chicken cuppa soup watch excit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2622 :\n",
      "\n",
      "\tTweet's text':  haha i go fun next year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'i', 'go', 'fun', 'next', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha i go fun next year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2623 :\n",
      "\n",
      "\tTweet's text':  men footbal clearli know good \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#archiesday', '#anychanceofasocial'] \n",
      "\n",
      "\tTweet tokenized by words:  ['men', 'footbal', 'clearli', 'know', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['men footbal clearli know good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2624 :\n",
      "\n",
      "\tTweet's text':  rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#and', '#As', '#But', '#Cake', '#Like', '#MMs', '#Made', '#Make', '#Food'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2625 :\n",
      "\n",
      "\tTweet's text':  so tori stood thank ford servic citi i want barf \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'tori', 'stood', 'thank', 'ford', 'servic', 'citi', 'i', 'want', 'barf'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so tori stood thank ford servic citi i want barf'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2626 :\n",
      "\n",
      "\tTweet's text':  appl jd sure \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['appl', 'jd', 'sure'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['appl jd sure'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2627 :\n",
      "\n",
      "\tTweet's text':  dip drip \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fat', '#sumo', '#hippoes', '#happy', '#like', '#so', '#turtle', '#googlemapcibae', '#love', '#bij'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dip', 'drip'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dip drip'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2628 :\n",
      "\n",
      "\tTweet's text':  i believ religi indoctrin either indoctrin futur group \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#indoctrination', '#Lefties'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'believ', 'religi', 'indoctrin', 'either', 'indoctrin', 'futur', 'group'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i believ religi indoctrin either indoctrin futur group'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2629 :\n",
      "\n",
      "\tTweet's text':  if gon judg peopl drink blaze foh go choke foreskin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'gon', 'judg', 'peopl', 'drink', 'blaze', 'foh', 'go', 'choke', 'foreskin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if gon judg peopl drink blaze foh go choke foreskin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2630 :\n",
      "\n",
      "\tTweet's text':  the champion leagu overr anyway \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'champion', 'leagu', 'overr', 'anyway'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the champion leagu overr anyway'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2631 :\n",
      "\n",
      "\tTweet's text':  danniella westbrook went food bank gone iceland oh yeah fuck \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#freedomofspeech'] \n",
      "\n",
      "\tTweet tokenized by words:  ['danniella', 'westbrook', 'went', 'food', 'bank', 'gone', 'iceland', 'oh', 'yeah', 'fuck'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['danniella westbrook went food bank gone iceland oh yeah fuck'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2632 :\n",
      "\n",
      "\tTweet's text':  day snuggl sofa happen \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['day', 'snuggl', 'sofa', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['day snuggl sofa happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2633 :\n",
      "\n",
      "\tTweet's text':  ugh i would give first born pepto bismol right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#upsettummy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ugh', 'i', 'would', 'give', 'first', 'born', 'pepto', 'bismol', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ugh i would give first born pepto bismol right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2634 :\n",
      "\n",
      "\tTweet's text':  so tht look yr acc specif wld need speak phone call charg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'tht', 'look', 'yr', 'acc', 'specif', 'wld', 'need', 'speak', 'phone', 'call', 'charg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so tht look yr acc specif wld need speak phone call charg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2635 :\n",
      "\n",
      "\tTweet's text':  consist free lebara lebara min sm unlimit unlimit sm to other network onli consist sm \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#UKPLUS', '#NO'] \n",
      "\n",
      "\tTweet tokenized by words:  ['consist', 'free', 'lebara', 'lebara', 'min', 'sm', 'unlimit', 'unlimit', 'sm', 'to', 'other', 'network', 'onli', 'consist', 'sm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['consist free lebara lebara min sm unlimit unlimit sm to other network onli consist sm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2636 :\n",
      "\n",
      "\tTweet's text':  beauti \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['beauti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['beauti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2637 :\n",
      "\n",
      "\tTweet's text':  realli show fastest lte around \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#speedtest'] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'show', 'fastest', 'lte', 'around'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli show fastest lte around'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2638 :\n",
      "\n",
      "\tTweet's text':  down not right that ya \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['down', 'not', 'right', 'that', 'ya'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['down not right that ya'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2639 :\n",
      "\n",
      "\tTweet's text':  is obamacar slow health care spend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'obamacar', 'slow', 'health', 'care', 'spend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is obamacar slow health care spend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2640 :\n",
      "\n",
      "\tTweet's text':  that fantast date news also \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'fantast', 'date', 'news', 'also'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that fantast date news also'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2641 :\n",
      "\n",
      "\tTweet's text':  corey brewer look like readi minnesota \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TradeBait'] \n",
      "\n",
      "\tTweet tokenized by words:  ['corey', 'brewer', 'look', 'like', 'readi', 'minnesota'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['corey brewer look like readi minnesota'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2642 :\n",
      "\n",
      "\tTweet's text':  do i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Cthulhu', '#Christmas', '#Lovecraft', '#SantaClaus', '#funny'] \n",
      "\n",
      "\tTweet tokenized by words:  ['do', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['do i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2643 :\n",
      "\n",
      "\tTweet's text':  sorkin identifi attack free speech soni hacker attack media publish leak \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SonyHack'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sorkin', 'identifi', 'attack', 'free', 'speech', 'soni', 'hacker', 'attack', 'media', 'publish', 'leak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sorkin identifi attack free speech soni hacker attack media publish leak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2644 :\n",
      "\n",
      "\tTweet's text':  most hindu depend western research explain written hindu scriptur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FacePalm'] \n",
      "\n",
      "\tTweet tokenized by words:  ['most', 'hindu', 'depend', 'western', 'research', 'explain', 'written', 'hindu', 'scriptur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['most hindu depend western research explain written hindu scriptur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2645 :\n",
      "\n",
      "\tTweet's text':  manag fall flat face librari stair made top list proudest student moment \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['manag', 'fall', 'flat', 'face', 'librari', 'stair', 'made', 'top', 'list', 'proudest', 'student', 'moment'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['manag fall flat face librari stair made top list proudest student moment'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2646 :\n",
      "\n",
      "\tTweet's text':  thank connect alway look forward exchang thought n idea work n \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#entrepreneur', '#green', '#sustainability'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'connect', 'alway', 'look', 'forward', 'exchang', 'thought', 'n', 'idea', 'work', 'n'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank connect alway look forward exchang thought n idea work n'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2647 :\n",
      "\n",
      "\tTweet's text':  btw dummi limit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['btw', 'dummi', 'limit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['btw dummi limit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2648 :\n",
      "\n",
      "\tTweet's text':  i need pillow fall asleep mymalsh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'need', 'pillow', 'fall', 'asleep', 'mymalsh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i need pillow fall asleep mymalsh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2649 :\n",
      "\n",
      "\tTweet's text':  i think get embarrass trashi realli cute \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'get', 'embarrass', 'trashi', 'realli', 'cute'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think get embarrass trashi realli cute'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2650 :\n",
      "\n",
      "\tTweet's text':  wow i feel bad actual job teacher \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#stopcomplaing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'feel', 'bad', 'actual', 'job', 'teacher'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i feel bad actual job teacher'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2651 :\n",
      "\n",
      "\tTweet's text':  he half pace season henderson would bigger loss \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['he', 'half', 'pace', 'season', 'henderson', 'would', 'bigger', 'loss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['he half pace season henderson would bigger loss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2652 :\n",
      "\n",
      "\tTweet's text':  grip new ebook faintheart polit correct pleas visit site \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['grip', 'new', 'ebook', 'faintheart', 'polit', 'correct', 'pleas', 'visit', 'site'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['grip new ebook faintheart polit correct pleas visit site'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2653 :\n",
      "\n",
      "\tTweet's text':  just saw roel de vri nissan boss say market focu emot quantifi everyth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#marketing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'saw', 'roel', 'de', 'vri', 'nissan', 'boss', 'say', 'market', 'focu', 'emot', 'quantifi', 'everyth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just saw roel de vri nissan boss say market focu emot quantifi everyth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2654 :\n",
      "\n",
      "\tTweet's text':  year sinc tweet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#DoinItRight', '#MaybeNextYear', '#NewYearsResolution'] \n",
      "\n",
      "\tTweet tokenized by words:  ['year', 'sinc', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['year sinc tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2655 :\n",
      "\n",
      "\tTweet's text':  i three test two danc perform tomorrow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EasyDay'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'three', 'test', 'two', 'danc', 'perform', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i three test two danc perform tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2656 :\n",
      "\n",
      "\tTweet's text':  tl show lester deal hit boston wish announc made parti involv least coher \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Notsarcasm'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tl', 'show', 'lester', 'deal', 'hit', 'boston', 'wish', 'announc', 'made', 'parti', 'involv', 'least', 'coher'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tl show lester deal hit boston wish announc made parti involv least coher'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2657 :\n",
      "\n",
      "\tTweet's text':  proud artwork \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['sparkling_heart', 'smiling_face_with_halo'] \n",
      "\n",
      "\tTweet's hashtags':  ['#proud'] \n",
      "\n",
      "\tTweet tokenized by words:  ['proud', 'artwork'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['proud artwork'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2658 :\n",
      "\n",
      "\tTweet's text':  i find farrrrr funni \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  ['#wow', '#can', '#u'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'find', 'farrrrr', 'funni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i find farrrrr funni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2659 :\n",
      "\n",
      "\tTweet's text':  hope everyon love marxist christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hope', 'everyon', 'love', 'marxist', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hope everyon love marxist christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2660 :\n",
      "\n",
      "\tTweet's text':  i blame bro marri i would support milan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'blame', 'bro', 'marri', 'i', 'would', 'support', 'milan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i blame bro marri i would support milan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2661 :\n",
      "\n",
      "\tTweet's text':  let hope nene hurt day day instead week week pleas \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#praying', '#basketballgods'] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'hope', 'nene', 'hurt', 'day', 'day', 'instead', 'week', 'week', 'pleas'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let hope nene hurt day day instead week week pleas'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2662 :\n",
      "\n",
      "\tTweet's text':  peak \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['peak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2663 :\n",
      "\n",
      "\tTweet's text':  all i want see \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['all', 'i', 'want', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['all i want see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2664 :\n",
      "\n",
      "\tTweet's text':  nice origin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'origin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice origin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2665 :\n",
      "\n",
      "\tTweet's text':  i miss close \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pensive_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'miss', 'close'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i miss close'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2666 :\n",
      "\n",
      "\tTweet's text':  i loveee final soooo much and get sleep best part \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['pistol', 'astonished_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'loveee', 'final', 'soooo', 'much', 'and', 'get', 'sleep', 'best', 'part'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i loveee final soooo much and get sleep best part'] \n",
      "\n",
      "---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tweet  2667 :\n",
      "\n",
      "\tTweet's text':  race human dont look thing myth race \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['race', 'human', 'dont', 'look', 'thing', 'myth', 'race'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['race human dont look thing myth race'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2668 :\n",
      "\n",
      "\tTweet's text':  still wonder pop save password still pop even tick keep log sarcast \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['still', 'wonder', 'pop', 'save', 'password', 'still', 'pop', 'even', 'tick', 'keep', 'log', 'sarcast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['still wonder pop save password still pop even tick keep log sarcast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2669 :\n",
      "\n",
      "\tTweet's text':  thank share mike opinion mean lot us \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#orisit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'share', 'mike', 'opinion', 'mean', 'lot', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank share mike opinion mean lot us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2670 :\n",
      "\n",
      "\tTweet's text':  it funni sit minut and notic taylor swift \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MTVStars'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'funni', 'sit', 'minut', 'and', 'notic', 'taylor', 'swift'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it funni sit minut and notic taylor swift'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2671 :\n",
      "\n",
      "\tTweet's text':  now offici look singl ha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['now', 'offici', 'look', 'singl', 'ha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['now offici look singl ha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2672 :\n",
      "\n",
      "\tTweet's text':  what els would friday tgif \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TGIF', '#8crap'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'els', 'would', 'friday', 'tgif'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what els would friday tgif'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2673 :\n",
      "\n",
      "\tTweet's text':  historian collect correct fact wrong abus \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Correct', '#Wrong', '#FactAboutAbuse'] \n",
      "\n",
      "\tTweet tokenized by words:  ['historian', 'collect', 'correct', 'fact', 'wrong', 'abus'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['historian collect correct fact wrong abus'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2674 :\n",
      "\n",
      "\tTweet's text':  i see \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2675 :\n",
      "\n",
      "\tTweet's text':  i see eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['purple_heart'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Kingofpop', '#mjackson', '#michaeljackson', '#invicible', '#breakofdawn', '#king', '#is', '#dead'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'see', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i see eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2676 :\n",
      "\n",
      "\tTweet's text':  hahaha enjoy i got christma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#selfiestick'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hahaha', 'enjoy', 'i', 'got', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hahaha enjoy i got christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2677 :\n",
      "\n",
      "\tTweet's text':  such qualiti custom servic today xbox one \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thisiscrap', '#nothelpfulatall'] \n",
      "\n",
      "\tTweet tokenized by words:  ['such', 'qualiti', 'custom', 'servic', 'today', 'xbox', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['such qualiti custom servic today xbox one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2678 :\n",
      "\n",
      "\tTweet's text':  tiger wood is now hero group global brand ambassador read stori \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#brand', '#buzzfeed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tiger', 'wood', 'is', 'now', 'hero', 'group', 'global', 'brand', 'ambassador', 'read', 'stori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tiger wood is now hero group global brand ambassador read stori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2679 :\n",
      "\n",
      "\tTweet's text':  i box set the complet stepto son that cheer \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'box', 'set', 'the', 'complet', 'stepto', 'son', 'that', 'cheer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i box set the complet stepto son that cheer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2680 :\n",
      "\n",
      "\tTweet's text':  i love i complet wide awak \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'i', 'complet', 'wide', 'awak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love i complet wide awak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2681 :\n",
      "\n",
      "\tTweet's text':  so far today go awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fuckoff'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'far', 'today', 'go', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so far today go awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2682 :\n",
      "\n",
      "\tTweet's text':  mcrodyn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#indonesian', '#czech', '#mix', '#girl', '#with', '#my', '#boy', '#elvis', '#im', '#single'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mcrodyn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mcrodyn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2683 :\n",
      "\n",
      "\tTweet's text':  just notic i cross follow past month guy i hope enjoy sarcasm b c know valu ad nil \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'notic', 'i', 'cross', 'follow', 'past', 'month', 'guy', 'i', 'hope', 'enjoy', 'sarcasm', 'b', 'c', 'know', 'valu', 'ad', 'nil'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just notic i cross follow past month guy i hope enjoy sarcasm b c know valu ad nil'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2684 :\n",
      "\n",
      "\tTweet's text':  follow relev \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['follow', 'relev'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['follow relev'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2685 :\n",
      "\n",
      "\tTweet's text':  the american justic system \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign', 'clapping_hands_sign', 'person_raising_both_hands_in_celebration'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'american', 'justic', 'system'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the american justic system'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2686 :\n",
      "\n",
      "\tTweet's text':  as littl girl i would dream shout instruct repeatedli complet ignor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#motherhood'] \n",
      "\n",
      "\tTweet tokenized by words:  ['as', 'littl', 'girl', 'i', 'would', 'dream', 'shout', 'instruct', 'repeatedli', 'complet', 'ignor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['as littl girl i would dream shout instruct repeatedli complet ignor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2687 :\n",
      "\n",
      "\tTweet's text':  nice friendli driver never get bu note mate way make feel welcom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'friendli', 'driver', 'never', 'get', 'bu', 'note', 'mate', 'way', 'make', 'feel', 'welcom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice friendli driver never get bu note mate way make feel welcom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2688 :\n",
      "\n",
      "\tTweet's text':  thank mom love word love let know proud \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wordshurt'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'mom', 'love', 'word', 'love', 'let', 'know', 'proud'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank mom love word love let know proud'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2689 :\n",
      "\n",
      "\tTweet's text':  rt rich rodriguez avail photo op he fiesta bowl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Michigan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt', 'rich', 'rodriguez', 'avail', 'photo', 'op', 'he', 'fiesta', 'bowl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt rich rodriguez avail photo op he fiesta bowl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2690 :\n",
      "\n",
      "\tTweet's text':  use brain stop drink tea feel sober good bring tomorrow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_throwing_a_kiss'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['use', 'brain', 'stop', 'drink', 'tea', 'feel', 'sober', 'good', 'bring', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['use brain stop drink tea feel sober good bring tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2691 :\n",
      "\n",
      "\tTweet's text':  ok know cleen go win let end not excit amen to that \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#InkRivals'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ok', 'know', 'cleen', 'go', 'win', 'let', 'end', 'not', 'excit', 'amen', 'to', 'that'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ok know cleen go win let end not excit amen to that'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2692 :\n",
      "\n",
      "\tTweet's text':  merri christma xd thank make \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BFHardline'] \n",
      "\n",
      "\tTweet tokenized by words:  ['merri', 'christma', 'xd', 'thank', 'make'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['merri christma xd thank make'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2693 :\n",
      "\n",
      "\tTweet's text':  we still got alot moonlight left \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'still', 'got', 'alot', 'moonlight', 'left'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we still got alot moonlight left'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2694 :\n",
      "\n",
      "\tTweet's text':  love trier mate serious game seem pass poor ball pick runner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'trier', 'mate', 'serious', 'game', 'seem', 'pass', 'poor', 'ball', 'pick', 'runner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love trier mate serious game seem pass poor ball pick runner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2695 :\n",
      "\n",
      "\tTweet's text':  the mous first incept memori sound braaaaaawwwwwwwwwp \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'mous', 'first', 'incept', 'memori', 'sound', 'braaaaaawwwwwwwwwp'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the mous first incept memori sound braaaaaawwwwwwwwwp'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2696 :\n",
      "\n",
      "\tTweet's text':  bad gift wall give gooden k cash via \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bad', 'gift', 'wall', 'give', 'gooden', 'k', 'cash', 'via'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bad gift wall give gooden k cash via'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2697 :\n",
      "\n",
      "\tTweet's text':  porygon found \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#firemen', '#paint'] \n",
      "\n",
      "\tTweet tokenized by words:  ['porygon', 'found'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['porygon found'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2698 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OPEC', '#chief', '#defends', '#policy', '#says', '#group', '#try', '#ride', '#out', '#price', '#fall'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2699 :\n",
      "\n",
      "\tTweet's text':  i think i gonna check music later thank \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'i', 'gon', 'na', 'check', 'music', 'later', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think i gonna check music later thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2700 :\n",
      "\n",
      "\tTweet's text':  care cayc that almost racist statement \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['care', 'cayc', 'that', 'almost', 'racist', 'statement'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['care cayc that almost racist statement'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2701 :\n",
      "\n",
      "\tTweet's text':  you gone i gotta stay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#coldpants', '#offtomysteriousplaces', '#bye'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'gone', 'i', 'got', 'ta', 'stay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you gone i gotta stay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2702 :\n",
      "\n",
      "\tTweet's text':  ya i rememb win one regular season game like super bowl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ya', 'i', 'rememb', 'win', 'one', 'regular', 'season', 'game', 'like', 'super', 'bowl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ya i rememb win one regular season game like super bowl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2703 :\n",
      "\n",
      "\tTweet's text':  oversleep bestttt \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oversleep', 'bestttt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oversleep bestttt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2704 :\n",
      "\n",
      "\tTweet's text':  i tomorrow danger way live \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'tomorrow', 'danger', 'way', 'live'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i tomorrow danger way live'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2705 :\n",
      "\n",
      "\tTweet's text':  may alreadi gone littl far eyebrow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#goodgrief'] \n",
      "\n",
      "\tTweet tokenized by words:  ['may', 'alreadi', 'gone', 'littl', 'far', 'eyebrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['may alreadi gone littl far eyebrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2706 :\n",
      "\n",
      "\tTweet's text':  cheap expens \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cheap', 'expens'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cheap expens'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2707 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CHRISTMAS', '#GIFT', '#BLESSING', '#Santa', '#follow', '#TheInterview', '#BharatRatna', '#CallMeEva'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2708 :\n",
      "\n",
      "\tTweet's text':  hire manag will wait day guy join immedi cannot take guy day notic period \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hire', 'manag', 'will', 'wait', 'day', 'guy', 'join', 'immedi', 'can', 'not', 'take', 'guy', 'day', 'notic', 'period'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hire manag will wait day guy join immedi cannot take guy day notic period'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2709 :\n",
      "\n",
      "\tTweet's text':  still believ teammat engag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Holymoly', '#RingBySpring', '#TurnUpppp'] \n",
      "\n",
      "\tTweet tokenized by words:  ['still', 'believ', 'teammat', 'engag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['still believ teammat engag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2710 :\n",
      "\n",
      "\tTweet's text':  gee so hard believ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gee', 'so', 'hard', 'believ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gee so hard believ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2711 :\n",
      "\n",
      "\tTweet's text':  thank help gile \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'help', 'gile'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank help gile'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2712 :\n",
      "\n",
      "\tTweet's text':  whi everyth must b turn disast aveng anoth disast what gratifi forget tht human pakistani \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'everyth', 'must', 'b', 'turn', 'disast', 'aveng', 'anoth', 'disast', 'what', 'gratifi', 'forget', 'tht', 'human', 'pakistani'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi everyth must b turn disast aveng anoth disast what gratifi forget tht human pakistani'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2713 :\n",
      "\n",
      "\tTweet's text':  i keep smile face get bullcrap instead break like usual \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'keep', 'smile', 'face', 'get', 'bullcrap', 'instead', 'break', 'like', 'usual'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i keep smile face get bullcrap instead break like usual'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2714 :\n",
      "\n",
      "\tTweet's text':  is wrong want read horribl thing world one day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'wrong', 'want', 'read', 'horribl', 'thing', 'world', 'one', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is wrong want read horribl thing world one day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2715 :\n",
      "\n",
      "\tTweet's text':  the sooner i find sooner i go love convers hr i yet tell work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lookingforwardtothat'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'sooner', 'i', 'find', 'sooner', 'i', 'go', 'love', 'convers', 'hr', 'i', 'yet', 'tell', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the sooner i find sooner i go love convers hr i yet tell work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2716 :\n",
      "\n",
      "\tTweet's text':  coin erraji zeeginganinja seem peopl need clarif \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sydneysiege'] \n",
      "\n",
      "\tTweet tokenized by words:  ['coin', 'erraji', 'zeeginganinja', 'seem', 'peopl', 'need', 'clarif'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['coin erraji zeeginganinja seem peopl need clarif'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2717 :\n",
      "\n",
      "\tTweet's text':  hernanpuent repostapp perfect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['black_rightwards_arrow', 'soon_with_rightwards_arrow_above', 'camera'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Repost', '#ComingSoon', '#LoveIt', '#LoveU'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hernanpuent', 'repostapp', 'perfect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hernanpuent repostapp perfect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2718 :\n",
      "\n",
      "\tTweet's text':  wish i mayb next year i one mad sock cloth sock \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wish', 'i', 'mayb', 'next', 'year', 'i', 'one', 'mad', 'sock', 'cloth', 'sock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wish i mayb next year i one mad sock cloth sock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2719 :\n",
      "\n",
      "\tTweet's text':  i rememb last time i saw bit integ mainstream media \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Software', '#GangnamStyle', '#Geek'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'rememb', 'last', 'time', 'i', 'saw', 'bit', 'integ', 'mainstream', 'media'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i rememb last time i saw bit integ mainstream media'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2720 :\n",
      "\n",
      "\tTweet's text':  christma music stair master \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SundayFunday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['christma', 'music', 'stair', 'master'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['christma music stair master'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2721 :\n",
      "\n",
      "\tTweet's text':  i love way male buffoon woman smart alway win \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#white', '#black', '#culturalmarxism'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'way', 'male', 'buffoon', 'woman', 'smart', 'alway', 'win'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love way male buffoon woman smart alway win'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2722 :\n",
      "\n",
      "\tTweet's text':  can almost smell turkey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hungry'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'almost', 'smell', 'turkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can almost smell turkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2723 :\n",
      "\n",
      "\tTweet's text':  funni thing secur guard fed ex la i pick time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['funni', 'thing', 'secur', 'guard', 'fed', 'ex', 'la', 'i', 'pick', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['funni thing secur guard fed ex la i pick time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2724 :\n",
      "\n",
      "\tTweet's text':  noth beat surpris tetanu shot doctor offic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#blessed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['noth', 'beat', 'surpris', 'tetanu', 'shot', 'doctor', 'offic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noth beat surpris tetanu shot doctor offic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2725 :\n",
      "\n",
      "\tTweet's text':  school \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['school'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['school'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2726 :\n",
      "\n",
      "\tTweet's text':  photo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tea', '#art', '#abstract', '#color', '#colors', '#fun', '#how', '#are', '#you', '#artist', '#spainish', '#exhibit', '#spain'] \n",
      "\n",
      "\tTweet tokenized by words:  ['photo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['photo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2727 :\n",
      "\n",
      "\tTweet's text':  absolut appal servic can wait rise fare next month \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#excuses', '#joke'] \n",
      "\n",
      "\tTweet tokenized by words:  ['absolut', 'appal', 'servic', 'can', 'wait', 'rise', 'fare', 'next', 'month'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['absolut appal servic can wait rise fare next month'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2728 :\n",
      "\n",
      "\tTweet's text':  wait citi data becom fox new site soon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wait', 'citi', 'data', 'becom', 'fox', 'new', 'site', 'soon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wait citi data becom fox new site soon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2729 :\n",
      "\n",
      "\tTweet's text':  not everyon understand that life goodnight gatecrash \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#goodnight', '#gatecrasher'] \n",
      "\n",
      "\tTweet tokenized by words:  ['not', 'everyon', 'understand', 'that', 'life', 'goodnight', 'gatecrash'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['not everyon understand that life goodnight gatecrash'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2730 :\n",
      "\n",
      "\tTweet's text':  resembl uncanni \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#firefly'] \n",
      "\n",
      "\tTweet tokenized by words:  ['resembl', 'uncanni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['resembl uncanni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2731 :\n",
      "\n",
      "\tTweet's text':  pleas rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Canned', '#Food', '#Lot', '#Of', '#Space', '#InteriorDecor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pleas', 'rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pleas rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2732 :\n",
      "\n",
      "\tTweet's text':  my christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#blessed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2733 :\n",
      "\n",
      "\tTweet's text':  well posit note i stay awak anoth hour i go get blood work done fun stuff \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#positivenote'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'posit', 'note', 'i', 'stay', 'awak', 'anoth', 'hour', 'i', 'go', 'get', 'blood', 'work', 'done', 'fun', 'stuff'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well posit note i stay awak anoth hour i go get blood work done fun stuff'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2734 :\n",
      "\n",
      "\tTweet's text':  love wake earli morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HockeyTournament', '#RefLife', '#Zebras'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'wake', 'earli', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love wake earli morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2735 :\n",
      "\n",
      "\tTweet's text':  cell phone accessori accessori kit audio adapt batteri bluetooth speaker \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cell', 'phone', 'accessori', 'accessori', 'kit', 'audio', 'adapt', 'batteri', 'bluetooth', 'speaker'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cell phone accessori accessori kit audio adapt batteri bluetooth speaker'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2736 :\n",
      "\n",
      "\tTweet's text':  i complet suck sub haha go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'complet', 'suck', 'sub', 'haha', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i complet suck sub haha go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2737 :\n",
      "\n",
      "\tTweet's text':  weather bomb weather bomb i applaud media innov help sensationalis usual autumn climat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['weather', 'bomb', 'weather', 'bomb', 'i', 'applaud', 'media', 'innov', 'help', 'sensationalis', 'usual', 'autumn', 'climat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['weather bomb weather bomb i applaud media innov help sensationalis usual autumn climat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2738 :\n",
      "\n",
      "\tTweet's text':  thi clinic psycholog exam gunna main caus whatev mental disord i develop \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'clinic', 'psycholog', 'exam', 'gunna', 'main', 'caus', 'whatev', 'mental', 'disord', 'i', 'develop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi clinic psycholog exam gunna main caus whatev mental disord i develop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2739 :\n",
      "\n",
      "\tTweet's text':  happi describ today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['white_smiling_face', 'purple_heart'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'describ', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi describ today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2740 :\n",
      "\n",
      "\tTweet's text':  look back saturday night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'back', 'saturday', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look back saturday night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2741 :\n",
      "\n",
      "\tTweet's text':  if i chose live winnipeg never see leaf win cup no cup \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TMLtalk', '#Leafs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'i', 'chose', 'live', 'winnipeg', 'never', 'see', 'leaf', 'win', 'cup', 'no', 'cup'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if i chose live winnipeg never see leaf win cup no cup'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2742 :\n",
      "\n",
      "\tTweet's text':  wrap crotch mountain commerci tonight pack everyth head loon mountain r \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wrap', 'crotch', 'mountain', 'commerci', 'tonight', 'pack', 'everyth', 'head', 'loon', 'mountain', 'r'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wrap crotch mountain commerci tonight pack everyth head loon mountain r'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2743 :\n",
      "\n",
      "\tTweet's text':  you still shit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cheater', '#pong'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'still', 'shit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you still shit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2744 :\n",
      "\n",
      "\tTweet's text':  oh lordi eat hardest go someon place esp i eat meat eye roll feed \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'lordi', 'eat', 'hardest', 'go', 'someon', 'place', 'esp', 'i', 'eat', 'meat', 'eye', 'roll', 'feed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh lordi eat hardest go someon place esp i eat meat eye roll feed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2745 :\n",
      "\n",
      "\tTweet's text':  fun day sunday ask travi lulay get face paint like toni the tiger \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Basics4Babies', '#worthashot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fun', 'day', 'sunday', 'ask', 'travi', 'lulay', 'get', 'face', 'paint', 'like', 'toni', 'the', 'tiger'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fun day sunday ask travi lulay get face paint like toni the tiger'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2746 :\n",
      "\n",
      "\tTweet's text':  tfln if i feel would hurt \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tfln', 'if', 'i', 'feel', 'would', 'hurt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tfln if i feel would hurt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2747 :\n",
      "\n",
      "\tTweet's text':  it excit see snapchat everybodi christma dinner wow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'excit', 'see', 'snapchat', 'everybodi', 'christma', 'dinner', 'wow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it excit see snapchat everybodi christma dinner wow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2748 :\n",
      "\n",
      "\tTweet's text':  yaaaayyy valentin day stuff alreadi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['two_hearts'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yaaaayyy', 'valentin', 'day', 'stuff', 'alreadi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yaaaayyy valentin day stuff alreadi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2749 :\n",
      "\n",
      "\tTweet's text':  bae energi drink want stay sleeeeeepi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#love', '#sleep'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bae', 'energi', 'drink', 'want', 'stay', 'sleeeeeepi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bae energi drink want stay sleeeeeepi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2750 :\n",
      "\n",
      "\tTweet's text':  so alli mccoist hand notic get pay rise realli ranger best interest heart \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'alli', 'mccoist', 'hand', 'notic', 'get', 'pay', 'rise', 'realli', 'ranger', 'best', 'interest', 'heart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so alli mccoist hand notic get pay rise realli ranger best interest heart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2751 :\n",
      "\n",
      "\tTweet's text':  imagin imaginari menageri manag manag imaginari menageri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['imagin', 'imaginari', 'menageri', 'manag', 'manag', 'imaginari', 'menageri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['imagin imaginari menageri manag manag imaginari menageri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2752 :\n",
      "\n",
      "\tTweet's text':  i swallow giant lozeng now throat actual hurt i glad i twitter share despair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sick'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'swallow', 'giant', 'lozeng', 'now', 'throat', 'actual', 'hurt', 'i', 'glad', 'i', 'twitter', 'share', 'despair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i swallow giant lozeng now throat actual hurt i glad i twitter share despair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2753 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WOW', '#CRAZYkids', '#OutofControlKids', '#DrPhi'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2754 :\n",
      "\n",
      "\tTweet's text':  some action along board \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tblightning', '#Tampa', '#fuji', '#x30', '#boltssocial', '#bethethunder'] \n",
      "\n",
      "\tTweet tokenized by words:  ['some', 'action', 'along', 'board'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['some action along board'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2755 :\n",
      "\n",
      "\tTweet's text':  i cut domin tweet finger milo tin but see i survivor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'cut', 'domin', 'tweet', 'finger', 'milo', 'tin', 'but', 'see', 'i', 'survivor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i cut domin tweet finger milo tin but see i survivor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2756 :\n",
      "\n",
      "\tTweet's text':  well come anoth page paper \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ilovecollege'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'come', 'anoth', 'page', 'paper'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well come anoth page paper'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2757 :\n",
      "\n",
      "\tTweet's text':  gotta bap hoe thou \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'bap', 'hoe', 'thou'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta bap hoe thou'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2758 :\n",
      "\n",
      "\tTweet's text':  current write i plan stop procrastin leav paper untouch day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['current', 'write', 'i', 'plan', 'stop', 'procrastin', 'leav', 'paper', 'untouch', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['current write i plan stop procrastin leav paper untouch day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2759 :\n",
      "\n",
      "\tTweet's text':  secur engin secur guard \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Hackers', '#security'] \n",
      "\n",
      "\tTweet tokenized by words:  ['secur', 'engin', 'secur', 'guard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['secur engin secur guard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2760 :\n",
      "\n",
      "\tTweet's text':  everyon compet privat good way better work togeth whole advanc human \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['everyon', 'compet', 'privat', 'good', 'way', 'better', 'work', 'togeth', 'whole', 'advanc', 'human'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everyon compet privat good way better work togeth whole advanc human'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2761 :\n",
      "\n",
      "\tTweet's text':  cours not \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cours', 'not'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cours not'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2762 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whoops', '#CelebrityLeakedPhotos'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2763 :\n",
      "\n",
      "\tTweet's text':  about take long ass drive music blast \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['person_raising_both_hands_in_celebration'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['about', 'take', 'long', 'ass', 'drive', 'music', 'blast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['about take long ass drive music blast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2764 :\n",
      "\n",
      "\tTweet's text':  absolut love harass group twatti adolesc late night shop \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['absolut', 'love', 'harass', 'group', 'twatti', 'adolesc', 'late', 'night', 'shop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['absolut love harass group twatti adolesc late night shop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2765 :\n",
      "\n",
      "\tTweet's text':  these student athlet realli pick the wrong class to cheat in \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['these', 'student', 'athlet', 'realli', 'pick', 'the', 'wrong', 'class', 'to', 'cheat', 'in'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['these student athlet realli pick the wrong class to cheat in'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2766 :\n",
      "\n",
      "\tTweet's text':  chortl would like palmer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['chortl', 'would', 'like', 'palmer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['chortl would like palmer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2767 :\n",
      "\n",
      "\tTweet's text':  it good thing obama open cuba first term wait elect cuba \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cuba'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'good', 'thing', 'obama', 'open', 'cuba', 'first', 'term', 'wait', 'elect', 'cuba'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it good thing obama open cuba first term wait elect cuba'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2768 :\n",
      "\n",
      "\tTweet's text':  sure bring peac justic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AnEyeForAnEye', '#PeshawarAttack', '#Taliban'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sure', 'bring', 'peac', 'justic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sure bring peac justic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2769 :\n",
      "\n",
      "\tTweet's text':  xma blog feat read stori share love click \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['heavy_black_heart'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['xma', 'blog', 'feat', 'read', 'stori', 'share', 'love', 'click'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['xma blog feat read stori share love click'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2770 :\n",
      "\n",
      "\tTweet's text':  pick one time homi back stickin right us thank answer dm \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#realmvp'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pick', 'one', 'time', 'homi', 'back', 'stickin', 'right', 'us', 'thank', 'answer', 'dm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pick one time homi back stickin right us thank answer dm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2771 :\n",
      "\n",
      "\tTweet's text':  hostel fine actual i prob caught like germ walk around london thank wish better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hostel', 'fine', 'actual', 'i', 'prob', 'caught', 'like', 'germ', 'walk', 'around', 'london', 'thank', 'wish', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hostel fine actual i prob caught like germ walk around london thank wish better'] \n",
      "\n",
      "---------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet  2772 :\n",
      "\n",
      "\tTweet's text':  spider web lace chemis with line underwir cup strappi open back adjust strap \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['spider', 'web', 'lace', 'chemis', 'with', 'line', 'underwir', 'cup', 'strappi', 'open', 'back', 'adjust', 'strap'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['spider web lace chemis with line underwir cup strappi open back adjust strap'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2773 :\n",
      "\n",
      "\tTweet's text':  tell truth may smartest thing ever tweet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ireallythinkyouareafuckingidiot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tell', 'truth', 'may', 'smartest', 'thing', 'ever', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tell truth may smartest thing ever tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2774 :\n",
      "\n",
      "\tTweet's text':  realiz tweet advic day spill coffe right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sloppy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['realiz', 'tweet', 'advic', 'day', 'spill', 'coffe', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realiz tweet advic day spill coffe right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2775 :\n",
      "\n",
      "\tTweet's text':  it ador keep happen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'ador', 'keep', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it ador keep happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2776 :\n",
      "\n",
      "\tTweet's text':  advertis onlin special expiri countdown yet cant order anyth check postcod valid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['advertis', 'onlin', 'special', 'expiri', 'countdown', 'yet', 'cant', 'order', 'anyth', 'check', 'postcod', 'valid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['advertis onlin special expiri countdown yet cant order anyth check postcod valid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2777 :\n",
      "\n",
      "\tTweet's text':  the last time i get i miss \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'last', 'time', 'i', 'get', 'i', 'miss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the last time i get i miss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2778 :\n",
      "\n",
      "\tTweet's text':  it easi focu hand million thought run mind time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'easi', 'focu', 'hand', 'million', 'thought', 'run', 'mind', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it easi focu hand million thought run mind time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2779 :\n",
      "\n",
      "\tTweet's text':  wallahi speak unbeliev bid let alon wish happi celebr \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wallahi', 'speak', 'unbeliev', 'bid', 'let', 'alon', 'wish', 'happi', 'celebr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wallahi speak unbeliev bid let alon wish happi celebr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2780 :\n",
      "\n",
      "\tTweet's text':  and start p getench \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['P'] \n",
      "\n",
      "\tTweet's hashtags':  ['#GetEnchanted'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'start', 'p', 'getench'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and start p getench'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2781 :\n",
      "\n",
      "\tTweet's text':  i feel bless get ocular migrain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'feel', 'bless', 'get', 'ocular', 'migrain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i feel bless get ocular migrain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2782 :\n",
      "\n",
      "\tTweet's text':  yup sarcasm wine \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['information_desk_person', 'smiling_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  ['#winelover'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yup', 'sarcasm', 'wine'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yup sarcasm wine'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2783 :\n",
      "\n",
      "\tTweet's text':  one nighter semest done \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'nighter', 'semest', 'done'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one nighter semest done'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2784 :\n",
      "\n",
      "\tTweet's text':  great doe mean also give hunt kill wildlif europ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'doe', 'mean', 'also', 'give', 'hunt', 'kill', 'wildlif', 'europ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great doe mean also give hunt kill wildlif europ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2785 :\n",
      "\n",
      "\tTweet's text':  still w back sprain \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['still', 'w', 'back', 'sprain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['still w back sprain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2786 :\n",
      "\n",
      "\tTweet's text':  would will purchas vend machin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['would', 'will', 'purchas', 'vend', 'machin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['would will purchas vend machin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2787 :\n",
      "\n",
      "\tTweet's text':  i tweet nearli time i sure tweet realli need \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'tweet', 'nearli', 'time', 'i', 'sure', 'tweet', 'realli', 'need'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i tweet nearli time i sure tweet realli need'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2788 :\n",
      "\n",
      "\tTweet's text':  rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#40', '#Corner', '#Cute', '#Day', '#Expensive', '#diy', '#crafts'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2789 :\n",
      "\n",
      "\tTweet's text':  look forward mine boyfriend nd christma togeth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'forward', 'mine', 'boyfriend', 'nd', 'christma', 'togeth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look forward mine boyfriend nd christma togeth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2790 :\n",
      "\n",
      "\tTweet's text':  i love folk call bradi system qb the biggest peyton man fan \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'folk', 'call', 'bradi', 'system', 'qb', 'the', 'biggest', 'peyton', 'man', 'fan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love folk call bradi system qb the biggest peyton man fan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2791 :\n",
      "\n",
      "\tTweet's text':  look recommend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'recommend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look recommend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2792 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FLOOD', '#NOAH', '#HovindTheory', '#ICEAGE', '#Bible', '#Church', '#Christians', '#Jews', '#tcot'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2793 :\n",
      "\n",
      "\tTweet's text':  i sure made day lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'sure', 'made', 'day', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i sure made day lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2794 :\n",
      "\n",
      "\tTweet's text':  shit keep get better better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ShouldOfStayedInBed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['shit', 'keep', 'get', 'better', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shit keep get better better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2795 :\n",
      "\n",
      "\tTweet's text':  fever that fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fever', 'that', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fever that fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2796 :\n",
      "\n",
      "\tTweet's text':  and round ligament pain return yay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PregnancyProblems'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'round', 'ligament', 'pain', 'return', 'yay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and round ligament pain return yay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2797 :\n",
      "\n",
      "\tTweet's text':  great job report mental unstabl man call drug craze \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'job', 'report', 'mental', 'unstabl', 'man', 'call', 'drug', 'craze'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great job report mental unstabl man call drug craze'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2798 :\n",
      "\n",
      "\tTweet's text':  russel brand discuss today much london mansion \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#scum', '#weak'] \n",
      "\n",
      "\tTweet tokenized by words:  ['russel', 'brand', 'discuss', 'today', 'much', 'london', 'mansion'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['russel brand discuss today much london mansion'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2799 :\n",
      "\n",
      "\tTweet's text':  hey her profil say i heart jesu bad \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'her', 'profil', 'say', 'i', 'heart', 'jesu', 'bad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey her profil say i heart jesu bad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2800 :\n",
      "\n",
      "\tTweet's text':  logic invent kuffar everyth make perfect sens like monkey stone monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['logic', 'invent', 'kuffar', 'everyth', 'make', 'perfect', 'sens', 'like', 'monkey', 'stone', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['logic invent kuffar everyth make perfect sens like monkey stone monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2801 :\n",
      "\n",
      "\tTweet's text':  just hunch i think steven gerrard leav possibl go ml \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hesnodeed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'hunch', 'i', 'think', 'steven', 'gerrard', 'leav', 'possibl', 'go', 'ml'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just hunch i think steven gerrard leav possibl go ml'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2802 :\n",
      "\n",
      "\tTweet's text':  well sinc basic employe oil ga sector would make sens oper way \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'sinc', 'basic', 'employe', 'oil', 'ga', 'sector', 'would', 'make', 'sens', 'oper', 'way'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well sinc basic employe oil ga sector would make sens oper way'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2803 :\n",
      "\n",
      "\tTweet's text':  just hangin dawg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#eyesup'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'hangin', 'dawg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just hangin dawg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2804 :\n",
      "\n",
      "\tTweet's text':  sit around listen sad music realli help depress \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sit', 'around', 'listen', 'sad', 'music', 'realli', 'help', 'depress'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sit around listen sad music realli help depress'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2805 :\n",
      "\n",
      "\tTweet's text':  still awak sooo \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['still', 'awak', 'sooo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['still awak sooo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2806 :\n",
      "\n",
      "\tTweet's text':  watch move begin again verisimilitud overpow like i back music busi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'move', 'begin', 'again', 'verisimilitud', 'overpow', 'like', 'i', 'back', 'music', 'busi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch move begin again verisimilitud overpow like i back music busi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2807 :\n",
      "\n",
      "\tTweet's text':  i love mom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'mom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love mom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2808 :\n",
      "\n",
      "\tTweet's text':  some peopl listen ah well guess learn hard way \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['some', 'peopl', 'listen', 'ah', 'well', 'guess', 'learn', 'hard', 'way'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['some peopl listen ah well guess learn hard way'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2809 :\n",
      "\n",
      "\tTweet's text':  imagin high school today delusion dad make fool internet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['imagin', 'high', 'school', 'today', 'delusion', 'dad', 'make', 'fool', 'internet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['imagin high school today delusion dad make fool internet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2810 :\n",
      "\n",
      "\tTweet's text':  final open xd i use youtub video help thank much \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'open', 'xd', 'i', 'use', 'youtub', 'video', 'help', 'thank', 'much'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final open xd i use youtub video help thank much'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2811 :\n",
      "\n",
      "\tTweet's text':  the funki tast chocol chunki monkey cup georg jungl cup lick \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'funki', 'tast', 'chocol', 'chunki', 'monkey', 'cup', 'georg', 'jungl', 'cup', 'lick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the funki tast chocol chunki monkey cup georg jungl cup lick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2812 :\n",
      "\n",
      "\tTweet's text':  ye fountain jump sound like great januari activ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'fountain', 'jump', 'sound', 'like', 'great', 'januari', 'activ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye fountain jump sound like great januari activ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2813 :\n",
      "\n",
      "\tTweet's text':  i surpris coanchor alreadi nomin worst list \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'surpris', 'coanchor', 'alreadi', 'nomin', 'worst', 'list'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i surpris coanchor alreadi nomin worst list'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2814 :\n",
      "\n",
      "\tTweet's text':  l real cute \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['l', 'real', 'cute'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['l real cute'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2815 :\n",
      "\n",
      "\tTweet's text':  cours day monsoon outsid class am pm \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ilovelife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cours', 'day', 'monsoon', 'outsid', 'class', 'am', 'pm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cours day monsoon outsid class am pm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2816 :\n",
      "\n",
      "\tTweet's text':  late night snuggl boy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['two_hearts', 'purple_heart'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['late', 'night', 'snuggl', 'boy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['late night snuggl boy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2817 :\n",
      "\n",
      "\tTweet's text':  i want eat pizza friend rest life \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'want', 'eat', 'pizza', 'friend', 'rest', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i want eat pizza friend rest life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2818 :\n",
      "\n",
      "\tTweet's text':  i love cocoa \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'cocoa'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love cocoa'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2819 :\n",
      "\n",
      "\tTweet's text':  know want alway keep think bigger \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sagittarius'] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'want', 'alway', 'keep', 'think', 'bigger'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know want alway keep think bigger'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2820 :\n",
      "\n",
      "\tTweet's text':  come lad fuck better shite keep show \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['come', 'lad', 'fuck', 'better', 'shite', 'keep', 'show'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['come lad fuck better shite keep show'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2821 :\n",
      "\n",
      "\tTweet's text':  i know i see is see what i know feel see \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#time'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'i', 'see', 'is', 'see', 'what', 'i', 'know', 'feel', 'see'] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by sentences:  ['i know i see is see what i know feel see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2822 :\n",
      "\n",
      "\tTweet's text':  be project univers day my life sooooo interest \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'project', 'univers', 'day', 'my', 'life', 'sooooo', 'interest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be project univers day my life sooooo interest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2823 :\n",
      "\n",
      "\tTweet's text':  real tough whoop dungey ass \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['real', 'tough', 'whoop', 'dungey', 'ass'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['real tough whoop dungey ass'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2824 :\n",
      "\n",
      "\tTweet's text':  by dipmag gear releas next issu wifey seri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#covermodels'] \n",
      "\n",
      "\tTweet tokenized by words:  ['by', 'dipmag', 'gear', 'releas', 'next', 'issu', 'wifey', 'seri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['by dipmag gear releas next issu wifey seri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2825 :\n",
      "\n",
      "\tTweet's text':  the power went delano part still everyon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#blackout', '#HappyNewYear', '#besafe', '#goodnight'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'power', 'went', 'delano', 'part', 'still', 'everyon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the power went delano part still everyon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2826 :\n",
      "\n",
      "\tTweet's text':  whi sue give bonni anxieti stress pill \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'sue', 'give', 'bonni', 'anxieti', 'stress', 'pill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi sue give bonni anxieti stress pill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2827 :\n",
      "\n",
      "\tTweet's text':  now i written everyth i need know seem lot manag \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['now', 'i', 'written', 'everyth', 'i', 'need', 'know', 'seem', 'lot', 'manag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['now i written everyth i need know seem lot manag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2828 :\n",
      "\n",
      "\tTweet's text':  dont say anyth just rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dont', 'say', 'anyth', 'just', 'rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dont say anyth just rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2829 :\n",
      "\n",
      "\tTweet's text':  love i minut wait i reach wait knock back minut fantast \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'i', 'minut', 'wait', 'i', 'reach', 'wait', 'knock', 'back', 'minut', 'fantast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love i minut wait i reach wait knock back minut fantast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2830 :\n",
      "\n",
      "\tTweet's text':  funni annoy you men tee \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#funny', '#tees'] \n",
      "\n",
      "\tTweet tokenized by words:  ['funni', 'annoy', 'you', 'men', 'tee'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['funni annoy you men tee'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2831 :\n",
      "\n",
      "\tTweet's text':  newday jebbush consid run shock \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#5Things'] \n",
      "\n",
      "\tTweet tokenized by words:  ['newday', 'jebbush', 'consid', 'run', 'shock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['newday jebbush consid run shock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2832 :\n",
      "\n",
      "\tTweet's text':  jacki just had best joke i heard in awhil see evil monkeyse evil monkeyse evil monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'see-no-evil_monkey', 'weary_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jacki', 'just', 'had', 'best', 'joke', 'i', 'heard', 'in', 'awhil', 'see', 'evil', 'monkeyse', 'evil', 'monkeyse', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jacki just had best joke i heard in awhil see evil monkeyse evil monkeyse evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2833 :\n",
      "\n",
      "\tTweet's text':  i e except c right what w e i r d \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Tshirt', '#RulesWereMadeToBeBroken'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'e', 'except', 'c', 'right', 'what', 'w', 'e', 'i', 'r', 'd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i e except c right what w e i r d'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2834 :\n",
      "\n",
      "\tTweet's text':  i clarifi legion follow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NotForTheIntellectuals', '#DrHandsomeDennis'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'clarifi', 'legion', 'follow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i clarifi legion follow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2835 :\n",
      "\n",
      "\tTweet's text':  oh look i make peopl happi i magic man happi land who live gumdrop hous lolli pop lane \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'look', 'i', 'make', 'peopl', 'happi', 'i', 'magic', 'man', 'happi', 'land', 'who', 'live', 'gumdrop', 'hous', 'lolli', 'pop', 'lane'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh look i make peopl happi i magic man happi land who live gumdrop hous lolli pop lane'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2836 :\n",
      "\n",
      "\tTweet's text':  the place wanna sit seat earn danc quiksilvergoessuperson \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Dancing', '#QuiksilverGoesSupersonic'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'place', 'wan', 'na', 'sit', 'seat', 'earn', 'danc', 'quiksilvergoessuperson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the place wanna sit seat earn danc quiksilvergoessuperson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2837 :\n",
      "\n",
      "\tTweet's text':  those great last minut substitut \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['those', 'great', 'last', 'minut', 'substitut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['those great last minut substitut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2838 :\n",
      "\n",
      "\tTweet's text':  my famili might find giant lump ice sit i sit right transform nigher fellow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'famili', 'might', 'find', 'giant', 'lump', 'ice', 'sit', 'i', 'sit', 'right', 'transform', 'nigher', 'fellow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my famili might find giant lump ice sit i sit right transform nigher fellow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2839 :\n",
      "\n",
      "\tTweet's text':  the ultim how \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'ultim', 'how'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the ultim how'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2840 :\n",
      "\n",
      "\tTweet's text':  women get hit marri manag crack \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Hypocrites', '#practicewhatyoupreach'] \n",
      "\n",
      "\tTweet tokenized by words:  ['women', 'get', 'hit', 'marri', 'manag', 'crack'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['women get hit marri manag crack'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2841 :\n",
      "\n",
      "\tTweet's text':  love i came work charli said yeah got place pack charli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'i', 'came', 'work', 'charli', 'said', 'yeah', 'got', 'place', 'pack', 'charli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love i came work charli said yeah got place pack charli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2842 :\n",
      "\n",
      "\tTweet's text':  drjanechi but white white crime it like ribbon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['drjanechi', 'but', 'white', 'white', 'crime', 'it', 'like', 'ribbon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['drjanechi but white white crime it like ribbon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2843 :\n",
      "\n",
      "\tTweet's text':  aap said declar ak candid last list declar thi issu affect india gdp term u turn bjp \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AK4Delhi'] \n",
      "\n",
      "\tTweet tokenized by words:  ['aap', 'said', 'declar', 'ak', 'candid', 'last', 'list', 'declar', 'thi', 'issu', 'affect', 'india', 'gdp', 'term', 'u', 'turn', 'bjp'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aap said declar ak candid last list declar thi issu affect india gdp term u turn bjp'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2844 :\n",
      "\n",
      "\tTweet's text':  i happi thad lead multiplay design hardlin follow xd \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'happi', 'thad', 'lead', 'multiplay', 'design', 'hardlin', 'follow', 'xd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i happi thad lead multiplay design hardlin follow xd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2845 :\n",
      "\n",
      "\tTweet's text':  a \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BestDayEver'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2846 :\n",
      "\n",
      "\tTweet's text':  it longer polit barackobama set stage race war that way succeed \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'longer', 'polit', 'barackobama', 'set', 'stage', 'race', 'war', 'that', 'way', 'succeed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it longer polit barackobama set stage race war that way succeed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2847 :\n",
      "\n",
      "\tTweet's text':  salt n peppa geico commerci liter best ever onli one beat hump day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['salt', 'n', 'peppa', 'geico', 'commerci', 'liter', 'best', 'ever', 'onli', 'one', 'beat', 'hump', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['salt n peppa geico commerci liter best ever onli one beat hump day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2848 :\n",
      "\n",
      "\tTweet's text':  today blast \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'blast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today blast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2849 :\n",
      "\n",
      "\tTweet's text':  how look compar caus effect decis framework \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bigdata', '#analytics', '#cynefin'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'look', 'compar', 'caus', 'effect', 'decis', 'framework'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how look compar caus effect decis framework'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2850 :\n",
      "\n",
      "\tTweet's text':  smh yesterday i lose voic today woke mean ass cough headach christma could better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['Christmas', 'unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['smh', 'yesterday', 'i', 'lose', 'voic', 'today', 'woke', 'mean', 'ass', 'cough', 'headach', 'christma', 'could', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['smh yesterday i lose voic today woke mean ass cough headach christma could better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2851 :\n",
      "\n",
      "\tTweet's text':  rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#All', '#And', '#For', '#Hot', '#Rachel', '#style', '#fashion'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2852 :\n",
      "\n",
      "\tTweet's text':  well live till i yr old \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sarci', '#wit', '#low', '#constant'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'live', 'till', 'i', 'yr', 'old'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well live till i yr old'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2853 :\n",
      "\n",
      "\tTweet's text':  never fail make laugh talk show tv \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#chattyman', '#1', '#loveit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['never', 'fail', 'make', 'laugh', 'talk', 'show', 'tv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['never fail make laugh talk show tv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2854 :\n",
      "\n",
      "\tTweet's text':  women crazi ass shit guy least break heart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['women', 'crazi', 'ass', 'shit', 'guy', 'least', 'break', 'heart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['women crazi ass shit guy least break heart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2855 :\n",
      "\n",
      "\tTweet's text':  latest album free the univers \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SupersonicWithGionee', '#Mumbai'] \n",
      "\n",
      "\tTweet tokenized by words:  ['latest', 'album', 'free', 'the', 'univers'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['latest album free the univers'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2856 :\n",
      "\n",
      "\tTweet's text':  time post christma car wash yay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#friesenfamilychristmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'post', 'christma', 'car', 'wash', 'yay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time post christma car wash yay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2857 :\n",
      "\n",
      "\tTweet's text':  ebola but greed aka badmind kill easili and quickquick \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ebola', 'but', 'greed', 'aka', 'badmind', 'kill', 'easili', 'and', 'quickquick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ebola but greed aka badmind kill easili and quickquick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2858 :\n",
      "\n",
      "\tTweet's text':  tramp shit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#youoweme', '#follow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tramp', 'shit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tramp shit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2859 :\n",
      "\n",
      "\tTweet's text':  emwatson thank cover femin issu my favourit magazin cover ever lorraineel x \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['emwatson', 'thank', 'cover', 'femin', 'issu', 'my', 'favourit', 'magazin', 'cover', 'ever', 'lorraineel', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['emwatson thank cover femin issu my favourit magazin cover ever lorraineel x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2860 :\n",
      "\n",
      "\tTweet's text':  a alway chase want get keepgo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sagittarius', '#keepgoing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'alway', 'chase', 'want', 'get', 'keepgo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a alway chase want get keepgo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2861 :\n",
      "\n",
      "\tTweet's text':  wa pretti windi summit memphi love floppiti ear watch raptor soar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#getoutside', '#yyj'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wa', 'pretti', 'windi', 'summit', 'memphi', 'love', 'floppiti', 'ear', 'watch', 'raptor', 'soar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wa pretti windi summit memphi love floppiti ear watch raptor soar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2862 :\n",
      "\n",
      "\tTweet's text':  i need get sasha way cute \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'need', 'get', 'sasha', 'way', 'cute'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i need get sasha way cute'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2863 :\n",
      "\n",
      "\tTweet's text':  i fuck realli badli advancedwarfar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  ['#AdvancedWarfare'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'fuck', 'realli', 'badli', 'advancedwarfar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i fuck realli badli advancedwarfar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2864 :\n",
      "\n",
      "\tTweet's text':  cute i sure citizen feel real safe show us \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['worried_face', 'crying_face', 'disappointed_face', 'confused_face', 'sleepy_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#NYPD', '#NYPDMutiny'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cute', 'i', 'sure', 'citizen', 'feel', 'real', 'safe', 'show', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cute i sure citizen feel real safe show us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2865 :\n",
      "\n",
      "\tTweet's text':  so pull spin today interest \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#oops'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'pull', 'spin', 'today', 'interest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so pull spin today interest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2866 :\n",
      "\n",
      "\tTweet's text':  harri liter good person hurt heart bye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#InternationalHarryStylesDay'] \n",
      "\n",
      "\tTweet tokenized by words:  ['harri', 'liter', 'good', 'person', 'hurt', 'heart', 'bye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['harri liter good person hurt heart bye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2867 :\n",
      "\n",
      "\tTweet's text':  ever wonder shit would think \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ever', 'wonder', 'shit', 'would', 'think'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ever wonder shit would think'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2868 :\n",
      "\n",
      "\tTweet's text':  what normal peopl see vs i see \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'normal', 'peopl', 'see', 'vs', 'i', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what normal peopl see vs i see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2869 :\n",
      "\n",
      "\tTweet's text':  long tast purpos work are meat like \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['long', 'tast', 'purpos', 'work', 'are', 'meat', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['long tast purpos work are meat like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2870 :\n",
      "\n",
      "\tTweet's text':  these guy amaz the allman brother band stormi monday at f \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#gottalisten'] \n",
      "\n",
      "\tTweet tokenized by words:  ['these', 'guy', 'amaz', 'the', 'allman', 'brother', 'band', 'stormi', 'monday', 'at', 'f'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['these guy amaz the allman brother band stormi monday at f'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2871 :\n",
      "\n",
      "\tTweet's text':  rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bra', '#Fitting', '#Guide', '#How', '#diy', '#crafts'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2872 :\n",
      "\n",
      "\tTweet's text':  park meter obvious forgot get park ticket \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['park', 'meter', 'obvious', 'forgot', 'get', 'park', 'ticket'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['park meter obvious forgot get park ticket'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2873 :\n",
      "\n",
      "\tTweet's text':  but hey studi guid chemistri go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'hey', 'studi', 'guid', 'chemistri', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but hey studi guid chemistri go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2874 :\n",
      "\n",
      "\tTweet's text':  grace barf bag me barf bag grace sometim see peopl feel like vomit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['grace', 'barf', 'bag', 'me', 'barf', 'bag', 'grace', 'sometim', 'see', 'peopl', 'feel', 'like', 'vomit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['grace barf bag me barf bag grace sometim see peopl feel like vomit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2875 :\n",
      "\n",
      "\tTweet's text':  oh funni i saw crowd we dinner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'funni', 'i', 'saw', 'crowd', 'we', 'dinner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh funni i saw crowd we dinner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2876 :\n",
      "\n",
      "\tTweet's text':  review \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['review'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['review'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2877 :\n",
      "\n",
      "\tTweet's text':  sound like soooo much fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sound', 'like', 'soooo', 'much', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sound like soooo much fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2878 :\n",
      "\n",
      "\tTweet's text':  here list lot great choic help win cup next year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Coyotes'] \n",
      "\n",
      "\tTweet tokenized by words:  ['here', 'list', 'lot', 'great', 'choic', 'help', 'win', 'cup', 'next', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['here list lot great choic help win cup next year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2879 :\n",
      "\n",
      "\tTweet's text':  player support protest kill sure donat wb come \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NBA', '#NY', '#police', '#money', '#college'] \n",
      "\n",
      "\tTweet tokenized by words:  ['player', 'support', 'protest', 'kill', 'sure', 'donat', 'wb', 'come'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['player support protest kill sure donat wb come'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2880 :\n",
      "\n",
      "\tTweet's text':  hope nice xma babe x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hope', 'nice', 'xma', 'babe', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hope nice xma babe x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2881 :\n",
      "\n",
      "\tTweet's text':  love hang dad \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'hang', 'dad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love hang dad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2882 :\n",
      "\n",
      "\tTweet's text':  friday lit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['friday', 'lit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['friday lit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2883 :\n",
      "\n",
      "\tTweet's text':  look forward new year d \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['D'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'forward', 'new', 'year', 'd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look forward new year d'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2884 :\n",
      "\n",
      "\tTweet's text':  sweet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2885 :\n",
      "\n",
      "\tTweet's text':  i wish son like i said twitter wit twitter magic photo d smoke mirror effect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wish', 'son', 'like', 'i', 'said', 'twitter', 'wit', 'twitter', 'magic', 'photo', 'd', 'smoke', 'mirror', 'effect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wish son like i said twitter wit twitter magic photo d smoke mirror effect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2886 :\n",
      "\n",
      "\tTweet's text':  shock \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shock'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shock'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2887 :\n",
      "\n",
      "\tTweet's text':  check latest blog post myfairdaili pin that realli work \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lbloggers', '#lifestyle', '#pinterest', '#triedandtrue'] \n",
      "\n",
      "\tTweet tokenized by words:  ['check', 'latest', 'blog', 'post', 'myfairdaili', 'pin', 'that', 'realli', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['check latest blog post myfairdaili pin that realli work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2888 :\n",
      "\n",
      "\tTweet's text':  i go surviv today w break tear least twice possibl pass all nighter librari bad idea \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'go', 'surviv', 'today', 'w', 'break', 'tear', 'least', 'twice', 'possibl', 'pass', 'all', 'nighter', 'librari', 'bad', 'idea'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i go surviv today w break tear least twice possibl pass all nighter librari bad idea'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2889 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet's text':  much \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['much'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['much'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2890 :\n",
      "\n",
      "\tTweet's text':  know well erickson \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'well', 'erickson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know well erickson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2891 :\n",
      "\n",
      "\tTweet's text':  i give peopl break say without support cast none work would made tosh did nobodi get \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Extras'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'give', 'peopl', 'break', 'say', 'without', 'support', 'cast', 'none', 'work', 'would', 'made', 'tosh', 'did', 'nobodi', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i give peopl break say without support cast none work would made tosh did nobodi get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2892 :\n",
      "\n",
      "\tTweet's text':  lord merci us the world power nation rule two famili \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bush', '#Clinton', '#wasps', '#elxn2016'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lord', 'merci', 'us', 'the', 'world', 'power', 'nation', 'rule', 'two', 'famili'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lord merci us the world power nation rule two famili'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2893 :\n",
      "\n",
      "\tTweet's text':  watch blue chelsea cours \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'blue', 'chelsea', 'cours'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch blue chelsea cours'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2894 :\n",
      "\n",
      "\tTweet's text':  thi gone fire jan th \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['Jan', 'fire'] \n",
      "\n",
      "\tTweet's hashtags':  ['#getlifted'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'gone', 'fire', 'jan', 'th'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi gone fire jan th'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2895 :\n",
      "\n",
      "\tTweet's text':  happi monday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pbloggers', '#mbloggers'] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'monday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi monday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2896 :\n",
      "\n",
      "\tTweet's text':  foreign affair committe mep discuss lebanon prime minist \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcies', '#eu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['foreign', 'affair', 'committe', 'mep', 'discuss', 'lebanon', 'prime', 'minist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['foreign affair committe mep discuss lebanon prime minist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2897 :\n",
      "\n",
      "\tTweet's text':  i love sometim i skip greet repli toward odin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'sometim', 'i', 'skip', 'greet', 'repli', 'toward', 'odin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love sometim i skip greet repli toward odin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2898 :\n",
      "\n",
      "\tTweet's text':  tri ring plumb issu her phone goe upstair super mario theme tune \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#retrogaming'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tri', 'ring', 'plumb', 'issu', 'her', 'phone', 'goe', 'upstair', 'super', 'mario', 'theme', 'tune'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tri ring plumb issu her phone goe upstair super mario theme tune'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2899 :\n",
      "\n",
      "\tTweet's text':  celticowlwisdom alert media some guy twitter un cite proof evolut wrong let get nobel prize readi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['celticowlwisdom', 'alert', 'media', 'some', 'guy', 'twitter', 'un', 'cite', 'proof', 'evolut', 'wrong', 'let', 'get', 'nobel', 'prize', 'readi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['celticowlwisdom alert media some guy twitter un cite proof evolut wrong let get nobel prize readi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2900 :\n",
      "\n",
      "\tTweet's text':  chase dog though hous fun \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['chase', 'dog', 'though', 'hous', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['chase dog though hous fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2901 :\n",
      "\n",
      "\tTweet's text':  smartphon app pay see sprint \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sprint', '#Verizon', '#folloback', '#tcot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['smartphon', 'app', 'pay', 'see', 'sprint'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['smartphon app pay see sprint'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2902 :\n",
      "\n",
      "\tTweet's text':  too bad cube door bestcoworkersev \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bestcoworkersever'] \n",
      "\n",
      "\tTweet tokenized by words:  ['too', 'bad', 'cube', 'door', 'bestcoworkersev'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['too bad cube door bestcoworkersev'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2903 :\n",
      "\n",
      "\tTweet's text':  talk bias behavior go read paid articl paycoin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['talk', 'bias', 'behavior', 'go', 'read', 'paid', 'articl', 'paycoin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['talk bias behavior go read paid articl paycoin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2904 :\n",
      "\n",
      "\tTweet's text':  execut command begin job use end person life now \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['execut', 'command', 'begin', 'job', 'use', 'end', 'person', 'life', 'now'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['execut command begin job use end person life now'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2905 :\n",
      "\n",
      "\tTweet's text':  hmmm interest juri edg toward right side favour \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hopethathelps'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hmmm', 'interest', 'juri', 'edg', 'toward', 'right', 'side', 'favour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hmmm interest juri edg toward right side favour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2906 :\n",
      "\n",
      "\tTweet's text':  what love morn govern ban look like rape stop delhi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Delhi', '#Uber', '#aretheyserious'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'love', 'morn', 'govern', 'ban', 'look', 'like', 'rape', 'stop', 'delhi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what love morn govern ban look like rape stop delhi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2907 :\n",
      "\n",
      "\tTweet's text':  well i watch make clip drive rescor now i see easili compos \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'i', 'watch', 'make', 'clip', 'drive', 'rescor', 'now', 'i', 'see', 'easili', 'compos'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well i watch make clip drive rescor now i see easili compos'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2908 :\n",
      "\n",
      "\tTweet's text':  i stare boob hun i look heart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#relax'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'stare', 'boob', 'hun', 'i', 'look', 'heart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i stare boob hun i look heart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2909 :\n",
      "\n",
      "\tTweet's text':  fun fact i color guard rifl name stitch i got stitch plu stitch fav \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fun', 'fact', 'i', 'color', 'guard', 'rifl', 'name', 'stitch', 'i', 'got', 'stitch', 'plu', 'stitch', 'fav'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fun fact i color guard rifl name stitch i got stitch plu stitch fav'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2910 :\n",
      "\n",
      "\tTweet's text':  ye tast the slight aroma tea smile face heart shape eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes', 'thumbs_up_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'tast', 'the', 'slight', 'aroma', 'tea', 'smile', 'face', 'heart', 'shape', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye tast the slight aroma tea smile face heart shape eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2911 :\n",
      "\n",
      "\tTweet's text':  amen bless huda mean lot you \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['amen', 'bless', 'huda', 'mean', 'lot', 'you'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['amen bless huda mean lot you'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2912 :\n",
      "\n",
      "\tTweet's text':  hey mayb reach scoreboard fix latest issu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hey', 'mayb', 'reach', 'scoreboard', 'fix', 'latest', 'issu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hey mayb reach scoreboard fix latest issu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2913 :\n",
      "\n",
      "\tTweet's text':  just bruce springsteen flashback shudder \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'bruce', 'springsteen', 'flashback', 'shudder'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just bruce springsteen flashback shudder'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2914 :\n",
      "\n",
      "\tTweet's text':  push peopl read push peopl breed truefact \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Twitter', '#Facebook', '#TrueFact'] \n",
      "\n",
      "\tTweet tokenized by words:  ['push', 'peopl', 'read', 'push', 'peopl', 'breed', 'truefact'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['push peopl read push peopl breed truefact'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2915 :\n",
      "\n",
      "\tTweet's text':  thirst make settl grenad bruh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thirst', 'make', 'settl', 'grenad', 'bruh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thirst make settl grenad bruh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2916 :\n",
      "\n",
      "\tTweet's text':  throw christma morn ideal way spend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['throw', 'christma', 'morn', 'ideal', 'way', 'spend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['throw christma morn ideal way spend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2917 :\n",
      "\n",
      "\tTweet's text':  adavi great se u mate thank cheap shot safe trip back dri train lost \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'clinking_beer_mugs', 'winking_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['adavi', 'great', 'se', 'u', 'mate', 'thank', 'cheap', 'shot', 'safe', 'trip', 'back', 'dri', 'train', 'lost'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['adavi great se u mate thank cheap shot safe trip back dri train lost'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2918 :\n",
      "\n",
      "\tTweet's text':  i love freez rain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'freez', 'rain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love freez rain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2919 :\n",
      "\n",
      "\tTweet's text':  friend i still need \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#me', '#change', '#time'] \n",
      "\n",
      "\tTweet tokenized by words:  ['friend', 'i', 'still', 'need'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['friend i still need'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2920 :\n",
      "\n",
      "\tTweet's text':  go sleep hope sort morn \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sydneysiege'] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'sleep', 'hope', 'sort', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go sleep hope sort morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2921 :\n",
      "\n",
      "\tTweet's text':  use boy when u smile like sun girl awe boy ur teeth yellow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pick', '#up', '#linez'] \n",
      "\n",
      "\tTweet tokenized by words:  ['use', 'boy', 'when', 'u', 'smile', 'like', 'sun', 'girl', 'awe', 'boy', 'ur', 'teeth', 'yellow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['use boy when u smile like sun girl awe boy ur teeth yellow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2922 :\n",
      "\n",
      "\tTweet's text':  i see toledo made good name last night \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'see', 'toledo', 'made', 'good', 'name', 'last', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i see toledo made good name last night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2923 :\n",
      "\n",
      "\tTweet's text':  so lakesid like million scaveng place \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hadfun', '#neverboxingdayshoppingagain'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'lakesid', 'like', 'million', 'scaveng', 'place'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so lakesid like million scaveng place'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2924 :\n",
      "\n",
      "\tTweet's text':  religion unfound els allah would save kid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PeshawarAttack', '#PakSchoolSiege'] \n",
      "\n",
      "\tTweet tokenized by words:  ['religion', 'unfound', 'els', 'allah', 'would', 'save', 'kid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['religion unfound els allah would save kid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2925 :\n",
      "\n",
      "\tTweet's text':  come server \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#YesCracker', '#FAIL', '#SPAM'] \n",
      "\n",
      "\tTweet tokenized by words:  ['come', 'server'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['come server'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2926 :\n",
      "\n",
      "\tTweet's text':  it nice know everyon back yet one mine \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'nice', 'know', 'everyon', 'back', 'yet', 'one', 'mine'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it nice know everyon back yet one mine'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2927 :\n",
      "\n",
      "\tTweet's text':  thank bu thank tell i so help \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'bu', 'thank', 'tell', 'i', 'so', 'help'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank bu thank tell i so help'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2928 :\n",
      "\n",
      "\tTweet's text':  come australia us need sleep \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OrionLaunch', '#geeks'] \n",
      "\n",
      "\tTweet tokenized by words:  ['come', 'australia', 'us', 'need', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['come australia us need sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2929 :\n",
      "\n",
      "\tTweet's text':  nice see dwight york normal imparti self usual \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#villalovein', '#AstLei', '#lcfc'] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'see', 'dwight', 'york', 'normal', 'imparti', 'self', 'usual'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice see dwight york normal imparti self usual'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2930 :\n",
      "\n",
      "\tTweet's text':  it gonna great day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'gon', 'na', 'great', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it gonna great day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2931 :\n",
      "\n",
      "\tTweet's text':  i alway wait see work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#IfYouKnowWhatIMean'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'alway', 'wait', 'see', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i alway wait see work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2932 :\n",
      "\n",
      "\tTweet's text':  i also go enjoy two beer sit car that illeg what done usc medic penn mar \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'also', 'go', 'enjoy', 'two', 'beer', 'sit', 'car', 'that', 'illeg', 'what', 'done', 'usc', 'medic', 'penn', 'mar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i also go enjoy two beer sit car that illeg what done usc medic penn mar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2933 :\n",
      "\n",
      "\tTweet's text':  i snap tell \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#funnyGuy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'snap', 'tell'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i snap tell'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2934 :\n",
      "\n",
      "\tTweet's text':  jihadi killer rogu act fratboy uva rapist symbol deeper societ tcot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ottawa', '#Sidney', '#Peshawar', '#tcot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['jihadi', 'killer', 'rogu', 'act', 'fratboy', 'uva', 'rapist', 'symbol', 'deeper', 'societ', 'tcot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jihadi killer rogu act fratboy uva rapist symbol deeper societ tcot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2935 :\n",
      "\n",
      "\tTweet's text':  august birthday februari least serial killer born novemb dont mess nov \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nov26'] \n",
      "\n",
      "\tTweet tokenized by words:  ['august', 'birthday', 'februari', 'least', 'serial', 'killer', 'born', 'novemb', 'dont', 'mess', 'nov'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['august birthday februari least serial killer born novemb dont mess nov'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2936 :\n",
      "\n",
      "\tTweet's text':  realli fuckin pay today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tequila', '#is', '#the', '#one'] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'fuckin', 'pay', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli fuckin pay today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2937 :\n",
      "\n",
      "\tTweet's text':  still feel sorri ill go last night memori \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['loudly_crying_face', 'crying_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['still', 'feel', 'sorri', 'ill', 'go', 'last', 'night', 'memori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['still feel sorri ill go last night memori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2938 :\n",
      "\n",
      "\tTweet's text':  coffe fiber one it worth get \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['coffe', 'fiber', 'one', 'it', 'worth', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['coffe fiber one it worth get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2939 :\n",
      "\n",
      "\tTweet's text':  anoth new politician state social scienc degre liber art \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#greensfail'] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'new', 'politician', 'state', 'social', 'scienc', 'degre', 'liber', 'art'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth new politician state social scienc degre liber art'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2940 :\n",
      "\n",
      "\tTweet's text':  choke hold offic tri keep fall forward \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EricGarner'] \n",
      "\n",
      "\tTweet tokenized by words:  ['choke', 'hold', 'offic', 'tri', 'keep', 'fall', 'forward'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['choke hold offic tri keep fall forward'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2941 :\n",
      "\n",
      "\tTweet's text':  irish fan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['irish', 'fan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['irish fan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2942 :\n",
      "\n",
      "\tTweet's text':  rcarrick ga per litr ottawa happi holiday ye crisi avert \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rcarrick', 'ga', 'per', 'litr', 'ottawa', 'happi', 'holiday', 'ye', 'crisi', 'avert'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rcarrick ga per litr ottawa happi holiday ye crisi avert'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2943 :\n",
      "\n",
      "\tTweet's text':  the fact white prone univers think actual racial \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'fact', 'white', 'prone', 'univers', 'think', 'actual', 'racial'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the fact white prone univers think actual racial'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2944 :\n",
      "\n",
      "\tTweet's text':  funni rn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['funni', 'rn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['funni rn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2945 :\n",
      "\n",
      "\tTweet's text':  i need someth legendari winter break \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'need', 'someth', 'legendari', 'winter', 'break'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i need someth legendari winter break'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2946 :\n",
      "\n",
      "\tTweet's text':  prune toffe effervesc good drink delirium nocturnum memphi pint dram \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#photo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['prune', 'toffe', 'effervesc', 'good', 'drink', 'delirium', 'nocturnum', 'memphi', 'pint', 'dram'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['prune toffe effervesc good drink delirium nocturnum memphi pint dram'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2947 :\n",
      "\n",
      "\tTweet's text':  happen cultur compet continu argu ignor face class \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happen', 'cultur', 'compet', 'continu', 'argu', 'ignor', 'face', 'class'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happen cultur compet continu argu ignor face class'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2948 :\n",
      "\n",
      "\tTweet's text':  i watch commerci follow commerci advertis belgian chocol mouss crepe \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Fitbit', '#IHOP'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'watch', 'commerci', 'follow', 'commerci', 'advertis', 'belgian', 'chocol', 'mouss', 'crepe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i watch commerci follow commerci advertis belgian chocol mouss crepe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2949 :\n",
      "\n",
      "\tTweet's text':  all i want christma quick quot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['all', 'i', 'want', 'christma', 'quick', 'quot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['all i want christma quick quot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2950 :\n",
      "\n",
      "\tTweet's text':  i lohan anymor detox week new week tomorrow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes', 'face_throwing_a_kiss'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'lohan', 'anymor', 'detox', 'week', 'new', 'week', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i lohan anymor detox week new week tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2951 :\n",
      "\n",
      "\tTweet's text':  hate \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hate'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hate'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2952 :\n",
      "\n",
      "\tTweet's text':  if could stop lose plane would great \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'could', 'stop', 'lose', 'plane', 'would', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if could stop lose plane would great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2953 :\n",
      "\n",
      "\tTweet's text':  oh yeah funni hell \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'yeah', 'funni', 'hell'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh yeah funni hell'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2954 :\n",
      "\n",
      "\tTweet's text':  everyon got selfi stick year i one age say \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mainsteam', '#TrendSetter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['everyon', 'got', 'selfi', 'stick', 'year', 'i', 'one', 'age', 'say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everyon got selfi stick year i one age say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2955 :\n",
      "\n",
      "\tTweet's text':  pass world valuabl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#startup', '#growth', '#nyc'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pass', 'world', 'valuabl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pass world valuabl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2956 :\n",
      "\n",
      "\tTweet's text':  hell ever \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hell', 'ever'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hell ever'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2957 :\n",
      "\n",
      "\tTweet's text':  captur spirit devolut well \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['captur', 'spirit', 'devolut', 'well'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['captur spirit devolut well'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2958 :\n",
      "\n",
      "\tTweet's text':  sorri make sens make even tough that go produc player \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sorri', 'make', 'sens', 'make', 'even', 'tough', 'that', 'go', 'produc', 'player'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sorri make sens make even tough that go produc player'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2959 :\n",
      "\n",
      "\tTweet's text':  i realli excit tomorrow mean assign respons today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'realli', 'excit', 'tomorrow', 'mean', 'assign', 'respons', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i realli excit tomorrow mean assign respons today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2960 :\n",
      "\n",
      "\tTweet's text':  better \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2961 :\n",
      "\n",
      "\tTweet's text':  i kinda miss summer summer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#summer', '#2o14', '#bestie', '#alena', '#bestfriend', '#idek', '#we', '#cool', '#chips', '#food', '#followme', '#ifoll'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'kinda', 'miss', 'summer', 'summer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i kinda miss summer summer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2962 :\n",
      "\n",
      "\tTweet's text':  someon great sens humor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TheyGaveMeTCUColorsForChristmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['someon', 'great', 'sens', 'humor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['someon great sens humor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2963 :\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's text':  wenger slam refere ski ha ha ha ha blatantli bia toward \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#saintsfc'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wenger', 'slam', 'refere', 'ski', 'ha', 'ha', 'ha', 'ha', 'blatantli', 'bia', 'toward'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wenger slam refere ski ha ha ha ha blatantli bia toward'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2964 :\n",
      "\n",
      "\tTweet's text':  good morn livingqwal \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'morn', 'livingqwal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good morn livingqwal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2965 :\n",
      "\n",
      "\tTweet's text':  torbay live with dementia from it peter js ashley \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Dementia', '#Action', '#Alliance', '#Living', '#Dying'] \n",
      "\n",
      "\tTweet tokenized by words:  ['torbay', 'live', 'with', 'dementia', 'from', 'it', 'peter', 'js', 'ashley'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['torbay live with dementia from it peter js ashley'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2966 :\n",
      "\n",
      "\tTweet's text':  make proud american \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['make', 'proud', 'american'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['make proud american'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2967 :\n",
      "\n",
      "\tTweet's text':  who would imagin smoke weed regularli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#jakeplummer', '#outsidethelines'] \n",
      "\n",
      "\tTweet tokenized by words:  ['who', 'would', 'imagin', 'smoke', 'weed', 'regularli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['who would imagin smoke weed regularli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2968 :\n",
      "\n",
      "\tTweet's text':  well done great job skynew a e wait time worst sinc record began \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'done', 'great', 'job', 'skynew', 'a', 'e', 'wait', 'time', 'worst', 'sinc', 'record', 'began'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well done great job skynew a e wait time worst sinc record began'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2969 :\n",
      "\n",
      "\tTweet's text':  whi i you retweet tweet thi import issu need resolv \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'i', 'you', 'retweet', 'tweet', 'thi', 'import', 'issu', 'need', 'resolv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi i you retweet tweet thi import issu need resolv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2970 :\n",
      "\n",
      "\tTweet's text':  nice soak bubbl bath \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_throwing_a_kiss'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'soak', 'bubbl', 'bath'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice soak bubbl bath'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2971 :\n",
      "\n",
      "\tTweet's text':  thank requir facebook particip twitch chat realli good way push away interest player \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'requir', 'facebook', 'particip', 'twitch', 'chat', 'realli', 'good', 'way', 'push', 'away', 'interest', 'player'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank requir facebook particip twitch chat realli good way push away interest player'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2972 :\n",
      "\n",
      "\tTweet's text':  cant score goal sit bench min max hard pal fill sorri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cant', 'score', 'goal', 'sit', 'bench', 'min', 'max', 'hard', 'pal', 'fill', 'sorri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cant score goal sit bench min max hard pal fill sorri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2973 :\n",
      "\n",
      "\tTweet's text':  here hered environment \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Blame', '#Bad', '#Luck', '#Genes', '#as', '#Cause', '#of', '#Most', '#Cancer', '#Types', '#Why'] \n",
      "\n",
      "\tTweet tokenized by words:  ['here', 'hered', 'environment'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['here hered environment'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2974 :\n",
      "\n",
      "\tTweet's text':  stop fan and person blow mind \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stop', 'fan', 'and', 'person', 'blow', 'mind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stop fan and person blow mind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2975 :\n",
      "\n",
      "\tTweet's text':  huge rt congrat today winner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#12DaysOfChristmasSweatersContest'] \n",
      "\n",
      "\tTweet tokenized by words:  ['huge', 'rt', 'congrat', 'today', 'winner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['huge rt congrat today winner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2976 :\n",
      "\n",
      "\tTweet's text':  see call teammat soft practic week \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#overpaid'] \n",
      "\n",
      "\tTweet tokenized by words:  ['see', 'call', 'teammat', 'soft', 'practic', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['see call teammat soft practic week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2977 :\n",
      "\n",
      "\tTweet's text':  rockefel center \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sundayfunday', '#mylove', '#mermaidlove', '#newyear2015'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rockefel', 'center'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rockefel center'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2978 :\n",
      "\n",
      "\tTweet's text':  the peopl support polic violenc seem asshol scream govern reach \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cognitivedissonance'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'peopl', 'support', 'polic', 'violenc', 'seem', 'asshol', 'scream', 'govern', 'reach'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the peopl support polic violenc seem asshol scream govern reach'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2979 :\n",
      "\n",
      "\tTweet's text':  my glass blind \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'glass', 'blind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my glass blind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2980 :\n",
      "\n",
      "\tTweet's text':  face health crise india slash healthcar \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoodGovernance', '#NaMo', '#GoGo', '#BureDin'] \n",
      "\n",
      "\tTweet tokenized by words:  ['face', 'health', 'crise', 'india', 'slash', 'healthcar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['face health crise india slash healthcar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2981 :\n",
      "\n",
      "\tTweet's text':  morn cri session roomi today go great day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['morn', 'cri', 'session', 'roomi', 'today', 'go', 'great', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['morn cri session roomi today go great day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2982 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Cuba', '#sees', '#long', '#struggle', '#ahead', '#before', '#U', '#lifts', '#embargo'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2983 :\n",
      "\n",
      "\tTweet's text':  alway worthi choic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['alway', 'worthi', 'choic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['alway worthi choic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2984 :\n",
      "\n",
      "\tTweet's text':  hi singl vote poll poll station kulgam im tune p thnx \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['p'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Kashmir', '#KashmirBoycotts'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hi', 'singl', 'vote', 'poll', 'poll', 'station', 'kulgam', 'im', 'tune', 'p', 'thnx'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hi singl vote poll poll station kulgam im tune p thnx'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2985 :\n",
      "\n",
      "\tTweet's text':  ah week next medschool interview \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ah', 'week', 'next', 'medschool', 'interview'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ah week next medschool interview'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2986 :\n",
      "\n",
      "\tTweet's text':  on take first step toward independ the storm antifrackingsco \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HumanRightsDay', '#Manchester', '#NotOnwWell'] \n",
      "\n",
      "\tTweet tokenized by words:  ['on', 'take', 'first', 'step', 'toward', 'independ', 'the', 'storm', 'antifrackingsco'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['on take first step toward independ the storm antifrackingsco'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2987 :\n",
      "\n",
      "\tTweet's text':  west monkseaton \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Christmas', '#been', '#the', '#best'] \n",
      "\n",
      "\tTweet tokenized by words:  ['west', 'monkseaton'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['west monkseaton'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2988 :\n",
      "\n",
      "\tTweet's text':  write articl mood enhanc food tell peopl eat happi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['write', 'articl', 'mood', 'enhanc', 'food', 'tell', 'peopl', 'eat', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['write articl mood enhanc food tell peopl eat happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2989 :\n",
      "\n",
      "\tTweet's text':  tsu websit worth million peopl get paid post \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TSU'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tsu', 'websit', 'worth', 'million', 'peopl', 'get', 'paid', 'post'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tsu websit worth million peopl get paid post'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2990 :\n",
      "\n",
      "\tTweet's text':  that moment someon accident delet everyth phone \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BestChristmasEver'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'moment', 'someon', 'accident', 'delet', 'everyth', 'phone'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that moment someon accident delet everyth phone'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2991 :\n",
      "\n",
      "\tTweet's text':  i love meaning messag automak \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'meaning', 'messag', 'automak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love meaning messag automak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2992 :\n",
      "\n",
      "\tTweet's text':  fuck get flat tire car die come home work thank god friend great way end start day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fuck', 'get', 'flat', 'tire', 'car', 'die', 'come', 'home', 'work', 'thank', 'god', 'friend', 'great', 'way', 'end', 'start', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fuck get flat tire car die come home work thank god friend great way end start day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2993 :\n",
      "\n",
      "\tTweet's text':  spill milk onto boob oh \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['spill', 'milk', 'onto', 'boob', 'oh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['spill milk onto boob oh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2994 :\n",
      "\n",
      "\tTweet's text':  anoth bush whitehous \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'bush', 'whitehous'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth bush whitehous'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2995 :\n",
      "\n",
      "\tTweet's text':  you are pretti i better play free game i sure ask money level \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SkinnerBox'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'are', 'pretti', 'i', 'better', 'play', 'free', 'game', 'i', 'sure', 'ask', 'money', 'level'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you are pretti i better play free game i sure ask money level'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2996 :\n",
      "\n",
      "\tTweet's text':  find hip hop mixtap promot packag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['find', 'hip', 'hop', 'mixtap', 'promot', 'packag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['find hip hop mixtap promot packag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2997 :\n",
      "\n",
      "\tTweet's text':  well throw alway fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['white_smiling_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'throw', 'alway', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well throw alway fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2998 :\n",
      "\n",
      "\tTweet's text':  hour nap ct scan hospit perfect time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hour', 'nap', 'ct', 'scan', 'hospit', 'perfect', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hour nap ct scan hospit perfect time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  2999 :\n",
      "\n",
      "\tTweet's text':  it nice see continu gender struggl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'nice', 'see', 'continu', 'gender', 'struggl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it nice see continu gender struggl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3000 :\n",
      "\n",
      "\tTweet's text':  sad hear pass hi famili friend prayer today \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#rip'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sad', 'hear', 'pass', 'hi', 'famili', 'friend', 'prayer', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sad hear pass hi famili friend prayer today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3001 :\n",
      "\n",
      "\tTweet's text':  when i hw time watch seri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#1am', '#now', '#still', '#finish', '#my', '#work'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'i', 'hw', 'time', 'watch', 'seri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when i hw time watch seri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3002 :\n",
      "\n",
      "\tTweet's text':  the routin text irk nerv i guess thought count \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#needAnewRoutine'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'routin', 'text', 'irk', 'nerv', 'i', 'guess', 'thought', 'count'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the routin text irk nerv i guess thought count'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3003 :\n",
      "\n",
      "\tTweet's text':  i know sever charg i read internet pray wife \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'sever', 'charg', 'i', 'read', 'internet', 'pray', 'wife'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know sever charg i read internet pray wife'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3004 :\n",
      "\n",
      "\tTweet's text':  i wonder gf \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wonder', 'gf'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wonder gf'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3005 :\n",
      "\n",
      "\tTweet's text':  who ever thought move middl decemb would peac \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['who', 'ever', 'thought', 'move', 'middl', 'decemb', 'would', 'peac'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['who ever thought move middl decemb would peac'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3006 :\n",
      "\n",
      "\tTweet's text':  retweet book sign screen area \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['retweet', 'book', 'sign', 'screen', 'area'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['retweet book sign screen area'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3007 :\n",
      "\n",
      "\tTweet's text':  oh ff bodi clock f \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#iwanttosleep'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'ff', 'bodi', 'clock', 'f'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh ff bodi clock f'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3008 :\n",
      "\n",
      "\tTweet's text':  sooo mad right great way start day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sooo', 'mad', 'right', 'great', 'way', 'start', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sooo mad right great way start day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3009 :\n",
      "\n",
      "\tTweet's text':  i guy brook davi stori sad thrill confus but i love smile face heart shape eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OneTreeHill'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guy', 'brook', 'davi', 'stori', 'sad', 'thrill', 'confus', 'but', 'i', 'love', 'smile', 'face', 'heart', 'shape', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guy brook davi stori sad thrill confus but i love smile face heart shape eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3010 :\n",
      "\n",
      "\tTweet's text':  thank wake wrap coffe morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CheapBastard'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'wake', 'wrap', 'coffe', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank wake wrap coffe morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3011 :\n",
      "\n",
      "\tTweet's text':  heheheh trevoredgar shame \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['heheheh', 'trevoredgar', 'shame'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['heheheh trevoredgar shame'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3012 :\n",
      "\n",
      "\tTweet's text':  rt should great watch miami tri block sweat featherston edg next two year real fun stuff \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt', 'should', 'great', 'watch', 'miami', 'tri', 'block', 'sweat', 'featherston', 'edg', 'next', 'two', 'year', 'real', 'fun', 'stuff'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt should great watch miami tri block sweat featherston edg next two year real fun stuff'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3013 :\n",
      "\n",
      "\tTweet's text':  would also push rate fun game \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['would', 'also', 'push', 'rate', 'fun', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['would also push rate fun game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3014 :\n",
      "\n",
      "\tTweet's text':  gareth polar opposit chicken love vegetarian \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'hatching_chick'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bones'] \n",
      "\n",
      "\tTweet tokenized by words:  ['gareth', 'polar', 'opposit', 'chicken', 'love', 'vegetarian'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gareth polar opposit chicken love vegetarian'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3015 :\n",
      "\n",
      "\tTweet's text':  everi wonder turkey take \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Thanksgiving'] \n",
      "\n",
      "\tTweet tokenized by words:  ['everi', 'wonder', 'turkey', 'take'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everi wonder turkey take'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3016 :\n",
      "\n",
      "\tTweet's text':  i extrem excit know reza aslan cj werleman think happen pakistan \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PeshawarAttack'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'extrem', 'excit', 'know', 'reza', 'aslan', 'cj', 'werleman', 'think', 'happen', 'pakistan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i extrem excit know reza aslan cj werleman think happen pakistan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3017 :\n",
      "\n",
      "\tTweet's text':  i get excit mexico \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'get', 'excit', 'mexico'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i get excit mexico'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3018 :\n",
      "\n",
      "\tTweet's text':  look wrong profil pictur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'wrong', 'profil', 'pictur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look wrong profil pictur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3019 :\n",
      "\n",
      "\tTweet's text':  home alon aka turn light \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#scaredycat'] \n",
      "\n",
      "\tTweet tokenized by words:  ['home', 'alon', 'aka', 'turn', 'light'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['home alon aka turn light'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3020 :\n",
      "\n",
      "\tTweet's text':  actual crop daughter pic selfi see evil monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['see-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  ['#topmum'] \n",
      "\n",
      "\tTweet tokenized by words:  ['actual', 'crop', 'daughter', 'pic', 'selfi', 'see', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['actual crop daughter pic selfi see evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3021 :\n",
      "\n",
      "\tTweet's text':  u might b bigest fan srk find u better actor sayng fr sayng reali mean express king \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#expression'] \n",
      "\n",
      "\tTweet tokenized by words:  ['u', 'might', 'b', 'bigest', 'fan', 'srk', 'find', 'u', 'better', 'actor', 'sayng', 'fr', 'sayng', 'reali', 'mean', 'express', 'king'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['u might b bigest fan srk find u better actor sayng fr sayng reali mean express king'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3022 :\n",
      "\n",
      "\tTweet's text':  friday morn lectur blood smile face heart shape eyessmil face heart shape eyessmil face heart shape eyessmil face heart shape eyessmil face heart shape eyessmil face heart shape eye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_heart-shaped_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['friday', 'morn', 'lectur', 'blood', 'smile', 'face', 'heart', 'shape', 'eyessmil', 'face', 'heart', 'shape', 'eyessmil', 'face', 'heart', 'shape', 'eyessmil', 'face', 'heart', 'shape', 'eyessmil', 'face', 'heart', 'shape', 'eyessmil', 'face', 'heart', 'shape', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['friday morn lectur blood smile face heart shape eyessmil face heart shape eyessmil face heart shape eyessmil face heart shape eyessmil face heart shape eyessmil face heart shape eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3023 :\n",
      "\n",
      "\tTweet's text':  doctoratlarg yeah tone obviou thing tweet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['doctoratlarg', 'yeah', 'tone', 'obviou', 'thing', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['doctoratlarg yeah tone obviou thing tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3024 :\n",
      "\n",
      "\tTweet's text':  disturb dedic girl rape \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TeenAnalCasting', '#Highway', '#8211'] \n",
      "\n",
      "\tTweet tokenized by words:  ['disturb', 'dedic', 'girl', 'rape'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['disturb dedic girl rape'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3025 :\n",
      "\n",
      "\tTweet's text':  i sue parent \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'sue', 'parent'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i sue parent'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3026 :\n",
      "\n",
      "\tTweet's text':  great start morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#flattire'] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'start', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great start morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3027 :\n",
      "\n",
      "\tTweet's text':  final project ugh keep product \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#butnotreally'] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'project', 'ugh', 'keep', 'product'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final project ugh keep product'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3028 :\n",
      "\n",
      "\tTweet's text':  myrcuri aaaaaamd time bedtim better tweet dad night hous i want get troubl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['myrcuri', 'aaaaaamd', 'time', 'bedtim', 'better', 'tweet', 'dad', 'night', 'hous', 'i', 'want', 'get', 'troubl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['myrcuri aaaaaamd time bedtim better tweet dad night hous i want get troubl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3029 :\n",
      "\n",
      "\tTweet's text':  can wait till birthday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'wait', 'till', 'birthday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can wait till birthday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3030 :\n",
      "\n",
      "\tTweet's text':  clovi cartoon tuesday decemb \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#jamaicaobserverandroidapp'] \n",
      "\n",
      "\tTweet tokenized by words:  ['clovi', 'cartoon', 'tuesday', 'decemb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['clovi cartoon tuesday decemb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3031 :\n",
      "\n",
      "\tTweet's text':  just layin go bed colleg great guy it stress keep night or make cri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'layin', 'go', 'bed', 'colleg', 'great', 'guy', 'it', 'stress', 'keep', 'night', 'or', 'make', 'cri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just layin go bed colleg great guy it stress keep night or make cri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3032 :\n",
      "\n",
      "\tTweet's text':  pretti sure i sat behind mcdonald drive peek see movi play \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pretti', 'sure', 'i', 'sat', 'behind', 'mcdonald', 'drive', 'peek', 'see', 'movi', 'play'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pretti sure i sat behind mcdonald drive peek see movi play'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3033 :\n",
      "\n",
      "\tTweet's text':  well among republican voter jebbush i think could well democrat like \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ChrisChristy', '#JebBush'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'among', 'republican', 'voter', 'jebbush', 'i', 'think', 'could', 'well', 'democrat', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well among republican voter jebbush i think could well democrat like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3034 :\n",
      "\n",
      "\tTweet's text':  night like tonight reason i abl carri weekend \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SUCHAGOODWEEK'] \n",
      "\n",
      "\tTweet tokenized by words:  ['night', 'like', 'tonight', 'reason', 'i', 'abl', 'carri', 'weekend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['night like tonight reason i abl carri weekend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3035 :\n",
      "\n",
      "\tTweet's text':  wow i love frizzi hair get \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'love', 'frizzi', 'hair', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i love frizzi hair get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3036 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoodMorning'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3037 :\n",
      "\n",
      "\tTweet's text':  hate roulett heavi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hate', 'roulett', 'heavi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hate roulett heavi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3038 :\n",
      "\n",
      "\tTweet's text':  joke year congrat \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Kuivaa'] \n",
      "\n",
      "\tTweet tokenized by words:  ['joke', 'year', 'congrat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['joke year congrat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3039 :\n",
      "\n",
      "\tTweet's text':  use know i line \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['use', 'know', 'i', 'line'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['use know i line'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3040 :\n",
      "\n",
      "\tTweet's text':  girl put much effort dress nice school i overs sweat van \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#maybetomorrow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['girl', 'put', 'much', 'effort', 'dress', 'nice', 'school', 'i', 'overs', 'sweat', 'van'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['girl put much effort dress nice school i overs sweat van'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3041 :\n",
      "\n",
      "\tTweet's text':  christma adult broken famili just awesom noth like stepsist kid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['christma', 'adult', 'broken', 'famili', 'just', 'awesom', 'noth', 'like', 'stepsist', 'kid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['christma adult broken famili just awesom noth like stepsist kid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3042 :\n",
      "\n",
      "\tTweet's text':  it incred hear justic ginsburg speak today she truli inspir \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'incred', 'hear', 'justic', 'ginsburg', 'speak', 'today', 'she', 'truli', 'inspir'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it incred hear justic ginsburg speak today she truli inspir'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3043 :\n",
      "\n",
      "\tTweet's text':  we need \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Democracy', '#CoPocracy', '#Police', '#MorningJoe', '#BlackLivesMatter', '#DemocracyMatters', '#Ferguson', '#EricGarner'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'need'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we need'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3044 :\n",
      "\n",
      "\tTweet's text':  when polic offic pursu dare villain way abus pursu frighten prey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Police_officer', '#Abuser', '#Villain', '#Prey'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'polic', 'offic', 'pursu', 'dare', 'villain', 'way', 'abus', 'pursu', 'frighten', 'prey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when polic offic pursu dare villain way abus pursu frighten prey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3045 :\n",
      "\n",
      "\tTweet's text':  cool \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cool'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cool'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3046 :\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Putin', '#says', '#Russia', '#won', '#be', '#intimidated', '#over', '#Crimea'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3047 :\n",
      "\n",
      "\tTweet's text':  just receiv email i heir nigerian petroleum corpor i immedi send bank info \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'receiv', 'email', 'i', 'heir', 'nigerian', 'petroleum', 'corpor', 'i', 'immedi', 'send', 'bank', 'info'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just receiv email i heir nigerian petroleum corpor i immedi send bank info'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3048 :\n",
      "\n",
      "\tTweet's text':  race sandown dog tonight sponsor dandenong budgi club hope joke love seat tabl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nerds', '#getalife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['race', 'sandown', 'dog', 'tonight', 'sponsor', 'dandenong', 'budgi', 'club', 'hope', 'joke', 'love', 'seat', 'tabl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['race sandown dog tonight sponsor dandenong budgi club hope joke love seat tabl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3049 :\n",
      "\n",
      "\tTweet's text':  loov guy friend give thorough descript bowel \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WHY', '#STOPTHIS'] \n",
      "\n",
      "\tTweet tokenized by words:  ['loov', 'guy', 'friend', 'give', 'thorough', 'descript', 'bowel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['loov guy friend give thorough descript bowel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3050 :\n",
      "\n",
      "\tTweet's text':  i pink eye i sooo excit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'pink', 'eye', 'i', 'sooo', 'excit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i pink eye i sooo excit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3051 :\n",
      "\n",
      "\tTweet's text':  slmpd warn bassem heck might alreadi know \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ferguson', '#NYC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['slmpd', 'warn', 'bassem', 'heck', 'might', 'alreadi', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['slmpd warn bassem heck might alreadi know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3052 :\n",
      "\n",
      "\tTweet's text':  puli turn co want spend load money year old journeymen parish let neither would ma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NUFC', '#cpfc'] \n",
      "\n",
      "\tTweet tokenized by words:  ['puli', 'turn', 'co', 'want', 'spend', 'load', 'money', 'year', 'old', 'journeymen', 'parish', 'let', 'neither', 'would', 'ma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['puli turn co want spend load money year old journeymen parish let neither would ma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3053 :\n",
      "\n",
      "\tTweet's text':  mari shit whatsoev \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['information_desk_person'] \n",
      "\n",
      "\tTweet's hashtags':  ['#done', '#shesdone'] \n",
      "\n",
      "\tTweet tokenized by words:  ['mari', 'shit', 'whatsoev'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mari shit whatsoev'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3054 :\n",
      "\n",
      "\tTweet's text':  great day wilko \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'day', 'wilko'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great day wilko'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3055 :\n",
      "\n",
      "\tTweet's text':  friday hilar cso pick award \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sony', '#security', '#SonyHack'] \n",
      "\n",
      "\tTweet tokenized by words:  ['friday', 'hilar', 'cso', 'pick', 'award'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['friday hilar cso pick award'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3056 :\n",
      "\n",
      "\tTweet's text':  whoa i hope dion taylor got stand ovat perform incred voic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whoa', 'i', 'hope', 'dion', 'taylor', 'got', 'stand', 'ovat', 'perform', 'incred', 'voic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whoa i hope dion taylor got stand ovat perform incred voic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3057 :\n",
      "\n",
      "\tTweet's text':  they seem found altern use bibl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Hotel', '#NewYears', '#Religious'] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'seem', 'found', 'altern', 'use', 'bibl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they seem found altern use bibl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3058 :\n",
      "\n",
      "\tTweet's text':  dog dinner anyon bring kid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Cultivo', '#Letchworth'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dog', 'dinner', 'anyon', 'bring', 'kid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dog dinner anyon bring kid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3059 :\n",
      "\n",
      "\tTweet's text':  n promot r human n religion for strictli speak religion believ right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['n', 'promot', 'r', 'human', 'n', 'religion', 'for', 'strictli', 'speak', 'religion', 'believ', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['n promot r human n religion for strictli speak religion believ right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3060 :\n",
      "\n",
      "\tTweet's text':  drudgeri personifi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#commuterprobs', '#northernline', '#tfl'] \n",
      "\n",
      "\tTweet tokenized by words:  ['drudgeri', 'personifi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['drudgeri personifi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3061 :\n",
      "\n",
      "\tTweet's text':  damn i lost lot follow prob cuz i tweet much relat anymor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['damn', 'i', 'lost', 'lot', 'follow', 'prob', 'cuz', 'i', 'tweet', 'much', 'relat', 'anymor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['damn i lost lot follow prob cuz i tweet much relat anymor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3062 :\n",
      "\n",
      "\tTweet's text':  sorri butt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sorri', 'butt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sorri butt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3063 :\n",
      "\n",
      "\tTweet's text':  now gonna enjoy day babi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['now', 'gon', 'na', 'enjoy', 'day', 'babi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['now gonna enjoy day babi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3064 :\n",
      "\n",
      "\tTweet's text':  i refus \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#workout', '#motivation', '#fitfam'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'refus'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i refus'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3065 :\n",
      "\n",
      "\tTweet's text':  fan smartphon app pay your fan see go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fan', 'smartphon', 'app', 'pay', 'your', 'fan', 'see', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fan smartphon app pay your fan see go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3066 :\n",
      "\n",
      "\tTweet's text':  ghostwrit s \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ghostwrit', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ghostwrit s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3067 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  ['#math', '#class', '#drawing', '#music', '#eye', '#snowflake', '#flo'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3068 :\n",
      "\n",
      "\tTweet's text':  confuciu motiv quot free android app \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['confuciu', 'motiv', 'quot', 'free', 'android', 'app'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['confuciu motiv quot free android app'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3069 :\n",
      "\n",
      "\tTweet's text':  doubt i first block but pretend good \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['doubt', 'i', 'first', 'block', 'but', 'pretend', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['doubt i first block but pretend good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3070 :\n",
      "\n",
      "\tTweet's text':  group messag bbc start morn thank hannah \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['group', 'messag', 'bbc', 'start', 'morn', 'thank', 'hannah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['group messag bbc start morn thank hannah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3071 :\n",
      "\n",
      "\tTweet's text':  tri spell beeyotch iphon made spell beyonc that fire \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tri', 'spell', 'beeyotch', 'iphon', 'made', 'spell', 'beyonc', 'that', 'fire'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tri spell beeyotch iphon made spell beyonc that fire'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3072 :\n",
      "\n",
      "\tTweet's text':  find one costum \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'face_savouring_delicious_food'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['find', 'one', 'costum'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['find one costum'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3073 :\n",
      "\n",
      "\tTweet's text':  i use \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'use'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i use'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3074 :\n",
      "\n",
      "\tTweet's text':  westbrook point shot ok ok i see work \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['westbrook', 'point', 'shot', 'ok', 'ok', 'i', 'see', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['westbrook point shot ok ok i see work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3075 :\n",
      "\n",
      "\tTweet's text':  hello indoor lung nice see back \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['expressionless_face', 'runner'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hello', 'indoor', 'lung', 'nice', 'see', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hello indoor lung nice see back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3076 :\n",
      "\n",
      "\tTweet's text':  so think anim \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#anime', '#is', '#for', '#kids', '#Frozen'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'think', 'anim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so think anim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3077 :\n",
      "\n",
      "\tTweet's text':  moscovici quizz extra time three eu countri hit eurozon target \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcies', '#eu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['moscovici', 'quizz', 'extra', 'time', 'three', 'eu', 'countri', 'hit', 'eurozon', 'target'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['moscovici quizz extra time three eu countri hit eurozon target'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3078 :\n",
      "\n",
      "\tTweet's text':  so fuck excit th wheel anoth new year eve can blame anybodi super picki men \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'fuck', 'excit', 'th', 'wheel', 'anoth', 'new', 'year', 'eve', 'can', 'blame', 'anybodi', 'super', 'picki', 'men'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so fuck excit th wheel anoth new year eve can blame anybodi super picki men'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3079 :\n",
      "\n",
      "\tTweet's text':  go game tonight sound fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'game', 'tonight', 'sound', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go game tonight sound fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3080 :\n",
      "\n",
      "\tTweet's text':  well peopl ask would without mccormack \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'peopl', 'ask', 'would', 'without', 'mccormack'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well peopl ask would without mccormack'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3081 :\n",
      "\n",
      "\tTweet's text':  what import today famili health rather nba action \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'import', 'today', 'famili', 'health', 'rather', 'nba', 'action'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what import today famili health rather nba action'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3082 :\n",
      "\n",
      "\tTweet's text':  best pickup line \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['best', 'pickup', 'line'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['best pickup line'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3083 :\n",
      "\n",
      "\tTweet's text':  whi iphon purchas full price still need mobil devic unlock code work intern \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#uncarrier'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'iphon', 'purchas', 'full', 'price', 'still', 'need', 'mobil', 'devic', 'unlock', 'code', 'work', 'intern'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi iphon purchas full price still need mobil devic unlock code work intern'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3084 :\n",
      "\n",
      "\tTweet's text':  hope better hope tokyo nic kill \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hope', '#tokyo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hope', 'better', 'hope', 'tokyo', 'nic', 'kill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hope better hope tokyo nic kill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3085 :\n",
      "\n",
      "\tTweet's text':  can i get amen \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'i', 'get', 'amen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can i get amen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3086 :\n",
      "\n",
      "\tTweet's text':  final i readi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'i', 'readi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final i readi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3087 :\n",
      "\n",
      "\tTweet's text':  wow write review concert i attend exactli i want right instead sleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'write', 'review', 'concert', 'i', 'attend', 'exactli', 'i', 'want', 'right', 'instead', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow write review concert i attend exactli i want right instead sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3088 :\n",
      "\n",
      "\tTweet's text':  readi tax final \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['readi', 'tax', 'final'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['readi tax final'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3089 :\n",
      "\n",
      "\tTweet's text':  love pleas publicis \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'pleas', 'publicis'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love pleas publicis'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3090 :\n",
      "\n",
      "\tTweet's text':  but cours \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lucky13', '#myloves', '#sundayfunday', '#lastsunday2014'] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'cours'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but cours'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3091 :\n",
      "\n",
      "\tTweet's text':  hmmm next year say team move sd la \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hmmm', 'next', 'year', 'say', 'team', 'move', 'sd', 'la'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hmmm next year say team move sd la'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3092 :\n",
      "\n",
      "\tTweet's text':  lmao i may time high lmfaoo \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lmao', 'i', 'may', 'time', 'high', 'lmfaoo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lmao i may time high lmfaoo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3093 :\n",
      "\n",
      "\tTweet's text':  null how much know period \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['null', 'how', 'much', 'know', 'period'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['null how much know period'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3094 :\n",
      "\n",
      "\tTweet's text':  realli \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3095 :\n",
      "\n",
      "\tTweet's text':  emptynett penguin cancel morn skate option due ici road condit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['emptynett', 'penguin', 'cancel', 'morn', 'skate', 'option', 'due', 'ici', 'road', 'condit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['emptynett penguin cancel morn skate option due ici road condit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3096 :\n",
      "\n",
      "\tTweet's text':  lol i hope good kinda crazi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'i', 'hope', 'good', 'kinda', 'crazi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol i hope good kinda crazi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3097 :\n",
      "\n",
      "\tTweet's text':  christma day box day new year day enough so much other month \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#enough', '#hours', '#in', '#the', '#day'] \n",
      "\n",
      "\tTweet tokenized by words:  ['christma', 'day', 'box', 'day', 'new', 'year', 'day', 'enough', 'so', 'much', 'other', 'month'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['christma day box day new year day enough so much other month'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3098 :\n",
      "\n",
      "\tTweet's text':  wa swarm teenag girl i walk \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wa', 'swarm', 'teenag', 'girl', 'i', 'walk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wa swarm teenag girl i walk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3099 :\n",
      "\n",
      "\tTweet's text':  and i use hate come uni work lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'i', 'use', 'hate', 'come', 'uni', 'work', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and i use hate come uni work lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3100 :\n",
      "\n",
      "\tTweet's text':  i hope anyway finger cross x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hope', 'anyway', 'finger', 'cross', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hope anyway finger cross x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3101 :\n",
      "\n",
      "\tTweet's text':  someon describ pass like laxett budgi i rememb \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['someon', 'describ', 'pass', 'like', 'laxett', 'budgi', 'i', 'rememb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['someon describ pass like laxett budgi i rememb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3102 :\n",
      "\n",
      "\tTweet's text':  tx saw must great shot defend oneself fierc attack giraff \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HungerGames'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tx', 'saw', 'must', 'great', 'shot', 'defend', 'oneself', 'fierc', 'attack', 'giraff'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tx saw must great shot defend oneself fierc attack giraff'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3103 :\n",
      "\n",
      "\tTweet's text':  nice know give much import n \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'know', 'give', 'much', 'import', 'n'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice know give much import n'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3104 :\n",
      "\n",
      "\tTweet's text':  drink ipa ground control \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#photo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['drink', 'ipa', 'ground', 'control'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['drink ipa ground control'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3105 :\n",
      "\n",
      "\tTweet's text':  that weird \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'weird'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that weird'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3106 :\n",
      "\n",
      "\tTweet's text':  i work front laptop hour day suffer terribl dri eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bloodshot', '#eyerony'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'work', 'front', 'laptop', 'hour', 'day', 'suffer', 'terribl', 'dri', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i work front laptop hour day suffer terribl dri eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3107 :\n",
      "\n",
      "\tTweet's text':  bummer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Gophers'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bummer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bummer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3108 :\n",
      "\n",
      "\tTweet's text':  dalla washington new orlean tampa bay green bay detroit carolina atlanta \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dalla', 'washington', 'new', 'orlean', 'tampa', 'bay', 'green', 'bay', 'detroit', 'carolina', 'atlanta'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dalla washington new orlean tampa bay green bay detroit carolina atlanta'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3109 :\n",
      "\n",
      "\tTweet's text':  fuck mite warch eastend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fuck', 'mite', 'warch', 'eastend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fuck mite warch eastend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3110 :\n",
      "\n",
      "\tTweet's text':  i know stori noah transform man modern biblic tale killsssss \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#whatarethelivingrockpeoplefor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'know', 'stori', 'noah', 'transform', 'man', 'modern', 'biblic', 'tale', 'killsssss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i know stori noah transform man modern biblic tale killsssss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3111 :\n",
      "\n",
      "\tTweet's text':  could probabl call text inform \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#allcelebritiesarefriends'] \n",
      "\n",
      "\tTweet tokenized by words:  ['could', 'probabl', 'call', 'text', 'inform'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['could probabl call text inform'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3112 :\n",
      "\n",
      "\tTweet's text':  aw love boss schedul work day storm come bay area \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['aw', 'love', 'boss', 'schedul', 'work', 'day', 'storm', 'come', 'bay', 'area'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['aw love boss schedul work day storm come bay area'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3113 :\n",
      "\n",
      "\tTweet's text':  and i though one programm oper money power ea \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TheMoreYouKnow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'i', 'though', 'one', 'programm', 'oper', 'money', 'power', 'ea'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and i though one programm oper money power ea'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3114 :\n",
      "\n",
      "\tTweet's text':  saturday night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['saturday', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['saturday night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3115 :\n",
      "\n",
      "\tTweet's text':  th just like real world \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['th', 'just', 'like', 'real', 'world'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['th just like real world'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3116 :\n",
      "\n",
      "\tTweet's text':  on hand condol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['on', 'hand', 'condol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['on hand condol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3117 :\n",
      "\n",
      "\tTweet's text':  i tri imagin confus \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'tri', 'imagin', 'confus'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i tri imagin confus'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3118 :\n",
      "\n",
      "\tTweet's text':  haha chainsaw murder corrupt fortun ceo rapist w e make happi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hebetripping'] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'chainsaw', 'murder', 'corrupt', 'fortun', 'ceo', 'rapist', 'w', 'e', 'make', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha chainsaw murder corrupt fortun ceo rapist w e make happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3119 :\n",
      "\n",
      "\tTweet's text':  there noth like almost rear end someon slam brake reason get alert readi exam \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'noth', 'like', 'almost', 'rear', 'end', 'someon', 'slam', 'brake', 'reason', 'get', 'alert', 'readi', 'exam'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there noth like almost rear end someon slam brake reason get alert readi exam'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3120 :\n",
      "\n",
      "\tTweet's text':  go class import \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fuckyou'] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'class', 'import'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go class import'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3121 :\n",
      "\n",
      "\tTweet's text':  damn earli south carolina what shitti state proud \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['damn', 'earli', 'south', 'carolina', 'what', 'shitti', 'state', 'proud'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['damn earli south carolina what shitti state proud'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3122 :\n",
      "\n",
      "\tTweet's text':  believ in boegart rt the red sox must realli believ xander boegart ss go gb theme \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['believ', 'in', 'boegart', 'rt', 'the', 'red', 'sox', 'must', 'realli', 'believ', 'xander', 'boegart', 'ss', 'go', 'gb', 'theme'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['believ in boegart rt the red sox must realli believ xander boegart ss go gb theme'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3123 :\n",
      "\n",
      "\tTweet's text':  appar guy citi airport if swear drive even taxi rank \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#13CABS', '#goodguy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['appar', 'guy', 'citi', 'airport', 'if', 'swear', 'drive', 'even', 'taxi', 'rank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['appar guy citi airport if swear drive even taxi rank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3124 :\n",
      "\n",
      "\tTweet's text':  yo boy you guy know keep parti mood go ezonegoadiari \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EzoneGoaDiaries'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yo', 'boy', 'you', 'guy', 'know', 'keep', 'parti', 'mood', 'go', 'ezonegoadiari'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yo boy you guy know keep parti mood go ezonegoadiari'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3125 :\n",
      "\n",
      "\tTweet's text':  supaaa sweet final am ya sleep \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['supaaa', 'sweet', 'final', 'am', 'ya', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['supaaa sweet final am ya sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3126 :\n",
      "\n",
      "\tTweet's text':  wow mad babe \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_open_mouth_and_cold_sweat'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'mad', 'babe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow mad babe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3127 :\n",
      "\n",
      "\tTweet's text':  did i realli need put hashtag oh dear \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['did', 'i', 'realli', 'need', 'put', 'hashtag', 'oh', 'dear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['did i realli need put hashtag oh dear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3128 :\n",
      "\n",
      "\tTweet's text':  can fck hoe i sorri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'open_hands_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'fck', 'hoe', 'i', 'sorri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can fck hoe i sorri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3129 :\n",
      "\n",
      "\tTweet's text':  gotta love honest kid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#saywhattheythink'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'love', 'honest', 'kid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta love honest kid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3130 :\n",
      "\n",
      "\tTweet's text':  i sure larg ignor practic in ny govt work convict \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'sure', 'larg', 'ignor', 'practic', 'in', 'ny', 'govt', 'work', 'convict'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i sure larg ignor practic in ny govt work convict'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3131 :\n",
      "\n",
      "\tTweet's text':  use sentenc unheard turn keyboard sir \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Liberal'] \n",
      "\n",
      "\tTweet tokenized by words:  ['use', 'sentenc', 'unheard', 'turn', 'keyboard', 'sir'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['use sentenc unheard turn keyboard sir'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3132 :\n",
      "\n",
      "\tTweet's text':  watch amaz race contest talk juici \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'amaz', 'race', 'contest', 'talk', 'juici'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch amaz race contest talk juici'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3133 :\n",
      "\n",
      "\tTweet's text':  kebab order snug sofa watch shit tele dad \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['two_hearts', 'purple_heart'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['kebab', 'order', 'snug', 'sofa', 'watch', 'shit', 'tele', 'dad'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kebab order snug sofa watch shit tele dad'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3134 :\n",
      "\n",
      "\tTweet's text':  if i could kidnap friend new puppi navi i would heartbeat \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'i', 'could', 'kidnap', 'friend', 'new', 'puppi', 'navi', 'i', 'would', 'heartbeat'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if i could kidnap friend new puppi navi i would heartbeat'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3135 :\n",
      "\n",
      "\tTweet's text':  let go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#afraid', '#frozen'] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3136 :\n",
      "\n",
      "\tTweet's text':  fake where star \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fake', 'where', 'star'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fake where star'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3137 :\n",
      "\n",
      "\tTweet's text':  love studi anatomi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['beating_heart'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'studi', 'anatomi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love studi anatomi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3138 :\n",
      "\n",
      "\tTweet's text':  box yeah \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'fisted_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['box', 'yeah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['box yeah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3139 :\n",
      "\n",
      "\tTweet's text':  knowledg mean person qualifi repres religion human saniti absent \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['knowledg', 'mean', 'person', 'qualifi', 'repres', 'religion', 'human', 'saniti', 'absent'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['knowledg mean person qualifi repres religion human saniti absent'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3140 :\n",
      "\n",
      "\tTweet's text':  and day start civilis trip \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#appointments', '#road', '#bestdayever', '#neverlaughed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'day', 'start', 'civilis', 'trip'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and day start civilis trip'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3141 :\n",
      "\n",
      "\tTweet's text':  made think tfln i need vodka mix w bit holi water right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['made', 'think', 'tfln', 'i', 'need', 'vodka', 'mix', 'w', 'bit', 'holi', 'water', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['made think tfln i need vodka mix w bit holi water right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3142 :\n",
      "\n",
      "\tTweet's text':  note you can get paid for post on \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fOLLOW', '#MONEY', '#HOMEbiz', '#mlm'] \n",
      "\n",
      "\tTweet tokenized by words:  ['note', 'you', 'can', 'get', 'paid', 'for', 'post', 'on'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['note you can get paid for post on'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3143 :\n",
      "\n",
      "\tTweet's text':  a chunk hair got stuck blow dryer i cut alway fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['expressionless_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'chunk', 'hair', 'got', 'stuck', 'blow', 'dryer', 'i', 'cut', 'alway', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a chunk hair got stuck blow dryer i cut alway fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3144 :\n",
      "\n",
      "\tTweet's text':  claim man peac violat hr orient make free speech argument hr issu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['claim', 'man', 'peac', 'violat', 'hr', 'orient', 'make', 'free', 'speech', 'argument', 'hr', 'issu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['claim man peac violat hr orient make free speech argument hr issu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3145 :\n",
      "\n",
      "\tTweet's text':  can i ask hv gej n pdp trend yesterday night \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'i', 'ask', 'hv', 'gej', 'n', 'pdp', 'trend', 'yesterday', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can i ask hv gej n pdp trend yesterday night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3146 :\n",
      "\n",
      "\tTweet's text':  i love wake abl sleep anymor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wake', 'abl', 'sleep', 'anymor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wake abl sleep anymor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3147 :\n",
      "\n",
      "\tTweet's text':  hang niec day face stuck tongu wink eye joke \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'face_with_stuck-out_tongue_and_winking_eye'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hang', 'niec', 'day', 'face', 'stuck', 'tongu', 'wink', 'eye', 'joke'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hang niec day face stuck tongu wink eye joke'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3148 :\n",
      "\n",
      "\tTweet's text':  i heard liber defend bomb civilian along terrorist w trial still claim enh interrog gitmo evil \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'heard', 'liber', 'defend', 'bomb', 'civilian', 'along', 'terrorist', 'w', 'trial', 'still', 'claim', 'enh', 'interrog', 'gitmo', 'evil'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i heard liber defend bomb civilian along terrorist w trial still claim enh interrog gitmo evil'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3149 :\n",
      "\n",
      "\tTweet's text':  offer made sure board refus doubl octob ranger interest \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['offer', 'made', 'sure', 'board', 'refus', 'doubl', 'octob', 'ranger', 'interest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['offer made sure board refus doubl octob ranger interest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3150 :\n",
      "\n",
      "\tTweet's text':  today shitti day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'shitti', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today shitti day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3151 :\n",
      "\n",
      "\tTweet's text':  neither i i gonna ambul pre book gorj \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['neither', 'i', 'i', 'gon', 'na', 'ambul', 'pre', 'book', 'gorj'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['neither i i gonna ambul pre book gorj'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3152 :\n",
      "\n",
      "\tTweet's text':  fell asleep pm woke can get back i almost forgotten welcom back \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sleep', '#insomnia'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fell', 'asleep', 'pm', 'woke', 'can', 'get', 'back', 'i', 'almost', 'forgotten', 'welcom', 'back'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fell asleep pm woke can get back i almost forgotten welcom back'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3153 :\n",
      "\n",
      "\tTweet's text':  thank behh lovey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bestfriends', '#behh', '#beh', '#sweet', '#love', '#distance', '#to', '#far'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'behh', 'lovey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank behh lovey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3154 :\n",
      "\n",
      "\tTweet's text':  light went school tri learn one emerg light classroom great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['light', 'went', 'school', 'tri', 'learn', 'one', 'emerg', 'light', 'classroom', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['light went school tri learn one emerg light classroom great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3155 :\n",
      "\n",
      "\tTweet's text':  the new jd gym bein right next sayer sausag roll salad pleas \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'new', 'jd', 'gym', 'bein', 'right', 'next', 'sayer', 'sausag', 'roll', 'salad', 'pleas'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the new jd gym bein right next sayer sausag roll salad pleas'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3156 :\n",
      "\n",
      "\tTweet's text':  just barter bottl rum best one got happi fuck new year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'barter', 'bottl', 'rum', 'best', 'one', 'got', 'happi', 'fuck', 'new', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just barter bottl rum best one got happi fuck new year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3157 :\n",
      "\n",
      "\tTweet's text':  rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#034i', '#100', '#Glitter', '#Inside', '#Just', '#Lamp', '#Of'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3158 :\n",
      "\n",
      "\tTweet's text':  ye mother wish \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'mother', 'wish'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye mother wish'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3159 :\n",
      "\n",
      "\tTweet's text':  i assum rex grossman start \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'assum', 'rex', 'grossman', 'start'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i assum rex grossman start'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3160 :\n",
      "\n",
      "\tTweet's text':  is iron song come song \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ipod', '#SelenaGomez', '#JustinBeiber'] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'iron', 'song', 'come', 'song'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is iron song come song'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3161 :\n",
      "\n",
      "\tTweet's text':  oh let forget \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'let', 'forget'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh let forget'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3162 :\n",
      "\n",
      "\tTweet's text':  walk school awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['walk', 'school', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['walk school awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3163 :\n",
      "\n",
      "\tTweet's text':  love take subway alon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'take', 'subway', 'alon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love take subway alon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3164 :\n",
      "\n",
      "\tTweet's text':  ha ha christma cat look well impress \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ha', 'ha', 'christma', 'cat', 'look', 'well', 'impress'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ha ha christma cat look well impress'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3165 :\n",
      "\n",
      "\tTweet's text':  you cup tea total ass i switch coffe \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'person_raising_both_hands_in_celebration'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'cup', 'tea', 'total', 'ass', 'i', 'switch', 'coffe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you cup tea total ass i switch coffe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3166 :\n",
      "\n",
      "\tTweet's text':  do bertrand russel \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Do', '#Fear', '#to', '#be', '#Eccentric', '#in', '#Opinion', '#for', '#Every', '#Opinion', '#now', '#Accepted', '#was', '#Once', '#Eccentric'] \n",
      "\n",
      "\tTweet tokenized by words:  ['do', 'bertrand', 'russel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['do bertrand russel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3167 :\n",
      "\n",
      "\tTweet's text':  step but i dig \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['step', 'but', 'i', 'dig'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['step but i dig'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3168 :\n",
      "\n",
      "\tTweet's text':  that moment want break someon finger \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'moment', 'want', 'break', 'someon', 'finger'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that moment want break someon finger'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3169 :\n",
      "\n",
      "\tTweet's text':  you cool \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'cool'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you cool'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3170 :\n",
      "\n",
      "\tTweet's text':  where good govern order celebr dec th \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#goodgovernanceday', '#Christmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['where', 'good', 'govern', 'order', 'celebr', 'dec', 'th'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['where good govern order celebr dec th'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3171 :\n",
      "\n",
      "\tTweet's text':  lose key car drive airport catch flight awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lose', 'key', 'car', 'drive', 'airport', 'catch', 'flight', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lose key car drive airport catch flight awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3172 :\n",
      "\n",
      "\tTweet's text':  onlin shop credit card \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['white_smiling_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Umm', '#JustBrowsing'] \n",
      "\n",
      "\tTweet tokenized by words:  ['onlin', 'shop', 'credit', 'card'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['onlin shop credit card'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3173 :\n",
      "\n",
      "\tTweet's text':  syria \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Russia', '#says', '#new', '#U', '#sanctions', '#may', '#hamper', '#dialogue', '#Iran'] \n",
      "\n",
      "\tTweet tokenized by words:  ['syria'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['syria'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3174 :\n",
      "\n",
      "\tTweet's text':  gop love immigr they like illeg border crosser illeg presidenti action ignor constitut \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gop', 'love', 'immigr', 'they', 'like', 'illeg', 'border', 'crosser', 'illeg', 'presidenti', 'action', 'ignor', 'constitut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gop love immigr they like illeg border crosser illeg presidenti action ignor constitut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3175 :\n",
      "\n",
      "\tTweet's text':  whi fuck twitter tell follow follow someon \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'fuck', 'twitter', 'tell', 'follow', 'follow', 'someon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi fuck twitter tell follow follow someon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3176 :\n",
      "\n",
      "\tTweet's text':  listen paranard mix polosweet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#my', '#np', '#SoundCloud'] \n",
      "\n",
      "\tTweet tokenized by words:  ['listen', 'paranard', 'mix', 'polosweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['listen paranard mix polosweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3177 :\n",
      "\n",
      "\tTweet's text':  pretti flip cold outsid today i tell ya \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pretti', 'flip', 'cold', 'outsid', 'today', 'i', 'tell', 'ya'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pretti flip cold outsid today i tell ya'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3178 :\n",
      "\n",
      "\tTweet's text':  fuck pure cloth though spoil bless \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fuck', 'pure', 'cloth', 'though', 'spoil', 'bless'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fuck pure cloth though spoil bless'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3179 :\n",
      "\n",
      "\tTweet's text':  time look golden girl nite love show \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#love'] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'look', 'golden', 'girl', 'nite', 'love', 'show'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time look golden girl nite love show'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3180 :\n",
      "\n",
      "\tTweet's text':  how even keep great music \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'even', 'keep', 'great', 'music'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how even keep great music'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3181 :\n",
      "\n",
      "\tTweet's text':  the hashtag got racist goin s \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#blackbrunchnyc'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'hashtag', 'got', 'racist', 'goin', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the hashtag got racist goin s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3182 :\n",
      "\n",
      "\tTweet's text':  he tri drive suh price \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['he', 'tri', 'drive', 'suh', 'price'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['he tri drive suh price'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3183 :\n",
      "\n",
      "\tTweet's text':  welp back draw board \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['persevering_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#mua', '#sike', '#eyeliner', '#fail', '#notforme', '#makeup', '#naturalgirl'] \n",
      "\n",
      "\tTweet tokenized by words:  ['welp', 'back', 'draw', 'board'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['welp back draw board'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3184 :\n",
      "\n",
      "\tTweet's text':  illinoi made illeg film cop i guess step right direct \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wtf'] \n",
      "\n",
      "\tTweet tokenized by words:  ['illinoi', 'made', 'illeg', 'film', 'cop', 'i', 'guess', 'step', 'right', 'direct'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['illinoi made illeg film cop i guess step right direct'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3185 :\n",
      "\n",
      "\tTweet's text':  thi call otak letak kat lutut melayu \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#melayu'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'call', 'otak', 'letak', 'kat', 'lutut', 'melayu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi call otak letak kat lutut melayu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3186 :\n",
      "\n",
      "\tTweet's text':  just found etch a sketch app \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#oldschool', '#notoldschool'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'found', 'etch', 'a', 'sketch', 'app'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just found etch a sketch app'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3187 :\n",
      "\n",
      "\tTweet's text':  believ life god creat race \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['believ', 'life', 'god', 'creat', 'race'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['believ life god creat race'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3188 :\n",
      "\n",
      "\tTweet's text':  but i never realli check mayb thing wrong everi week \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'i', 'never', 'realli', 'check', 'mayb', 'thing', 'wrong', 'everi', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but i never realli check mayb thing wrong everi week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3189 :\n",
      "\n",
      "\tTweet's text':  ideolog nutshel mean life sentenc everi perspect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ideolog', 'nutshel', 'mean', 'life', 'sentenc', 'everi', 'perspect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ideolog nutshel mean life sentenc everi perspect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3190 :\n",
      "\n",
      "\tTweet's text':  fine atm glaze appl shower gel perfum smell amaz \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fine', 'atm', 'glaze', 'appl', 'shower', 'gel', 'perfum', 'smell', 'amaz'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fine atm glaze appl shower gel perfum smell amaz'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3191 :\n",
      "\n",
      "\tTweet's text':  ew realli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ew', 'realli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ew realli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3192 :\n",
      "\n",
      "\tTweet's text':  i don t want to see a remak of my favorit movi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'don', 't', 'want', 'to', 'see', 'a', 'remak', 'of', 'my', 'favorit', 'movi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i don t want to see a remak of my favorit movi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3193 :\n",
      "\n",
      "\tTweet's text':  today fabul day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Work', '#Ugggh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'fabul', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today fabul day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3194 :\n",
      "\n",
      "\tTweet's text':  song angel death good one it lyric bash vatican \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['song', 'angel', 'death', 'good', 'one', 'it', 'lyric', 'bash', 'vatican'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['song angel death good one it lyric bash vatican'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3195 :\n",
      "\n",
      "\tTweet's text':  rememb black friday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rememb', 'black', 'friday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rememb black friday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3196 :\n",
      "\n",
      "\tTweet's text':  i thought funni p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'thought', 'funni', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i thought funni p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3197 :\n",
      "\n",
      "\tTweet's text':  the shadowi investigatori power tribun say tap major internet cabl ok that alright \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'shadowi', 'investigatori', 'power', 'tribun', 'say', 'tap', 'major', 'internet', 'cabl', 'ok', 'that', 'alright'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the shadowi investigatori power tribun say tap major internet cabl ok that alright'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3198 :\n",
      "\n",
      "\tTweet's text':  is jamei winston get paid photo coincid \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#5'] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'jamei', 'winston', 'get', 'paid', 'photo', 'coincid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is jamei winston get paid photo coincid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3199 :\n",
      "\n",
      "\tTweet's text':  what know tom crean coach geniu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#iubb'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'know', 'tom', 'crean', 'coach', 'geniu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what know tom crean coach geniu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3200 :\n",
      "\n",
      "\tTweet's text':  good point republican parti fractur togeth make disench elector \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'point', 'republican', 'parti', 'fractur', 'togeth', 'make', 'disench', 'elector'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good point republican parti fractur togeth make disench elector'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3201 :\n",
      "\n",
      "\tTweet's text':  greek salad i lover that \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['greek', 'salad', 'i', 'lover', 'that'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['greek salad i lover that'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3202 :\n",
      "\n",
      "\tTweet's text':  follow get free demo industri buzz app seen \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['follow', 'get', 'free', 'demo', 'industri', 'buzz', 'app', 'seen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['follow get free demo industri buzz app seen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3203 :\n",
      "\n",
      "\tTweet's text':  on page harri potter chamber secret j k rowl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['on', 'page', 'harri', 'potter', 'chamber', 'secret', 'j', 'k', 'rowl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['on page harri potter chamber secret j k rowl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3204 :\n",
      "\n",
      "\tTweet's text':  silenc tast like wet flower wet dead die flower flower without life fallen piec silenc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['silenc', 'tast', 'like', 'wet', 'flower', 'wet', 'dead', 'die', 'flower', 'flower', 'without', 'life', 'fallen', 'piec', 'silenc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['silenc tast like wet flower wet dead die flower flower without life fallen piec silenc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3205 :\n",
      "\n",
      "\tTweet's text':  went bed \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Twitter', '#Sleepy', '#2am'] \n",
      "\n",
      "\tTweet tokenized by words:  ['went', 'bed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['went bed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3206 :\n",
      "\n",
      "\tTweet's text':  don love guy tri give number keyword tri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#backupoff'] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'love', 'guy', 'tri', 'give', 'number', 'keyword', 'tri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don love guy tri give number keyword tri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3207 :\n",
      "\n",
      "\tTweet's text':  pilat now i get go home get readi work amaz \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pilat', 'now', 'i', 'get', 'go', 'home', 'get', 'readi', 'work', 'amaz'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pilat now i get go home get readi work amaz'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3208 :\n",
      "\n",
      "\tTweet's text':  begin look lot like christma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['christmas_tree', 'father_christmas'] \n",
      "\n",
      "\tTweet's hashtags':  ['#office', '#tinsel', '#christmassy', '#happy', '#long', '#now'] \n",
      "\n",
      "\tTweet tokenized by words:  ['begin', 'look', 'lot', 'like', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['begin look lot like christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3209 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BBC', '#News', '#China', '#Shanghai', '#crush', '#Xi', '#Jinping', '#orders', '#new', '#year', '#investigation'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3210 :\n",
      "\n",
      "\tTweet's text':  a design firm holiday card skewer corpor jargon hand bite mouth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#jargon', '#design'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'design', 'firm', 'holiday', 'card', 'skewer', 'corpor', 'jargon', 'hand', 'bite', 'mouth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a design firm holiday card skewer corpor jargon hand bite mouth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3211 :\n",
      "\n",
      "\tTweet's text':  just put first gear move liber ever give life caus they destroy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'put', 'first', 'gear', 'move', 'liber', 'ever', 'give', 'life', 'caus', 'they', 'destroy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just put first gear move liber ever give life caus they destroy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3212 :\n",
      "\n",
      "\tTweet's text':  man much tweet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['man', 'much', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['man much tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3213 :\n",
      "\n",
      "\tTweet's text':  see burnsvil pm \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['see', 'burnsvil', 'pm'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['see burnsvil pm'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3214 :\n",
      "\n",
      "\tTweet's text':  happi birthday young one gooden lad x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happi', 'birthday', 'young', 'one', 'gooden', 'lad', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happi birthday young one gooden lad x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3215 :\n",
      "\n",
      "\tTweet's text':  the greatest unsolv mysteri god \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'greatest', 'unsolv', 'mysteri', 'god'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the greatest unsolv mysteri god'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3216 :\n",
      "\n",
      "\tTweet's text':  yellow page need phone book futur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#truth', '#reallynotreally'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yellow', 'page', 'need', 'phone', 'book', 'futur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yellow page need phone book futur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3217 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet's text':  fox new critic poor journal regard uva incid hilari \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fox', 'new', 'critic', 'poor', 'journal', 'regard', 'uva', 'incid', 'hilari'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fox new critic poor journal regard uva incid hilari'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3218 :\n",
      "\n",
      "\tTweet's text':  buddhism chant kid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Music', '#Education'] \n",
      "\n",
      "\tTweet tokenized by words:  ['buddhism', 'chant', 'kid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['buddhism chant kid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3219 :\n",
      "\n",
      "\tTweet's text':  support compyut system idea robotway \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#skill'] \n",
      "\n",
      "\tTweet tokenized by words:  ['support', 'compyut', 'system', 'idea', 'robotway'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['support compyut system idea robotway'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3220 :\n",
      "\n",
      "\tTweet's text':  we spend childhood hurri grow grow want retain childlik natur \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#justsaying', '#lifegoals', '#kids'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'spend', 'childhood', 'hurri', 'grow', 'grow', 'want', 'retain', 'childlik', 'natur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we spend childhood hurri grow grow want retain childlik natur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3221 :\n",
      "\n",
      "\tTweet's text':  i got readi got school park less minut \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#miracle'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'got', 'readi', 'got', 'school', 'park', 'less', 'minut'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i got readi got school park less minut'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3222 :\n",
      "\n",
      "\tTweet's text':  good step bjp goon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'step', 'bjp', 'goon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good step bjp goon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3223 :\n",
      "\n",
      "\tTweet's text':  we vote republican their civil right record abil empath amaz \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'vote', 'republican', 'their', 'civil', 'right', 'record', 'abil', 'empath', 'amaz'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we vote republican their civil right record abil empath amaz'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3224 :\n",
      "\n",
      "\tTweet's text':  i wonder professor iaukea say new disney p \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wonder', 'professor', 'iaukea', 'say', 'new', 'disney', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wonder professor iaukea say new disney p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3225 :\n",
      "\n",
      "\tTweet's text':  everi one love lot x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MerryChristmas', '#PeaceOnEarth'] \n",
      "\n",
      "\tTweet tokenized by words:  ['everi', 'one', 'love', 'lot', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everi one love lot x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3226 :\n",
      "\n",
      "\tTweet's text':  tweet yesterday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tweet', 'yesterday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tweet yesterday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3227 :\n",
      "\n",
      "\tTweet's text':  polic turn violent i love truth headlin \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['polic', 'turn', 'violent', 'i', 'love', 'truth', 'headlin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['polic turn violent i love truth headlin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3228 :\n",
      "\n",
      "\tTweet's text':  if i make i love beer ten talk basebal you good dude \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'i', 'make', 'i', 'love', 'beer', 'ten', 'talk', 'basebal', 'you', 'good', 'dude'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if i make i love beer ten talk basebal you good dude'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3229 :\n",
      "\n",
      "\tTweet's text':  i sure cereal box i decor accur represent well i know book \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'sure', 'cereal', 'box', 'i', 'decor', 'accur', 'represent', 'well', 'i', 'know', 'book'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i sure cereal box i decor accur represent well i know book'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3230 :\n",
      "\n",
      "\tTweet's text':  can hear traine watch train dvd i break sound fun p \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['p'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'hear', 'traine', 'watch', 'train', 'dvd', 'i', 'break', 'sound', 'fun', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can hear traine watch train dvd i break sound fun p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3231 :\n",
      "\n",
      "\tTweet's text':  yet anoth angri moron block one tweet p \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bluehand'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yet', 'anoth', 'angri', 'moron', 'block', 'one', 'tweet', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yet anoth angri moron block one tweet p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3232 :\n",
      "\n",
      "\tTweet's text':  what ridicul hashtag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#massive', '#twat'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'ridicul', 'hashtag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what ridicul hashtag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3233 :\n",
      "\n",
      "\tTweet's text':  storm come \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#todayimloving'] \n",
      "\n",
      "\tTweet tokenized by words:  ['storm', 'come'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['storm come'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3234 :\n",
      "\n",
      "\tTweet's text':  oh keep finger cross sometim wors quicker go \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HandyMedicalFact'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'keep', 'finger', 'cross', 'sometim', 'wors', 'quicker', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh keep finger cross sometim wors quicker go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3235 :\n",
      "\n",
      "\tTweet's text':  i glad jonathan stewart best game yr fantasi fb \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#imout'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'glad', 'jonathan', 'stewart', 'best', 'game', 'yr', 'fantasi', 'fb'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i glad jonathan stewart best game yr fantasi fb'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3236 :\n",
      "\n",
      "\tTweet's text':  for reason i feel classiest i wear fake pearl necklac lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['for', 'reason', 'i', 'feel', 'classiest', 'i', 'wear', 'fake', 'pearl', 'necklac', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['for reason i feel classiest i wear fake pearl necklac lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3237 :\n",
      "\n",
      "\tTweet's text':  had take snow fall still thi total clear i went sleep \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#PatioPics', '#WCCO'] \n",
      "\n",
      "\tTweet tokenized by words:  ['had', 'take', 'snow', 'fall', 'still', 'thi', 'total', 'clear', 'i', 'went', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['had take snow fall still thi total clear i went sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3238 :\n",
      "\n",
      "\tTweet's text':  cours card what card \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cours', 'card', 'what', 'card'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cours card what card'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3239 :\n",
      "\n",
      "\tTweet's text':  more word selfi the egyptian legend bestselfi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BestSelfie2014'] \n",
      "\n",
      "\tTweet tokenized by words:  ['more', 'word', 'selfi', 'the', 'egyptian', 'legend', 'bestselfi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['more word selfi the egyptian legend bestselfi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3240 :\n",
      "\n",
      "\tTweet's text':  ohhh joy get pull \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['green_heart'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ohhh', 'joy', 'get', 'pull'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ohhh joy get pull'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3241 :\n",
      "\n",
      "\tTweet's text':  gotta love shake someon hand offici i death hand winter \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#coldhandswarmheart'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'love', 'shake', 'someon', 'hand', 'offici', 'i', 'death', 'hand', 'winter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta love shake someon hand offici i death hand winter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3242 :\n",
      "\n",
      "\tTweet's text':  can u help more conserv need get paid post stuff like you can too go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TSU'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'u', 'help', 'more', 'conserv', 'need', 'get', 'paid', 'post', 'stuff', 'like', 'you', 'can', 'too', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can u help more conserv need get paid post stuff like you can too go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3243 :\n",
      "\n",
      "\tTweet's text':  thank god wait appoint februari \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'god', 'wait', 'appoint', 'februari'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank god wait appoint februari'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3244 :\n",
      "\n",
      "\tTweet's text':  what app outragi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'app', 'outragi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what app outragi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3245 :\n",
      "\n",
      "\tTweet's text':  how world i start day kaitlyn get tire \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Frozen', '#Idontwanttobuildasnowman', '#mommyproblems', '#mommylife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'world', 'i', 'start', 'day', 'kaitlyn', 'get', 'tire'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how world i start day kaitlyn get tire'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3246 :\n",
      "\n",
      "\tTweet's text':  robert handsom ugli rdj i love ga btw tomtom i love u \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#RDJ', '#你就算5隔格我都知你讲me', '#BTW'] \n",
      "\n",
      "\tTweet tokenized by words:  ['robert', 'handsom', 'ugli', 'rdj', 'i', 'love', 'ga', 'btw', 'tomtom', 'i', 'love', 'u'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['robert handsom ugli rdj i love ga btw tomtom i love u'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3247 :\n",
      "\n",
      "\tTweet's text':  the fact offic would threaten throw mother squad car lament die child wick absurd \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'fact', 'offic', 'would', 'threaten', 'throw', 'mother', 'squad', 'car', 'lament', 'die', 'child', 'wick', 'absurd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the fact offic would threaten throw mother squad car lament die child wick absurd'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3248 :\n",
      "\n",
      "\tTweet's text':  work dirti bird \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'dirti', 'bird'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work dirti bird'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3249 :\n",
      "\n",
      "\tTweet's text':  for union represent decad teacher pay still suck short due \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['for', 'union', 'represent', 'decad', 'teacher', 'pay', 'still', 'suck', 'short', 'due'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['for union represent decad teacher pay still suck short due'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3250 :\n",
      "\n",
      "\tTweet's text':  and \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#calledit', '#bandwagon', '#Houseisafeeling', '#EDUCATE'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3251 :\n",
      "\n",
      "\tTweet's text':  i still \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'still'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i still'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3252 :\n",
      "\n",
      "\tTweet's text':  wonder weather drink tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['wrapped_present', 'christmas_tree', 'father_christmas'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wonder', 'weather', 'drink', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wonder weather drink tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3253 :\n",
      "\n",
      "\tTweet's text':  go watch movi murder merri christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['go', 'watch', 'movi', 'murder', 'merri', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['go watch movi murder merri christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3254 :\n",
      "\n",
      "\tTweet's text':  and hour i final get freak sleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HappyHolidays', '#AlwaysWorking'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'hour', 'i', 'final', 'get', 'freak', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and hour i final get freak sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3255 :\n",
      "\n",
      "\tTweet's text':  obvious day go go fantast well \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['obvious', 'day', 'go', 'go', 'fantast', 'well'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['obvious day go go fantast well'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3256 :\n",
      "\n",
      "\tTweet's text':  way could mean track record whatsoev \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['way', 'could', 'mean', 'track', 'record', 'whatsoev'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['way could mean track record whatsoev'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3257 :\n",
      "\n",
      "\tTweet's text':  casual stroll lauralobaugh rochest key west island florida u s a \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FunInTheSun'] \n",
      "\n",
      "\tTweet tokenized by words:  ['casual', 'stroll', 'lauralobaugh', 'rochest', 'key', 'west', 'island', 'florida', 'u', 's', 'a'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['casual stroll lauralobaugh rochest key west island florida u s a'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3258 :\n",
      "\n",
      "\tTweet's text':  coffe priorit mess tri clearli i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#grown'] \n",
      "\n",
      "\tTweet tokenized by words:  ['coffe', 'priorit', 'mess', 'tri', 'clearli', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['coffe priorit mess tri clearli i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3259 :\n",
      "\n",
      "\tTweet's text':  lol actual use email \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'actual', 'use', 'email'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol actual use email'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3260 :\n",
      "\n",
      "\tTweet's text':  christma less week away wtaf \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['christma', 'less', 'week', 'away', 'wtaf'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['christma less week away wtaf'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3261 :\n",
      "\n",
      "\tTweet's text':  make pair lung tobacco box i collect sculptur project \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['make', 'pair', 'lung', 'tobacco', 'box', 'i', 'collect', 'sculptur', 'project'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['make pair lung tobacco box i collect sculptur project'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3262 :\n",
      "\n",
      "\tTweet's text':  big guy like sephora jcpenni killer \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['big', 'guy', 'like', 'sephora', 'jcpenni', 'killer'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['big guy like sephora jcpenni killer'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3263 :\n",
      "\n",
      "\tTweet's text':  q what slower pakistan bat a ptcl evo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pakvnz'] \n",
      "\n",
      "\tTweet tokenized by words:  ['q', 'what', 'slower', 'pakistan', 'bat', 'a', 'ptcl', 'evo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['q what slower pakistan bat a ptcl evo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3264 :\n",
      "\n",
      "\tTweet's text':  i complet day day ab challeng workout join download app \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'complet', 'day', 'day', 'ab', 'challeng', 'workout', 'join', 'download', 'app'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i complet day day ab challeng workout join download app'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3265 :\n",
      "\n",
      "\tTweet's text':  soon stop wtf omg deff fav thing hear \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['soon', 'stop', 'wtf', 'omg', 'deff', 'fav', 'thing', 'hear'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['soon stop wtf omg deff fav thing hear'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3266 :\n",
      "\n",
      "\tTweet's text':  merri christma topspin monkey hope great holiday readi train new year x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['merri', 'christma', 'topspin', 'monkey', 'hope', 'great', 'holiday', 'readi', 'train', 'new', 'year', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['merri christma topspin monkey hope great holiday readi train new year x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3267 :\n",
      "\n",
      "\tTweet's text':  how much stupid peopl get \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'much', 'stupid', 'peopl', 'get'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how much stupid peopl get'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3268 :\n",
      "\n",
      "\tTweet's text':  difficult and happi life enjoy becaus life come just onc so he went so he will not be back ez \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['difficult', 'and', 'happi', 'life', 'enjoy', 'becaus', 'life', 'come', 'just', 'onc', 'so', 'he', 'went', 'so', 'he', 'will', 'not', 'be', 'back', 'ez'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['difficult and happi life enjoy becaus life come just onc so he went so he will not be back ez'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3269 :\n",
      "\n",
      "\tTweet's text':  what differ year make \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bestfriends', '#changed', '#one', '#bit'] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'differ', 'year', 'make'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what differ year make'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3270 :\n",
      "\n",
      "\tTweet's text':  i let bb know i get xx \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'let', 'bb', 'know', 'i', 'get', 'xx'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i let bb know i get xx'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3271 :\n",
      "\n",
      "\tTweet's text':  definit consult tax profession one \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['definit', 'consult', 'tax', 'profession', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['definit consult tax profession one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3272 :\n",
      "\n",
      "\tTweet's text':  free date relationship book \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#freebiebookdownload', '#GreenLiving'] \n",
      "\n",
      "\tTweet tokenized by words:  ['free', 'date', 'relationship', 'book'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['free date relationship book'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3273 :\n",
      "\n",
      "\tTweet's text':  adult onesi meet cloth requir walmart employe just put yr vest smile \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Fact', '#StarTrek'] \n",
      "\n",
      "\tTweet tokenized by words:  ['adult', 'onesi', 'meet', 'cloth', 'requir', 'walmart', 'employe', 'just', 'put', 'yr', 'vest', 'smile'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['adult onesi meet cloth requir walmart employe just put yr vest smile'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3274 :\n",
      "\n",
      "\tTweet's text':  depend mean caus everyon differ \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['depend', 'mean', 'caus', 'everyon', 'differ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['depend mean caus everyon differ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3275 :\n",
      "\n",
      "\tTweet's text':  today start fabul \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'start', 'fabul'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today start fabul'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3276 :\n",
      "\n",
      "\tTweet's text':  who wanna hit slope \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['who', 'wan', 'na', 'hit', 'slope'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['who wanna hit slope'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3277 :\n",
      "\n",
      "\tTweet's text':  be bless friend merri christma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'bless', 'friend', 'merri', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be bless friend merri christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3278 :\n",
      "\n",
      "\tTweet's text':  a colleagu told uncl dupe acid saddam hussein thug usual offic banter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'colleagu', 'told', 'uncl', 'dupe', 'acid', 'saddam', 'hussein', 'thug', 'usual', 'offic', 'banter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a colleagu told uncl dupe acid saddam hussein thug usual offic banter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3279 :\n",
      "\n",
      "\tTweet's text':  kiwi heineken drink steinlag pure new zealand breweri limit raglan golf club \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#photo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['kiwi', 'heineken', 'drink', 'steinlag', 'pure', 'new', 'zealand', 'breweri', 'limit', 'raglan', 'golf', 'club'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kiwi heineken drink steinlag pure new zealand breweri limit raglan golf club'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3280 :\n",
      "\n",
      "\tTweet's text':  it funni think liter book whatev want life \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'funni', 'think', 'liter', 'book', 'whatev', 'want', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it funni think liter book whatev want life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3281 :\n",
      "\n",
      "\tTweet's text':  thi great time feel \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'great', 'time', 'feel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi great time feel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3282 :\n",
      "\n",
      "\tTweet's text':  much import unilater remov restrict oil ga sector \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['much', 'import', 'unilater', 'remov', 'restrict', 'oil', 'ga', 'sector'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['much import unilater remov restrict oil ga sector'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3283 :\n",
      "\n",
      "\tTweet's text':  i much tomorrow i think mayb i take nap \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'much', 'tomorrow', 'i', 'think', 'mayb', 'i', 'take', 'nap'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i much tomorrow i think mayb i take nap'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3284 :\n",
      "\n",
      "\tTweet's text':  product aaron rodger eric decker pretti good last year it situat when jordi cash non factor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['product', 'aaron', 'rodger', 'eric', 'decker', 'pretti', 'good', 'last', 'year', 'it', 'situat', 'when', 'jordi', 'cash', 'non', 'factor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['product aaron rodger eric decker pretti good last year it situat when jordi cash non factor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3285 :\n",
      "\n",
      "\tTweet's text':  how i miss taken \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'i', 'miss', 'taken'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how i miss taken'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3286 :\n",
      "\n",
      "\tTweet's text':  what pleasant way minneapoli prestigi public describ femal audienc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'pleasant', 'way', 'minneapoli', 'prestigi', 'public', 'describ', 'femal', 'audienc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what pleasant way minneapoli prestigi public describ femal audienc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3287 :\n",
      "\n",
      "\tTweet's text':  wow i wait post \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  ['#newyearnewme'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'wait', 'post'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i wait post'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3288 :\n",
      "\n",
      "\tTweet's text':  that moment drop phone right kid give case xma actual open put use \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'moment', 'drop', 'phone', 'right', 'kid', 'give', 'case', 'xma', 'actual', 'open', 'put', 'use'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that moment drop phone right kid give case xma actual open put use'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3289 :\n",
      "\n",
      "\tTweet's text':  you rbrnetwork do not repres all black fact reject \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'rbrnetwork', 'do', 'not', 'repres', 'all', 'black', 'fact', 'reject'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you rbrnetwork do not repres all black fact reject'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3290 :\n",
      "\n",
      "\tTweet's text':  i fell asleep post last post \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'fell', 'asleep', 'post', 'last', 'post'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i fell asleep post last post'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3291 :\n",
      "\n",
      "\tTweet's text':  i guess i dream how els i abl visit site guess let prison phone right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'i', 'dream', 'how', 'els', 'i', 'abl', 'visit', 'site', 'guess', 'let', 'prison', 'phone', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guess i dream how els i abl visit site guess let prison phone right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3292 :\n",
      "\n",
      "\tTweet's text':  i give feedback food i happi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'give', 'feedback', 'food', 'i', 'happi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i give feedback food i happi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3293 :\n",
      "\n",
      "\tTweet's text':  damnit dude i see i get back though \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['damnit', 'dude', 'i', 'see', 'i', 'get', 'back', 'though'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['damnit dude i see i get back though'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3294 :\n",
      "\n",
      "\tTweet's text':  lol appar i leav big impress \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'appar', 'i', 'leav', 'big', 'impress'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol appar i leav big impress'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3295 :\n",
      "\n",
      "\tTweet's text':  find sxi lov on your mobil \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#twink', '#engine', '#goldenkrust', '#greensmoothiegirl'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet tokenized by words:  ['find', 'sxi', 'lov', 'on', 'your', 'mobil'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['find sxi lov on your mobil'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3296 :\n",
      "\n",
      "\tTweet's text':  tweet explain what muslim should sorri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#MuslimApologies'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tweet', 'explain', 'what', 'muslim', 'should', 'sorri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tweet explain what muslim should sorri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3297 :\n",
      "\n",
      "\tTweet's text':  yeah i show convo stuff gonna text no \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'i', 'show', 'convo', 'stuff', 'gon', 'na', 'text', 'no'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah i show convo stuff gonna text no'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3298 :\n",
      "\n",
      "\tTweet's text':  at who gonna favourit an owl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['at', 'who', 'gon', 'na', 'favourit', 'an', 'owl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['at who gonna favourit an owl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3299 :\n",
      "\n",
      "\tTweet's text':  wasn playoff suppos make process easier \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NCAA'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wasn', 'playoff', 'suppos', 'make', 'process', 'easier'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wasn playoff suppos make process easier'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3300 :\n",
      "\n",
      "\tTweet's text':  same whoopi said rape yo roman polanski not rape rape b c drug \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['same', 'whoopi', 'said', 'rape', 'yo', 'roman', 'polanski', 'not', 'rape', 'rape', 'b', 'c', 'drug'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['same whoopi said rape yo roman polanski not rape rape b c drug'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3301 :\n",
      "\n",
      "\tTweet's text':  those fail develop hair bald hear talk abr develop \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['those', 'fail', 'develop', 'hair', 'bald', 'hear', 'talk', 'abr', 'develop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['those fail develop hair bald hear talk abr develop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3302 :\n",
      "\n",
      "\tTweet's text':  so glad work morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'glad', 'work', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so glad work morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3303 :\n",
      "\n",
      "\tTweet's text':  prepar sampl answer rehears exam qs digit media googl drive i technolog advanc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['prepar', 'sampl', 'answer', 'rehears', 'exam', 'qs', 'digit', 'media', 'googl', 'drive', 'i', 'technolog', 'advanc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['prepar sampl answer rehears exam qs digit media googl drive i technolog advanc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3304 :\n",
      "\n",
      "\tTweet's text':  casual meal mate turn expect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#disappointed'] \n",
      "\n",
      "\tTweet tokenized by words:  ['casual', 'meal', 'mate', 'turn', 'expect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['casual meal mate turn expect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3305 :\n",
      "\n",
      "\tTweet's text':  lucki i finish coursework revis super hard feel super healthi two \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lucki', 'i', 'finish', 'coursework', 'revis', 'super', 'hard', 'feel', 'super', 'healthi', 'two'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lucki i finish coursework revis super hard feel super healthi two'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3306 :\n",
      "\n",
      "\tTweet's text':  hahahhaha realli made jelous \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hahahhaha', 'realli', 'made', 'jelous'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hahahhaha realli made jelous'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3307 :\n",
      "\n",
      "\tTweet's text':  i tri decid cover say lone widow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'tri', 'decid', 'cover', 'say', 'lone', 'widow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i tri decid cover say lone widow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3308 :\n",
      "\n",
      "\tTweet's text':  anoth day love comcast subscrib \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#neverworks'] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'day', 'love', 'comcast', 'subscrib'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth day love comcast subscrib'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3309 :\n",
      "\n",
      "\tTweet's text':  iv even start think i go get parent babi someth fam multipli quickli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pensive_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['iv', 'even', 'start', 'think', 'i', 'go', 'get', 'parent', 'babi', 'someth', 'fam', 'multipli', 'quickli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['iv even start think i go get parent babi someth fam multipli quickli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3310 :\n",
      "\n",
      "\tTweet's text':  young chap asham god savior word god n life christ entrepreneur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Happy', '#spreading', '#successful', '#MindOfGod'] \n",
      "\n",
      "\tTweet tokenized by words:  ['young', 'chap', 'asham', 'god', 'savior', 'word', 'god', 'n', 'life', 'christ', 'entrepreneur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['young chap asham god savior word god n life christ entrepreneur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3311 :\n",
      "\n",
      "\tTweet's text':  monday fine it life suck it first day class see ugh face ursulaonamonday wow \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#UrsulaOnAMonday', '#wow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['monday', 'fine', 'it', 'life', 'suck', 'it', 'first', 'day', 'class', 'see', 'ugh', 'face', 'ursulaonamonday', 'wow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['monday fine it life suck it first day class see ugh face ursulaonamonday wow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3312 :\n",
      "\n",
      "\tTweet's text':  glad find quiz due yesterday i even know thank notif blackboard \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['glad', 'find', 'quiz', 'due', 'yesterday', 'i', 'even', 'know', 'thank', 'notif', 'blackboard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['glad find quiz due yesterday i even know thank notif blackboard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3313 :\n",
      "\n",
      "\tTweet's text':  new england new york jet pittsburgh kansa citi carolina cleveland \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['new', 'england', 'new', 'york', 'jet', 'pittsburgh', 'kansa', 'citi', 'carolina', 'cleveland'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['new england new york jet pittsburgh kansa citi carolina cleveland'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3314 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GuruMantra', '#success', '#entrepreneur', '#startup'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3315 :\n",
      "\n",
      "\tTweet's text':  wow i serious die see evil monkeyse evil monkey \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['see-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'i', 'serious', 'die', 'see', 'evil', 'monkeyse', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow i serious die see evil monkeyse evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3316 :\n",
      "\n",
      "\tTweet's text':  you prettiest face world stretch mark ruin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'prettiest', 'face', 'world', 'stretch', 'mark', 'ruin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you prettiest face world stretch mark ruin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3317 :\n",
      "\n",
      "\tTweet's text':  follow saw post thot might add \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['follow', 'saw', 'post', 'thot', 'might', 'add'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['follow saw post thot might add'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3318 :\n",
      "\n",
      "\tTweet's text':  todd love todd life \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['todd', 'love', 'todd', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['todd love todd life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3319 :\n",
      "\n",
      "\tTweet's text':  twitter keep insist i follow someon who i rather \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['confused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['twitter', 'keep', 'insist', 'i', 'follow', 'someon', 'who', 'i', 'rather'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['twitter keep insist i follow someon who i rather'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3320 :\n",
      "\n",
      "\tTweet's text':  it current fair outsid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'current', 'fair', 'outsid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it current fair outsid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3321 :\n",
      "\n",
      "\tTweet's text':  definit latter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['definit', 'latter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['definit latter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3322 :\n",
      "\n",
      "\tTweet's text':  clever \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['clever'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['clever'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3323 :\n",
      "\n",
      "\tTweet's text':  obama like difi use scorch earth method tcot \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TortureReport', '#tcot'] \n",
      "\n",
      "\tTweet tokenized by words:  ['obama', 'like', 'difi', 'use', 'scorch', 'earth', 'method', 'tcot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['obama like difi use scorch earth method tcot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3324 :\n",
      "\n",
      "\tTweet's text':  here alon you privaci and anyth your fantasi getmetoevc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GetMeToEVC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['here', 'alon', 'you', 'privaci', 'and', 'anyth', 'your', 'fantasi', 'getmetoevc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['here alon you privaci and anyth your fantasi getmetoevc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3325 :\n",
      "\n",
      "\tTweet's text':  close \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['close'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['close'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3326 :\n",
      "\n",
      "\tTweet's text':  ah soul show make sunday morn work bearabl yet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#cold', '#happy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ah', 'soul', 'show', 'make', 'sunday', 'morn', 'work', 'bearabl', 'yet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ah soul show make sunday morn work bearabl yet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3327 :\n",
      "\n",
      "\tTweet's text':  ill see final \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ill', 'see', 'final'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ill see final'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3328 :\n",
      "\n",
      "\tTweet's text':  i go hawaii bye bye friend i back hawaii trip myfamiri girlfriend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Hawaii', '#trip', '#with', '#myfamiry', '#because', '#girlfriend'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'go', 'hawaii', 'bye', 'bye', 'friend', 'i', 'back', 'hawaii', 'trip', 'myfamiri', 'girlfriend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i go hawaii bye bye friend i back hawaii trip myfamiri girlfriend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3329 :\n",
      "\n",
      "\tTweet's text':  comit blacklivesmatt post rt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BlackOnBlackCrime', '#BlackLivesMatter', '#Protest', '#FERGUSON'] \n",
      "\n",
      "\tTweet tokenized by words:  ['comit', 'blacklivesmatt', 'post', 'rt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['comit blacklivesmatt post rt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3330 :\n",
      "\n",
      "\tTweet's text':  best thing think worri obsess just faith everyth work \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sometimes', '#best'] \n",
      "\n",
      "\tTweet tokenized by words:  ['best', 'thing', 'think', 'worri', 'obsess', 'just', 'faith', 'everyth', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['best thing think worri obsess just faith everyth work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3331 :\n",
      "\n",
      "\tTweet's text':  well i clearli wrote last tweet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'i', 'clearli', 'wrote', 'last', 'tweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well i clearli wrote last tweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3332 :\n",
      "\n",
      "\tTweet's text':  okay went court case got adjourn till januari my back play pain wbu x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['weary_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['okay', 'went', 'court', 'case', 'got', 'adjourn', 'till', 'januari', 'my', 'back', 'play', 'pain', 'wbu', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['okay went court case got adjourn till januari my back play pain wbu x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3333 :\n",
      "\n",
      "\tTweet's text':  must b lol x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#blood'] \n",
      "\n",
      "\tTweet tokenized by words:  ['must', 'b', 'lol', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['must b lol x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3334 :\n",
      "\n",
      "\tTweet's text':  not strong show pittsburgh sport weekend thank great season \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#stillafan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['not', 'strong', 'show', 'pittsburgh', 'sport', 'weekend', 'thank', 'great', 'season'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['not strong show pittsburgh sport weekend thank great season'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3335 :\n",
      "\n",
      "\tTweet's text':  hello sunday by the way it s decemb pm random inform \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hello', 'sunday', 'by', 'the', 'way', 'it', 's', 'decemb', 'pm', 'random', 'inform'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hello sunday by the way it s decemb pm random inform'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3336 :\n",
      "\n",
      "\tTweet's text':  watch watch anoth time \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'watch', 'anoth', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch watch anoth time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3337 :\n",
      "\n",
      "\tTweet's text':  cannot wait home gonna miss alot peopl ah roll new year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['thumbs_up_sign', 'thumbs_down_sign'] \n",
      "\n",
      "\tTweet's hashtags':  ['#sligowillbehithardagain'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'not', 'wait', 'home', 'gon', 'na', 'miss', 'alot', 'peopl', 'ah', 'roll', 'new', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cannot wait home gonna miss alot peopl ah roll new year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3338 :\n",
      "\n",
      "\tTweet's text':  flag merri christma much prayer hostag \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ISIS', '#blackHumor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['flag', 'merri', 'christma', 'much', 'prayer', 'hostag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['flag merri christma much prayer hostag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3339 :\n",
      "\n",
      "\tTweet's text':  i go call today commut qualiti time w mini hour minut qualiti time thank dc rush hour \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Optimism'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'go', 'call', 'today', 'commut', 'qualiti', 'time', 'w', 'mini', 'hour', 'minut', 'qualiti', 'time', 'thank', 'dc', 'rush', 'hour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i go call today commut qualiti time w mini hour minut qualiti time thank dc rush hour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3340 :\n",
      "\n",
      "\tTweet's text':  yeh still unclear know \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeh', 'still', 'unclear', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeh still unclear know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3341 :\n",
      "\n",
      "\tTweet's text':  feel ironi use find peopl iron use work ironi wrong \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#metahipster'] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'ironi', 'use', 'find', 'peopl', 'iron', 'use', 'work', 'ironi', 'wrong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel ironi use find peopl iron use work ironi wrong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3342 :\n",
      "\n",
      "\tTweet's text':  is naughti dog go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TGA'] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'naughti', 'dog', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is naughti dog go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3343 :\n",
      "\n",
      "\tTweet's text':  the oh classi also belittl disgust littl video notinmywallet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ALS', '#IceBucketChallenge', '#NotInMyWallet'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'oh', 'classi', 'also', 'belittl', 'disgust', 'littl', 'video', 'notinmywallet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the oh classi also belittl disgust littl video notinmywallet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3344 :\n",
      "\n",
      "\tTweet's text':  cod aw server \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#OFFLINE'] \n",
      "\n",
      "\tTweet tokenized by words:  ['cod', 'aw', 'server'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cod aw server'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3345 :\n",
      "\n",
      "\tTweet's text':  wow tim horton cobourg realli a game today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'tim', 'horton', 'cobourg', 'realli', 'a', 'game', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow tim horton cobourg realli a game today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3346 :\n",
      "\n",
      "\tTweet's text':  haven sleep feel awesom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['haven', 'sleep', 'feel', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haven sleep feel awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3347 :\n",
      "\n",
      "\tTweet's text':  thank plan c two week row get rid exot engram also amaz move \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'plan', 'c', 'two', 'week', 'row', 'get', 'rid', 'exot', 'engram', 'also', 'amaz', 'move'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank plan c two week row get rid exot engram also amaz move'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3348 :\n",
      "\n",
      "\tTweet's text':  it funni fake ass bitch \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#yourAtruefriendtoher'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'funni', 'fake', 'ass', 'bitch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it funni fake ass bitch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3349 :\n",
      "\n",
      "\tTweet's text':  if year would realli argument shouldn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CFBPlayoff', '#ALAvsOre', '#NationalChampionship'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'year', 'would', 'realli', 'argument', 'shouldn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if year would realli argument shouldn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3350 :\n",
      "\n",
      "\tTweet's text':  there shoot old neighborhood famili live pray everyon okay stay safe \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['heavy_black_heart'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'shoot', 'old', 'neighborhood', 'famili', 'live', 'pray', 'everyon', 'okay', 'stay', 'safe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there shoot old neighborhood famili live pray everyon okay stay safe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3351 :\n",
      "\n",
      "\tTweet's text':  it alway nice teacher leav lesson plan \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'alway', 'nice', 'teacher', 'leav', 'lesson', 'plan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it alway nice teacher leav lesson plan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3352 :\n",
      "\n",
      "\tTweet's text':  dont love captcha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dont', 'love', 'captcha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dont love captcha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3353 :\n",
      "\n",
      "\tTweet's text':  yeah hast rose bird beer much better richardson zampa laughlin tait \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'hast', 'rose', 'bird', 'beer', 'much', 'better', 'richardson', 'zampa', 'laughlin', 'tait'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah hast rose bird beer much better richardson zampa laughlin tait'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3354 :\n",
      "\n",
      "\tTweet's text':  amaz one ignor think set free \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['amaz', 'one', 'ignor', 'think', 'set', 'free'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['amaz one ignor think set free'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3355 :\n",
      "\n",
      "\tTweet's text':  quick feet slow motion never stop love knee high arm move still lot \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['quick', 'feet', 'slow', 'motion', 'never', 'stop', 'love', 'knee', 'high', 'arm', 'move', 'still', 'lot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['quick feet slow motion never stop love knee high arm move still lot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3356 :\n",
      "\n",
      "\tTweet's text':  wish i still bed \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['growing_heart', 'pistol', 'disappointed_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#ICouldSleepForeverRightNow'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wish', 'i', 'still', 'bed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wish i still bed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3357 :\n",
      "\n",
      "\tTweet's text':  work cart golfer day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['pistol', 'unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'cart', 'golfer', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work cart golfer day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3358 :\n",
      "\n",
      "\tTweet's text':  yeah i hate \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'i', 'hate'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah i hate'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3359 :\n",
      "\n",
      "\tTweet's text':  favorit love romanc novel \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Love', '#Drama', '#Romance'] \n",
      "\n",
      "\tTweet tokenized by words:  ['favorit', 'love', 'romanc', 'novel'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['favorit love romanc novel'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3360 :\n",
      "\n",
      "\tTweet's text':  absolut love song \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CantStopSinging'] \n",
      "\n",
      "\tTweet tokenized by words:  ['absolut', 'love', 'song'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['absolut love song'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3361 :\n",
      "\n",
      "\tTweet's text':  ye i rememb littl but entir new lineup came is happen \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'i', 'rememb', 'littl', 'but', 'entir', 'new', 'lineup', 'came', 'is', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye i rememb littl but entir new lineup came is happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3362 :\n",
      "\n",
      "\tTweet's text':  yeah cool fuck woke \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'cool', 'fuck', 'woke'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah cool fuck woke'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3363 :\n",
      "\n",
      "\tTweet's text':  nice lazi search googl scholar find free copi openaccess win \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'lazi', 'search', 'googl', 'scholar', 'find', 'free', 'copi', 'openaccess', 'win'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice lazi search googl scholar find free copi openaccess win'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3364 :\n",
      "\n",
      "\tTweet's text':  fed studi gay differ speci add word lesbian studi doubl grant \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fed', 'studi', 'gay', 'differ', 'speci', 'add', 'word', 'lesbian', 'studi', 'doubl', 'grant'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fed studi gay differ speci add word lesbian studi doubl grant'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3365 :\n",
      "\n",
      "\tTweet's text':  well if one thing anoth but hey like new exhaust \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pissed', '#GRRRR'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'if', 'one', 'thing', 'anoth', 'but', 'hey', 'like', 'new', 'exhaust'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well if one thing anoth but hey like new exhaust'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3366 :\n",
      "\n",
      "\tTweet's text':  move \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#elf', '#why'] \n",
      "\n",
      "\tTweet tokenized by words:  ['move'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['move'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3367 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTweet's text':  a math tutori exactli i need right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lol', '#struggle', '#uni'] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'math', 'tutori', 'exactli', 'i', 'need', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a math tutori exactli i need right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3368 :\n",
      "\n",
      "\tTweet's text':  a strang day far everyon seem good moodmayb actual nap still drunk still time grumpi return \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'strang', 'day', 'far', 'everyon', 'seem', 'good', 'moodmayb', 'actual', 'nap', 'still', 'drunk', 'still', 'time', 'grumpi', 'return'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a strang day far everyon seem good moodmayb actual nap still drunk still time grumpi return'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3369 :\n",
      "\n",
      "\tTweet's text':  i small jacket big coat later i back train stn go back town work xma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#joy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'small', 'jacket', 'big', 'coat', 'later', 'i', 'back', 'train', 'stn', 'go', 'back', 'town', 'work', 'xma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i small jacket big coat later i back train stn go back town work xma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3370 :\n",
      "\n",
      "\tTweet's text':  i swear biggest tool wear belt even though wear suspend pick one \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'swear', 'biggest', 'tool', 'wear', 'belt', 'even', 'though', 'wear', 'suspend', 'pick', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i swear biggest tool wear belt even though wear suspend pick one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3371 :\n",
      "\n",
      "\tTweet's text':  that go stand good stead \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#chancellor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'go', 'stand', 'good', 'stead'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that go stand good stead'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3372 :\n",
      "\n",
      "\tTweet's text':  it monday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [\"It's\", 'party_popper'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'monday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it monday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3373 :\n",
      "\n",
      "\tTweet's text':  i hope get ice palac invis car \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SPECTRE'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hope', 'get', 'ice', 'palac', 'invis', 'car'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hope get ice palac invis car'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3374 :\n",
      "\n",
      "\tTweet's text':  yay time \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yay', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yay time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3375 :\n",
      "\n",
      "\tTweet's text':  readi jeb first femal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#POTUS'] \n",
      "\n",
      "\tTweet tokenized by words:  ['readi', 'jeb', 'first', 'femal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['readi jeb first femal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3376 :\n",
      "\n",
      "\tTweet's text':  thi week keep get better better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'week', 'keep', 'get', 'better', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi week keep get better better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3377 :\n",
      "\n",
      "\tTweet's text':  more clean or cleaner never cleaner \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['more', 'clean', 'or', 'cleaner', 'never', 'cleaner'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['more clean or cleaner never cleaner'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3378 :\n",
      "\n",
      "\tTweet's text':  i stop laugh the fact special viral market especi amus \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'stop', 'laugh', 'the', 'fact', 'special', 'viral', 'market', 'especi', 'amus'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i stop laugh the fact special viral market especi amus'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3379 :\n",
      "\n",
      "\tTweet's text':  one week back sudburi i go lake nepahwin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'week', 'back', 'sudburi', 'i', 'go', 'lake', 'nepahwin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one week back sudburi i go lake nepahwin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3380 :\n",
      "\n",
      "\tTweet's text':  gerrymand neither parti give it hard inform voter ferguson \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ferguson'] \n",
      "\n",
      "\tTweet tokenized by words:  ['gerrymand', 'neither', 'parti', 'give', 'it', 'hard', 'inform', 'voter', 'ferguson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gerrymand neither parti give it hard inform voter ferguson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3381 :\n",
      "\n",
      "\tTweet's text':  nice cook face stuck tongu wink eyefac stuck tongu wink eye \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nice', 'cook', 'face', 'stuck', 'tongu', 'wink', 'eyefac', 'stuck', 'tongu', 'wink', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nice cook face stuck tongu wink eyefac stuck tongu wink eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3382 :\n",
      "\n",
      "\tTweet's text':  say no them first way say ye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['say', 'no', 'them', 'first', 'way', 'say', 'ye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['say no them first way say ye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3383 :\n",
      "\n",
      "\tTweet's text':  i realli talk night one talk \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'realli', 'talk', 'night', 'one', 'talk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i realli talk night one talk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3384 :\n",
      "\n",
      "\tTweet's text':  first line correct can say latter one \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['grinning_face_with_smiling_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['first', 'line', 'correct', 'can', 'say', 'latter', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['first line correct can say latter one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3385 :\n",
      "\n",
      "\tTweet's text':  a phone bill love email wake \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['a', 'phone', 'bill', 'love', 'email', 'wake'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['a phone bill love email wake'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3386 :\n",
      "\n",
      "\tTweet's text':  stop subtweet \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['winking_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stop', 'subtweet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stop subtweet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3387 :\n",
      "\n",
      "\tTweet's text':  hmm train encourag motiv chang tonight don know i bother go \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#burnout'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hmm', 'train', 'encourag', 'motiv', 'chang', 'tonight', 'don', 'know', 'i', 'bother', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hmm train encourag motiv chang tonight don know i bother go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3388 :\n",
      "\n",
      "\tTweet's text':  i wish i could make peopl like person \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wish', 'i', 'could', 'make', 'peopl', 'like', 'person'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wish i could make peopl like person'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3389 :\n",
      "\n",
      "\tTweet's text':  gotta go home cook big breakfast \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['fork_and_knife'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'go', 'home', 'cook', 'big', 'breakfast'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta go home cook big breakfast'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3390 :\n",
      "\n",
      "\tTweet's text':  read victoria secret fashion show recap plate french fri front \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['french_fries'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['read', 'victoria', 'secret', 'fashion', 'show', 'recap', 'plate', 'french', 'fri', 'front'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['read victoria secret fashion show recap plate french fri front'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3391 :\n",
      "\n",
      "\tTweet's text':  peopl never chang \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'never', 'chang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl never chang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3392 :\n",
      "\n",
      "\tTweet's text':  ye ara know hahaha speak evil monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'speak-no-evil_monkey'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'ara', 'know', 'hahaha', 'speak', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye ara know hahaha speak evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3393 :\n",
      "\n",
      "\tTweet's text':  lol aye funni fecker and anytim ironsid fanci wee race let know \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'aye', 'funni', 'fecker', 'and', 'anytim', 'ironsid', 'fanci', 'wee', 'race', 'let', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol aye funni fecker and anytim ironsid fanci wee race let know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3394 :\n",
      "\n",
      "\tTweet's text':  admit read via \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Congressmen', '#NDAA', '#Voting'] \n",
      "\n",
      "\tTweet tokenized by words:  ['admit', 'read', 'via'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['admit read via'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3395 :\n",
      "\n",
      "\tTweet's text':  room \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#LoveYouBro'] \n",
      "\n",
      "\tTweet tokenized by words:  ['room'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['room'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3396 :\n",
      "\n",
      "\tTweet's text':  ask mystic mona your question psychic view weekday pdt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BlogTalkRadio'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ask', 'mystic', 'mona', 'your', 'question', 'psychic', 'view', 'weekday', 'pdt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ask mystic mona your question psychic view weekday pdt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3397 :\n",
      "\n",
      "\tTweet's text':  lol bad budwies bad like drink water \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'bad', 'budwies', 'bad', 'like', 'drink', 'water'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol bad budwies bad like drink water'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3398 :\n",
      "\n",
      "\tTweet's text':  peopl school seem amaz \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['peopl', 'school', 'seem', 'amaz'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['peopl school seem amaz'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3399 :\n",
      "\n",
      "\tTweet's text':  continu wonder custom servic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['continu', 'wonder', 'custom', 'servic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['continu wonder custom servic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3400 :\n",
      "\n",
      "\tTweet's text':  sale it steam go buy amaz game v steamsal \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['v|#SteamSale'] \n",
      "\n",
      "\tTweet's hashtags':  ['#ACUnity', '#SteamSale', '#SteamWinterSale'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sale', 'it', 'steam', 'go', 'buy', 'amaz', 'game', 'v', 'steamsal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sale it steam go buy amaz game v steamsal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3401 :\n",
      "\n",
      "\tTweet's text':  produc kind creativ design \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#like15'] \n",
      "\n",
      "\tTweet tokenized by words:  ['produc', 'kind', 'creativ', 'design'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['produc kind creativ design'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3402 :\n",
      "\n",
      "\tTweet's text':  me so yall forc call keep price bh silenc me googl fiber \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ilovebrighthouse'] \n",
      "\n",
      "\tTweet tokenized by words:  ['me', 'so', 'yall', 'forc', 'call', 'keep', 'price', 'bh', 'silenc', 'me', 'googl', 'fiber'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['me so yall forc call keep price bh silenc me googl fiber'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3403 :\n",
      "\n",
      "\tTweet's text':  the moder queue flush everi one planet miller hour \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'moder', 'queue', 'flush', 'everi', 'one', 'planet', 'miller', 'hour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the moder queue flush everi one planet miller hour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3404 :\n",
      "\n",
      "\tTweet's text':  be ignor still top ten thing i love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sarcasmtweet'] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'ignor', 'still', 'top', 'ten', 'thing', 'i', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be ignor still top ten thing i love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3405 :\n",
      "\n",
      "\tTweet's text':  listen tron legaci album clean make feel like clean world \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['listen', 'tron', 'legaci', 'album', 'clean', 'make', 'feel', 'like', 'clean', 'world'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['listen tron legaci album clean make feel like clean world'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3406 :\n",
      "\n",
      "\tTweet's text':  have night misha still need twitter chines movi night \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#unilife', '#nightin'] \n",
      "\n",
      "\tTweet tokenized by words:  ['have', 'night', 'misha', 'still', 'need', 'twitter', 'chines', 'movi', 'night'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['have night misha still need twitter chines movi night'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3407 :\n",
      "\n",
      "\tTweet's text':  weird without christma music but yay happi christma sammi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['father_christmas', 'party_popper', 'face_throwing_a_kiss', 'multiple_musical_notes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['weird', 'without', 'christma', 'music', 'but', 'yay', 'happi', 'christma', 'sammi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['weird without christma music but yay happi christma sammi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3408 :\n",
      "\n",
      "\tTweet's text':  today alreadi shape fabul \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'alreadi', 'shape', 'fabul'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today alreadi shape fabul'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3409 :\n",
      "\n",
      "\tTweet's text':  good crowd independ b \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'crowd', 'independ', 'b'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good crowd independ b'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3410 :\n",
      "\n",
      "\tTweet's text':  whooo god i love my team \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dcRising', '#WizRockets'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whooo', 'god', 'i', 'love', 'my', 'team'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whooo god i love my team'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3411 :\n",
      "\n",
      "\tTweet's text':  i bet i first use one \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'bet', 'i', 'first', 'use', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i bet i first use one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3412 :\n",
      "\n",
      "\tTweet's text':  ooooh econom destruct countri now make world differ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ooooh', 'econom', 'destruct', 'countri', 'now', 'make', 'world', 'differ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ooooh econom destruct countri now make world differ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3413 :\n",
      "\n",
      "\tTweet's text':  everyth you been told about copywrit bs \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['everyth', 'you', 'been', 'told', 'about', 'copywrit', 'bs'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everyth you been told about copywrit bs'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3414 :\n",
      "\n",
      "\tTweet's text':  that aw ben i know exactli dread hug x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'aw', 'ben', 'i', 'know', 'exactli', 'dread', 'hug', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that aw ben i know exactli dread hug x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3415 :\n",
      "\n",
      "\tTweet's text':  the worst part crosswalk memori kid kill nigga like him stop \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'worst', 'part', 'crosswalk', 'memori', 'kid', 'kill', 'nigga', 'like', 'him', 'stop'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the worst part crosswalk memori kid kill nigga like him stop'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3416 :\n",
      "\n",
      "\tTweet's text':  oh great pop ad just i want tri quickli access account info \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'great', 'pop', 'ad', 'just', 'i', 'want', 'tri', 'quickli', 'access', 'account', 'info'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh great pop ad just i want tri quickli access account info'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3417 :\n",
      "\n",
      "\tTweet's text':  migrain throw alway fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['migrain', 'throw', 'alway', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['migrain throw alway fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3418 :\n",
      "\n",
      "\tTweet's text':  you go explain \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'go', 'explain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you go explain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3419 :\n",
      "\n",
      "\tTweet's text':  there surpris \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'surpris'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there surpris'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3420 :\n",
      "\n",
      "\tTweet's text':  khan brook mayweath khan make poor excus avoid big fight \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['khan', 'brook', 'mayweath', 'khan', 'make', 'poor', 'excus', 'avoid', 'big', 'fight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['khan brook mayweath khan make poor excus avoid big fight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3421 :\n",
      "\n",
      "\tTweet's text':  sport rock hard sometim \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sport', 'rock', 'hard', 'sometim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sport rock hard sometim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3422 :\n",
      "\n",
      "\tTweet's text':  surpris sjw tri get call duti ban you make male femal guy men kill women misogyni \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Misogyny'] \n",
      "\n",
      "\tTweet tokenized by words:  ['surpris', 'sjw', 'tri', 'get', 'call', 'duti', 'ban', 'you', 'make', 'male', 'femal', 'guy', 'men', 'kill', 'women', 'misogyni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['surpris sjw tri get call duti ban you make male femal guy men kill women misogyni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3423 :\n",
      "\n",
      "\tTweet's text':  you miss i watch rain castamer rob stark entourag die \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoT'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'miss', 'i', 'watch', 'rain', 'castamer', 'rob', 'stark', 'entourag', 'die'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you miss i watch rain castamer rob stark entourag die'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3424 :\n",
      "\n",
      "\tTweet's text':  slow enough time left \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Christmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['slow', 'enough', 'time', 'left'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['slow enough time left'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3425 :\n",
      "\n",
      "\tTweet's text':  duli note p p p \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['duli', 'note', 'p', 'p', 'p'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['duli note p p p'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3426 :\n",
      "\n",
      "\tTweet's text':  great way start day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['great', 'way', 'start', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['great way start day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3427 :\n",
      "\n",
      "\tTweet's text':  stomach hurt sick sinu infect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['stomach', 'hurt', 'sick', 'sinu', 'infect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stomach hurt sick sinu infect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3428 :\n",
      "\n",
      "\tTweet's text':  the first nsfw look at jessica cameron mania via \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'first', 'nsfw', 'look', 'at', 'jessica', 'cameron', 'mania', 'via'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the first nsfw look at jessica cameron mania via'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3429 :\n",
      "\n",
      "\tTweet's text':  everon support fawad alam d no fawad cricket d v supportfawad usman \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['v|#Supportfawad', 'D|No', 'D'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Supportfawad', '#Usman'] \n",
      "\n",
      "\tTweet tokenized by words:  ['everon', 'support', 'fawad', 'alam', 'd', 'no', 'fawad', 'cricket', 'd', 'v', 'supportfawad', 'usman'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everon support fawad alam d no fawad cricket d v supportfawad usman'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3430 :\n",
      "\n",
      "\tTweet's text':  they seen www monstermmorpg com sinc gist \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#been', '#MonsterMMORPG', '#darumaka'] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'seen', 'www', 'monstermmorpg', 'com', 'sinc', 'gist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they seen www monstermmorpg com sinc gist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3431 :\n",
      "\n",
      "\tTweet's text':  pretti much real deal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thanksmom'] \n",
      "\n",
      "\tTweet tokenized by words:  ['pretti', 'much', 'real', 'deal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pretti much real deal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3432 :\n",
      "\n",
      "\tTweet's text':  glad see someon final realis funni mark lawrenson given work he hoot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#goodgrief'] \n",
      "\n",
      "\tTweet tokenized by words:  ['glad', 'see', 'someon', 'final', 'realis', 'funni', 'mark', 'lawrenson', 'given', 'work', 'he', 'hoot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['glad see someon final realis funni mark lawrenson given work he hoot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3433 :\n",
      "\n",
      "\tTweet's text':  mayb drip death lol \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mayb', 'drip', 'death', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mayb drip death lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3434 :\n",
      "\n",
      "\tTweet's text':  who tf want christma elf tattoo that dumbest shit i ever heard \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sorryimstoned', '#inkmasterfinale', '#inkmasterrivals'] \n",
      "\n",
      "\tTweet tokenized by words:  ['who', 'tf', 'want', 'christma', 'elf', 'tattoo', 'that', 'dumbest', 'shit', 'i', 'ever', 'heard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['who tf want christma elf tattoo that dumbest shit i ever heard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3435 :\n",
      "\n",
      "\tTweet's text':  lol cant see block best thing instal differ browser \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'cant', 'see', 'block', 'best', 'thing', 'instal', 'differ', 'browser'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol cant see block best thing instal differ browser'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3436 :\n",
      "\n",
      "\tTweet's text':  someth rememb i head tonight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#goodboy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['someth', 'rememb', 'i', 'head', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['someth rememb i head tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3437 :\n",
      "\n",
      "\tTweet's text':  look great today dian fair enough dian \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'great', 'today', 'dian', 'fair', 'enough', 'dian'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look great today dian fair enough dian'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3438 :\n",
      "\n",
      "\tTweet's text':  one old fart anoth ever tire get go bed \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#allthetime'] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'old', 'fart', 'anoth', 'ever', 'tire', 'get', 'go', 'bed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one old fart anoth ever tire get go bed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3439 :\n",
      "\n",
      "\tTweet's text':  hate awesom \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hate', 'awesom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hate awesom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3440 :\n",
      "\n",
      "\tTweet's text':  white iow guilti racism fact skin color ferguson taught \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ferguson'] \n",
      "\n",
      "\tTweet tokenized by words:  ['white', 'iow', 'guilti', 'racism', 'fact', 'skin', 'color', 'ferguson', 'taught'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['white iow guilti racism fact skin color ferguson taught'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3441 :\n",
      "\n",
      "\tTweet's text':  guess work best combin wanna see \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bronut', '#mentissues'] \n",
      "\n",
      "\tTweet tokenized by words:  ['guess', 'work', 'best', 'combin', 'wan', 'na', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['guess work best combin wanna see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3442 :\n",
      "\n",
      "\tTweet's text':  tht impox koz late kajwang brother stil aliv kan occupi seat raila \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tht', 'impox', 'koz', 'late', 'kajwang', 'brother', 'stil', 'aliv', 'kan', 'occupi', 'seat', 'raila'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tht impox koz late kajwang brother stil aliv kan occupi seat raila'] \n",
      "\n",
      "---------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet  3443 :\n",
      "\n",
      "\tTweet's text':  ask back model next month \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ask', 'back', 'model', 'next', 'month'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ask back model next month'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3444 :\n",
      "\n",
      "\tTweet's text':  we go hotel vega it theme parti \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'go', 'hotel', 'vega', 'it', 'theme', 'parti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we go hotel vega it theme parti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3445 :\n",
      "\n",
      "\tTweet's text':  rted yeah total make sens \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['rted', 'yeah', 'total', 'make', 'sens'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rted yeah total make sens'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3446 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Sports', '#Carrick', '#replaces', '#Fletcher', '#Man', '#United', '#vice', '#captain'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3447 :\n",
      "\n",
      "\tTweet's text':  accept hour drive mile cheshir manchest yesterday northern powerhous \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['accept', 'hour', 'drive', 'mile', 'cheshir', 'manchest', 'yesterday', 'northern', 'powerhous'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['accept hour drive mile cheshir manchest yesterday northern powerhous'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3448 :\n",
      "\n",
      "\tTweet's text':  core look the second come soon \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#trolls', '#trolls', '#itm', '#noagenda'] \n",
      "\n",
      "\tTweet tokenized by words:  ['core', 'look', 'the', 'second', 'come', 'soon'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['core look the second come soon'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3449 :\n",
      "\n",
      "\tTweet's text':  i wait see mani pair beat headphon show gym christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'wait', 'see', 'mani', 'pair', 'beat', 'headphon', 'show', 'gym', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i wait see mani pair beat headphon show gym christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3450 :\n",
      "\n",
      "\tTweet's text':  oh look anoth storm sydney how unusu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'look', 'anoth', 'storm', 'sydney', 'how', 'unusu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh look anoth storm sydney how unusu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3451 :\n",
      "\n",
      "\tTweet's text':  googl greatest travel hack make flight much easier \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tech', '#business'] \n",
      "\n",
      "\tTweet tokenized by words:  ['googl', 'greatest', 'travel', 'hack', 'make', 'flight', 'much', 'easier'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['googl greatest travel hack make flight much easier'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3452 :\n",
      "\n",
      "\tTweet's text':  let western bastard bank account freez dark \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#seewhatidid', '#readpeople'] \n",
      "\n",
      "\tTweet tokenized by words:  ['let', 'western', 'bastard', 'bank', 'account', 'freez', 'dark'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['let western bastard bank account freez dark'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3453 :\n",
      "\n",
      "\tTweet's text':  maddenthetwiggi so happi i got offer triniti laban i take greenwich leed day leed \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['dancer', 'raised_hand'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['maddenthetwiggi', 'so', 'happi', 'i', 'got', 'offer', 'triniti', 'laban', 'i', 'take', 'greenwich', 'leed', 'day', 'leed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['maddenthetwiggi so happi i got offer triniti laban i take greenwich leed day leed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3454 :\n",
      "\n",
      "\tTweet's text':  amaz follow last week tomorrow grow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['amaz', 'follow', 'last', 'week', 'tomorrow', 'grow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['amaz follow last week tomorrow grow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3455 :\n",
      "\n",
      "\tTweet's text':  jim cooki nikki kill everyon need go enjoy amaz pastri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jim', 'cooki', 'nikki', 'kill', 'everyon', 'need', 'go', 'enjoy', 'amaz', 'pastri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jim cooki nikki kill everyon need go enjoy amaz pastri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3456 :\n",
      "\n",
      "\tTweet's text':  my vision look like let enjoy first winter outsid peep hole \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#growingwinter'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'vision', 'look', 'like', 'let', 'enjoy', 'first', 'winter', 'outsid', 'peep', 'hole'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my vision look like let enjoy first winter outsid peep hole'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3457 :\n",
      "\n",
      "\tTweet's text':  surpris epic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['surpris', 'epic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['surpris epic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3458 :\n",
      "\n",
      "\tTweet's text':  i i i speak i like who i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#speak', '#because', '#want', '#save', '#someone', '#to'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'i', 'i', 'speak', 'i', 'like', 'who', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i i i speak i like who i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3459 :\n",
      "\n",
      "\tTweet's text':  vodka lime lemonad one \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['ok_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['vodka', 'lime', 'lemonad', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['vodka lime lemonad one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3460 :\n",
      "\n",
      "\tTweet's text':  sneez pee \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#jusygirlythings'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sneez', 'pee'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sneez pee'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3461 :\n",
      "\n",
      "\tTweet's text':  i encourag \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'encourag'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i encourag'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3462 :\n",
      "\n",
      "\tTweet's text':  d test first day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['victory_hand'] \n",
      "\n",
      "\tTweet's hashtags':  ['#read', '#book', '#งวย', '#doing', '#home', '#work'] \n",
      "\n",
      "\tTweet tokenized by words:  ['d', 'test', 'first', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['d test first day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3463 :\n",
      "\n",
      "\tTweet's text':  rt jameer nelson start return orlando tonight marcu smart come bench \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Celtics'] \n",
      "\n",
      "\tTweet tokenized by words:  ['rt', 'jameer', 'nelson', 'start', 'return', 'orlando', 'tonight', 'marcu', 'smart', 'come', 'bench'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['rt jameer nelson start return orlando tonight marcu smart come bench'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3464 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TeenAnalCasting', '#What'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3465 :\n",
      "\n",
      "\tTweet's text':  i love hypocrisi holiday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'hypocrisi', 'holiday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love hypocrisi holiday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3466 :\n",
      "\n",
      "\tTweet's text':  anoth day paradis haha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'day', 'paradis', 'haha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth day paradis haha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3467 :\n",
      "\n",
      "\tTweet's text':  whi he draft pick compens tie name six month younger \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'he', 'draft', 'pick', 'compens', 'tie', 'name', 'six', 'month', 'younger'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi he draft pick compens tie name six month younger'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3468 :\n",
      "\n",
      "\tTweet's text':  the dude told money everyth argu son money in public \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'dude', 'told', 'money', 'everyth', 'argu', 'son', 'money', 'in', 'public'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the dude told money everyth argu son money in public'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3469 :\n",
      "\n",
      "\tTweet's text':  someon quit vocal liber time support \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['someon', 'quit', 'vocal', 'liber', 'time', 'support'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['someon quit vocal liber time support'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3470 :\n",
      "\n",
      "\tTweet's text':  tellychakkar vote who underr actor tink jimmi oter got ter fame im \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tink', '#oters'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tellychakkar', 'vote', 'who', 'underr', 'actor', 'tink', 'jimmi', 'oter', 'got', 'ter', 'fame', 'im'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tellychakkar vote who underr actor tink jimmi oter got ter fame im'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3471 :\n",
      "\n",
      "\tTweet's text':  to honest tide high beach got higher night crept \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lagos'] \n",
      "\n",
      "\tTweet tokenized by words:  ['to', 'honest', 'tide', 'high', 'beach', 'got', 'higher', 'night', 'crept'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['to honest tide high beach got higher night crept'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3472 :\n",
      "\n",
      "\tTweet's text':  haha cool i feel i need consid actual racist comment keep good fight \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'cool', 'i', 'feel', 'i', 'need', 'consid', 'actual', 'racist', 'comment', 'keep', 'good', 'fight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha cool i feel i need consid actual racist comment keep good fight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3473 :\n",
      "\n",
      "\tTweet's text':  my favorit new app chicago comedi scene cc radio you check \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Chicago', '#Comedy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'favorit', 'new', 'app', 'chicago', 'comedi', 'scene', 'cc', 'radio', 'you', 'check'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my favorit new app chicago comedi scene cc radio you check'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3474 :\n",
      "\n",
      "\tTweet's text':  elrufai repres mass victori \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#he', '#so'] \n",
      "\n",
      "\tTweet tokenized by words:  ['elrufai', 'repres', 'mass', 'victori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['elrufai repres mass victori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3475 :\n",
      "\n",
      "\tTweet's text':  autoincorrect strike worth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['autoincorrect', 'strike', 'worth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['autoincorrect strike worth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3476 :\n",
      "\n",
      "\tTweet's text':  excel respect interview last week love lack \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#JohnSchneider', '#TomWopat'] \n",
      "\n",
      "\tTweet tokenized by words:  ['excel', 'respect', 'interview', 'last', 'week', 'love', 'lack'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['excel respect interview last week love lack'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3477 :\n",
      "\n",
      "\tTweet's text':  i attitud think hot shit buffet restuar \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lifegoals', '#sideworknazi'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'attitud', 'think', 'hot', 'shit', 'buffet', 'restuar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i attitud think hot shit buffet restuar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3478 :\n",
      "\n",
      "\tTweet's text':  turn paper come back home studi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#perfectday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['turn', 'paper', 'come', 'back', 'home', 'studi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['turn paper come back home studi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3479 :\n",
      "\n",
      "\tTweet's text':  constip eat noth shit three week \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['constip', 'eat', 'noth', 'shit', 'three', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['constip eat noth shit three week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3480 :\n",
      "\n",
      "\tTweet's text':  is it friday heavi sigh nooo it is total wednesday what mess wait day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'it', 'friday', 'heavi', 'sigh', 'nooo', 'it', 'is', 'total', 'wednesday', 'what', 'mess', 'wait', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is it friday heavi sigh nooo it is total wednesday what mess wait day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3481 :\n",
      "\n",
      "\tTweet's text':  affili market blog post way meantim tip expert \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#howitworks', '#marketingnewbie'] \n",
      "\n",
      "\tTweet tokenized by words:  ['affili', 'market', 'blog', 'post', 'way', 'meantim', 'tip', 'expert'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['affili market blog post way meantim tip expert'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3482 :\n",
      "\n",
      "\tTweet's text':  my husband think i crazi i tape tape dispens hehe i handi like \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'husband', 'think', 'i', 'crazi', 'i', 'tape', 'tape', 'dispens', 'hehe', 'i', 'handi', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my husband think i crazi i tape tape dispens hehe i handi like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3483 :\n",
      "\n",
      "\tTweet's text':  it took hour end morosi right nightengal sourc wrong \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'took', 'hour', 'end', 'morosi', 'right', 'nightengal', 'sourc', 'wrong'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it took hour end morosi right nightengal sourc wrong'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3484 :\n",
      "\n",
      "\tTweet's text':  mama korean award show held hong kong headlin american artist \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mama', 'korean', 'award', 'show', 'held', 'hong', 'kong', 'headlin', 'american', 'artist'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mama korean award show held hong kong headlin american artist'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3485 :\n",
      "\n",
      "\tTweet's text':  from diktat brussel ruin life britain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['from', 'diktat', 'brussel', 'ruin', 'life', 'britain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['from diktat brussel ruin life britain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3486 :\n",
      "\n",
      "\tTweet's text':  i good sight sing \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'good', 'sight', 'sing'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i good sight sing'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3487 :\n",
      "\n",
      "\tTweet's text':  dear manila i traffic twin bangkok yahooo sirat express way \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dear', 'manila', 'i', 'traffic', 'twin', 'bangkok', 'yahooo', 'sirat', 'express', 'way'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dear manila i traffic twin bangkok yahooo sirat express way'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3488 :\n",
      "\n",
      "\tTweet's text':  atheist celebr christma \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['atheist', 'celebr', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['atheist celebr christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3489 :\n",
      "\n",
      "\tTweet's text':  i hope i could recov fever today i need start strama \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hope', 'i', 'could', 'recov', 'fever', 'today', 'i', 'need', 'start', 'strama'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hope i could recov fever today i need start strama'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3490 :\n",
      "\n",
      "\tTweet's text':  i feel comfort misinform vocal \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#pleasedontspeak'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'feel', 'comfort', 'misinform', 'vocal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i feel comfort misinform vocal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3491 :\n",
      "\n",
      "\tTweet's text':  fair u get lie i earli colleg bloodi freez \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fair', '#lucky', '#duck'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fair', 'u', 'get', 'lie', 'i', 'earli', 'colleg', 'bloodi', 'freez'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fair u get lie i earli colleg bloodi freez'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3492 :\n",
      "\n",
      "\tTweet's text':  reveal drink \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['reveal', 'drink'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['reveal drink'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3493 :\n",
      "\n",
      "\tTweet's text':  i hungov i end stay \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hungov', 'i', 'end', 'stay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hungov i end stay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3494 :\n",
      "\n",
      "\tTweet's text':  ha yeah opinion like mine mean noth \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ha', 'yeah', 'opinion', 'like', 'mine', 'mean', 'noth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ha yeah opinion like mine mean noth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3495 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ministers', '#criticised', '#over', '#train', '#deals'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3496 :\n",
      "\n",
      "\tTweet's text':  well nice text wake \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'nice', 'text', 'wake'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well nice text wake'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3497 :\n",
      "\n",
      "\tTweet's text':  love advert woman black say sleep week \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#SheNeverLeft'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'advert', 'woman', 'black', 'say', 'sleep', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love advert woman black say sleep week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3498 :\n",
      "\n",
      "\tTweet's text':  spiki popular name spike u s rt babi name sourc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dataviz'] \n",
      "\n",
      "\tTweet tokenized by words:  ['spiki', 'popular', 'name', 'spike', 'u', 's', 'rt', 'babi', 'name', 'sourc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['spiki popular name spike u s rt babi name sourc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3499 :\n",
      "\n",
      "\tTweet's text':  jfk baggag idiot accus of steal shit right outa your luggag shock ummmm so they hire moron put the armi in there \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['jfk', 'baggag', 'idiot', 'accus', 'of', 'steal', 'shit', 'right', 'outa', 'your', 'luggag', 'shock', 'ummmm', 'so', 'they', 'hire', 'moron', 'put', 'the', 'armi', 'in', 'there'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['jfk baggag idiot accus of steal shit right outa your luggag shock ummmm so they hire moron put the armi in there'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3500 :\n",
      "\n",
      "\tTweet's text':  new wii u \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['new', 'wii', 'u'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['new wii u'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3501 :\n",
      "\n",
      "\tTweet's text':  perfect way start morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['perfect', 'way', 'start', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['perfect way start morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3502 :\n",
      "\n",
      "\tTweet's text':  get hit tsa agent think first name bowi \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wifemeup'] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'hit', 'tsa', 'agent', 'think', 'first', 'name', 'bowi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get hit tsa agent think first name bowi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3503 :\n",
      "\n",
      "\tTweet's text':  i hurt i still love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'hurt', 'i', 'still', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i hurt i still love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3504 :\n",
      "\n",
      "\tTweet's text':  on small diet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['on', 'small', 'diet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['on small diet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3505 :\n",
      "\n",
      "\tTweet's text':  we studi hard speak evil monkey \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['woman_with_bunny_ears', 'speak-no-evil_monkey', 'books'] \n",
      "\n",
      "\tTweet's hashtags':  ['#procrastinators'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'studi', 'hard', 'speak', 'evil', 'monkey'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we studi hard speak evil monkey'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3506 :\n",
      "\n",
      "\tTweet's text':  feel bad confus ny cop controversi that one camera brown clear neighbor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Love'] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'bad', 'confus', 'ny', 'cop', 'controversi', 'that', 'one', 'camera', 'brown', 'clear', 'neighbor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel bad confus ny cop controversi that one camera brown clear neighbor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3507 :\n",
      "\n",
      "\tTweet's text':  worst mobil india everi look everi model hang th day onward \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#samsung', '#recommended'] \n",
      "\n",
      "\tTweet tokenized by words:  ['worst', 'mobil', 'india', 'everi', 'look', 'everi', 'model', 'hang', 'th', 'day', 'onward'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['worst mobil india everi look everi model hang th day onward'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3508 :\n",
      "\n",
      "\tTweet's text':  that hour sleep put hyper mode \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'hour', 'sleep', 'put', 'hyper', 'mode'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that hour sleep put hyper mode'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3509 :\n",
      "\n",
      "\tTweet's text':  twirra not place rt twitter place virgin tweet sexual hoe form \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['twirra', 'not', 'place', 'rt', 'twitter', 'place', 'virgin', 'tweet', 'sexual', 'hoe', 'form'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['twirra not place rt twitter place virgin tweet sexual hoe form'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3510 :\n",
      "\n",
      "\tTweet's text':  the grinch stole my saniti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lol', '#fun', '#funny'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'grinch', 'stole', 'my', 'saniti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the grinch stole my saniti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3511 :\n",
      "\n",
      "\tTweet's text':  so despit fact i till studi wake i think day go great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['unamused_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'despit', 'fact', 'i', 'till', 'studi', 'wake', 'i', 'think', 'day', 'go', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so despit fact i till studi wake i think day go great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3512 :\n",
      "\n",
      "\tTweet's text':  i realli happi hear nbc hockey talk head point ovechkin strong corsi statu season \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'realli', 'happi', 'hear', 'nbc', 'hockey', 'talk', 'head', 'point', 'ovechkin', 'strong', 'corsi', 'statu', 'season'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i realli happi hear nbc hockey talk head point ovechkin strong corsi statu season'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3513 :\n",
      "\n",
      "\tTweet's text':  senat summari report detent programm must end stori \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#USA', '#CIA'] \n",
      "\n",
      "\tTweet tokenized by words:  ['senat', 'summari', 'report', 'detent', 'programm', 'must', 'end', 'stori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['senat summari report detent programm must end stori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3514 :\n",
      "\n",
      "\tTweet's text':  yup definit more \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fosho', '#merrycuteness'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yup', 'definit', 'more'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yup definit more'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3515 :\n",
      "\n",
      "\tTweet's text':  thi histori essay liter shit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'histori', 'essay', 'liter', 'shit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi histori essay liter shit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3516 :\n",
      "\n",
      "\tTweet's text':  i love wake dead sleep two firetruck blare past window \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['ambulance', 'fire_engine', 'sleeping_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wake', 'dead', 'sleep', 'two', 'firetruck', 'blare', 'past', 'window'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wake dead sleep two firetruck blare past window'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3517 :\n",
      "\n",
      "\tTweet's text':  i love wide awak \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#insomnia', '#nosleepdecember'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'wide', 'awak'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love wide awak'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3518 :\n",
      "\n",
      "\tTweet's text':  thank appreci look care \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'appreci', 'look', 'care'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank appreci look care'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3519 :\n",
      "\n",
      "\tTweet's text':  ahhh winner and epik high \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#2014MAMA'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ahhh', 'winner', 'and', 'epik', 'high'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ahhh winner and epik high'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3520 :\n",
      "\n",
      "\tTweet's text':  love abl comfort room \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'abl', 'comfort', 'room'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love abl comfort room'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3521 :\n",
      "\n",
      "\tTweet's text':  irrat fan i stand watch game louisvil fan they bad steeler fan \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#UKvsLOU', '#BBN'] \n",
      "\n",
      "\tTweet tokenized by words:  ['irrat', 'fan', 'i', 'stand', 'watch', 'game', 'louisvil', 'fan', 'they', 'bad', 'steeler', 'fan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['irrat fan i stand watch game louisvil fan they bad steeler fan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3522 :\n",
      "\n",
      "\tTweet's text':  thi photo pool via realli brighten \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'photo', 'pool', 'via', 'realli', 'brighten'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi photo pool via realli brighten'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3523 :\n",
      "\n",
      "\tTweet's text':  yea keep bardgin stuff dont even care get hobbi sjw also babymet nice \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yea', 'keep', 'bardgin', 'stuff', 'dont', 'even', 'care', 'get', 'hobbi', 'sjw', 'also', 'babymet', 'nice'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yea keep bardgin stuff dont even care get hobbi sjw also babymet nice'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3524 :\n",
      "\n",
      "\tTweet's text':  can believ ash made funni \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Tolo', '#Never'] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'believ', 'ash', 'made', 'funni'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can believ ash made funni'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3525 :\n",
      "\n",
      "\tTweet's text':  thi like end well more vaccin exactli need health human s \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thi', 'like', 'end', 'well', 'more', 'vaccin', 'exactli', 'need', 'health', 'human', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thi like end well more vaccin exactli need health human s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3526 :\n",
      "\n",
      "\tTweet's text':  i love sleep it best \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'sleep', 'it', 'best'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love sleep it best'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3527 :\n",
      "\n",
      "\tTweet's text':  i cant even watch anim \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'cant', 'even', 'watch', 'anim'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i cant even watch anim'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3528 :\n",
      "\n",
      "\tTweet's text':  final went doctor feel much better \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'went', 'doctor', 'feel', 'much', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final went doctor feel much better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3529 :\n",
      "\n",
      "\tTweet's text':  grind gear worthless thank \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['grind', 'gear', 'worthless', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['grind gear worthless thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3530 :\n",
      "\n",
      "\tTweet's text':  thank u u beauti ppl talk extra loud i tri watch tv i love guy much \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#srslyofALLrooms'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'u', 'u', 'beauti', 'ppl', 'talk', 'extra', 'loud', 'i', 'tri', 'watch', 'tv', 'i', 'love', 'guy', 'much'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank u u beauti ppl talk extra loud i tri watch tv i love guy much'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3531 :\n",
      "\n",
      "\tTweet's text':  you result excus not both \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'result', 'excus', 'not', 'both'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you result excus not both'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3532 :\n",
      "\n",
      "\tTweet's text':  got earli get earlier bu i miss now i \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'earli', 'get', 'earlier', 'bu', 'i', 'miss', 'now', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['got earli get earlier bu i miss now i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3533 :\n",
      "\n",
      "\tTweet's text':  well today great start might well monday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'today', 'great', 'start', 'might', 'well', 'monday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well today great start might well monday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3534 :\n",
      "\n",
      "\tTweet's text':  wow thing go chang never heard opposit pleas vote work well \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'thing', 'go', 'chang', 'never', 'heard', 'opposit', 'pleas', 'vote', 'work', 'well'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow thing go chang never heard opposit pleas vote work well'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3535 :\n",
      "\n",
      "\tTweet's text':  person protect nd amend noth see \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SMFH'] \n",
      "\n",
      "\tTweet tokenized by words:  ['person', 'protect', 'nd', 'amend', 'noth', 'see'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['person protect nd amend noth see'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3536 :\n",
      "\n",
      "\tTweet's text':  just abt say i sure whether oxford brook uni part oxford uni yet cv impress still \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'abt', 'say', 'i', 'sure', 'whether', 'oxford', 'brook', 'uni', 'part', 'oxford', 'uni', 'yet', 'cv', 'impress', 'still'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just abt say i sure whether oxford brook uni part oxford uni yet cv impress still'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3537 :\n",
      "\n",
      "\tTweet's text':  i loooov argu insur compani \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'loooov', 'argu', 'insur', 'compani'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i loooov argu insur compani'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3538 :\n",
      "\n",
      "\tTweet's text':  usa hippa law prohibit psychiatrist releas info \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['usa', 'hippa', 'law', 'prohibit', 'psychiatrist', 'releas', 'info'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['usa hippa law prohibit psychiatrist releas info'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3539 :\n",
      "\n",
      "\tTweet's text':  no finnish work fascist kyiv nice guy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#snipers'] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'finnish', 'work', 'fascist', 'kyiv', 'nice', 'guy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no finnish work fascist kyiv nice guy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3540 :\n",
      "\n",
      "\tTweet's text':  my dorm actual realli creepi i one \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['confounded_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'dorm', 'actual', 'realli', 'creepi', 'i', 'one'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my dorm actual realli creepi i one'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3541 :\n",
      "\n",
      "\tTweet's text':  beauti day climb newzealand \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NewZealand', '#earnaview'] \n",
      "\n",
      "\tTweet tokenized by words:  ['beauti', 'day', 'climb', 'newzealand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['beauti day climb newzealand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3542 :\n",
      "\n",
      "\tTweet's text':  im place word job mean steal \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['im', 'place', 'word', 'job', 'mean', 'steal'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['im place word job mean steal'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3543 :\n",
      "\n",
      "\tTweet's text':  i think tori actual favorit human earth tbh \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'tori', 'actual', 'favorit', 'human', 'earth', 'tbh'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think tori actual favorit human earth tbh'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3544 :\n",
      "\n",
      "\tTweet's text':  brother sister speak way our father in heaven child either \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#yes'] \n",
      "\n",
      "\tTweet tokenized by words:  ['brother', 'sister', 'speak', 'way', 'our', 'father', 'in', 'heaven', 'child', 'either'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['brother sister speak way our father in heaven child either'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3545 :\n",
      "\n",
      "\tTweet's text':  no repli what surpris \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'repli', 'what', 'surpris'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no repli what surpris'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3546 :\n",
      "\n",
      "\tTweet's text':  eleven big gulp health care \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['eleven', 'big', 'gulp', 'health', 'care'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['eleven big gulp health care'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3547 :\n",
      "\n",
      "\tTweet's text':  amen due respect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['amen', 'due', 'respect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['amen due respect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3548 :\n",
      "\n",
      "\tTweet's text':  oh yeah nd d hahaha lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['D'] \n",
      "\n",
      "\tTweet's hashtags':  ['#HoldTheApplause'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'yeah', 'nd', 'd', 'hahaha', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh yeah nd d hahaha lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3549 :\n",
      "\n",
      "\tTweet's text':  final stress free cant wait \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'stress', 'free', 'cant', 'wait'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final stress free cant wait'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3550 :\n",
      "\n",
      "\tTweet's text':  never expect would lie much back first encount \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['never', 'expect', 'would', 'lie', 'much', 'back', 'first', 'encount'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['never expect would lie much back first encount'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3551 :\n",
      "\n",
      "\tTweet's text':  fan freakin tastic can wait \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fan', 'freakin', 'tastic', 'can', 'wait'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fan freakin tastic can wait'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3552 :\n",
      "\n",
      "\tTweet's text':  there point effort come one direct i left chang direct \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'point', 'effort', 'come', 'one', 'direct', 'i', 'left', 'chang', 'direct'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there point effort come one direct i left chang direct'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3553 :\n",
      "\n",
      "\tTweet's text':  absolut great lesson half half today \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#zzzz'] \n",
      "\n",
      "\tTweet tokenized by words:  ['absolut', 'great', 'lesson', 'half', 'half', 'today'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['absolut great lesson half half today'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3554 :\n",
      "\n",
      "\tTweet's text':  grandad watch absolut shit telli no serious it channel i never even heard \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FunChristmas'] \n",
      "\n",
      "\tTweet tokenized by words:  ['grandad', 'watch', 'absolut', 'shit', 'telli', 'no', 'serious', 'it', 'channel', 'i', 'never', 'even', 'heard'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['grandad watch absolut shit telli no serious it channel i never even heard'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3555 :\n",
      "\n",
      "\tTweet's text':  nobodi deni word \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#career', '#gita', '#profound'] \n",
      "\n",
      "\tTweet tokenized by words:  ['nobodi', 'deni', 'word'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nobodi deni word'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3556 :\n",
      "\n",
      "\tTweet's text':  min class n alreadi wana kio \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['min', 'class', 'n', 'alreadi', 'wana', 'kio'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['min class n alreadi wana kio'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3557 :\n",
      "\n",
      "\tTweet's text':  actual i believ henri undef turf \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['actual', 'i', 'believ', 'henri', 'undef', 'turf'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['actual i believ henri undef turf'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3558 :\n",
      "\n",
      "\tTweet's text':  all eat watch movi kick shit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  ['#RelationshipGoalsAccomplished'] \n",
      "\n",
      "\tTweet tokenized by words:  ['all', 'eat', 'watch', 'movi', 'kick', 'shit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['all eat watch movi kick shit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3559 :\n",
      "\n",
      "\tTweet's text':  just case thought blanketi blank job check guy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#2a', '#HappyNewYear'] \n",
      "\n",
      "\tTweet tokenized by words:  ['just', 'case', 'thought', 'blanketi', 'blank', 'job', 'check', 'guy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['just case thought blanketi blank job check guy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3560 :\n",
      "\n",
      "\tTweet's text':  ye also show ignor hate \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ye', 'also', 'show', 'ignor', 'hate'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ye also show ignor hate'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3561 :\n",
      "\n",
      "\tTweet's text':  wow catch news fals intellig found fals see wikileak sourc \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wow', 'catch', 'news', 'fals', 'intellig', 'found', 'fals', 'see', 'wikileak', 'sourc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wow catch news fals intellig found fals see wikileak sourc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3562 :\n",
      "\n",
      "\tTweet's text':  call show train wreck way respect guest guy \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['call', 'show', 'train', 'wreck', 'way', 'respect', 'guest', 'guy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['call show train wreck way respect guest guy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3563 :\n",
      "\n",
      "\tTweet's text':  everyon broken some em good hide so good i want punch face \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['everyon', 'broken', 'some', 'em', 'good', 'hide', 'so', 'good', 'i', 'want', 'punch', 'face'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['everyon broken some em good hide so good i want punch face'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3564 :\n",
      "\n",
      "\tTweet's text':  here final episod \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#minecraft', '#hardcore'] \n",
      "\n",
      "\tTweet tokenized by words:  ['here', 'final', 'episod'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['here final episod'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3565 :\n",
      "\n",
      "\tTweet's text':  i guess i one suppos say \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'i', 'one', 'suppos', 'say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guess i one suppos say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3566 :\n",
      "\n",
      "\tTweet's text':  animailif i think i make aaaawww \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['animailif', 'i', 'think', 'i', 'make', 'aaaawww'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['animailif i think i make aaaawww'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3567 :\n",
      "\n",
      "\tTweet's text':  shameless account firm make vast sum advis rich rip taxpay account chief \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shameless', 'account', 'firm', 'make', 'vast', 'sum', 'advis', 'rich', 'rip', 'taxpay', 'account', 'chief'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shameless account firm make vast sum advis rich rip taxpay account chief'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3568 :\n",
      "\n",
      "\tTweet's text':  accur v sad inde \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['accur', 'v', 'sad', 'inde'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['accur v sad inde'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3569 :\n",
      "\n",
      "\tTweet's text':  true we keep give return \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['money_bag'] \n",
      "\n",
      "\tTweet's hashtags':  ['#charity'] \n",
      "\n",
      "\tTweet tokenized by words:  ['true', 'we', 'keep', 'give', 'return'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['true we keep give return'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3570 :\n",
      "\n",
      "\tTweet's text':  joli hollywood actor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Getting', '#married', '#was', '#biggest', '#moment', '#of', '#the', '#year', '#But', '#this'] \n",
      "\n",
      "\tTweet tokenized by words:  ['joli', 'hollywood', 'actor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['joli hollywood actor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3571 :\n",
      "\n",
      "\tTweet's text':  healthday new fewer half american \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#CDC', '#Enough', '#Patients', '#Getting', '#Flu', '#Shots', '#This', '#Year'] \n",
      "\n",
      "\tTweet tokenized by words:  ['healthday', 'new', 'fewer', 'half', 'american'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['healthday new fewer half american'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3572 :\n",
      "\n",
      "\tTweet's text':  get readi anoth one saturday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'readi', 'anoth', 'one', 'saturday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get readi anoth one saturday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3573 :\n",
      "\n",
      "\tTweet's text':  tnt replay cav knick \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tnt', 'replay', 'cav', 'knick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tnt replay cav knick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3574 :\n",
      "\n",
      "\tTweet's text':  depress sadli part mani peopl testimoni my monster secret \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Depression', '#Abuse', '#DamonLeroi'] \n",
      "\n",
      "\tTweet tokenized by words:  ['depress', 'sadli', 'part', 'mani', 'peopl', 'testimoni', 'my', 'monster', 'secret'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['depress sadli part mani peopl testimoni my monster secret'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3575 :\n",
      "\n",
      "\tTweet's text':  i mean matter game \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'mean', 'matter', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i mean matter game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3576 :\n",
      "\n",
      "\tTweet's text':  work job pm w minut job alreadi plan sleep immedi work tomorrow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'job', 'pm', 'w', 'minut', 'job', 'alreadi', 'plan', 'sleep', 'immedi', 'work', 'tomorrow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work job pm w minut job alreadi plan sleep immedi work tomorrow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3577 :\n",
      "\n",
      "\tTweet's text':  don give want want \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#inspiration', '#motivationalquotes', '#startup'] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'give', 'want', 'want'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don give want want'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3578 :\n",
      "\n",
      "\tTweet's text':  i smarter peopl lie i fun pick hole stori \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'smarter', 'peopl', 'lie', 'i', 'fun', 'pick', 'hole', 'stori'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i smarter peopl lie i fun pick hole stori'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3579 :\n",
      "\n",
      "\tTweet's text':  fart like world end \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fart', 'like', 'world', 'end'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fart like world end'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3580 :\n",
      "\n",
      "\tTweet's text':  lol doc know \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fuckthat'] \n",
      "\n",
      "\tTweet tokenized by words:  ['lol', 'doc', 'know'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lol doc know'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3581 :\n",
      "\n",
      "\tTweet's text':  stuck traffic yuppi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#happytuesday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['stuck', 'traffic', 'yuppi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['stuck traffic yuppi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3582 :\n",
      "\n",
      "\tTweet's text':  be averag get averag result \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'averag', 'get', 'averag', 'result'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be averag get averag result'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3583 :\n",
      "\n",
      "\tTweet's text':  anti union governor inaugur ball credit union center a slap \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Iowa', '#Branstad', '#CommunityChoice', '#AFSCME', '#Homan'] \n",
      "\n",
      "\tTweet tokenized by words:  ['anti', 'union', 'governor', 'inaugur', 'ball', 'credit', 'union', 'center', 'a', 'slap'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anti union governor inaugur ball credit union center a slap'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3584 :\n",
      "\n",
      "\tTweet's text':  i guess get time spend time \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'guess', 'get', 'time', 'spend', 'time'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i guess get time spend time'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3585 :\n",
      "\n",
      "\tTweet's text':  urgent contract assur manag privat bank singapor not specifi singapor s \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#newjob'] \n",
      "\n",
      "\tTweet tokenized by words:  ['urgent', 'contract', 'assur', 'manag', 'privat', 'bank', 'singapor', 'not', 'specifi', 'singapor', 's'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['urgent contract assur manag privat bank singapor not specifi singapor s'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3586 :\n",
      "\n",
      "\tTweet's text':  shout out guy took shower million head the whole bu thank \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['shout', 'out', 'guy', 'took', 'shower', 'million', 'head', 'the', 'whole', 'bu', 'thank'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['shout out guy took shower million head the whole bu thank'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3587 :\n",
      "\n",
      "\tTweet's text':  it christma one day i get year i even sign xbox one typic \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Typical'] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'christma', 'one', 'day', 'i', 'get', 'year', 'i', 'even', 'sign', 'xbox', 'one', 'typic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it christma one day i get year i even sign xbox one typic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3588 :\n",
      "\n",
      "\tTweet's text':  two peopl got sock clutch af \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['two', 'peopl', 'got', 'sock', 'clutch', 'af'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['two peopl got sock clutch af'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3589 :\n",
      "\n",
      "\tTweet's text':  i think that made confus i daze \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'that', 'made', 'confus', 'i', 'daze'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think that made confus i daze'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3590 :\n",
      "\n",
      "\tTweet's text':  good yeah good feel tire self bed soon x \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['sleeping_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'yeah', 'good', 'feel', 'tire', 'self', 'bed', 'soon', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good yeah good feel tire self bed soon x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3591 :\n",
      "\n",
      "\tTweet's text':  happen everi day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['happen', 'everi', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happen everi day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3592 :\n",
      "\n",
      "\tTweet's text':  ugli christma sweater \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#uglychristmassweaters', '#happyholidays', '#merrychristmas', '#kissesandhugs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['ugli', 'christma', 'sweater'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ugli christma sweater'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3593 :\n",
      "\n",
      "\tTweet's text':  twitter annoy \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['twitter', 'annoy'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['twitter annoy'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3594 :\n",
      "\n",
      "\tTweet's text':  be awak sinc am alway much fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['be', 'awak', 'sinc', 'am', 'alway', 'much', 'fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['be awak sinc am alway much fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3595 :\n",
      "\n",
      "\tTweet's text':  you kid right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#poortaste'] \n",
      "\n",
      "\tTweet tokenized by words:  ['you', 'kid', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['you kid right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3596 :\n",
      "\n",
      "\tTweet's text':  i procrastin get work done b c i read new book \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'procrastin', 'get', 'work', 'done', 'b', 'c', 'i', 'read', 'new', 'book'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i procrastin get work done b c i read new book'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3597 :\n",
      "\n",
      "\tTweet's text':  they decid chang king trunk gold logo green tight blue how creativ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['they', 'decid', 'chang', 'king', 'trunk', 'gold', 'logo', 'green', 'tight', 'blue', 'how', 'creativ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['they decid chang king trunk gold logo green tight blue how creativ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3598 :\n",
      "\n",
      "\tTweet's text':  i watch like rest ador girl ditsi hahahaha \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TakeMeOut', '#zzzz'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'watch', 'like', 'rest', 'ador', 'girl', 'ditsi', 'hahahaha'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i watch like rest ador girl ditsi hahahaha'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3599 :\n",
      "\n",
      "\tTweet's text':  presum evid back claim simpli feel base interact \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['presum', 'evid', 'back', 'claim', 'simpli', 'feel', 'base', 'interact'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['presum evid back claim simpli feel base interact'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3600 :\n",
      "\n",
      "\tTweet's text':  fals slaveri base econom \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fals', 'slaveri', 'base', 'econom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fals slaveri base econom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3601 :\n",
      "\n",
      "\tTweet's text':  follow friday everyday help new one feel good twitter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['follow', 'friday', 'everyday', 'help', 'new', 'one', 'feel', 'good', 'twitter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['follow friday everyday help new one feel good twitter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3602 :\n",
      "\n",
      "\tTweet's text':  do use instagram well get free follow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['do', 'use', 'instagram', 'well', 'get', 'free', 'follow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['do use instagram well get free follow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3603 :\n",
      "\n",
      "\tTweet's text':  easiest final life so glad i studi hour \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['easiest', 'final', 'life', 'so', 'glad', 'i', 'studi', 'hour'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['easiest final life so glad i studi hour'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3604 :\n",
      "\n",
      "\tTweet's text':  as lamar entertain put money i make right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#tbt'] \n",
      "\n",
      "\tTweet tokenized by words:  ['as', 'lamar', 'entertain', 'put', 'money', 'i', 'make', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['as lamar entertain put money i make right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3605 :\n",
      "\n",
      "\tTweet's text':  in last movi i seen alan arkin argo grudgematch absolut roll \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'last', 'movi', 'i', 'seen', 'alan', 'arkin', 'argo', 'grudgematch', 'absolut', 'roll'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in last movi i seen alan arkin argo grudgematch absolut roll'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3606 :\n",
      "\n",
      "\tTweet's text':  work birthday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#yay', '#sucks'] \n",
      "\n",
      "\tTweet tokenized by words:  ['work', 'birthday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['work birthday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3607 :\n",
      "\n",
      "\tTweet's text':  wanna mine im pussi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wan', 'na', 'mine', 'im', 'pussi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wanna mine im pussi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3608 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Oil', '#plunges', '#percent', '#new', '#five', '#year', '#lows', '#after', '#bearish', '#IEA', '#outlook'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3609 :\n",
      "\n",
      "\tTweet's text':  love much taylor \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['sparkles', 'person_bowing_deeply'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'much', 'taylor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love much taylor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3610 :\n",
      "\n",
      "\tTweet's text':  first final day done three go \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#greatscheduling', '#incaseyoucanttell'] \n",
      "\n",
      "\tTweet tokenized by words:  ['first', 'final', 'day', 'done', 'three', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['first final day done three go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3611 :\n",
      "\n",
      "\tTweet's text':  band play two ticket paradis park lot redskin game \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Redskins'] \n",
      "\n",
      "\tTweet tokenized by words:  ['band', 'play', 'two', 'ticket', 'paradis', 'park', 'lot', 'redskin', 'game'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['band play two ticket paradis park lot redskin game'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3612 :\n",
      "\n",
      "\tTweet's text':  confer call love \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#love'] \n",
      "\n",
      "\tTweet tokenized by words:  ['confer', 'call', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['confer call love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3613 :\n",
      "\n",
      "\tTweet's text':  watch cradl leg i saw episod chicken \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bones', '#tasteslikechicken', '#termite', '#TheWalkingDead'] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'cradl', 'leg', 'i', 'saw', 'episod', 'chicken'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch cradl leg i saw episod chicken'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3614 :\n",
      "\n",
      "\tTweet's text':  today i stand front tesco wear elf hat say hello custom get ignor \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dreamjob'] \n",
      "\n",
      "\tTweet tokenized by words:  ['today', 'i', 'stand', 'front', 'tesco', 'wear', 'elf', 'hat', 'say', 'hello', 'custom', 'get', 'ignor'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['today i stand front tesco wear elf hat say hello custom get ignor'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3615 :\n",
      "\n",
      "\tTweet's text':  big ur post when cunt run photo check da \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#its', '#a', '#struggle', '#its', '#a', '#problem'] \n",
      "\n",
      "\tTweet tokenized by words:  ['big', 'ur', 'post', 'when', 'cunt', 'run', 'photo', 'check', 'da'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['big ur post when cunt run photo check da'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3616 :\n",
      "\n",
      "\tTweet's text':  love call work morn even hour sleep \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thanks', '#splitshift'] \n",
      "\n",
      "\tTweet tokenized by words:  ['love', 'call', 'work', 'morn', 'even', 'hour', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['love call work morn even hour sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3617 :\n",
      "\n",
      "\tTweet's text':  second major noseble day halt train effort nare mean war \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['second', 'major', 'noseble', 'day', 'halt', 'train', 'effort', 'nare', 'mean', 'war'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['second major noseble day halt train effort nare mean war'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3618 :\n",
      "\n",
      "\tTweet's text':  well wors better stark rave \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'wors', 'better', 'stark', 'rave'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well wors better stark rave'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3619 :\n",
      "\n",
      "\tTweet's text':  predict erv santana disinterest play twin aka offer enough \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['predict', 'erv', 'santana', 'disinterest', 'play', 'twin', 'aka', 'offer', 'enough'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['predict erv santana disinterest play twin aka offer enough'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3620 :\n",
      "\n",
      "\tTweet's text':  smile face open mouth tightli close eyessmil face open mouth tightli close eye he would get floor one poke see evil monkeywhit smile face \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['see-no-evil_monkey', 'white_smiling_face', 'ok_hand_sign', 'smiling_face_with_open_mouth_and_tightly-closed_eyes'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['smile', 'face', 'open', 'mouth', 'tightli', 'close', 'eyessmil', 'face', 'open', 'mouth', 'tightli', 'close', 'eye', 'he', 'would', 'get', 'floor', 'one', 'poke', 'see', 'evil', 'monkeywhit', 'smile', 'face'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['smile face open mouth tightli close eyessmil face open mouth tightli close eye he would get floor one poke see evil monkeywhit smile face'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3621 :\n",
      "\n",
      "\tTweet's text':  get friendzon someon tri \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'friendzon', 'someon', 'tri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get friendzon someon tri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3622 :\n",
      "\n",
      "\tTweet's text':  the music alway offic current listen kid bop hanukkah spotifi ani recommend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#onlyatnycr'] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'music', 'alway', 'offic', 'current', 'listen', 'kid', 'bop', 'hanukkah', 'spotifi', 'ani', 'recommend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the music alway offic current listen kid bop hanukkah spotifi ani recommend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3623 :\n",
      "\n",
      "\tTweet's text':  yo i got ten squad member khajo chri said tear you gang kevin respond thuglif \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thuglife'] \n",
      "\n",
      "\tTweet tokenized by words:  ['yo', 'i', 'got', 'ten', 'squad', 'member', 'khajo', 'chri', 'said', 'tear', 'you', 'gang', 'kevin', 'respond', 'thuglif'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yo i got ten squad member khajo chri said tear you gang kevin respond thuglif'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3624 :\n",
      "\n",
      "\tTweet's text':  part articl uexpect \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['part', 'articl', 'uexpect'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['part articl uexpect'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3625 :\n",
      "\n",
      "\tTweet's text':  know hand dont shoot thing proven fals right \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['know', 'hand', 'dont', 'shoot', 'thing', 'proven', 'fals', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['know hand dont shoot thing proven fals right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3626 :\n",
      "\n",
      "\tTweet's text':  dear address come no matter name if mistak fix \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#USPS', '#ThanksForTheAnnoyingNote'] \n",
      "\n",
      "\tTweet tokenized by words:  ['dear', 'address', 'come', 'no', 'matter', 'name', 'if', 'mistak', 'fix'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dear address come no matter name if mistak fix'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3627 :\n",
      "\n",
      "\tTweet's text':  i check twitter snapchat i tell day someon pleas help face stuck tongu wink eye \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_stuck-out_tongue_and_winking_eye'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'check', 'twitter', 'snapchat', 'i', 'tell', 'day', 'someon', 'pleas', 'help', 'face', 'stuck', 'tongu', 'wink', 'eye'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i check twitter snapchat i tell day someon pleas help face stuck tongu wink eye'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3628 :\n",
      "\n",
      "\tTweet's text':  all hell break \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['all', 'hell', 'break'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['all hell break'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3629 :\n",
      "\n",
      "\tTweet's text':  gavaskar freakin geniu \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gavaskar', 'freakin', 'geniu'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gavaskar freakin geniu'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3630 :\n",
      "\n",
      "\tTweet's text':  if i possess half balanc legola \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'i', 'possess', 'half', 'balanc', 'legola'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if i possess half balanc legola'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3631 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3632 :\n",
      "\n",
      "\tTweet's text':  my grandpa gave credit card \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'grandpa', 'gave', 'credit', 'card'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my grandpa gave credit card'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3633 :\n",
      "\n",
      "\tTweet's text':  roman mytholog get soooo pump \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['roman', 'mytholog', 'get', 'soooo', 'pump'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['roman mytholog get soooo pump'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3634 :\n",
      "\n",
      "\tTweet's text':  total kill assign late \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#socollege'] \n",
      "\n",
      "\tTweet tokenized by words:  ['total', 'kill', 'assign', 'late'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['total kill assign late'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3635 :\n",
      "\n",
      "\tTweet's text':  whi i stay sleep \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'i', 'stay', 'sleep'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi i stay sleep'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3636 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Ebola', '#Racism', '#RacePimps', '#JesseJackson', '#Doctors', '#Tcot', '#pjnet', '#CCot', '#Pjtv', '#Tea'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3637 :\n",
      "\n",
      "\tTweet's text':  kind frustrat christma break first real oblig free break \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['kind', 'frustrat', 'christma', 'break', 'first', 'real', 'oblig', 'free', 'break'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['kind frustrat christma break first real oblig free break'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3638 :\n",
      "\n",
      "\tTweet's text':  lool guy multipl twitter handl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lool', 'guy', 'multipl', 'twitter', 'handl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lool guy multipl twitter handl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3639 :\n",
      "\n",
      "\tTweet's text':  y x \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['y', 'x'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['y x'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3640 :\n",
      "\n",
      "\tTweet's text':  realli sure i want place today stop drag day \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#SoMuchBadNegativity', '#SmileYouFuckTards'] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'sure', 'i', 'want', 'place', 'today', 'stop', 'drag', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli sure i want place today stop drag day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3641 :\n",
      "\n",
      "\tTweet's text':  thank aidyn adel get sick \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'aidyn', 'adel', 'get', 'sick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank aidyn adel get sick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3642 :\n",
      "\n",
      "\tTweet's text':  lid suck offici will use good \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['lid', 'suck', 'offici', 'will', 'use', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['lid suck offici will use good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3643 :\n",
      "\n",
      "\tTweet's text':  thx catch \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#urock'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thx', 'catch'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thx catch'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3644 :\n",
      "\n",
      "\tTweet's text':  cocktail tonight yep one year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['cocktail', 'tonight', 'yep', 'one', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cocktail tonight yep one year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3645 :\n",
      "\n",
      "\tTweet's text':  nxt gone ski \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nxt', 'gone', 'ski'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nxt gone ski'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3646 :\n",
      "\n",
      "\tTweet's text':  divid one anoth good \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Already'] \n",
      "\n",
      "\tTweet tokenized by words:  ['divid', 'one', 'anoth', 'good'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['divid one anoth good'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3647 :\n",
      "\n",
      "\tTweet's text':  archiv pick who make you laugh when they off sick \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#mehblog', '#littlemeh', '#doctor'] \n",
      "\n",
      "\tTweet tokenized by words:  ['archiv', 'pick', 'who', 'make', 'you', 'laugh', 'when', 'they', 'off', 'sick'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['archiv pick who make you laugh when they off sick'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3648 :\n",
      "\n",
      "\tTweet's text':  there much less controversi bc replac \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'much', 'less', 'controversi', 'bc', 'replac'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there much less controversi bc replac'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3649 :\n",
      "\n",
      "\tTweet's text':  can believ nearli month sinc mum pass away miss much everyday \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['two_hearts', 'purple_heart', 'grimacing_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'believ', 'nearli', 'month', 'sinc', 'mum', 'pass', 'away', 'miss', 'much', 'everyday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['can believ nearli month sinc mum pass away miss much everyday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3650 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Foreplay', '#cuddling', '#Jedi', '#craves', '#things', '#Yoda', '#Quotes'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3651 :\n",
      "\n",
      "\tTweet's text':  saic design director trend advic student \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['saic', 'design', 'director', 'trend', 'advic', 'student'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['saic design director trend advic student'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3652 :\n",
      "\n",
      "\tTweet's text':  oh bradford aw \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'bradford', 'aw'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh bradford aw'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3653 :\n",
      "\n",
      "\tTweet's text':  maaaaan stupid instagram i went follow cat mom tom myspac \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#smh', '#butstill'] \n",
      "\n",
      "\tTweet tokenized by words:  ['maaaaan', 'stupid', 'instagram', 'i', 'went', 'follow', 'cat', 'mom', 'tom', 'myspac'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['maaaaan stupid instagram i went follow cat mom tom myspac'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3654 :\n",
      "\n",
      "\tTweet's text':  i love button pusher \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'button', 'pusher'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love button pusher'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3655 :\n",
      "\n",
      "\tTweet's text':  normal relat cuba huh get readi crap \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ThanksObama', '#bad'] \n",
      "\n",
      "\tTweet tokenized by words:  ['normal', 'relat', 'cuba', 'huh', 'get', 'readi', 'crap'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['normal relat cuba huh get readi crap'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3656 :\n",
      "\n",
      "\tTweet's text':  instead play pompou know i card actual make educ rebutt \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['instead', 'play', 'pompou', 'know', 'i', 'card', 'actual', 'make', 'educ', 'rebutt'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['instead play pompou know i card actual make educ rebutt'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3657 :\n",
      "\n",
      "\tTweet's text':  i consider issu n care i but i take posit back i give damn wht u think \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'consider', 'issu', 'n', 'care', 'i', 'but', 'i', 'take', 'posit', 'back', 'i', 'give', 'damn', 'wht', 'u', 'think'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i consider issu n care i but i take posit back i give damn wht u think'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3658 :\n",
      "\n",
      "\tTweet's text':  gotta love latest featur vnx side \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#EMC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['got', 'ta', 'love', 'latest', 'featur', 'vnx', 'side'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gotta love latest featur vnx side'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3659 :\n",
      "\n",
      "\tTweet's text':  bf sp shit mp broken month \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bf', 'sp', 'shit', 'mp', 'broken', 'month'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bf sp shit mp broken month'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3660 :\n",
      "\n",
      "\tTweet's text':  juugin everyth nigga got warrant pay \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['juugin', 'everyth', 'nigga', 'got', 'warrant', 'pay'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['juugin everyth nigga got warrant pay'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3661 :\n",
      "\n",
      "\tTweet's text':  name \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#basura', '#immondizia'] \n",
      "\n",
      "\tTweet tokenized by words:  ['name'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['name'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3662 :\n",
      "\n",
      "\tTweet's text':  take physic challeng \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['take', 'physic', 'challeng'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['take physic challeng'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3663 :\n",
      "\n",
      "\tTweet's text':  get sick time final great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['get', 'sick', 'time', 'final', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['get sick time final great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3664 :\n",
      "\n",
      "\tTweet's text':  look trash you clearli see handl he stole name pictur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['look', 'trash', 'you', 'clearli', 'see', 'handl', 'he', 'stole', 'name', 'pictur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['look trash you clearli see handl he stole name pictur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3665 :\n",
      "\n",
      "\tTweet's text':  find quit funni gillett soccer saturday ski complain enough game pm saturday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['find', 'quit', 'funni', 'gillett', 'soccer', 'saturday', 'ski', 'complain', 'enough', 'game', 'pm', 'saturday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['find quit funni gillett soccer saturday ski complain enough game pm saturday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3666 :\n",
      "\n",
      "\tTweet's text':  when teacher say come tomorrow morn help never classroom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wow', '#thanksforthehelp'] \n",
      "\n",
      "\tTweet tokenized by words:  ['when', 'teacher', 'say', 'come', 'tomorrow', 'morn', 'help', 'never', 'classroom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['when teacher say come tomorrow morn help never classroom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3667 :\n",
      "\n",
      "\tTweet's text':  the chicago firehous restaur caught fire morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'chicago', 'firehous', 'restaur', 'caught', 'fire', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the chicago firehous restaur caught fire morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3668 :\n",
      "\n",
      "\tTweet's text':  wtf go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['wtf', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wtf go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3669 :\n",
      "\n",
      "\tTweet's text':  we cram minut exam get tag qualifi person \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'cram', 'minut', 'exam', 'get', 'tag', 'qualifi', 'person'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we cram minut exam get tag qualifi person'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3670 :\n",
      "\n",
      "\tTweet's text':  watch creepi shit bed alon bad idea is spell turn french bulldog big ass bulldog \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bewareofdog'] \n",
      "\n",
      "\tTweet tokenized by words:  ['watch', 'creepi', 'shit', 'bed', 'alon', 'bad', 'idea', 'is', 'spell', 'turn', 'french', 'bulldog', 'big', 'ass', 'bulldog'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['watch creepi shit bed alon bad idea is spell turn french bulldog big ass bulldog'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3671 :\n",
      "\n",
      "\tTweet's text':  xma blog feat intimissimioffici read stori share love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['xma', 'blog', 'feat', 'intimissimioffici', 'read', 'stori', 'share', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['xma blog feat intimissimioffici read stori share love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3672 :\n",
      "\n",
      "\tTweet's text':  tomorrow great \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['tomorrow', 'great'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tomorrow great'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3673 :\n",
      "\n",
      "\tTweet's text':  cannot wait go dentist later \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['can', 'not', 'wait', 'go', 'dentist', 'later'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['cannot wait go dentist later'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3674 :\n",
      "\n",
      "\tTweet's text':  life never easi seem till u come bring u r love insid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['life', 'never', 'easi', 'seem', 'till', 'u', 'come', 'bring', 'u', 'r', 'love', 'insid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['life never easi seem till u come bring u r love insid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3675 :\n",
      "\n",
      "\tTweet's text':  w font shirt comic san \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ICantBreathe'] \n",
      "\n",
      "\tTweet tokenized by words:  ['w', 'font', 'shirt', 'comic', 'san'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['w font shirt comic san'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3676 :\n",
      "\n",
      "\tTweet's text':  and revel african american commun faith law enforc skyrocket \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'revel', 'african', 'american', 'commun', 'faith', 'law', 'enforc', 'skyrocket'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and revel african american commun faith law enforc skyrocket'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3677 :\n",
      "\n",
      "\tTweet's text':  dont love peopl messag nowher act like guy close cu want someth \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dont', 'love', 'peopl', 'messag', 'nowher', 'act', 'like', 'guy', 'close', 'cu', 'want', 'someth'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dont love peopl messag nowher act like guy close cu want someth'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3678 :\n",
      "\n",
      "\tTweet's text':  miss skateboard even winter yet hoof life \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pensive_face', 'confounded_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#skateeverydamnday'] \n",
      "\n",
      "\tTweet tokenized by words:  ['miss', 'skateboard', 'even', 'winter', 'yet', 'hoof', 'life'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['miss skateboard even winter yet hoof life'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3679 :\n",
      "\n",
      "\tTweet's text':  that moment go bathroom clean ladi stillholdingit \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#StillHoldingIt'] \n",
      "\n",
      "\tTweet tokenized by words:  ['that', 'moment', 'go', 'bathroom', 'clean', 'ladi', 'stillholdingit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['that moment go bathroom clean ladi stillholdingit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3680 :\n",
      "\n",
      "\tTweet's text':  nit pick everi littl thing guy keep that show team behind \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nit', 'pick', 'everi', 'littl', 'thing', 'guy', 'keep', 'that', 'show', 'team', 'behind'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nit pick everi littl thing guy keep that show team behind'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3681 :\n",
      "\n",
      "\tTweet's text':  beauti way start morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['persevering_face', 'face_with_medical_mask'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['beauti', 'way', 'start', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['beauti way start morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3682 :\n",
      "\n",
      "\tTweet's text':  the person wrote clearli bit tit \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'person', 'wrote', 'clearli', 'bit', 'tit'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the person wrote clearli bit tit'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3683 :\n",
      "\n",
      "\tTweet's text':  there noth i love listen black eye pea way home saturday night loss petrolia \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#killerband'] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'noth', 'i', 'love', 'listen', 'black', 'eye', 'pea', 'way', 'home', 'saturday', 'night', 'loss', 'petrolia'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there noth i love listen black eye pea way home saturday night loss petrolia'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3684 :\n",
      "\n",
      "\tTweet's text':  upgrad seat kinda scare \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#sundayfunday', '#sundaydateday', '#mylove'] \n",
      "\n",
      "\tTweet tokenized by words:  ['upgrad', 'seat', 'kinda', 'scare'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['upgrad seat kinda scare'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3685 :\n",
      "\n",
      "\tTweet's text':  i feel love \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#im', '#ok'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'feel', 'love'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i feel love'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3686 :\n",
      "\n",
      "\tTweet's text':  myself walk civic offic get bu mutter think pay water \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['myself', 'walk', 'civic', 'offic', 'get', 'bu', 'mutter', 'think', 'pay', 'water'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['myself walk civic offic get bu mutter think pay water'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3687 :\n",
      "\n",
      "\tTweet's text':  becaus stand board dental hygien two hour i want spend birthday \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['becaus', 'stand', 'board', 'dental', 'hygien', 'two', 'hour', 'i', 'want', 'spend', 'birthday'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['becaus stand board dental hygien two hour i want spend birthday'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3688 :\n",
      "\n",
      "\tTweet's text':  like visit puppi per visit puppi maximum \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ATL'] \n",
      "\n",
      "\tTweet tokenized by words:  ['like', 'visit', 'puppi', 'per', 'visit', 'puppi', 'maximum'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['like visit puppi per visit puppi maximum'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3689 :\n",
      "\n",
      "\tTweet's text':  dont fish mammal noth common \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dont', 'fish', 'mammal', 'noth', 'common'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dont fish mammal noth common'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3690 :\n",
      "\n",
      "\tTweet's text':  bore check newest articl word link ridicul websit tri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bore', 'check', 'newest', 'articl', 'word', 'link', 'ridicul', 'websit', 'tri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bore check newest articl word link ridicul websit tri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3691 :\n",
      "\n",
      "\tTweet's text':  nichola spark manipul women believ guy realiti sensit male charact book \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nichola', 'spark', 'manipul', 'women', 'believ', 'guy', 'realiti', 'sensit', 'male', 'charact', 'book'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nichola spark manipul women believ guy realiti sensit male charact book'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3692 :\n",
      "\n",
      "\tTweet's text':  i readi first headlin tour north america ticket info \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lunatic2015'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'readi', 'first', 'headlin', 'tour', 'north', 'america', 'ticket', 'info'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i readi first headlin tour north america ticket info'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3693 :\n",
      "\n",
      "\tTweet's text':  we cross bear lol \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'cross', 'bear', 'lol'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we cross bear lol'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3694 :\n",
      "\n",
      "\tTweet's text':  i may need reread book ever find draco boggart \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#HarryPotter', '#dracomalfoy'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'may', 'need', 'reread', 'book', 'ever', 'find', 'draco', 'boggart'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i may need reread book ever find draco boggart'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3695 :\n",
      "\n",
      "\tTweet's text':  how far would go \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#safety', '#onlinedating', '#relationships'] \n",
      "\n",
      "\tTweet tokenized by words:  ['how', 'far', 'would', 'go'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['how far would go'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3696 :\n",
      "\n",
      "\tTweet's text':  incred rt the red sox agreement justin masterson \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['incred', 'rt', 'the', 'red', 'sox', 'agreement', 'justin', 'masterson'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['incred rt the red sox agreement justin masterson'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3697 :\n",
      "\n",
      "\tTweet's text':  no verbal submiss \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['no', 'verbal', 'submiss'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['no verbal submiss'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3698 :\n",
      "\n",
      "\tTweet's text':  final week plu hear grandma icu amaz \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#letmegohome'] \n",
      "\n",
      "\tTweet tokenized by words:  ['final', 'week', 'plu', 'hear', 'grandma', 'icu', 'amaz'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['final week plu hear grandma icu amaz'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3699 :\n",
      "\n",
      "\tTweet's text':  well said i one fed women breastfeed ostentati \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'said', 'i', 'one', 'fed', 'women', 'breastfeed', 'ostentati'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well said i one fed women breastfeed ostentati'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3700 :\n",
      "\n",
      "\tTweet's text':  like maldiv \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#seaandwhitesands'] \n",
      "\n",
      "\tTweet tokenized by words:  ['like', 'maldiv'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['like maldiv'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3701 :\n",
      "\n",
      "\tTweet's text':  good choic stay late ly \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#study', '#finalsweek', '#deathofme'] \n",
      "\n",
      "\tTweet tokenized by words:  ['good', 'choic', 'stay', 'late', 'ly'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['good choic stay late ly'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3702 :\n",
      "\n",
      "\tTweet's text':  i agre you see video photo taken two hour shoot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'agre', 'you', 'see', 'video', 'photo', 'taken', 'two', 'hour', 'shoot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i agre you see video photo taken two hour shoot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3703 :\n",
      "\n",
      "\tTweet's text':  i boyfriend hair flip walk away \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'boyfriend', 'hair', 'flip', 'walk', 'away'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i boyfriend hair flip walk away'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3704 :\n",
      "\n",
      "\tTweet's text':  i love half group realli commit half give crap \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#perfection'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'half', 'group', 'realli', 'commit', 'half', 'give', 'crap'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love half group realli commit half give crap'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3705 :\n",
      "\n",
      "\tTweet's text':  link somewher quit put finger \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['link', 'somewher', 'quit', 'put', 'finger'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['link somewher quit put finger'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3706 :\n",
      "\n",
      "\tTweet's text':  bodi languag confid easiest thing make differ \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['bodi', 'languag', 'confid', 'easiest', 'thing', 'make', 'differ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bodi languag confid easiest thing make differ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3707 :\n",
      "\n",
      "\tTweet's text':  loughton and basildon u \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['loughton', 'and', 'basildon', 'u'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['loughton and basildon u'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3708 :\n",
      "\n",
      "\tTweet's text':  ohhh i know that sound sooooo interest \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ohhh', 'i', 'know', 'that', 'sound', 'sooooo', 'interest'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ohhh i know that sound sooooo interest'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3709 :\n",
      "\n",
      "\tTweet's text':  oh skrillex big deal i see daili \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#skrillex', '#rave', '#edm'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'skrillex', 'big', 'deal', 'i', 'see', 'daili'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh skrillex big deal i see daili'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3710 :\n",
      "\n",
      "\tTweet's text':  packer fan twitter full meltdown \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['packer', 'fan', 'twitter', 'full', 'meltdown'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['packer fan twitter full meltdown'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3711 :\n",
      "\n",
      "\tTweet's text':  i time week lol i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'time', 'week', 'lol', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i time week lol i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3712 :\n",
      "\n",
      "\tTweet's text':  my dad big kid christma morn wake everyon bloodi earli \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'dad', 'big', 'kid', 'christma', 'morn', 'wake', 'everyon', 'bloodi', 'earli'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my dad big kid christma morn wake everyon bloodi earli'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3713 :\n",
      "\n",
      "\tTweet's text':  tryna learn skate tonight \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['smiling_face_with_sunglasses'] \n",
      "\n",
      "\tTweet's hashtags':  ['#pennyboard', '#skate'] \n",
      "\n",
      "\tTweet tokenized by words:  ['tryna', 'learn', 'skate', 'tonight'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['tryna learn skate tonight'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3714 :\n",
      "\n",
      "\tTweet's text':  wtf wa \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy'] \n",
      "\n",
      "\tTweet's hashtags':  ['#GangstaWankstaYard'] \n",
      "\n",
      "\tTweet tokenized by words:  ['wtf', 'wa'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['wtf wa'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3715 :\n",
      "\n",
      "\tTweet's text':  favourit day year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['favourit', 'day', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['favourit day year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3716 :\n",
      "\n",
      "\tTweet's text':  so happi havent gone bed yet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'happi', 'havent', 'gone', 'bed', 'yet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so happi havent gone bed yet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3717 :\n",
      "\n",
      "\tTweet's text':  i earn land free level badg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'earn', 'land', 'free', 'level', 'badg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i earn land free level badg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3718 :\n",
      "\n",
      "\tTweet's text':  hahahaha love mate have good xx \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['hahahaha', 'love', 'mate', 'have', 'good', 'xx'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hahahaha love mate have good xx'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3719 :\n",
      "\n",
      "\tTweet's text':  thei right protest end fundament right begin they cannot take right earn livelihood free movement \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thei', 'right', 'protest', 'end', 'fundament', 'right', 'begin', 'they', 'can', 'not', 'take', 'right', 'earn', 'livelihood', 'free', 'movement'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thei right protest end fundament right begin they cannot take right earn livelihood free movement'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3720 :\n",
      "\n",
      "\tTweet's text':  hous adjourn with pace dont expect ach din come parl n u cnt blame modi govt fr \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#RajyaSabha'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hous', 'adjourn', 'with', 'pace', 'dont', 'expect', 'ach', 'din', 'come', 'parl', 'n', 'u', 'cnt', 'blame', 'modi', 'govt', 'fr'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hous adjourn with pace dont expect ach din come parl n u cnt blame modi govt fr'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3721 :\n",
      "\n",
      "\tTweet's text':  yeah look like plastic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['yeah', 'look', 'like', 'plastic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['yeah look like plastic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3722 :\n",
      "\n",
      "\tTweet's text':  i pretti sure bad boy worth least stoke per round miranda place \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dreamon'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'pretti', 'sure', 'bad', 'boy', 'worth', 'least', 'stoke', 'per', 'round', 'miranda', 'place'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i pretti sure bad boy worth least stoke per round miranda place'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3723 :\n",
      "\n",
      "\tTweet's text':  i enough danc practic whatsapp group yet \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#december', '#winter', '#weddingseason'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'enough', 'danc', 'practic', 'whatsapp', 'group', 'yet'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i enough danc practic whatsapp group yet'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3724 :\n",
      "\n",
      "\tTweet's text':  need two hour long hug insecur \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['need', 'two', 'hour', 'long', 'hug', 'insecur'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['need two hour long hug insecur'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3725 :\n",
      "\n",
      "\tTweet's text':  thanksalot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#thanksalot', '#freelesson', '#english', '#esl', '#tesl'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thanksalot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thanksalot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3726 :\n",
      "\n",
      "\tTweet's text':  fischer order fish chip \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fischer', 'order', 'fish', 'chip'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fischer order fish chip'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3727 :\n",
      "\n",
      "\tTweet's text':  post tweet mean use twitter \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['post', 'tweet', 'mean', 'use', 'twitter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['post tweet mean use twitter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3728 :\n",
      "\n",
      "\tTweet's text':  i mess today guy i thought work d \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fail', '#itsabovemypaygradetocare', '#stillcare', '#lesigh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'mess', 'today', 'guy', 'i', 'thought', 'work', 'd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i mess today guy i thought work d'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3729 :\n",
      "\n",
      "\tTweet's text':  there million trillion thing i rather rather profound lyric big sean profound \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#worstsongever'] \n",
      "\n",
      "\tTweet tokenized by words:  ['there', 'million', 'trillion', 'thing', 'i', 'rather', 'rather', 'profound', 'lyric', 'big', 'sean', 'profound'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['there million trillion thing i rather rather profound lyric big sean profound'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3730 :\n",
      "\n",
      "\tTweet's text':  congratul well deserv i hope enjoy notif twitter \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['congratul', 'well', 'deserv', 'i', 'hope', 'enjoy', 'notif', 'twitter'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['congratul well deserv i hope enjoy notif twitter'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3731 :\n",
      "\n",
      "\tTweet's text':  soni got hack oh man big \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['soni', 'got', 'hack', 'oh', 'man', 'big'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['soni got hack oh man big'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3732 :\n",
      "\n",
      "\tTweet's text':  gonna miss other least got howi k \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#NotStoked', '#WTF'] \n",
      "\n",
      "\tTweet tokenized by words:  ['gon', 'na', 'miss', 'other', 'least', 'got', 'howi', 'k'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gonna miss other least got howi k'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3733 :\n",
      "\n",
      "\tTweet's text':  gay i bang \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['gay', 'i', 'bang'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['gay i bang'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3734 :\n",
      "\n",
      "\tTweet's text':  new curtain u s like travel torment seek asylum \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Christians', '#Russia', '#LGBT'] \n",
      "\n",
      "\tTweet tokenized by words:  ['new', 'curtain', 'u', 's', 'like', 'travel', 'torment', 'seek', 'asylum'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['new curtain u s like travel torment seek asylum'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3735 :\n",
      "\n",
      "\tTweet's text':  nevermind get work we need hump back game bc gooden play terribl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['nevermind', 'get', 'work', 'we', 'need', 'hump', 'back', 'game', 'bc', 'gooden', 'play', 'terribl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['nevermind get work we need hump back game bc gooden play terribl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3736 :\n",
      "\n",
      "\tTweet's text':  give cr water subsidi public crime wast cr on advertis develop waah ji waah \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['give', 'cr', 'water', 'subsidi', 'public', 'crime', 'wast', 'cr', 'on', 'advertis', 'develop', 'waah', 'ji', 'waah'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['give cr water subsidi public crime wast cr on advertis develop waah ji waah'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3737 :\n",
      "\n",
      "\tTweet's text':  oh someon got troubl make fun peopl behead innoc \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'someon', 'got', 'troubl', 'make', 'fun', 'peopl', 'behead', 'innoc'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh someon got troubl make fun peopl behead innoc'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3738 :\n",
      "\n",
      "\tTweet's text':  i happiest person ever wake morn \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'happiest', 'person', 'ever', 'wake', 'morn'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i happiest person ever wake morn'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3739 :\n",
      "\n",
      "\tTweet's text':  if i carri way half men i get call crank amongst thing ask i \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['nail_polish'] \n",
      "\n",
      "\tTweet's hashtags':  ['#PMT'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'i', 'carri', 'way', 'half', 'men', 'i', 'get', 'call', 'crank', 'amongst', 'thing', 'ask', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if i carri way half men i get call crank amongst thing ask i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3740 :\n",
      "\n",
      "\tTweet's text':  he virtu i dislik none vice i admir winston churchil \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['he', 'virtu', 'i', 'dislik', 'none', 'vice', 'i', 'admir', 'winston', 'churchil'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['he virtu i dislik none vice i admir winston churchil'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3741 :\n",
      "\n",
      "\tTweet's text':   \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#oldfriends', '#are', '#old', '#anymore'] \n",
      "\n",
      "\tTweet tokenized by words:  [] \n",
      "\n",
      "\tTweet tokenized by sentences:  [] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3742 :\n",
      "\n",
      "\tTweet's text':  hit them angl and duck face to hide those wrinkl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ThatsABossBitchRightThere'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hit', 'them', 'angl', 'and', 'duck', 'face', 'to', 'hide', 'those', 'wrinkl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hit them angl and duck face to hide those wrinkl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3743 :\n",
      "\n",
      "\tTweet's text':  what opposit cheat day call becaus that s i one per week what said \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['what', 'opposit', 'cheat', 'day', 'call', 'becaus', 'that', 's', 'i', 'one', 'per', 'week', 'what', 'said'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['what opposit cheat day call becaus that s i one per week what said'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3744 :\n",
      "\n",
      "\tTweet's text':  bang great insight rt interest read democraci ab manag ideolog \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#ableg'] \n",
      "\n",
      "\tTweet tokenized by words:  ['bang', 'great', 'insight', 'rt', 'interest', 'read', 'democraci', 'ab', 'manag', 'ideolog'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['bang great insight rt interest read democraci ab manag ideolog'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3745 :\n",
      "\n",
      "\tTweet's text':  v i e born soon signup gain access beta \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['v', 'i', 'e', 'born', 'soon', 'signup', 'gain', 'access', 'beta'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['v i e born soon signup gain access beta'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3746 :\n",
      "\n",
      "\tTweet's text':  don know get number \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#accounting', '#absolutetosh'] \n",
      "\n",
      "\tTweet tokenized by words:  ['don', 'know', 'get', 'number'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['don know get number'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3747 :\n",
      "\n",
      "\tTweet's text':  facebook owner mark zuckerberg say dislik creat dislik button \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['facebook', 'owner', 'mark', 'zuckerberg', 'say', 'dislik', 'creat', 'dislik', 'button'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['facebook owner mark zuckerberg say dislik creat dislik button'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3748 :\n",
      "\n",
      "\tTweet's text':  short hair \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#really'] \n",
      "\n",
      "\tTweet tokenized by words:  ['short', 'hair'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['short hair'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3749 :\n",
      "\n",
      "\tTweet's text':  student busi protest grand juri decis studi deserv fail action consequ \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['student', 'busi', 'protest', 'grand', 'juri', 'decis', 'studi', 'deserv', 'fail', 'action', 'consequ'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['student busi protest grand juri decis studi deserv fail action consequ'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3750 :\n",
      "\n",
      "\tTweet's text':  whi hero happi dc comic i mean even great flagship romanc fauxmanc bring destruct \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'hero', 'happi', 'dc', 'comic', 'i', 'mean', 'even', 'great', 'flagship', 'romanc', 'fauxmanc', 'bring', 'destruct'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi hero happi dc comic i mean even great flagship romanc fauxmanc bring destruct'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3751 :\n",
      "\n",
      "\tTweet's text':  we last train \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wemarchon', '#saintsfc'] \n",
      "\n",
      "\tTweet tokenized by words:  ['we', 'last', 'train'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['we last train'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3752 :\n",
      "\n",
      "\tTweet's text':  sane peopl would talk twitter find sane human talk \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#retweet', '#ifagree'] \n",
      "\n",
      "\tTweet tokenized by words:  ['sane', 'peopl', 'would', 'talk', 'twitter', 'find', 'sane', 'human', 'talk'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sane peopl would talk twitter find sane human talk'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3753 :\n",
      "\n",
      "\tTweet's text':  haha never nice guess i cool enough \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['pensive_face'] \n",
      "\n",
      "\tTweet's hashtags':  ['#sadface'] \n",
      "\n",
      "\tTweet tokenized by words:  ['haha', 'never', 'nice', 'guess', 'i', 'cool', 'enough'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['haha never nice guess i cool enough'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3754 :\n",
      "\n",
      "\tTweet's text':  head huntsvil tx afternoon tri contain jealousi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['head', 'huntsvil', 'tx', 'afternoon', 'tri', 'contain', 'jealousi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['head huntsvil tx afternoon tri contain jealousi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3755 :\n",
      "\n",
      "\tTweet's text':  read dunde unit chairmanship statement tonight say lot \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['read', 'dunde', 'unit', 'chairmanship', 'statement', 'tonight', 'say', 'lot'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['read dunde unit chairmanship statement tonight say lot'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3756 :\n",
      "\n",
      "\tTweet's text':  thank leav dish us \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#badbusiness'] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'leav', 'dish', 'us'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank leav dish us'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3757 :\n",
      "\n",
      "\tTweet's text':  noth say welcom home better \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#wemissedyoutoo'] \n",
      "\n",
      "\tTweet tokenized by words:  ['noth', 'say', 'welcom', 'home', 'better'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noth say welcom home better'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3758 :\n",
      "\n",
      "\tTweet's text':  so far today ruin mug i cri twice i gotten thing to do list done i furiou \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GoodStartToTheDay'] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'far', 'today', 'ruin', 'mug', 'i', 'cri', 'twice', 'i', 'gotten', 'thing', 'to', 'do', 'list', 'done', 'i', 'furiou'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so far today ruin mug i cri twice i gotten thing to do list done i furiou'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3759 :\n",
      "\n",
      "\tTweet's text':  i love abl sleep right \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'abl', 'sleep', 'right'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love abl sleep right'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3760 :\n",
      "\n",
      "\tTweet's text':  velvet and rhineston babydol size medium larg come softli pad wire shelf cup \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['velvet', 'and', 'rhineston', 'babydol', 'size', 'medium', 'larg', 'come', 'softli', 'pad', 'wire', 'shelf', 'cup'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['velvet and rhineston babydol size medium larg come softli pad wire shelf cup'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3761 :\n",
      "\n",
      "\tTweet's text':  well i say \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['bust_in_silhouette'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'i', 'say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well i say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3762 :\n",
      "\n",
      "\tTweet's text':  it wonder time fiscal year \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'wonder', 'time', 'fiscal', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it wonder time fiscal year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3763 :\n",
      "\n",
      "\tTweet's text':  pleas book one appoint tell happen \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['pleas', 'book', 'one', 'appoint', 'tell', 'happen'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['pleas book one appoint tell happen'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3764 :\n",
      "\n",
      "\tTweet's text':  i love morn start like \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'morn', 'start', 'like'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love morn start like'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3765 :\n",
      "\n",
      "\tTweet's text':  and today what surpris \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['pile_of_poo'] \n",
      "\n",
      "\tTweet's hashtags':  ['#2of6', '#6daystretch'] \n",
      "\n",
      "\tTweet tokenized by words:  ['and', 'today', 'what', 'surpris'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['and today what surpris'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3766 :\n",
      "\n",
      "\tTweet's text':  dual seek protect heard propos secur bill trampl basic right pple freedom \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['dual', 'seek', 'protect', 'heard', 'propos', 'secur', 'bill', 'trampl', 'basic', 'right', 'pple', 'freedom'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['dual seek protect heard propos secur bill trampl basic right pple freedom'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3767 :\n",
      "\n",
      "\tTweet's text':  call \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['call'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['call'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3768 :\n",
      "\n",
      "\tTweet's text':  whi mostella get much play time h understand \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['whi', 'mostella', 'get', 'much', 'play', 'time', 'h', 'understand'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whi mostella get much play time h understand'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3769 :\n",
      "\n",
      "\tTweet's text':  realli my respect feminist women movement roof \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['realli', 'my', 'respect', 'feminist', 'women', 'movement', 'roof'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['realli my respect feminist women movement roof'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3770 :\n",
      "\n",
      "\tTweet's text':  fun \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['fun'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fun'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3771 :\n",
      "\n",
      "\tTweet's text':  time free tyranni usa lean toward toler societi like russia china \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['time', 'free', 'tyranni', 'usa', 'lean', 'toward', 'toler', 'societi', 'like', 'russia', 'china'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['time free tyranni usa lean toward toler societi like russia china'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3772 :\n",
      "\n",
      "\tTweet's text':  i understand anyon watch bowl game they matter great team outsid top domin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dontcare'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'understand', 'anyon', 'watch', 'bowl', 'game', 'they', 'matter', 'great', 'team', 'outsid', 'top', 'domin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i understand anyon watch bowl game they matter great team outsid top domin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3773 :\n",
      "\n",
      "\tTweet's text':  i think caramel frapp salti enough \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#McYuck', '#lostsale'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'think', 'caramel', 'frapp', 'salti', 'enough'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i think caramel frapp salti enough'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3774 :\n",
      "\n",
      "\tTweet's text':  oh ga haul semi flammabl sign driver smoke \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#truestory', '#I10', '#Texas2015'] \n",
      "\n",
      "\tTweet tokenized by words:  ['oh', 'ga', 'haul', 'semi', 'flammabl', 'sign', 'driver', 'smoke'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['oh ga haul semi flammabl sign driver smoke'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3775 :\n",
      "\n",
      "\tTweet's text':  ur boyfriend interrupt selfi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ur', 'boyfriend', 'interrupt', 'selfi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ur boyfriend interrupt selfi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3776 :\n",
      "\n",
      "\tTweet's text':  is snow canada just hill minut hope white christma \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['is', 'snow', 'canada', 'just', 'hill', 'minut', 'hope', 'white', 'christma'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['is snow canada just hill minut hope white christma'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3777 :\n",
      "\n",
      "\tTweet's text':  take call phone thing work \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['take', 'call', 'phone', 'thing', 'work'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['take call phone thing work'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3778 :\n",
      "\n",
      "\tTweet's text':  weapon ninja train assasin creed \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#GamerGate'] \n",
      "\n",
      "\tTweet tokenized by words:  ['weapon', 'ninja', 'train', 'assasin', 'creed'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['weapon ninja train assasin creed'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3779 :\n",
      "\n",
      "\tTweet's text':  it brrrrrrr kinda feel would go kitchen make coffe \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['it', 'brrrrrrr', 'kinda', 'feel', 'would', 'go', 'kitchen', 'make', 'coffe'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['it brrrrrrr kinda feel would go kitchen make coffe'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3780 :\n",
      "\n",
      "\tTweet's text':  more proof never lose bet intellig elector how anyon believ word say \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['more', 'proof', 'never', 'lose', 'bet', 'intellig', 'elector', 'how', 'anyon', 'believ', 'word', 'say'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['more proof never lose bet intellig elector how anyon believ word say'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3781 :\n",
      "\n",
      "\tTweet's text':  need get back colleg \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#feeling', '#this'] \n",
      "\n",
      "\tTweet tokenized by words:  ['need', 'get', 'back', 'colleg'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['need get back colleg'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3782 :\n",
      "\n",
      "\tTweet's text':  still q still one best d \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['D'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['still', 'q', 'still', 'one', 'best', 'd'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['still q still one best d'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3783 :\n",
      "\n",
      "\tTweet's text':  uncov hidden arsen wmd iraq result tortur enhanc interrog \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['uncov', 'hidden', 'arsen', 'wmd', 'iraq', 'result', 'tortur', 'enhanc', 'interrog'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['uncov hidden arsen wmd iraq result tortur enhanc interrog'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3784 :\n",
      "\n",
      "\tTweet's text':  home page show dow can make home page stat real time pl \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['home', 'page', 'show', 'dow', 'can', 'make', 'home', 'page', 'stat', 'real', 'time', 'pl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['home page show dow can make home page stat real time pl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3785 :\n",
      "\n",
      "\tTweet's text':  mark read becassin pendant la grand guerr caumeri \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['mark', 'read', 'becassin', 'pendant', 'la', 'grand', 'guerr', 'caumeri'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['mark read becassin pendant la grand guerr caumeri'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3786 :\n",
      "\n",
      "\tTweet's text':  the wind friend \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'wind', 'friend'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the wind friend'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3787 :\n",
      "\n",
      "\tTweet's text':  year i becam lord \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['crown'] \n",
      "\n",
      "\tTweet's hashtags':  ['#watchthelordman'] \n",
      "\n",
      "\tTweet tokenized by words:  ['year', 'i', 'becam', 'lord'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['year i becam lord'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3788 :\n",
      "\n",
      "\tTweet's text':  noth better get snapchat weight play background \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#the', '#sameparents', '#sametunes'] \n",
      "\n",
      "\tTweet tokenized by words:  ['noth', 'better', 'get', 'snapchat', 'weight', 'play', 'background'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['noth better get snapchat weight play background'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3789 :\n",
      "\n",
      "\tTweet's text':  those not presum \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#BritishRoyalty', '#Titles', '#PublicDuties'] \n",
      "\n",
      "\tTweet tokenized by words:  ['those', 'not', 'presum'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['those not presum'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3790 :\n",
      "\n",
      "\tTweet's text':  sunris far back i search googl calendar via sunris googl work search engin calendar \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['sunris', 'far', 'back', 'i', 'search', 'googl', 'calendar', 'via', 'sunris', 'googl', 'work', 'search', 'engin', 'calendar'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['sunris far back i search googl calendar via sunris googl work search engin calendar'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3791 :\n",
      "\n",
      "\tTweet's text':  i honestli never even watch a christma stori i seen random part \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'honestli', 'never', 'even', 'watch', 'a', 'christma', 'stori', 'i', 'seen', 'random', 'part'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i honestli never even watch a christma stori i seen random part'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3792 :\n",
      "\n",
      "\tTweet's text':  china call us hypocrit chines peac prize goe castro putin via \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#humanrights'] \n",
      "\n",
      "\tTweet tokenized by words:  ['china', 'call', 'us', 'hypocrit', 'chines', 'peac', 'prize', 'goe', 'castro', 'putin', 'via'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['china call us hypocrit chines peac prize goe castro putin via'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3793 :\n",
      "\n",
      "\tTweet's text':  empti threat even support \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#TheBear', '#united'] \n",
      "\n",
      "\tTweet tokenized by words:  ['empti', 'threat', 'even', 'support'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['empti threat even support'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3794 :\n",
      "\n",
      "\tTweet's text':  so monday ticket gener sale box \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['so', 'monday', 'ticket', 'gener', 'sale', 'box'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['so monday ticket gener sale box'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3795 :\n",
      "\n",
      "\tTweet's text':  my favorit color everi color \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['my', 'favorit', 'color', 'everi', 'color'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['my favorit color everi color'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3796 :\n",
      "\n",
      "\tTweet's text':  one could hope \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['one', 'could', 'hope'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['one could hope'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3797 :\n",
      "\n",
      "\tTweet's text':  i love i stress bodi decid react caus massiv pain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'love', 'i', 'stress', 'bodi', 'decid', 'react', 'caus', 'massiv', 'pain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i love i stress bodi decid react caus massiv pain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3798 :\n",
      "\n",
      "\tTweet's text':  girl british accent on point \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['ok_hand_sign'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['girl', 'british', 'accent', 'on', 'point'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['girl british accent on point'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3799 :\n",
      "\n",
      "\tTweet's text':  think almost die burn face \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#hategasbbqs'] \n",
      "\n",
      "\tTweet tokenized by words:  ['think', 'almost', 'die', 'burn', 'face'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['think almost die burn face'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3800 :\n",
      "\n",
      "\tTweet's text':  eua statement european commiss eu invest plan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#notcias', '#eu', '#europ'] \n",
      "\n",
      "\tTweet tokenized by words:  ['eua', 'statement', 'european', 'commiss', 'eu', 'invest', 'plan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['eua statement european commiss eu invest plan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3801 :\n",
      "\n",
      "\tTweet's text':  earicpatten present dj earic patten elektrik metro hous vibe mix session club \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nowplaying'] \n",
      "\n",
      "\tTweet tokenized by words:  ['earicpatten', 'present', 'dj', 'earic', 'patten', 'elektrik', 'metro', 'hous', 'vibe', 'mix', 'session', 'club'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['earicpatten present dj earic patten elektrik metro hous vibe mix session club'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3802 :\n",
      "\n",
      "\tTweet's text':  unless rogu theatr start show get sold onlin \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['unless', 'rogu', 'theatr', 'start', 'show', 'get', 'sold', 'onlin'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['unless rogu theatr start show get sold onlin'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3803 :\n",
      "\n",
      "\tTweet's text':  whoever hunger game whistl quiet floor i applaud origin cultur relev \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#oldjoke'] \n",
      "\n",
      "\tTweet tokenized by words:  ['whoever', 'hunger', 'game', 'whistl', 'quiet', 'floor', 'i', 'applaud', 'origin', 'cultur', 'relev'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['whoever hunger game whistl quiet floor i applaud origin cultur relev'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3804 :\n",
      "\n",
      "\tTweet's text':  feel like crap and treat horribl it great day \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#iwanttogohome'] \n",
      "\n",
      "\tTweet tokenized by words:  ['feel', 'like', 'crap', 'and', 'treat', 'horribl', 'it', 'great', 'day'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['feel like crap and treat horribl it great day'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3805 :\n",
      "\n",
      "\tTweet's text':  in progress list mn year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['in', 'progress', 'list', 'mn', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['in progress list mn year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3806 :\n",
      "\n",
      "\tTweet's text':  i get paid post stuff like tsu you can too go follow \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#FOLLOW', '#FOLLOWBACK'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'get', 'paid', 'post', 'stuff', 'like', 'tsu', 'you', 'can', 'too', 'go', 'follow'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i get paid post stuff like tsu you can too go follow'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3807 :\n",
      "\n",
      "\tTweet's text':  i want learn group develop and turn green bass thornton asset \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'want', 'learn', 'group', 'develop', 'and', 'turn', 'green', 'bass', 'thornton', 'asset'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i want learn group develop and turn green bass thornton asset'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3808 :\n",
      "\n",
      "\tTweet's text':  onli one cinema \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#putting', '#my', '#phone', '#on', '#silent'] \n",
      "\n",
      "\tTweet tokenized by words:  ['onli', 'one', 'cinema'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['onli one cinema'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3809 :\n",
      "\n",
      "\tTweet's text':  year ago m s rochdal left shoe sale reduct full price \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#bargain'] \n",
      "\n",
      "\tTweet tokenized by words:  ['year', 'ago', 'm', 's', 'rochdal', 'left', 'shoe', 'sale', 'reduct', 'full', 'price'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['year ago m s rochdal left shoe sale reduct full price'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3810 :\n",
      "\n",
      "\tTweet's text':  montana of the best versac remix in the \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['montana', 'of', 'the', 'best', 'versac', 'remix', 'in', 'the'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['montana of the best versac remix in the'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3811 :\n",
      "\n",
      "\tTweet's text':  i made canva coffe stain done \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#art'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'made', 'canva', 'coffe', 'stain', 'done'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i made canva coffe stain done'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3812 :\n",
      "\n",
      "\tTweet's text':  the world smiley place \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  ['flushed_face'] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['the', 'world', 'smiley', 'place'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['the world smiley place'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3813 :\n",
      "\n",
      "\tTweet's text':  two broke redneck father daughter rif team make fun old educ film n \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['two', 'broke', 'redneck', 'father', 'daughter', 'rif', 'team', 'make', 'fun', 'old', 'educ', 'film', 'n'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['two broke redneck father daughter rif team make fun old educ film n'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3814 :\n",
      "\n",
      "\tTweet's text':  happen kid are kid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#WTF', '#insulting', '#KnowYourHistory', '#WhoIsPaulMcCartney'] \n",
      "\n",
      "\tTweet tokenized by words:  ['happen', 'kid', 'are', 'kid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['happen kid are kid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3815 :\n",
      "\n",
      "\tTweet's text':  i would made much convinc bella swan \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'would', 'made', 'much', 'convinc', 'bella', 'swan'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i would made much convinc bella swan'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3816 :\n",
      "\n",
      "\tTweet's text':  i retweet chri graham block \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'retweet', 'chri', 'graham', 'block'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i retweet chri graham block'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3817 :\n",
      "\n",
      "\tTweet's text':  fri with that \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#AlabamaStateMajors'] \n",
      "\n",
      "\tTweet tokenized by words:  ['fri', 'with', 'that'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['fri with that'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3818 :\n",
      "\n",
      "\tTweet's text':  if need for i \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#dev', '#environmnet', '#then', '#a', '#great', '#pick', '#regular', '#web', '#stuff', '#do', '#like', '#it'] \n",
      "\n",
      "\tTweet tokenized by words:  ['if', 'need', 'for', 'i'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['if need for i'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3819 :\n",
      "\n",
      "\tTweet's text':  i glad dc council prioriti \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#DC'] \n",
      "\n",
      "\tTweet tokenized by words:  ['i', 'glad', 'dc', 'council', 'prioriti'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['i glad dc council prioriti'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3820 :\n",
      "\n",
      "\tTweet's text':  ride distract train choo choo \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['ride', 'distract', 'train', 'choo', 'choo'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ride distract train choo choo'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3821 :\n",
      "\n",
      "\tTweet's text':  chill \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  ['face_with_tears_of_joy', 'skull'] \n",
      "\n",
      "\tTweet's hashtags':  ['#Repost', '#Dead', '#Dominos', '#Haha'] \n",
      "\n",
      "\tTweet tokenized by words:  ['chill'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['chill'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3822 :\n",
      "\n",
      "\tTweet's text':  someon i work w let kid believ santa mythic odd w church dogma i realli want explain \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['someon', 'i', 'work', 'w', 'let', 'kid', 'believ', 'santa', 'mythic', 'odd', 'w', 'church', 'dogma', 'i', 'realli', 'want', 'explain'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['someon i work w let kid believ santa mythic odd w church dogma i realli want explain'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3823 :\n",
      "\n",
      "\tTweet's text':  check new post myfairdaili thing i been love late \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#lbloggers', '#holidays', '#myfairdaily', '#favorites'] \n",
      "\n",
      "\tTweet tokenized by words:  ['check', 'new', 'post', 'myfairdaili', 'thing', 'i', 'been', 'love', 'late'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['check new post myfairdaili thing i been love late'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3824 :\n",
      "\n",
      "\tTweet's text':  obama whisk away hospit diagnos acid reflux real news \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['obama', 'whisk', 'away', 'hospit', 'diagnos', 'acid', 'reflux', 'real', 'news'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['obama whisk away hospit diagnos acid reflux real news'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3825 :\n",
      "\n",
      "\tTweet's text':  true n r jade everi year \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['true', 'n', 'r', 'jade', 'everi', 'year'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['true n r jade everi year'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3826 :\n",
      "\n",
      "\tTweet's text':  anoth one support vehicl modifi iceland servic \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Bigfoot', '#LANDROVER'] \n",
      "\n",
      "\tTweet tokenized by words:  ['anoth', 'one', 'support', 'vehicl', 'modifi', 'iceland', 'servic'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['anoth one support vehicl modifi iceland servic'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3827 :\n",
      "\n",
      "\tTweet's text':  thank shut citi \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['thank', 'shut', 'citi'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['thank shut citi'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3828 :\n",
      "\n",
      "\tTweet's text':  ikr see gonna cri utter joy crybabi such beauti coupl \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTweet tokenized by words:  ['ikr', 'see', 'gon', 'na', 'cri', 'utter', 'joy', 'crybabi', 'such', 'beauti', 'coupl'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['ikr see gonna cri utter joy crybabi such beauti coupl'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3829 :\n",
      "\n",
      "\tTweet's text':  glad typhoon go holiday week \n",
      "\n",
      "\tTweet's score':  1 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#fml'] \n",
      "\n",
      "\tTweet tokenized by words:  ['glad', 'typhoon', 'go', 'holiday', 'week'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['glad typhoon go holiday week'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3830 :\n",
      "\n",
      "\tTweet's text':  regard psu presid \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['regard', 'psu', 'presid'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['regard psu presid'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3831 :\n",
      "\n",
      "\tTweet's text':  but still bother i see follow report \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  [] \n",
      "\n",
      "\tTweet tokenized by words:  ['but', 'still', 'bother', 'i', 'see', 'follow', 'report'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['but still bother i see follow report'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3832 :\n",
      "\n",
      "\tTweet's text':  well listen wood go listen fob \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#nosurprisethere'] \n",
      "\n",
      "\tTweet tokenized by words:  ['well', 'listen', 'wood', 'go', 'listen', 'fob'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['well listen wood go listen fob'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3833 :\n",
      "\n",
      "\tTweet's text':  hummingbird if hover abil \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#Are', '#Experts', '#at', '#Hovering', '#After', '#All', '#Background', '#Motion'] \n",
      "\n",
      "\tTweet tokenized by words:  ['hummingbird', 'if', 'hover', 'abil'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['hummingbird if hover abil'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet  3834 :\n",
      "\n",
      "\tTweet's text':  onli thing miss session \n",
      "\n",
      "\tTweet's score':  0 \n",
      "\n",
      "\tTweet's emojis':  [] \n",
      "\n",
      "\tTweet's hashtags':  ['#possible'] \n",
      "\n",
      "\tTweet tokenized by words:  ['onli', 'thing', 'miss', 'session'] \n",
      "\n",
      "\tTweet tokenized by sentences:  ['onli thing miss session'] \n",
      "\n",
      "---------------\n",
      "\n",
      "Tweet: i m so funny\n",
      "From 0 to 1, 0 being 'non-ironic' and 1 'ironic', you tweet scored  ['1']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import tweet_cleaning as tc\n",
    "import decisionTree as dt\n",
    "\n",
    "def listToString(s): \n",
    "    str1 = \"\" \n",
    "    for ele in s: \n",
    "        str1 += (\" \" + ele)\n",
    "    return str1 \n",
    "\n",
    "def readdata(filename):\n",
    "    tweets = []\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            tweets.append([line.split(\"\t\")[0], line.split(\"\t\")[1], line.split(\"\t\")[2]])\n",
    "    return tweets\n",
    "\n",
    "def getInfoFromTweets(data):\n",
    "    ids = []\n",
    "    scores = []\n",
    "    tweets = []\n",
    "    for line in data:\n",
    "        ids.append(line[0])\n",
    "        scores.append(line[1])\n",
    "        tweets.append(line[2])\n",
    "    return ids, scores, tweets\n",
    "\n",
    "def stripEmojisFromTweets(tweets):\n",
    "    emojis = []\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        emojis.append(getEmojisFromTweet(tweet))\n",
    "        new_tweets.append(re.sub(\"(:)\\w*(:)\", \"\", tweet))\n",
    "    return emojis, new_tweets\n",
    "\n",
    "def getEmojisFromTweet(tweet):\n",
    "    emoji = []\n",
    "    for i in tweet.split():\n",
    "        if i.startswith(\":\"):\n",
    "            emoji.extend(list(filter(None, i.split(\":\"))))\n",
    "    emoji = list(set(emoji))\n",
    "    emoji = [i for i in emoji if i[0].isalpha()]\n",
    "    return emoji\n",
    "\n",
    "def stripHashtagsFromTweets(tweets):\n",
    "    hashtags = []\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        hashtagsOfTweet = re.findall(\"#\\w+\", tweet)\n",
    "        hashtags.append(hashtagsOfTweet)\n",
    "        new_tweets.append(\" \".join(filter(lambda x: x[0] != '#', tweet.split())))\n",
    "    return hashtags, new_tweets\n",
    "\n",
    "def cleanTweets(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        new_tweets.append(tc.clean_tweet(tweet))\n",
    "    return new_tweets\n",
    "    \n",
    "data = readdata(\"../Train Data/train_taskA.txt\")\n",
    "\n",
    "ids, scores, tweets = getInfoFromTweets(data)\n",
    "\n",
    "emojis, tweets = stripEmojisFromTweets(tweets)\n",
    "\n",
    "hashtags, tweets  = stripHashtagsFromTweets(tweets)\n",
    "\n",
    "tweets = cleanTweets(tweets)\n",
    "\n",
    "finalData = []\n",
    "\n",
    "print(\"------- TASK A -------\\n\")\n",
    "print(\"Number of tweets: \", len(data))\n",
    "print(\"\\n\")\n",
    "count = 0\n",
    "for tweet in tweets:\n",
    "    finalData.append(tweets[count] + listToString(emojis[count]) + listToString(hashtags[count]))\n",
    "    \n",
    "    print(\"Tweet \", ids[count], \":\\n\")\n",
    "    print(\"\\tTweet's text': \", tweets[count], \"\\n\")\n",
    "    print(\"\\tTweet's score': \", scores[count], \"\\n\")\n",
    "    print(\"\\tTweet's emojis': \", emojis[count], \"\\n\")\n",
    "    print(\"\\tTweet's hashtags': \", hashtags[count], \"\\n\")\n",
    "    print(\"\\tTweet tokenized by words: \", word_tokenize(tweets[count]), \"\\n\")\n",
    "    print(\"\\tTweet tokenized by sentences: \", sent_tokenize(tweets[count]), \"\\n\")\n",
    "    print(\"---------------\\n\")\n",
    "    \n",
    "    #print(input[count], \"\\n\")\n",
    "    count += 1\n",
    "\n",
    "dt.decisionTreeAsking(finalData, scores,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
